{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the dataset, suggesting that it may contain noise due to its artificial creation. The reviewer notes that the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. While the comment identifies a concern, it does not provide explicit guidance on how the authors should address this issue. The suggestion to analyze the quality of the dataset and the amount of noise it contains is implicit, and the authors would need to infer that they should conduct additional analysis to address this concern. However, the comment lacks concrete details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the quality of the dataset, specifically mentioning that it is artificially created and may contain noise. It provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. However, it does not explicitly mention which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the dataset\"s quality and potential noise. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. This example supports the claim by providing a logical reasoning for the potential issues with the dataset. However, the comment could be strengthened by referencing specific studies or literature that discuss the challenges of working with artificially created datasets or the impact of noise on analysis results. Overall, the claim is 4, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. This feedback is valuable as it highlights a critical aspect of the dataset that could impact the validity of the analysis. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as proposing methods to evaluate the dataset\"s quality or suggesting ways to mitigate the impact of noise. Despite this, the comment provides a clear direction for the authors to consider, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what aspects of the theory should be explored or how to demonstrate convergence properties. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not specify which part of the paper this issue pertains to, such as a particular section or chapter where the theoretical aspects are discussed. Without explicit references or clear indications of where the authors should focus their efforts, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the theory should be explored or how to demonstrate convergence properties. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks an indepth exploration of the theoretical properties of the proposed algorithm, particularly regarding convergence. This is a critical area for improvement, as understanding the theoretical foundations of an algorithm is essential for its validation and potential adoption. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending particular theoretical frameworks or methods to explore. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. While the comment does not explicitly instruct the authors to include these operators or explain their reasoning, it implies that the authors should provide a justification for their choice. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why certain operators were chosen over others. However, the comment provides a clear direction for the authors to consider alternative operators and their implications, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or elementwise max, providing a clear direction for improvement. The comment explains the reasoning behind the suggestion by relating it to the concepts of union and intersection, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. The reviewer provides a logical reasoning by relating the \"and\" operator to the concept of union and intersection, suggesting that these operators might be more appropriate. However, the comment lacks specific examples or references to support the claim that these operators are better options. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3, as the authors may need to delve deeper to fully understand the rationale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the choice of operators used in the paper, specifically questioning why the \"and\" operator or elementwise max were not considered. It provides a logical connection by relating these operators to the concepts of union and intersection, which could be relevant to the paper\"s context. This feedback is 3 as it prompts the authors to consider alternative operators and their implications, potentially leading to a more comprehensive analysis or discussion in the paper. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how the \"and\" operator or elementwise max could be applied. Overall, the comment provides a useful direction for the authors to explore, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it implies that the authors should provide a justification or explanation for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the rationale behind this selection, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its inquiry about the rationale behind the selection, but it lacks grounding due to the lack of reference to a specific section or context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the selection of 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain a claim or opinion that requires verification. It is a factual inquiry, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and its potential impact on the underestimation of performances. This inquiry prompts the authors to provide a justification or explanation for this selection, which could be an important aspect of their methodology. By asking for clarification, the comment encourages the authors to reflect on their approach and potentially improve the transparency and robustness of their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide a supporting explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the purpose and scope of the average duration, but they are not given specific guidance on how to address this issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and asks for an explanation regarding whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the purpose of the average duration reported in Table 1, seeking clarification on whether it includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it prompts the authors to provide a supporting explanation for the reported data. By addressing this question, the authors can enhance the transparency and comprehensiveness of their results. However, the comment could be more helpful if it suggested potential ways to clarify the explanation or provided additional context. Overall, the comment is 4 as it directs the authors to improve the clarity of their presentation, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" The reviewer suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance. However, the comment does not provide explicit guidance on how to correct this issue or suggest alternative wording. While the action is implicit, it is 3 as it points out a potential problem that the authors should address, even if the exact steps to take are not fully outlined. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"l.791\") where the issue is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias in the wording used to describe performance, suggesting that \"on par or better\" might be misleading. The comment provides a clear suggestion for improvement by recommending a correction in the wording. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to label instances where they perform worse as \"on par\" and instances where they perform better as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and evidence presented to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" It suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance, where instances of worse performance are labeled as \"on par\" and better performance is labeled as \"better.\" This feedback is 3 as it points out a potential problem with the language used in the paper, but it does not provide specific guidance on how to correct this issue or suggest alternative wording. While it highlights an area for improvement, the comment could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point consists of two questions regarding the interpretation of results presented in Table 3. It asks for clarification on how to interpret specific comparisons between different models and their performance metrics. While the questions are explicit, they do not provide any guidance or suggestions on how the authors should address these questions or improve their draft. The lack of actionable advice or concrete steps makes it difficult for the authors to know exactly what to do with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the interpretation of results, specifically asking for clarification on the comparisons between NVSB and GT Mel A for Chinese MOSQ, and between Baseline and NVSB for Chinese and English MOSV. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions seeking clarification on the interpretation of results presented in Table 3. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and descriptive, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment consists of two questions seeking clarification on the interpretation of results presented in Table 3. It asks for an explanation of how to interpret specific comparisons between different models and their performance metrics. While the questions are clear and specific, they do not provide any suggestions or guidance on how the authors might address these questions or improve their draft. The lack of actionable feedback or constructive suggestions limits the comment\"s usefulness to the authors. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This inconsistency affects the appearance of the tables. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting a consistent formatting approach or offering examples of how to standardize the layout. The action is implicit and somewhat vague, as the authors can infer that they need to standardize the formatting but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects their appearance. This provides clear guidance on what needs to be addressed to improve the presentation of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the appearance of the tables. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it impacts the tables\" appearance. Without further explanation or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is clear and actionable, as it provides the authors with a direct suggestion to standardize the formatting to improve the appearance of the tables. However, the comment could be more helpful if it offered guidance on how to achieve this consistency or suggested alternative formatting options. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the paper only applies similar ideas to videotext models. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the work or suggestions for potential improvements. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the lack of novelty in the paper, specifically mentioning that adversarial attacks by perturbing text have been done on many NLP models and imagetext models. It notes that the paper only applies similar ideas to videotext models. However, the comment does not specify which part of the paper discusses these related works or where the lack of novelty is most apparent. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of novelty but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, as adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and the paper only applies similar ideas to videotext models. The comment provides a logical reasoning by referencing the related work section of the paper, which suggests that the novelty is not in the concept but in its application. However, the comment could be strengthened by providing specific examples or references to existing works on NLP and imagetext models, which would enhance the verifiability of the claim. As it stands, the comment is 3, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, noting that adversarial attacks by perturbing text have been extensively explored in NLP and imagetext models. It points out that the paper\"s contribution is merely an application of similar ideas to videotext models, which is not novel. While the comment highlights a significant weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests a clear and actionable solution by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback provides explicit guidance on how to improve the organization and clarity of the section, making it 5. The authors know exactly what changes to make to enhance the coherence and readability of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations being intertwined and suggests a solution by recommending separate paragraphs for each type of feature. This provides clear guidance on how to improve the organization and clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are \"somewhat intertwined and thus confusing.\" However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to organize the section with separate paragraphs for each type of feature is a logical recommendation, but it lacks evidence or examples to substantiate the need for this change. As a result, the comment is 3, as it provides a suggestion but lacks detailed justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It provides a clear and actionable suggestion by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and coherence of their draft. However, the comment could be more helpful if it included additional guidance on how to effectively separate these features or provided examples of how this reorganization could enhance the reader\"s understanding. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the amount of space dedicated to a particular section and its experimental results, suggesting that it is not useful. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for reducing the space allocated to this section. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that dedicating a whole section plus experimental results is a lot of space, suggesting that this section may not be necessary or could be condensed. However, it does not specify which section is being referred to, making it weakly grounded. The comment is specific in its critique of the space allocation but lacks detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion that the information presented in a section is not useful and that dedicating a whole section plus experimental results is excessive. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the amount of space dedicated to a particular section and its experimental results, suggesting that it may not be necessary or could be condensed. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or what aspects of the section could be reduced or improved. Without actionable feedback or detailed recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper should include more baselines based on related work. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to include these baselines or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional baselines but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison between the proposed models and those that only consider different senses but not sememes. The comment suggests that the emphasis on soft vs. hard word sense disambiguation is not sufficient and recommends including more baselines based on related work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or detailed reasoning to support the claim that the current comparison is unclear or insufficient. While it provides a logical suggestion for improvement, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and points out that the emphasis is placed on soft vs. hard word sense disambiguation rather than this comparison. The comment provides a clear and actionable suggestion to include more baselines based on related work, which would strengthen the paper. However, it could be more helpful if it offered specific examples of additional baselines or detailed guidance on how to incorporate them. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect in their draft. The comment implies that the authors should address this issue, but it lacks concrete details on how to do so, such as suggesting specific methods for explaining the selection process or providing examples. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of unclear selection processes, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide any guidance or suggestions on how the authors might clarify this aspect in their draft. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their work. Therefore, it is rated as 2, as it highlights an issue but lacks depth or actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs the authors to discuss the results for the task of inferring knowledge on objects, which is a clear and concrete action. Second, it suggests including results for model (B) and recommends using consistent terminology across tables. Additionally, the comment points out a specific issue with the mention of \"latent in verbs\" and questions why objects are not mentioned. These suggestions are explicit and provide concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (681 and 778) and references tables (1 and 2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing results for inferring knowledge on objects and including results for model (B), as well as using consistent terminology. Additionally, it questions the omission of objects in the discussion of \"latent in verbs.\" This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions and observations, but it does not contain any subjective claims, opinions, or judgments that require verification. It is a series of factual statements and requests for clarification or improvement, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it reminds the authors to discuss the results for the task of inferring knowledge on objects, which is a clear and important aspect of the paper. Second, it suggests including results for model (B) and recommends using consistent terminology across tables, which would enhance the clarity and coherence of the paper. Additionally, the comment questions the omission of objects in the discussion of \"latent in verbs,\" prompting the authors to consider this aspect. The feedback is detailed and provides concrete suggestions for enhancing the draft, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific sentence in line 212 that is not strictly correct and suggests a correction. It provides a clear and explicit action for the authors to take, which is to change the sentence to accurately reflect the use of a bidirectional encoder. The comment also offers a specific example from Figure 2 to guide the correction. This level of detail and explicit guidance makes the comment 5, as the authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, suggesting a correction to accurately describe the use of a bidirectional encoder. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific suggestion for improvement by recommending the use of a bidirectional encoder that encodes the source sentence into a set of vectors, as seen in Figure 2. This feedback is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by explaining why the original statement is incorrect or providing more context about the implications of the suggested change. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording of a sentence in the paper, pointing out that it is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending a change to accurately describe the use of a bidirectional encoder. This feedback is direct and helpful as it guides the authors to make a precise correction that can enhance the clarity and accuracy of their work. However, the comment could be more helpful if it explained why the original statement was incorrect or provided additional context about the implications of the suggested change. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part critiques the adopted baseline models as weak and suggests that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is an explicit suggestion for improvement, as it clearly identifies a missing comparison that the authors should make. The second part points out a grammatical error in the text, suggesting a correction. Both parts provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 277,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a grammatical error and suggests a correction, providing clear guidance on what needs to be addressed. Additionally, the comment critiques the adopted baseline models, suggesting comparisons with Campos et al. (2020) and other domain adaptation methods, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasons or evidence to support why the baseline models are weak or why these comparisons are necessary. The mention of Campos et al. (2020) and the suggestion to compare with other domain adaptation methods are vague and lack detailed justification or references. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies two main issues with the paper. First, it critiques the adopted baseline models as weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is a valuable suggestion for improving the paper by providing a more comprehensive comparison. Second, the comment points out a grammatical error in the text, suggesting a correction. Additionally, it highlights the absence of comparisons with other domain adaptation methods, which is an important aspect for the authors to consider. However, the comment could be more helpful if it provided specific examples or references for the domain adaptation methods to compare with. Overall, the feedback is 4 as it identifies areas for improvement and provides actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the potential impact of societal biases on their work, but it lacks concrete steps or examples to help the authors implement this consideration. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the potential impact of societal biases, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. This is a relevant point that could impact the validity and reliability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure their knowledge bases are unbiased. Additionally, the second part of the comment seems unrelated to the first part and appears to be a personal preference or opinion rather than a constructive suggestion. Overall, the comment identifies a potential issue but lacks actionable feedback, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning the baselines in reference 1. It asks the authors to justify the reason for not including these baselines. While the comment implies that the authors should provide a justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification and are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of strong baselines in the table, such as those mentioned in reference 1, and asks for a justification for this omission. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of strong baselines in Table 3, specifically mentioning the baselines in reference 1. However, it does not provide any further explanation or justification for why these baselines are important or how they relate to the current work. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, such as those mentioned in reference 1. It asks the authors to justify the reason for this omission, which is a clear and actionable request for improvement. By addressing this point, the authors can enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate these baselines or why they are important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper relies heavily on supplemental space, which makes it not truly independent. It specifically mentions references to supplemental figures and model comparisons, indicating that these sections are not fully integrated into the main text. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the integration of supplemental material into the main text. The action is implicit and vague, leaving the authors to infer that they need to better integrate their supplemental material into the main text, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the paper relying on supplemental space, which makes it not truly independent, and highlights specific references that support this claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper relies heavily on supplemental space, making it not truly independent. It provides specific examples, such as the reference to Sup. Fig. 6 in S3.1 and the model comparison, to support this claim. This level of detail provides a clear rationale for the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by further elaboration or references to similar cases in the literature, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space, which makes it not truly independent. It provides specific examples, such as the reference to Sup. Fig. 6 in S3.1 and the model comparison, to support this claim. This feedback is clear and actionable, as it highlights a critical area for improvement that the authors need to address to enhance the paper\"s independence and overall quality. However, the comment could be more helpful if it offered suggestions on how to integrate the supplemental material more effectively into the main text. Despite this, the comment is 4 as it directs the authors to a key area for improvement, making it a 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether treating concept map extraction as a separate task is necessary. It provides a balanced perspective, acknowledging both the potential benefits of treating it as a separate task and the challenges that arise with increasing node numbers. However, the comment does not explicitly instruct the authors to take any action or provide specific guidance on how to address this issue. The authors are left to infer that they might need to reconsider their approach, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a balanced perspective with both pros and cons. However, it does not specify which part of the paper this question pertains to, such as a particular section or methodology, making it weakly grounded. The comment is specific in its discussion of the potential benefits and challenges of treating concept map extraction as a separate task, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, providing a balanced perspective with both potential benefits and challenges. However, the comment lacks specific examples, references, or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of concrete evidence or detailed justification renders the claim 3, as it provides a general framework for consideration but does not offer sufficient guidance for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of treating concept map extraction as a separate task. It provides a balanced perspective by acknowledging both the potential benefits of this approach and the challenges that arise with increasing node numbers. This feedback encourages the authors to reconsider their approach and potentially improve the readability of their summaries. However, the comment could be more helpful if it offered specific suggestions or examples on how to address the issue or improve the concept map extraction process. Despite this, the comment provides valuable insight and prompts the authors to think critically about their methodology, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also asks specific questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what nonexperts would do, as well as whether it introduced any linguistic challenges. These questions and requests are clear and concrete, providing the authors with a direct and detailed guide on what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly relates to the first point mentioned in the review, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the traits of the experts involved in the annotation process and the justification for using expert annotation beyond its commercial value. The comment asks detailed questions about the nature of the experts and the differences in annotation compared to nonexperts, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the annotation process, specifically asking about the traits of the experts involved and the justification for using expert annotation. These questions are factual and seek additional information to better understand the paper, but they do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking the authors to describe more about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also raises questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what nonexperts would do, as well as whether it introduced any linguistic challenges. These questions and requests for clarification are clear and direct, offering the authors a structured approach to enhancing their draft by providing more detailed information and justification. This level of guidance is highly beneficial for the authors, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with lines 102106, stating that they are misleading. It points out that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the text. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reference, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically regarding the phrase \"such distribution.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, pointing out that lines 102106 are misleading. It highlights that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it directs the authors to clarify the reference to \"such distribution\" to ensure accuracy and coherence in their text. However, the comment could be more helpful if it provided additional guidance on how to rephrase or clarify the text. Overall, the comment is 4 as it effectively points out a potential issue and prompts the authors to make a specific improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, it does not provide specific guidance on how to implement this suggestion or what kind of examples would be most useful. The action is implicit, as the authors need to infer that they should include examples, and it is vague, as it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than just other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. Without explicit references or clear guidance on where these examples should be included, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of examples would be beneficial or how they would enhance the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, the comment does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that including examples of the system on actual texts would be beneficial, rather than just focusing on other components and models. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors could enhance the paper by providing more concrete examples. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what kind of examples would be most relevant. While it provides a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. The reviewer requests clarification on the data split used. While the comment implies that the authors should provide more information about the use of the CS, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of the CS but are not given specific guidance on how to present this information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. The reviewer requests clarification on the data split used. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or experimental setup, which the authors can infer. The comment is specific in detailing what needs to be clarified regarding the use of the CS. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and aim to gather more information, making the comment a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. The reviewer also requests clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify the use of the CS. The feedback is 3 as it points out a need for clarification, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify the discussion in section 5.2, which is currently too abstract. This request is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what is needed to enhance the clarity and effectiveness of the discussion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion being too abstract and requests examples of spurious structures to clarify why the new model is better than MH. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is too abstract and lacks clarity regarding why the new model is better than MH. The reviewer requests examples of spurious structures to clarify this point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the discussion is abstract or to justify the need for examples of spurious structures. Without additional context or explanation, the claim remains 1, as it does not offer a clear path for the authors to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks clarity regarding why the new model is better than MH. The reviewer requests examples of spurious structures to clarify this point, which is a clear and actionable suggestion for improvement. By providing this feedback, the comment helps the authors to focus on enhancing the clarity and effectiveness of their discussion, making it more valuable to the reader. However, the comment could be more helpful if it offered additional guidance on how to present these examples or what specific aspects of the discussion need more detail. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides clear guidance on what needs to be added to the draft. The comment is specific and concrete, as it directly instructs the authors to include a particular piece of information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. This provides clear guidance on what the authors should include to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be beneficial to include the maximum number of tasks done by any annotator. However, the comment does not provide any reasoning or justification for why this information is important or how it would enhance the paper. Without supporting evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of the significance of this information. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors include the maximum number of tasks done by any annotator, which is a specific and actionable piece of feedback. This recommendation can help improve the clarity and completeness of the paper by providing additional context about the annotation process. However, the comment could be more helpful if it explained why this information is important or how it would impact the reader\"s understanding of the study. Despite this, the feedback is clear and provides a concrete suggestion for improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. While the comment identifies a gap in the paper\"s presentation, it does not provide explicit guidance on how the authors might address this issue. The action is implicit, as the authors need to infer that they should clarify the connections between the empirical results and the research question or hypothesis. However, the comment lacks concrete details on how to achieve this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"many empirical results and analyses\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the overall understanding of the experiments and their connection to the research question and hypothesis. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. However, the comment does not provide specific examples or detailed reasoning to support the claim that the experiments are unclear or disconnected. This lack of detailed justification makes the claim 3, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite the presence of many empirical results and analyses, it is difficult to understand the overall picture of what the experiments reveal about the research question and hypothesis. This feedback is valuable as it highlights a critical gap in the paper\"s presentation and suggests that the authors need to better integrate their findings to provide a clearer understanding of their work. However, the comment could be more helpful if it offered specific suggestions on how to achieve this integration, such as recommending the use of visual aids or more detailed summaries. Overall, the comment is 3 as it points out a key area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy (DP) algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to use or how to conduct the comparisons. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy algorithms. However, it does not specify which part of the paper lacks numerical results or which algorithms are being referred to. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for numerical results and comparisons but lacks grounding, as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a curiosity about the application of the method to popular algorithms and its performance compared to existing differential privacy algorithms. However, it does not provide any specific examples, references, or reasoning to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the reviewer\"s interest in this aspect. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant gap in the paper, specifically the lack of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy algorithms. While the comment identifies an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or examples of algorithms to consider, leaving the authors with a general idea of what is missing but without detailed direction on how to improve their draft. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not welldrawn and should be formalized or clarified. The reviewer provides a clear action for the authors to take, which is to either \"cement this connection more formally\" or \"adjust the language to clarify.\" This feedback is explicit and provides concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the probabilistic connection in the paper, suggesting that it is not formally established and should be clarified. However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors either formalize the connection or adjust the language to clarify it, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection in the paper is not welldrawn and suggests that it should be formalized or clarified. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the probabilistic connection, which is not formally established. It suggests that the authors either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific area to focus on for improvement. However, the comment could be more helpful if it offered additional guidance on how to formalize the connection or provided examples of how to clarify the language. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This is an explicit action that the authors need to take, as it clearly instructs them to include empirical evidence to substantiate their claim. The comment provides a specific direction for improvement, making it 5. The authors know exactly what is expected of them, which is to conduct empirical tests and present the results to validate their claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of empirical evidence is needed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate why this evidence is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to conduct empirical tests to validate their claim. However, the comment could be more helpful if it provided specific guidance on what kind of empirical evidence is needed or how to present it. Despite this, the suggestion is 4 as it points out a critical area for improvement that could strengthen the paper. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the robustness of their training scheme. The action is implicit and vague, as the authors are left to infer that they need to consider the scalability of their method but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper discusses the robust training scheme or the scalability issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the scalability issue but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The reasoning is somewhat vague and does not provide a clear basis for the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. This feedback identifies a potential limitation of the proposed method and highlights an area where the authors might need to consider scalability and dimensionality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the robustness of their training scheme. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of the 4year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. While it implies that the authors should provide more information or justification regarding the dataset choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets, specifically questioning whether a 4year period is sufficient to study style shifts and what kind of style shifts occur within this timeframe. However, it does not specify which part of the paper discusses the dataset choice, making it weakly grounded. The comment is specific in its request for clarification on the dataset choice and its implications for understanding the model\"s captures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that a 4year period is insufficient. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets, specifically questioning whether a 4year period is sufficient to study style shifts and what kind of style shifts occur within this timeframe. This is a relevant point that could impact the understanding and interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, it lacks actionable feedback, making it 3. The authors are left with a general direction for improvement but without detailed steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern with the experiments, specifically noting that the paper only includes selfcomparisons and lacks explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue and provides a specific suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their experimental choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning that the paper only includes selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed in a generative setting. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper discusses the experiments, so the authors might need to infer that it refers to the results or methodology sections. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a concern due to the lack of comparisons with other models, specifically mentioning SketchRNN. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. The suggestion to include comparisons with SketchRNN is vague and lacks context, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other models, such as SketchRNN, in the experiments. It highlights that the paper only includes selfcomparisons, which adds to the poor motivation problem. The comment provides a clear and actionable suggestion to include comparisons with SketchRNN, which could enhance the paper\"s validity and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or why they are important. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not immediately obvious and require technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of making the results more accessible or how to enhance the clarity of the techniques used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, noting that while the techniques used are considered \"standard,\" they are not immediately obvious and require a high level of technical expertise. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not immediately obvious, requiring a high degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 3, as it provides a general observation but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential issue with the accessibility of the results, noting that while the techniques used are considered \"standard,\" they may not be immediately obvious to all readers. This observation suggests that the authors should consider making their results more accessible or providing additional context to help readers understand the techniques used. However, the comment does not offer specific suggestions or guidance on how to achieve this, such as recommending additional explanations, examples, or references. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. This is an explicit action that the authors can take to clarify their work. However, the comment does not provide specific guidance on how to implement this distinction or which specific updates should be highlighted. While the action is clear, the lack of detailed instructions makes it 3. The authors know what needs to be done but may need additional guidance on how to execute it effectively.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that update the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. This is a specific and actionable suggestion that could help clarify the paper\"s content and improve its organization. By highlighting this distinction, the authors can provide a clearer understanding of their work and its contributions. However, the comment could be more helpful if it provided additional context or examples of how this distinction might be implemented or why it is important. Overall, the feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used for training the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should reconsider their conclusion or provide more detailed comparisons, but the lack of concrete instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the difference in data used for training the text disambiguation model versus the endtoend system. However, it does not specify which sections or results this comparison is based on, making it weakly grounded. The comment is specific in questioning the conclusion based on the data difference, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the difference in data used for training the text disambiguation model and the endtoend system, questioning the conclusion that the direct model is clearly better. However, the comment does not provide specific data or performance metrics to support this claim, nor does it offer detailed reasoning or references to substantiate the assertion. This lack of evidence makes the claim difficult for the authors to address, as they would need to infer the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the comparison between the text disambiguation model and the endtoend system, noting that the difference in performance is only a few percentage points. It questions the conclusion that the direct model is clearly better, suggesting that both models are superior to the baseline. This feedback is 3 as it points out a potential weakness in the paper\"s conclusions, prompting the authors to reconsider their claims and possibly provide more detailed comparisons or justifications. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies two main issues: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. The comment explicitly suggests that the authors should provide evidence or justification for GaRare\"s advantages over GaLore and offer a more detailed algorithmic presentation. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be addressed and how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what is missing, such as evidence or justification for GaRare\"s advantages over GaLore and a more detailed algorithmic presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly regarding the recovery of updated parameters from projected gradients. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claim about the lack of motivation or detailed algorithmic presentation. This makes the claim 3, as the authors would need to infer the specific issues and address them based on the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of clear motivation for GaRare, specifically noting the absence of evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable as it prompts the authors to provide a more robust justification for their approach. Second, the comment suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is specific and provides a clear direction for enhancing the understanding of the method. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should incorporate this information into their draft. The action is implicit, as the authors need to infer that they should include references to these works, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields Ristovski 2013\" and \"Continuous Conditional Neural Fields Baltrusaitis 2014,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a link to these similar works that have a similar structure to the CRF and can perform exact inference. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. The claim is 3 as it references specific works, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to look up the referenced works to understand the context and relevance of the missing link. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the current paper. By mentioning these references, the comment provides the authors with a clear direction to enhance the context and relevance of their work. However, the comment could be more helpful if it included a suggestion on how to incorporate these references or why they are important for the paper. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input and whether any input could serve as a white paper. It also questions the effectiveness of Gaussian noise input compared to WPA, as suggested by Figure 2. The comment highlights the importance of understanding how WPA works to spark future research directions. While the comment implies that the authors should provide more insight into the workings of WPA, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should delve deeper into the explanation of WPA\"s functionality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the effectiveness of WPA with different inputs, such as np.ones and Gaussian noise, and highlights the need for a deeper explanation of how WPA works. The comment provides clear guidance on what aspects of the paper need further clarification or analysis, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the effectiveness of WPA with different inputs and the lack of insight into how WPA works. While the comment highlights areas that could be explored further, it does not provide specific evidence, examples, or references to support the claims. The reasoning is logical, but it lacks detailed justification or examples, making it 3. The authors would need to infer the potential issues and explore them further to address the comment effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could significantly enhance the paper. It suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input and whether any input could serve as a white paper. This is a valuable suggestion as it could lead to a better understanding of the model\"s functionality and potential applications. Additionally, the comment questions the effectiveness of Gaussian noise input compared to WPA, as suggested by Figure 2, and highlights the importance of understanding how WPA works to spark future research directions. The feedback is clear and actionable, providing the authors with specific areas to focus on for improvement. However, it could be more helpful if it included specific suggestions on how to approach these questions or if it provided more detailed guidance on what insights could be gained from exploring these aspects. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity between the method part and the related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the authors to provide more clarification on this issue. This request is direct and clear, giving the authors a specific action to take\u2014namely, to clarify the differences or similarities between their method and the cited work. The feedback is concrete and actionable, as it provides a clear direction for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a concern about the similarity between the method part and the related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It asks for clarification on this issue, which suggests that the authors should address the overlap or differences between their method and the cited work. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or elements, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the similarity between the method part and the related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any specific examples or detailed reasoning to support the claim of similarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1, as it lacks sufficient justification or evidence to support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method part and the related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a valid concern that could impact the originality and contribution of the paper. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or differentiate their work from the cited work. While it points out a potential problem, it does not offer actionable suggestions for improvement, making it 3. The authors are left with a general direction to clarify the differences, but without detailed guidance, the feedback is incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the setting of two important parameters/thresholds, specifically the minimum cluster size and the conductance threshold. It notes that these parameters are not discussed in the experimental section (Sec. 3), which is crucial for understanding the sensitivity of performance with respect to these parameters. The comment implies that the authors should address this gap by discussing how these parameters are set and how they affect the results. While the action is implicit, it is concrete in suggesting that the authors should include a discussion on parameter setting and sensitivity analysis. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the absence of discussion on the setting of two important parameters/thresholds (minimum cluster size and conductance threshold) in the experimental section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of discussing these parameters and their impact on performance, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the experimental section (Sec. 3) does not discuss how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a critical oversight that could impact the validity and reliability of the results. The comment provides clear guidance by suggesting that the authors should include a discussion on these parameters, which would enhance the comprehensiveness and robustness of the paper. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as recommending a sensitivity analysis or providing examples of how these parameters affect the results. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the need for reinforcement learning in a static VQA task, suggesting it may be a potential weakness that could make the approach less dataefficient and harder to train. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this potential weakness or suggestions for alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the need for reinforcement learning in a static VQA task, suggesting it may be a potential weakness. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach are less dataefficient or harder to train. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The statement is based on a personal belief rather than evidence or logical reasoning, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer any actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a cautious approach should be taken regarding the contribution of the dataset until it is made publicly available. However, it does not provide explicit guidance on what actions the authors should take to address this issue. The comment implies that the authors should wait for the dataset to be publicly accessible before considering it a significant contribution, but it does not specify how the authors should handle this situation or what steps they should take to ensure the dataset is made available. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, suggesting a cautious approach until it is made accessible. However, it does not specify which part of the paper discusses the dataset or where this issue is mentioned. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on how to address the issue or what changes should be made. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, suggesting a cautious approach until it is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the contribution of the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the basis of the concern or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment highlights a critical issue regarding the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is made publicly accessible. This feedback is important as it points out a potential limitation in the paper\"s contribution, which could impact its credibility and impact. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they could take to ensure the dataset is made available. While it identifies a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it raises an important point but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results and suggests that the performance is primarily due to the first step, implying that comparisons with existing detection methods are necessary. However, the comment does not provide explicit guidance on how to conduct these comparisons or what specific experiments should be performed. The action is implicit and somewhat vague, as the authors can infer that they need to conduct additional experiments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks and questions the validity of this claim. It suggests that the performance is primarily due to the first step, implying that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in suggesting that comparisons with existing detection methods are needed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results, suggesting that the performance is primarily due to the first step. The reviewer implies that comparisons with existing detection methods are necessary to substantiate this claim. However, the comment lacks specific examples or references to support the claim that the performance is mainly due to the first step. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to substantiate this claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or conduct the necessary comparisons. The feedback is 3 as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment explicitly requests the authors to provide an explanation for this observation, which is a clear and direct action. However, it does not specify how the authors should approach this explanation or what specific aspects to focus on. While the action is explicit, the lack of detailed guidance on how to address the issue makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm to different layers, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment does not make a claim or provide an opinion but rather seeks clarification from the authors. It is a request for explanation and does not contain any subjective claims or suggestions, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, as observed in Table 2. It points out a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment requests the authors to provide an explanation for this observation, which is a clear and actionable request for clarification. By addressing this question, the authors can gain a deeper understanding of their model\"s behavior and potentially identify areas for improvement. However, the comment could be more helpful if it provided additional context or suggestions on how to approach the explanation. Overall, the comment is 4 as it directs the authors to a specific area needing further clarification, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the \"required implicit call to the Witness oracle,\" indicating that it is confusing. However, it does not provide any explicit guidance or suggestions on how to clarify or address this confusion. The action is implicit, as the authors can infer that they need to clarify the call, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"required implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is located in, such as a particular section or figure. Without explicit references or detailed guidance, the authors may find it challenging to pinpoint the exact area needing clarification. This makes the comment weakly grounded, as the authors cannot confidently determine the specific part of the paper being addressed. The comment is specific in identifying the issue with the Witness oracle, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this call is confusing or how it could be clarified. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"required implicit call to the Witness oracle\" is confusing. This feedback is 3 as it points out a potential area of confusion that the authors should address. However, the comment lacks depth and does not provide any suggestions or guidance on how to clarify the issue or improve the clarity of the paper. While it highlights a specific problem, it does not offer actionable advice for resolution, limiting its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the proposed method, specifically its inability to handle headpose, and questions why it cannot condition headpose parameters similar to a previous work. While the comment identifies a specific issue and references a relevant previous work, it does not provide explicit guidance on how the authors should address this limitation or suggest potential solutions. The action is implicit and somewhat vague, as the authors are left to infer that they should explore ways to condition headpose parameters, but without concrete steps or examples, it remains unclear how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the issue of handling headpose, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the problem by referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, and it questions why the proposed method cannot condition headpose parameters similarly. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method cannot handle headpose and questions why it cannot condition headpose parameters similar to a previous work. The comment references a specific previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, providing a basis for the claim. However, the comment lacks detailed reasoning or examples of how the proposed method could be adapted to handle headpose, making the claim 3. The authors would need to delve deeper into the referenced work and the proposed method to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose, which is a critical aspect of facial expression control. It questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021), which can control both facial expression and headpose. This feedback is valuable as it highlights a specific area for improvement and encourages the authors to explore ways to address this limitation. However, the comment could be more helpful if it provided suggestions or examples of how the authors might adapt their method to handle headpose. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Sections 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing only a few times in the training set. It references examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the concept. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue in their draft. While it identifies a potential problem, it lacks actionable advice on how to mitigate it or improve the draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the spurious features being similar to backdoor triggers and provides examples from Chen et al. (2017) and Gu et al. (2019) to support the claim. This level of detail helps the authors understand what needs to be addressed in the sections mentioned. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers and notes that these artificial patterns can have a significant impact on the trained model. The comment supports this claim by referencing examples from Chen et al. (2017) and Gu et al. (2019), which use random noise patterns and singlepixel triggers, respectively. This provides a logical basis for the claim, as it highlights the potential vulnerability of the model to such triggers. However, the comment could be strengthened by providing more detailed analysis or examples from the current paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides examples from existing literature, such as Chen et al. (2017) and Gu et al. (2019), to illustrate the concept. This feedback is 3 as it highlights a specific area of concern and offers references that could help the authors understand the issue better. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the robustness of the model against such triggers. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the optimization algorithm being directly taken from previous works, which is perceived as reducing the contribution of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to make the optimization more original. The comment implies that the authors should consider developing their own optimization algorithm or explaining how their approach differs from existing ones, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of structural optimization, which is mentioned as a main component of the paper. However, it does not specify which part of the paper discusses this optimization, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm is directly taken from previous works, which is perceived as reducing the contribution of the paper. This provides clear guidance on what needs to be addressed, such as explaining how the current approach differs from existing ones or developing a more original optimization algorithm. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization algorithm is directly taken from previous works, which is perceived as reducing the contribution of the paper. However, the comment does not provide specific references or examples of the previous works, nor does it offer detailed reasoning or evidence to support this claim. This lack of supporting information makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, specifically regarding the structural optimization algorithm. It points out that the algorithm appears to be directly taken from previous works, which could reduce the paper\"s originality and contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance their contribution. Without actionable advice or examples, the feedback provides limited value to the authors in terms of improving their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include related work on modular networks for VQA, specifically mentioning a reference \"A\" that should be cited. This provides a clear and direct action for the authors to take, ensuring that the introduction accurately reflects the current state of research in modular architectures for VQA. The comment is 5 because it specifies exactly what needs to be added and provides a concrete reference to guide the authors. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"When discussing related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: mentioning related work on modular networks for VQA. This provides clear guidance on how to improve the introduction by ensuring it accurately reflects the current state of research. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not accurately reflect the current state of research on modular networks for VQA, suggesting that related work on this topic should be mentioned. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the omission or how to address it. The lack of detailed justification or evidence makes the claim 3, as the authors would need to conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that it does not adequately discuss related work on modular networks for VQA. This is a critical oversight, as it may give the impression that no one uses modular architectures for VQA. The comment provides a clear and actionable suggestion to include relevant references, which would enhance the accuracy and completeness of the introduction. By addressing this gap, the authors can improve the paper\"s credibility and provide a more comprehensive overview of the field. However, the comment could be more helpful if it suggested specific references or provided additional context on why these references are important. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors primarily focus on SSC and neglect to contrast their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and offer similar guarantees. While the comment identifies an area for improvement by suggesting the inclusion of these comparisons, it does not provide explicit guidance on how to conduct these comparisons or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to include these comparisons but may not know exactly how to execute this task. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific area of focus in the paper, namely the authors\" emphasis on SSC and the lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure where these comparisons should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to include comparisons with other methods, but without explicit grounding, it is challenging for the authors to pinpoint the exact changes needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and neglect to contrast their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and offer similar guarantees. The claim is 3 as it provides a logical reasoning for the suggestion to include comparisons with other methods. However, the comment lacks specific examples or references to these subsequent methods, which would strengthen the justification. The authors would need to look into the literature to understand the methods being referred to, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors primarily focus on SSC without adequately contrasting their method with other subsequent methods like TSC and greedy subspace clustering by Park. These methods are mentioned as being computationally efficient and offering similar guarantees, suggesting that the authors should include comparisons with these methods to provide a more comprehensive evaluation of their work. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct these comparisons or which aspects to focus on. This limits the helpfulness of the feedback, as the authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem or what specific changes they should make to their tables. The action is implicit and somewhat vague, as the authors can infer that they need to include these missing cases in the tables, but they are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment\" and \"the two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the tables, which is the lack of cases where both dependency tree and RL are not used. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree and points out that the tables do not include cases where both dependency tree and RL are not used. However, the comment lacks specific examples or detailed reasoning to support the claim about the performance drop. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. This feedback is clear and actionable, as it highlights a gap in the experimental setup and suggests that the authors should include these missing cases in the tables. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or address the observed performance drop. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback provides a clear direction for the authors to expand their experimental evaluation by considering additional datasets and models, which would enhance the comprehensiveness of their work. However, the comment could be more actionable by specifying which datasets or models the authors should include. Overall, the comment is 4 as it gives a concrete direction for improvement, even if it lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The comment further suggests consulting specific works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experimental evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 3 as it provides a logical reasoning for the limitation in the experimental scope and suggests a specific direction for improvement by referencing relevant literature. However, the comment could be strengthened by providing more detailed examples or specific references to datasets and models that should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. It suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types, providing a clear direction for improvement. This feedback is actionable and constructive, as it highlights a critical area for expansion and offers specific references to enhance the comprehensiveness of the experimental evaluation. By addressing this feedback, the authors can significantly improve the depth and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider alternative datasets for their study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other datasets but are not provided with specific guidance on how to implement this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly refers to a specific claim made in the paper regarding the improvement in accuracy and completeness, which can be identified by the authors. It also provides a specific suggestion to use another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This level of detail allows the authors to understand exactly what needs to be addressed and how to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to test the robustness of the findings, but it lacks specific reasoning or evidence to fully substantiate the claim. The comment provides a potential direction for further investigation but does not fully justify the need for an alternative dataset. Therefore, the claim is 3, as it offers a reasonable suggestion but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment questions the validity of a specific claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is 3 as it points out a potential weakness in the paper and offers a specific suggestion for improvement. However, it lacks depth and does not provide detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it directs the authors to consider alternative datasets, it does not fully address the need for a more comprehensive evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It also expresses skepticism about the ecological validity of the study and suggests that previous work has considered multiple CVEs or CWEs simultaneously. The reviewer asks if the authors are arguing that identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment identifies areas of concern and raises questions, it does not provide explicit guidance or suggestions for improvement. The authors are left to infer that they should address these concerns, but the lack of concrete action or detailed feedback makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It also expresses skepticism about the ecological validity of the study and compares it to previous work that considered multiple CVEs or CWEs. However, the comment does not explicitly mention which part of the paper discusses this methodology, making it weakly grounded. The authors can infer that it relates to the methodology section, but this is not entirely clear. The comment is specific in detailing the concerns about the methodology and the comparison with previous work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It compares this approach to previous work that considered multiple CVEs or CWEs, suggesting that the current methodology may lack ecological validity. The reviewer also questions the interpretability of the results, suggesting they are \"difficult to interpret\" or \"marginal improvements at best.\" While the comment provides some context by referencing previous work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The lack of explicit evidence or detailed justification makes the claim 3, as the authors would need to delve deeper into the methodology and previous work to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It highlights the potential lack of ecological validity compared to previous work that considers multiple CVEs or CWEs. The reviewer also questions the interpretability of the results, suggesting they may be marginal improvements at best. While the comment identifies a potential weakness in the methodology and raises questions about the study\"s validity, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment identifies areas where more detail is needed, it does not provide explicit instructions on how to incorporate these suggestions or what specific details should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment does not explicitly mention a specific section or part of the paper, it provides clear guidance on what needs to be addressed, such as providing more detailed explanations for certain concepts. This makes the comment weakly grounded, as the authors can infer the parts being addressed, but specific, as it specifies what needs to be improved. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, without making any subjective claims or opinions that require verification. It describes the content of the paper and suggests additional details could be provided, such as definitions and explanations. Since it does not contain any claims or opinions that need justification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. This feedback is 3 as it identifies areas where more detail is needed to improve the clarity of the paper. However, it lacks specificity and does not provide detailed guidance on how to enhance these sections. While it points out potential improvements, it does not offer actionable steps or examples, leaving the authors with a general idea of what needs attention but without detailed guidance on how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking for quantitative results on testing images. While it does not explicitly instruct the authors to conduct such an evaluation, it implies that this is a necessary step to fully prove the point. The action is implicit, as the authors need to infer that they should include quantitative results on testing images. However, the comment provides a clear direction on what needs to be done, making it 3. The authors know that they need to focus on evaluating the shape model invariance on testing images, but the comment does not specify how to conduct this evaluation or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether there are quantitative results on testing images, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance and asks for quantitative results on testing images. However, it does not provide any supporting evidence, reasoning, or references to justify why the evaluation on training images is insufficient or why testing images are necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the evaluation of shape model invariance, specifically questioning whether the evaluation on transformations of training images is sufficient to prove the point. It prompts the authors to consider whether there are any quantitative results on testing images, which could provide a more comprehensive understanding of the model\"s invariance. This feedback is clear and actionable, as it directs the authors to a specific area where additional evidence or analysis could strengthen their argument. However, it could be more helpful if it provided suggestions on how to conduct such an evaluation or what metrics to use. Overall, the comment is 4, as it guides the authors toward a potential improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment explicitly instructs the authors to discuss and compare this work to provide a better understanding of the stateoftheart. This feedback is clear and direct, providing a concrete action for the authors to take. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is a clear reference point for the authors. It also specifies what needs to be addressed, namely discussing and comparing this work to provide a better understanding of the stateoftheart. This level of detail allows the authors to accurately identify the part of the paper that requires revision and understand the nature of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this work should be discussed and compared to provide a better understanding of the stateoftheart. While the claim is based on a specific reference, it lacks detailed reasoning or examples of how this work relates to the authors\" paper. The authors would need to investigate the paper themselves to understand its relevance and potential impact on their work. Therefore, the comment is 3, as it provides a basis for the claim but requires further exploration by the authors.", "helpfulness_rationale": "The review comment identifies a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. It suggests that this work should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance the context and depth of their paper. By incorporating this comparison, the authors can provide a more comprehensive overview of their work in relation to existing research. However, the comment could be more helpful if it included specific suggestions on how to integrate this comparison or what aspects to focus on. Overall, the comment is 4 as it offers a valuable direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the scalability of the approach, specifically the computation of optimal transport distance, and questions the method used to compute it. The reviewer suggests testing the method on machines with fewer cores to assess its scalability. Additionally, the reviewer questions the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. While the comment implies that the authors should address these concerns, it does not provide explicit instructions on how to conduct the scalability tests or clarify the process of obtaining optimal transport. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Approach,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issues with the scalability of the method and the computation of optimal transport, providing clear guidance on what needs to be addressed. The comment raises questions about the scalability on normal machines and the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the approach, specifically the computation of optimal transport distance, and questions the method used to compute it. The reviewer suggests testing the method on machines with fewer cores to assess its scalability and questions the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. While the comment provides some logical reasoning and questions, it lacks specific examples or references to support the claims fully. The authors would need to infer the exact issues and potential solutions based on the provided information. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises important concerns about the scalability of the approach, specifically the computation of optimal transport distance. It questions the method used to compute optimal transport and suggests testing the method on machines with fewer cores to assess its scalability. Additionally, the comment questions the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. These points are critical and provide actionable feedback for the authors to address the scalability and computational efficiency of their approach. However, the comment could be more helpful if it offered specific suggestions or examples on how to improve the scalability or clarify the computational process. Overall, the comment is 4 as it identifies key areas for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests introducing specific aspects of the model that are relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and actionable, as it directs the authors to include specific details that would enhance the clarity and understanding of their work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, such as introducing specific aspects of the model relevant to the example being discussed. The comment suggests highlighting that the model operates in a setting with finite subdivisions for gamma^1 and gamma^m and that certain parameters are bounded on one side. This level of detail provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for gamma^1 and gamma^m, and the bounded parameters like acceleration and scaling parameters. However, the comment does not provide any reasoning or evidence to support why these aspects are important or how they impact the understanding of the model. Without additional context or explanation, the authors may find it challenging to understand the significance of these suggestions. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors clarify certain aspects of the model that are specific to the example being discussed. It highlights the need to explicitly mention the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and constructive, offering the authors a direct way to enhance the clarity and understanding of their work. By addressing these points, the authors can improve the comprehensibility of their model and its application, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should consider broader applications, it does not explicitly instruct them to do so. The suggestion is implicit and somewhat vague, as it lacks specific guidance on how to conduct these additional experiments or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters and experiments to other areas, such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. The reviewer questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the method cannot generalize to different architectures and tasks. This makes the claim 3, as it requires further evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the experiments and parameters presented in the paper, suggesting that they are primarily focused on image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain, which could demonstrate the method\"s generalizability. This feedback is 3 as it prompts the authors to consider broader applications and potential extensions of their work. However, it could be more helpful if it provided specific suggestions or examples of how to explore these additional areas or what benefits such an exploration might bring. Overall, the comment encourages the authors to think about the broader implications of their work, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the lack of clarity regarding the utility of tensor networks in representing the probability mass function (PMF) of discrete variables and their significance in machine learning algorithms. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the utility or significance of the results, nor are there suggestions for additional experiments, analyses, or discussions that could enhance the paper. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of clarity regarding the utility of tensor networks in representing the probability mass function (PMF) of discrete variables and their significance in machine learning algorithms. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the paper\"s significance but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because it does not clearly demonstrate how the results are useful to machine learning algorithms or for analyzing algorithms. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion about the lack of clarity or significance. Without additional context or justification, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the utility of tensor networks in representing the probability mass function (PMF) of discrete variables and their significance in machine learning algorithms. It points out that the paper\"s significance is poor due to this lack of clarity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the clarity of their work. Without actionable feedback or detailed recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper regarding the generalizability of the observations to fewshot learners beyond Prototypical Networks. It suggests that the scope of the submission\"s contributions might be limited due to this lack of evaluation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and vague, as the authors are left to infer that they need to conduct additional evaluations but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper regarding the generalizability of the observations to fewshot learners beyond Prototypical Networks. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of limited scope but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the extent to which the observations generalize to fewshot learners beyond Prototypical Networks, which may limit the scope of the submission\"s contributions. This claim is 3 as it highlights a potential gap in the evaluation of the paper\"s findings. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the observations presented do not evaluate their generalizability to fewshot learners beyond Prototypical Networks. This is a relevant observation that could impact the scope of the paper\"s contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or conduct additional evaluations to enhance the generalizability of their findings. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the contribution of different modalities of different instances, noting that some instances may perform well with one modality (e.g., modality A) while others perform well with another (e.g., modality B). It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how to deal with this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the problem but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential difference in contributions of different modalities across instances and questioning how to deal with this problem. The comment provides a clear direction for the authors to address the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this issue, specifically referencing Equation 3. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim or explain why this is a problem. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the contribution of different modalities of different instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. This feedback highlights a specific area where the authors may need to clarify or address the implications of their method, particularly in terms of how it handles instances with different modalities. However, the comment could be more helpful if it provided suggestions or examples on how to deal with this issue. Overall, the comment is 3 as it points out a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of description in the abstract regarding the evaluation of the proposed idea and its outcome. It suggests that the abstract does a good job of explaining the idea but lacks details on evaluation and outcome. However, the comment does not provide explicit guidance on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to add more details about the evaluation and outcome but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the abstract does a good job of explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job of explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear observation about the abstract, noting that it effectively explains the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is 3 as it identifies a specific area for improvement, suggesting that the authors should include more information about the evaluation and outcome in the abstract. However, the comment could be more helpful if it offered specific suggestions on what aspects of the evaluation or outcome should be included or how to present them effectively. Overall, the comment provides a useful direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out inconsistencies in the notation and questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. While the comment identifies specific areas of confusion and references the original paper for context, it does not provide explicit instructions on how to clarify or address these issues. The authors are left to infer that they need to clarify the notation and the use of unlabeled data in source domains. The action is implicit and somewhat vague, as it lacks detailed guidance on how to resolve the confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the description of the MFDA setting, including the confusion caused by the notation for the target domain and the use of labeled and unlabeled data. The comment provides specific examples and references to the original MFDA paper, which helps the authors understand what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing, specifically mentioning inconsistencies in notation and the use of labeled and unlabeled data. The reviewer references the original MFDA paper (Yue et al., 2021a) to support their claim, noting that the target data is unlabeled. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of confusion. While the reference to the original paper provides some context, the comment could be strengthened by providing more explicit comparisons or explanations of the differences. Therefore, the claim is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, pointing out confusion in the notation and the use of labeled and unlabeled data. It references the original MFDA paper (Yue et al., 2021a) to highlight the inconsistency and questions whether the unlabeled data in source domains are used during training, as in the original paper. This feedback is clear and actionable, as it directs the authors to clarify the notation and the use of data in their setting. However, the comment could be more helpful if it provided specific suggestions on how to address the confusion or offered examples of how to improve the clarity of the description. Overall, the comment is 4, as it effectively points out a critical area for improvement and guides the authors toward a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment implies that the authors should consider conducting an epochwise analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. This suggestion is specific in terms of what could be analyzed, but it does not specify which part of the paper should include this analysis. The authors can infer that it relates to the experimental or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. While the comment provides a logical reasoning for the potential benefits of such an analysis, it lacks specific examples or references to support the claim. The suggestion is 3 as it offers a plausible direction for further investigation, but it could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a potential area for improvement by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It provides specific examples of what could be investigated, such as the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment offers a clear and actionable suggestion, it could be more helpful if it provided additional guidance on how to implement this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a valuable area of exploration, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the immense workload, the incremental nature of the contribution, and the lack of citation of key baselines. It also suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include these missing citations and algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code and the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation of key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, essentially a combination of GraphRAG and GraphCare, and that key baselines were not cited. It also suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. The claim is 3 as it provides a logical reasoning for the incremental nature of the contribution and highlights specific missing citations and algorithms. However, the comment lacks detailed examples or references to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides several specific points for improvement, including the observation that the workload is immense and the contribution is incremental, essentially a combination of GraphRAG and GraphCare. It also highlights the lack of citation of key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is clear and actionable, as it identifies specific areas where the authors can enhance their work by including missing citations and algorithms. However, the comment could be more helpful if it provided additional guidance on how to integrate these elements effectively into the paper. Overall, the comment is 4, as it offers valuable insights for improving the draft, but could be more comprehensive with further suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, namely the difficulty in distinguishing between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance. The reviewer also raises a question about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies a problem and provides specific examples, it does not explicitly instruct the authors to address these issues or suggest how to improve the clarity of the distinction between the two types of extreme speech. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and refers to specific instances and lines in the sample data file, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of difficulty in differentiating between derogatory and exclusionary extreme speech, providing a concrete example from the sample data file. Additionally, it raises questions about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between derogatory and exclusionary extreme speech, as mentioned in the paper summary. It provides a specific example from the sample data file, questioning the classification of an instance and suggesting that local regulation may play a role in annotations. The comment also raises a question about the impact of local regulation on zeroshot crosscountry classification. While the comment identifies a potential issue, it lacks detailed reasoning or references to support the claim that the distinction is unclear or that local regulation affects the classification. The authors would need to infer the basis of the concern and potentially conduct further analysis to address it. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance and suggesting that local regulation may play a role in annotations. The comment also raises a question about the impact of local regulation on zeroshot crosscountry classification. This feedback is actionable as it points out a critical area for clarification and improvement, allowing the authors to refine their definitions and annotations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4, as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current formulation needs to be changed to be mathematically correct, implying that the authors should revise their equations. It also questions the use of \"L_l\" instead of \"L\" and suggests introducing the notation beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make the changes or introduce the notation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current formulation needs to be changed to be mathematically correct and questions the use of \"L_l\" instead of \"L,\" suggesting that the notation should be introduced beforehand. However, it does not specify which part of the paper this issue pertains to, such as a specific equation or section. The mention of \"Fig.\" implies that there is a figure involved, but without further context, the authors cannot confidently determine which figure is being referred to. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the current formulation needs to be changed to be mathematically correct and questions the use of \"L_l\" instead of \"L.\" However, it does not provide specific examples or detailed reasoning to support why the current formulation is incorrect or how the change would improve the mathematical correctness. The comment lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical formulation of the paper, suggesting that it needs to be changed to be mathematically correct. It also questions the use of \"L_l\" instead of \"L\" and recommends introducing the notation beforehand. While the comment highlights specific areas for improvement, it lacks detailed guidance or examples on how to address these issues. The feedback is 3 as it points out potential problems, but it could be more actionable with additional suggestions or explanations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the performance of the proposed method compared to the baseline model when trained and evaluated at the same timestep. It questions the effectiveness of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation timesteps differ. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should explore scenarios with different timesteps to demonstrate the method\"s effectiveness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of the proposed methods when trained and evaluated at the same timestep, questioning their effectiveness. The comment further suggests that the proposed method might be beneficial in scenarios where the training and evaluation timesteps differ. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the timeaware model when trained and evaluated at the same timestep. The reviewer questions the value of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation timesteps differ. However, the comment lacks specific examples or references to support the claim that the proposed methods are ineffective under the current conditions. The reasoning is somewhat logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the timeaware model when trained and evaluated at the same timestep. This observation questions the value of the proposed methods under the current conditions. The comment suggests that the proposed method might be more beneficial in scenarios where the training and evaluation timesteps differ. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative scenarios. The feedback is 3 as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the disentanglement process, noting that it is not clear how disentanglement is guaranteed. While it mentions that the \"Broader Impacts and Limitations\" section acknowledges obtaining fully disentangled latent vectors as a limitation, the comment emphasizes the need to clarify how disentanglement is realized and guaranteed without certain bias types. This feedback implies that the authors should provide more detailed information on the disentanglement process, but it does not specify exactly how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the disentanglement process, but they are not given explicit guidance on what specific details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the disentanglement process, noting that it is not clear how disentanglement is guaranteed and suggesting that the authors highlight how disentanglement is realized and guaranteed without certain bias types. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which acknowledges obtaining fully disentangled latent vectors as a limitation. However, the comment suggests that more detail is needed on how disentanglement is realized and guaranteed without certain bias types. While the comment provides some context, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the disentanglement process in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges obtaining fully disentangled latent vectors as a limitation, the paper does not provide sufficient detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it prompts the authors to provide more detailed information on the disentanglement process, which would enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of what additional information could be included. Overall, the comment is 4, as it directs the authors to a critical area that needs further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit instructions on how to address this issue or suggest specific ways to discuss the effect on the number of parameters. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the impact on the number of parameters but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation (Eq. 2) requires optimization over both the parameters of the transformation and the shared model, and that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. The comment provides a specific reference to AlignFlow, which supports the claim by indicating a relevant work for comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the effect on the number of parameters. Therefore, the claim is 4, as it provides some support but could be strengthened with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it highlights a gap in the discussion that the authors need to address. By suggesting that the authors should discuss the impact on the number of parameters, the comment provides a specific direction for improvement. However, it could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the questions or improve the results, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the implications of Eq. 4 and the value of u^l in Eq. 3, indicating that it is related to the equations and their analysis. However, it does not specify which part of the paper these equations are located in, making it weakly grounded. The comment also critiques the improvement in the designed solutions presented in Table 5, specifically mentioning the marginal improvement on the OfficeHome dataset. This part is specific as it identifies a particular dataset and the nature of the improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, and it critiques the improvement in the designed solutions presented in Table 5. The claim about the marginal improvement on the OfficeHome dataset is supported by specific numerical values (64.35 for CSAC and 64.71 for the proposed solution), which provides a clear basis for the critique. However, the comment lacks further elaboration or references to similar studies or benchmarks, which would strengthen the argument. Overall, the claim is 4, as it provides some evidence but could be more comprehensive with additional context or references.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, which could be an important point for the authors to clarify. Additionally, it critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential issue with the results and suggests that the authors should consider the significance of their improvements. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered additional context for understanding the implications of the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of certain stateoftheart references in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer also compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. While the comment identifies a gap in the references and provides a specific example, it does not explicitly instruct the authors to include these references or to address the comparison with the mentioned work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" along with a link to the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the missing references and provides a comparison with the results in Table 3, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a specific reference to the Baidu work and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the missing references impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the references used in the experiment on face recognition, pointing out the omission of a stateoftheart work by Baidu. It provides a detailed reference to the work, including a link to the results, and highlights a comparison with the results in Table 3 of the paper. This feedback is actionable as it directs the authors to include these references and consider the implications of the comparison. By doing so, the authors can enhance the credibility and relevance of their work by acknowledging and addressing the gap in the literature. However, the comment could be more helpful if it suggested how to incorporate these references or provided additional context for the comparison. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of template mapping in question answering, specifically mentioning the potential for poor generalization to questions that are not \"Whtypes\" or transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the template mapping approach, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the generalization of the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a specific concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or depth, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments to demonstrate the significance of the proposed projection errors. The suggestion is concrete, as it specifies the type of experiments needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results section, but this inference is not direct. The comment is specific in its suggestion for improvement but lacks full grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors by providing performance on models pretrained on synthetic data but finetuned on realworld datasets with different losses. The comment provides a logical reasoning for the claim by explaining that the current comparison is unfair and suggests a more appropriate approach. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the unfair comparison and the benefits of the suggested approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically the unfair comparison of the model\"s performance when only pretrained on synthetic data. It suggests a more appropriate approach by recommending the demonstration of the importance of the proposed three projection errors through experiments involving models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, providing the authors with a specific direction to improve their experimental design and analysis. However, it could be more helpful if it included additional guidance on how to implement these experiments or what specific outcomes to expect. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper\"s experimental rigor and clarity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests that it is common to average over subword representations, referencing a specific work by Hewitt and Manning (2019). This comment implies that the authors should consider averaging over subword representations as an alternative approach, but it does not explicitly instruct them to do so. While the suggestion is concrete, it is not explicitly stated as an action, leaving the authors to infer that they should consider this alternative. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement regarding the use of subword token embeddings and suggests an alternative approach by referencing a specific work by Hewitt and Manning (2019). This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an alternative approach to handling subword representations, specifically mentioning the practice of averaging over subword representations. It references a specific work by Hewitt and Manning (2019) as an example of this practice. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this alternative approach might improve the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests an alternative approach, which is to average over subword representations, and references a specific work by Hewitt and Manning (2019) that demonstrates this practice. This feedback provides the authors with a clear suggestion for improvement and a reference to consider, which can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included a detailed explanation of why averaging over subword representations might be beneficial or how it could impact the results. Overall, the comment offers a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these analyses or what specific aspects of the traditional method should be discussed. The actions are explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as demonstrating the consistency between predicted scores and actual risks, and suggests conducting calibration curves to show agreement. Additionally, it encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It encourages the use of calibration curves to show agreement, which is a common practice in evaluating predictive models. The comment also suggests discussing the differences between the traditional method and the proposed method. While the suggestion is logical and based on common practices in model evaluation, it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It points out that while the model AUC can assess discriminant ability, it may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The comment encourages the authors to conduct calibration curves to show this agreement and suggests proving the feasibility of the generated scoring system. Additionally, it recommends discussing the differences between the traditional method and the proposed method. This feedback is specific, actionable, and constructive, offering the authors a clear path to enhance the rigor and relevance of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues: the lack of change in the range of ID and OOD by sparsification, as observed in Figure 4, and the requirement for Lemma 2 to have an approximately identical mean as the assumption. The comment emphasizes that these conditions are crucial for DICE but notes that they are not well discussed. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to discuss these conditions further but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the range of ID and OOD does not change much by sparsification and that the conditions for Lemma 2 are not well discussed. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much by sparsification, as observed in Figure 4, and that Lemma 2 requires an approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples or detailed reasoning to support the claim that these conditions are not met or how they impact the paper. The absence of concrete evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, particularly regarding Figure 4 and Lemma 2. It points out that the range of ID and OOD does not change much by sparsification, which is a crucial condition for DICE. Additionally, it notes that Lemma 2 requires an approximately identical mean as the assumption, which is not well discussed. The comment highlights the importance of these conditions and suggests that the authors should discuss how to ensure DICE meets these conditions. While the comment provides clear and actionable feedback, it could be more helpful by offering specific suggestions on how to address these issues or provide examples of how to ensure DICE meets the conditions. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their experiments, use default settings for baselines, include missing baselines, and discuss limitations and societal impacts. However, the lack of specific guidance on how to implement these changes makes the comment 3. The authors know what needs to be done but may struggle with the exact steps to take.", "grounding_specificity_rationale": "The comment raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues relate to, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can make an educated guess about the general areas being addressed, the comment lacks full grounding. The feedback is specific in terms of the issues raised, such as the use of position kernels and the absence of certain baselines, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several claims about the experiments, including concerns about their strength and fairness, the use of position kernels, and the absence of certain baselines. The reviewer questions the choice of using position kernels and suggests comparing the proposed approach with baselines that use default settings. Additionally, the comment points out the lack of discussion on limitations and societal impacts. While the reviewer provides some reasoning for their concerns, such as questioning the use of position kernels and the absence of certain baselines, the comment lacks specific examples or references to support these claims. This makes the claims 3, as the authors would need to provide more detailed justification or evidence to fully address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including concerns about the strength and fairness of the experiments, the use of position kernels, and the absence of certain baselines. It also points out the need to discuss limitations and societal impacts of the proposed approach. While the comment highlights important issues that the authors should address, it lacks specific suggestions or guidance on how to improve the experiments, incorporate missing baselines, or discuss limitations and societal impacts. The feedback is 3 as it directs the authors to areas needing attention, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern that all sparsity patterns seem to perform equally well, without providing any insight into what is happening. It also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment identifies a potential issue and offers a specific correction, it does not provide guidance on how the authors might address the lack of insight into the sparsity patterns. The action is explicit but somewhat vague, as it lacks detailed instructions on how to improve the insight into the sparsity patterns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that all sparsity patterns seem to perform equally well and lacks insight into what is happening. Additionally, it suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that all sparsity patterns perform equally well and questions whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform equally well without providing any insight into what is happening. This observation raises a question about whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). The comment also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment highlights an area for further exploration and provides a specific suggestion for improvement, it lacks depth and does not offer detailed guidance on how the authors might address the lack of insight into the sparsity patterns. Therefore, the comment is 3, as it provides some direction but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This part is more of an observation than an actionable comment, as it does not provide specific guidance for the authors to address. The second part points out an error in the inequality on line 310, suggesting a comparison with line 227. This part is more actionable as it explicitly identifies a specific issue that needs correction. However, the comment could be more actionable if it provided a clearer explanation of how to correct the inequality or why the comparison is relevant. Overall, the comment is 3, as it provides a clear issue to address but lacks detailed guidance on how to implement the correction.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the claim about additional assumptions and the error in the inequality on line 310, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a factual statement about an error in the inequality on line 310. The first part is subjective and lacks specific evidence or references to support the claim that the assumption is too extreme. The second part is factual and does not contain a claim, as it points out an error in the inequality. Therefore, the first part is considered 1, while the second part is not a claim. Since the review point contains both a claim and a factual statement, it is rated as 1.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This feedback encourages the authors to reconsider their claim and potentially provide more context or justification. Second, it points out an error in the inequality on line 310, suggesting a comparison with line 227 to correct the base alpha value. This feedback is actionable as it identifies a specific issue that needs correction, providing a clear path for the authors to improve their draft. However, the comment could be more helpful if it offered additional guidance on how to address the claim about assumptions or provided more detailed feedback on the inequality correction. Overall, the comment is 4, as it provides clear and actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a comparison, but they are not provided with specific guidance on how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should compare the perspective taken in the present manuscript to the contributions of prior efforts in this section. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the related work section is comprehensive, it could benefit from comparing the current manuscript\"s perspective to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why such a comparison is necessary. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, specifically suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by contextualizing their contributions within the broader literature. However, the comment could be more helpful if it offered examples or guidance on how to effectively make these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not explicitly instruct the authors to conduct this examination or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should explore the impact of varying the number of scenarios, but they are not given specific instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental setup or results section, but this inference is not direct. The comment is specific in suggesting an area for exploration, but it lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a potential relationship between the number of scenarios used for training and the performance of the model. However, it does not provide any evidence, reasoning, or references to support this claim. The suggestion to examine the performance with different numbers of scenarios is logical but lacks specific examples or data to substantiate the claim. Therefore, the comment is considered 2, as it provides a reasonable suggestion but lacks sufficient evidence or detailed reasoning to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the performance of the model is likely related to the number of scenarios used for training, which is fixed at 200 in the paper. It recommends examining the performance with different numbers of scenarios, which could provide valuable insights into the model\"s robustness and generalizability. This feedback is clear and actionable, as it identifies a potential area for exploration and improvement in the experimental design. However, it could be more helpful if it provided specific guidance on how to conduct this analysis or what specific numbers of scenarios to consider. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper\"s experimental rigor."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests considering whether disturbances in the training data affect the model\"s performance in generating correct quality labels. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or conduct the analysis. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating quality labels and the model\"s ability to predict them, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its questioning of the model\"s ability to predict quality labels under certain conditions, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating quality labels and the model\"s ability to predict them, suggesting that disturbances in the training data might affect the model\"s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the relationship between generating quality labels and the model\"s ability to predict them. It suggests considering whether disturbances in the training data affect the model\"s performance in generating correct quality labels. This feedback is 3 as it prompts the authors to think critically about the robustness of their model and its ability to generalize under different conditions. However, the comment lacks specific guidance or suggestions on how to address this issue or conduct the analysis, which limits its usefulness. To be more helpful, the comment could include recommendations for testing or evaluating the model under different scenarios. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that Appendix A.2 does not clearly illustrate the state space representation of the environment. This provides a direct action for the authors to take, which is to clarify or improve the illustration in Appendix A.2. However, the comment does not specify how to improve the illustration or what specific aspects need clarification, leaving the authors with a general direction but lacking detailed guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not clearly illustrate the state space representation of the environment. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides the authors with a clear direction for improvement, suggesting that they need to enhance the illustration or explanation of the state space representation in this appendix. However, the comment does not offer specific suggestions or guidance on how to improve the illustration or what aspects should be clarified. While it highlights an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their draft. The references to other works imply that the authors should consider these extensions, but the comment lacks concrete instructions on how to incorporate this information into their paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"bounded noise assumption\" in the context of stochastic optimization literature, suggesting that it is somewhat restrictive. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which provide extensions to these noise conditions. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The comment is specific in suggesting that the authors consider these extensions, but it lacks detailed guidance on how to incorporate this information into their work. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they are recent and relevant studies that have explored extensions to the noise conditions. However, the comment could be strengthened by providing more detailed explanations or examples of how these works address the limitations of the bounded noise assumption. Overall, the claim is 4, as it is supported by references to relevant literature, but it could benefit from more detailed justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper\"s use of the bounded noise assumption, noting that it is somewhat restrictive in the context of stochastic optimization literature. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which have explored extensions to these noise conditions. This feedback is 3 as it points out a specific area for improvement and provides references to relevant literature. However, it lacks detailed guidance on how the authors might incorporate these extensions into their work or how they might address the limitations of the bounded noise assumption. To be more helpful, the comment could include suggestions or examples of how to apply these extensions or discuss their implications. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the motivation or what specific aspects of the motivation need further explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the motivation for using characteristic function regularization. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the motivation is discussed. Without explicit references or detailed guidance, the authors cannot confidently identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the motivation for using characteristic function regularization. However, it does not provide any specific suggestions or guidance on how the authors might clarify this aspect or improve the motivation. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might enhance their contribution or improve the novelty of their work. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the existing techniques used, but it lacks grounding as it does not explicitly mention the sections where these techniques are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. The reviewer provides specific references to support the claim, which makes the comment 4. However, the comment could be strengthened by providing more detailed analysis or examples of how these existing techniques are combined, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. It suggests that the contribution could be considered incremental because these results can be combined together, which is not surprising. However, the comment does not provide any actionable feedback or suggestions on how the authors might enhance their contribution or improve the novelty of their work. Without specific guidance or constructive criticism, the authors are left without a clear path to address the critique. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment does not explicitly instruct the authors to clarify or change anything, it implies that the authors should provide a clear explanation of this term. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"100 steps.\" However, the comment provides a clear direction on what needs to be clarified, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps,\" which is a clear and direct question that requires an explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1, specifically asking if it refers to 100 sampled strategies. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this point or improve the clarity of their work. The feedback is limited in its actionable nature, offering only a question without any constructive advice or direction for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. While the comment highlights an area for further exploration and a potential overlap with existing work, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is 3 as it identifies a potential area for improvement, but it lacks concrete steps or detailed advice on how to proceed. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation and goals of the model\" and the \"related work review part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the similarity between the model\"s goals and those of a prior VAE paper, suggesting that the authors should be aware of this overlap. This provides clear guidance on what needs to be addressed in the related work section. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to a prior VAE paper. The comment provides a logical reasoning by comparing the novelty of energy models to GANs and VAEs, and by referencing a specific prior work in the related work section. However, the comment lacks specific details or references to the prior VAE paper, which would strengthen the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but requires additional details for full verification.", "helpfulness_rationale": "The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more nuanced discussion of the model\"s goals in relation to existing work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the model\"s approach or how to address the similarity with the prior VAE paper. Overall, the feedback offers some guidance but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability to other domains. It also suggests verifying whether the method works with discrete action spaces and highdimensional observations. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to conduct additional experiments on a different benchmark and to test the method\"s performance in various scenarios. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation being conducted only on the Meta World domain, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the results may not generalize to other domains and suggests running experiments on a different benchmark like Atari to verify this. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited to a single domain, Meta World, and suggests that this makes it difficult to judge the method\"s generalizability to other domains. The reviewer recommends running experiments on a different benchmark, such as Atari, to verify the method\"s performance in various domains. This claim is 3 as it provides a logical reasoning for the need to test the method on different domains and suggests a specific benchmark for evaluation. However, the comment lacks specific examples or references to support the claim that Atari is a commonly used benchmark or that it would be an appropriate choice for testing the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, which is only tested on the Meta World domain. It highlights the difficulty in judging the method\"s generalizability to other domains due to this limited evaluation. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a different benchmark, such as Atari, which is commonly used in the literature. This suggestion not only helps the authors to broaden the evaluation scope but also to verify the method\"s performance in different scenarios, including discrete action spaces and highdimensional observations. The feedback is detailed and constructive, offering a clear path for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete. However, it suggests that there is a missing analysis of what the model does, which could be interesting. The comment implies that the authors should include this analysis, but it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. However, it does not specify which part of the paper lacks this analysis, making it weakly grounded. The comment is specific in suggesting that an analysis of the model\"s behavior could be interesting, but it does not provide detailed guidance on what aspects of the model should be analyzed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. The comment suggests that this analysis could be interesting, but it does not provide specific examples or reasoning to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the presentation of the method and the completeness of the experiments, which is a positive observation. However, it points out a missing analysis of what the model does, suggesting that this could be an interesting aspect to explore. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects of the model\"s behavior should be examined. This limits the helpfulness of the feedback, as the authors are left with a general idea of what to consider but without detailed instructions on how to implement it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions whether it might lead to scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the modulator\"s design. The comment lacks actionable details, such as recommending alternative approaches or methods for addressing scalability issues. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the modulator\"s design and potential scalability issues but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, the comment lacks specific examples or references to support the claim that the modulator might lead to scalability issues or the need for tedious hyperparameter tuning. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the heuristic design of the modulator, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the modulator\"s design. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it highlights an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experiments performed, noting that while f_R and f_P can be adapted over time, they incorporate a significant amount of domain knowledge. The comment suggests that a less informed version of f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experiments. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the experiments and the adaptation of f_R and f_P over time, incorporating domain knowledge. However, it does not specify which part of the paper this discussion is based on, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in its critique of the experiments and the potential need for more data, but it lacks grounding due to the lack of explicit references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might make a less informed version of f_R/f_P require an impractical amount of data to learn. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment highlights a potential issue with the experiments, noting that while f_R and f_P can be adapted over time, they incorporate a significant amount of domain knowledge. The comment suggests that a less informed version of f_R/f_P might require an impractical amount of data to learn. This feedback is 3 as it points out a potential limitation in the experimental setup and the potential need for more data. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their experiments. To be more helpful, the comment could provide recommendations or examples of how to adapt the experiments or incorporate more data. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It suggests that the authors should conduct experiments to address these issues. While the comment implies that the authors should conduct experiments, it does not provide specific guidance on how to design these experiments or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of experiments on obtaining labeled data for imitation learning and how performance changes with varying data sizes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for experiments on data acquisition and performance variation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are difficulties in obtaining labeled data for imitation learning and that the performance changes depending on the size of the labeled data. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It highlights the need for experiments to address these issues, which is a valuable insight for the authors. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use. Despite this, the feedback is clear and actionable, offering a clear direction for the authors to improve their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion but considered a serious question. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore this connection further but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the authors acknowledge this in the conclusion, the comment suggests it is a serious question. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the connection between robust memorization and generalization, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion. However, the comment does not provide specific evidence, examples, or references to support this claim, making it 3. The authors are left to infer the reasoning behind the concern, which could be clarified with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the relationship between the necessary conditions for robust memorization and generalization bounds. It points out that while the paper acknowledges this issue in the conclusion, it is a serious concern that needs further exploration. The comment highlights a potential gap in the paper\"s analysis and encourages the authors to delve deeper into this connection. However, it does not provide specific suggestions or guidance on how to address this issue, leaving the authors with a general direction but without detailed steps to take. While the comment identifies an important area for improvement, it lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images, as shown in recent papers. It also recommends comparing the current method with these types of methods. While the comment implies that the authors should include this information and comparison, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss and compare their method with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention the use of untrained neural networks (like deep image prior) for solving inverse problems and to place the current method in context by comparing it with those methods. This level of detail guides the authors on what needs to be addressed and how to improve their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s claim of strong OOD generalization by the trained network is interesting but notes that recent papers have shown that untrained neural networks can solve inverse problems across a wide class of images. The reviewer recommends mentioning this in the paper and comparing the current method with those approaches. While the comment provides a logical reasoning for the suggestion, it lacks specific references to the papers that demonstrate the effectiveness of untrained neural networks. This makes the claim 3, as the authors would need to conduct further research to fully understand the context and make the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interest in the OOD experiments, noting the strong OOD generalization of the trained network. However, it suggests that the authors should place their method in context by mentioning recent papers that have shown the effectiveness of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images. This feedback is 3 as it points out an area where the authors could enhance their paper by providing a broader context and comparison with existing work. While the comment identifies a potential improvement, it lacks specific guidance on how to incorporate this information or conduct the comparison, which would make it more actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The suggestion is concrete, as it specifies the types of experiments and references potential sources, but it is implicit in nature. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the types of experiments and providing references, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. It provides references to specific papers (1 MoBiNet, 2 Dynamic Channel Pruning, and 3 Learning Dynamic Routing) that could serve as examples or inspiration for these experiments. This provides a clear rationale for the suggestion, as the references offer concrete examples of how deeper networks and other structures have been explored in related work. The inclusion of references enhances the verifiability of the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would contribute to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from additional experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to further strengthen its findings. It provides specific references to papers that have explored similar approaches, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing. This feedback is clear and actionable, as it directs the authors to conduct specific experiments that could enhance the paper\"s contributions. However, the comment could be more helpful if it included a detailed explanation of why these experiments are necessary or how they would impact the paper\"s results. Overall, the comment is 4 as it provides a concrete suggestion for improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit guidance on how the authors might address this issue. There is no suggestion for additional experiments, modifications, or clarifications that could help resolve the ambiguity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper discusses this mechanism, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the mechanism are unclear or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the limited scope of the models evaluated in the results/analysis, noting that only two relatively old and small models are considered. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should include more models, newer models, or larger models in their evaluation. Without specific actions or recommendations, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results/analysis section, indicating that it is detailed and comprehensive but limited in scope due to the evaluation of only two relatively old and small models. However, it does not specify which part of the results/analysis section this critique pertains to, such as specific tables, figures, or sections. The authors can make an educated guess about the general area being discussed, but the comment lacks full grounding. It is specific in pointing out the limitation in model evaluation, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results/analysis are detailed and comprehensive but limited because only two relatively old and small models are evaluated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why these models are considered \"old\" or \"small\" or why their evaluation is insufficient. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of the results/analysis, noting that only two relatively old and small models are considered. While this feedback identifies a potential weakness in the scope of the evaluation, it lacks specific suggestions or guidance on how the authors might address this issue. The comment does not provide actionable advice on which models to include, how to expand the evaluation, or what specific aspects of newer or larger models should be considered. As a result, the authors are left without a clear path for improvement, making the comment 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is explicit and concrete, as it specifies exactly what information is needed to clarify the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to clarify why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the performance degradation in FBN results when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance degradation in FBN results when using additional information about missing, wrong, or redundant data. By asking the authors to provide clarification on this issue, the comment prompts the authors to address a potential weakness in their analysis. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out an area for improvement, it does not provide actionable feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is unclear and suggests that the introduction should be revised to make the paper easier to follow. However, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is explicit but vague, as the authors know they need to revise the introduction but lack detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation is unclear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction is unclear or what aspects of the motivation need clarification. The authors can infer that it relates to the introduction, but the comment lacks full grounding as it does not explicitly mention a specific section or element. Additionally, the comment is not specific about what needs to be addressed or how the introduction should be revised. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation is unclear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1, as it does not provide sufficient evidence or justification for the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It provides a clear and actionable suggestion by recommending that the introduction be revised to make the paper easier to follow. However, the comment lacks specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. While it points out a critical area for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to clarify the motivation. Therefore, the comment is 3, as it directs the authors to a key area for improvement but does not fully guide them in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of varying features and positions across categories or how to incorporate multiple local prompts effectively. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, it does not specify which part of the paper this observation is based on, nor does it provide guidance on how to address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed feedback on what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. This observation highlights a potential issue with the current approach, indicating that the authors should consider how to address this variability. However, the comment lacks specificity and does not provide actionable guidance on how to improve the draft or address the issue of varying features and positions. Without detailed suggestions or examples, the authors may find it challenging to incorporate this feedback into their work. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the validation process. The action is implicit, as the authors need to infer that they should focus on validating the alignment, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of insufficient validation but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. While the comment highlights a potential weakness in the paper, it lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue. Without specific recommendations or examples, the authors may find it challenging to improve the validation process. Therefore, the comment is 3, as it points out a concern but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and only provides indistribution testing for these samples. The reviewer suggests that the value of the method would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their experiments. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to a broader range of molecules or exploring alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the paper for only conducting experiments on a limited number of molecules and only providing indistribution testing for these samples. It suggests that the value of the method would be limited if it requires training for each molecule individually. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the experimental scope and limitations but lacks grounding, as it does not clearly identify the sections or experiments being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a small number of molecules and indistribution testing. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar studies or experiments that might have achieved broader applicability, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that it only conducts experiments on a limited number of molecules and only provides indistribution testing for these samples. The reviewer suggests that this limitation could restrict the value of the method, as it would require training for each molecule individually. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or expand their experiments to a broader range of molecules. The feedback is 3 as it points out a key area for improvement but lacks actionable advice, making it incomplete for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to clarify the source of the test data and the existence of a ground truth, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking about the source of the test data and the existence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking about the source of the test data and the existence of a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about Figure 3, asking about the source of the test data and whether there is a ground truth. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this issue or improve the figure. The comment is clear in its questioning but lacks actionable feedback or constructive advice, making it 3. The authors are left to infer that they need to address the question, but without specific guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the paper is not wellwritten and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the paper\"s writing quality and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are problematic, nor does it provide detailed guidance on how to improve the presentation or formatting. This makes it difficult for the authors to identify the exact areas that need attention. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"not very wellwritten\" and suggests it may have been written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without concrete evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a general critique of the paper\"s writing quality, suggesting that it may have been written in a hurry, which makes it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not offer any actionable advice or suggestions on how the authors might improve the writing, presentation, or formatting. Without concrete guidance or examples, the authors are left without a clear understanding of what changes are needed to enhance their draft. Therefore, the comment is 2, as it identifies a general issue but does not provide sufficient detail or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper\"s results in relation to prior work. It suggests that if the paper\"s contribution is not as novel as claimed, it should do a better job of highlighting its originality. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s results in relation to prior work, specifically mentioning the occurrence of samplewise multiple descent in linear regression. It suggests that the paper should better highlight its contribution, particularly regarding the removal of double descent in certain anisotropic settings. However, the comment does not specify which part of the paper discusses these results or how the novelty should be highlighted, making it weakly grounded. The comment is specific in its request for the authors to clarify the novelty of their results, but without explicit references to sections or specific elements, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper\"s results in relation to prior work, specifically mentioning that prior work has already theoretically shown samplewise multiple descent in linear regression. The reviewer suggests that the paper\"s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings. However, the comment does not provide specific references or detailed reasoning to support the claim that the paper\"s contribution is novel. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s results in relation to prior work. It points out that prior studies have already theoretically shown samplewise multiple descent in linear regression, which could impact the perceived originality of the paper\"s contribution. The reviewer suggests that if the paper\"s contribution is not as novel as claimed, it should do a better job of highlighting its originality in relation to prior results. This feedback is 3 as it prompts the authors to clarify the novelty of their findings and potentially reframe their contribution in the context of existing work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to highlight the paper\"s originality. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the ablation studies of MCT without adaptive metrics. While it identifies areas of potential concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to investigate and clarify these discrepancies, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the alignment of results and the absence of ablation studies for MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the absence of ablation studies for MCT without adaptive metrics. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises two specific questions about the results presented in the paper. It questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Additionally, it asks about the absence of ablation studies for MCT without adaptive metrics, suggesting that this could be an important aspect to explore. While the comment identifies potential issues, it does not provide detailed guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for further investigation, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all of them with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not explicitly instruct the authors to add more discussions or specify what kind of discussions are needed. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but are not provided with concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the 10 subtasks in the context of bAbi, suggesting that they are too simplistic and that the authors could solve all of them with their final model. However, it does not specify which part of the paper these subtasks are discussed in, making it weakly grounded. The comment is specific in suggesting that more discussions are required, but it lacks detailed guidance on what aspects should be discussed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for bAbi and that the authors could solve all of them with their final model. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks in the context of bAbi, suggesting that the authors could solve all of them with their final model. It implies that the paper lacks depth in its discussions, particularly regarding the complexity and challenges of these subtasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the discussion. While it highlights a potential area for improvement, the feedback lacks actionable details, making it 3. The authors are given some insight into a potential weakness but are not fully directed on how to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes might be necessary to clarify the nature of the study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the study\"s classification, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This claim is based on a logical reasoning that ablation studies typically involve removing or varying a specific component to assess its impact. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the context of their study and the typical definitions of ablation studies to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This feedback is 3 as it points out a potential misunderstanding or mislabeling in the study\"s methodology. However, it lacks depth and does not provide specific guidance on how the authors might clarify or correct this classification. The comment identifies a potential issue but does not offer actionable steps for improvement, leaving the authors with a general direction but not a clear path forward. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. While it suggests exploring this idea, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should consider this possibility, but it lacks specificity and detail on how to implement or evaluate this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion by asking if it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This level of detail provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be beneficial or how it relates to the current work. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. This suggestion provides a potential direction for the authors to explore, offering a way to enhance the applicability and utility of their work. However, the comment lacks depth and does not provide specific guidance on how to integrate AccNet into a larger predictor or what benefits this might bring. While it offers a starting point for further exploration, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, implying that the authors should expand their testing to multiple datasets to validate the metric\"s robustness. However, the comment does not provide explicit guidance on which datasets to use or how to conduct the testing. The action is implicit and somewhat vague, as the authors can infer that they need to test the metric on more datasets but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the testing of the new proposed metric, specifically noting that it is only tested on a single dataset. However, it does not specify which part of the paper this issue is discussed in, such as a specific section or table where the metric is introduced. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the limitation of testing on a single dataset, but without explicit grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which could be a limitation in the evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this limitation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is 3 as it identifies a potential weakness in the paper\"s methodology, suggesting that the authors should consider testing their metric on multiple datasets to enhance its robustness and generalizability. However, the comment lacks specific guidance on which datasets to use or how to conduct the testing, which would make it more actionable. To be fully helpful, the comment could include suggestions or examples of additional datasets that could be used for testing. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN, in addition to the proposed TransferNorm architecture. This implies that the authors should include these competitors in their evaluation to make the comparison more comprehensive. However, the comment does not provide specific guidance on how to implement this suggestion, such as which specific experiments to conduct or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not fully understand the scope of the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation would be stronger if the base DA methods were compared with and without architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This provides clear guidance on what needs to be addressed to enhance the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. The comment provides a logical reasoning for the suggestion, as it implies that including these competitors would provide a more comprehensive comparison. However, the comment lacks specific examples or references to support the claim that AutoDial and AdaBN are direct competitors to TransferNorm, which would strengthen the argument. Therefore, the claim is 3, as it provides a logical basis but requires additional evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment provides a constructive suggestion for enhancing the evaluation section of the paper. It acknowledges the current evaluation as a good start but suggests that it could be strengthened by including comparisons with architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This feedback is actionable and offers a clear direction for the authors to improve their evaluation methodology, making it 4. However, the comment could be more helpful if it provided specific guidance on how to incorporate these competitors into the evaluation or what aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their evaluation, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues: undefined abbreviations and superscript notation in an equation. It provides examples of the undefined abbreviations and the specific line numbers where the issues occur. This feedback is explicit and concrete, as it clearly instructs the authors to define the abbreviations and superscript notation to improve the clarity of their draft. The inclusion of references to relevant literature adds context and supports the need for clarification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issues with undefined abbreviations and superscript notation, providing clear guidance on what needs to be addressed. The inclusion of references to relevant literature adds further context and specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined and that superscript notation in an equation is not explained until later, which hinders understanding. The reviewer provides specific examples, such as \"NE\" on line 73 and the superscript notation in equation 6, which are not defined until much later. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more context or examples of how these issues impact the reader\"s understanding. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and superscript notation in an equation that is not explained until later. This feedback is actionable as it provides clear guidance on what needs to be addressed to improve the clarity and readability of the draft. By pointing out these specific areas, the comment empowers the authors to make targeted improvements, enhancing the overall quality and comprehensibility of their work. However, the comment could be more helpful if it included suggestions on how to define the abbreviations or explain the superscript notation in a way that is clear to readers. Overall, the comment is 4, as it effectively directs the authors to areas needing improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to strengthen the evaluation or which alternative baselines might be more suitable. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved for fair classification. Without explicit references to sections or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation methodology, specifically noting that the baselines used are not designed for fair classification. This is a critical observation that could impact the validity and reliability of the results. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative baselines that could be more appropriate. Without detailed suggestions or examples, the authors are left with a general understanding of the problem but without a clear path forward for improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to clarify the setting in the first three paragraphs of section 2. It implies that the current presentation may give the impression of a more general contribution than what is actually made, which \"muddles the exposition.\" However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be expanded upon. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the setting needs to be clarified more clearly, implying that the current presentation may give the impression of a more general contribution than what is actually made. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their contribution. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references leaves the claim 3, as the authors would need to infer the exact areas that need clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting their work as more general than it actually is, which \"muddles the exposition.\" This feedback is 3 as it points out a potential area for improvement in the clarity and accuracy of the paper\"s presentation. However, it lacks detailed guidance on how to clarify the setting or what specific aspects need to be expanded upon. While it provides some direction, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the authors should either test their method on these newer approaches or explain the advantage of their method compared to these alternatives. While the action is implicit, it is concrete in suggesting specific alternatives to consider, making it 4.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment is fully grounded as it explicitly mentions the experiments section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the proposed method works on these newer 3D CNNs and what advantage it offers compared to them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the proposed method should be compared to these newer approaches to demonstrate its advantage. However, the comment does not provide specific examples or references to support the claim that these newer approaches are superior or more relevant. This lack of detailed justification makes the claim 3, as the authors would need to conduct additional research to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment also prompts the authors to explain whether their method works on these newer 3D CNNs and what advantage it offers compared to them. This feedback is clear and actionable, as it identifies a specific area for improvement and provides concrete suggestions for enhancing the experimental section. By addressing these points, the authors can strengthen their paper and provide a more comprehensive comparison of their method with existing approaches. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the improvements over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance on what specific aspects of the analysis should be expanded upon or how the authors might improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to conduct more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements over previous works and selfimplemented baselines, suggesting that they are marginal. However, it does not specify which tasks or experiments are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures, and it is also not specific about what aspects of the analysis are insufficient. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, and that further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the improvements over previous works and selfimplemented baselines are marginal. It suggests that further analysis beyond the main experiments is necessary. However, the comment lacks specificity and does not provide actionable guidance on what aspects of the analysis should be expanded or how the authors might improve their results. Without detailed suggestions or examples, the authors are left with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the paper, specifically that the main theoretical result provides utility guarantees only under the assumption of Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific issue and suggests a comparison with existing literature, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it details the issue with the theoretical result, namely that it provides utility guarantees only under the assumption of Gaussian features and noise, and suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only under the assumption of Gaussian features and noise, which is a strong requirement on the data. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. The claim is 3 as it provides a logical reasoning about the limitation of the theoretical result and suggests a comparison with existing literature. However, the comment lacks specific references or examples of existing rates in the literature, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically that the main theoretical result provides utility guarantees only under the assumption of Gaussian features and noise. This is a critical observation that highlights a strong requirement on the data, which may limit the applicability of the proposed algorithm. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which would provide a more comprehensive understanding of the algorithm\"s performance. This feedback is clear and actionable, as it directs the authors to address a specific theoretical limitation and to provide a comparison with existing literature, which could significantly enhance the paper\"s impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how this comparison should be conducted or what aspects should be focused on, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the comparison are missing. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in suggesting a comparison but does not provide detailed guidance on how to conduct it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests a useful comparison between the proposed extension and the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including a comparative analysis. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or what aspects to focus on. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It implies that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., 1,2,3), are necessary. However, the comment does not specify which additional works should be included or how the experiments should be conducted. While the action is clear, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, referencing specific works (1,2,3) that focus on the same questions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It suggests that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., 1,2,3), are necessary. However, the comment does not provide specific examples or detailed reasoning to support why these additional comparisons are crucial or how they would enhance the paper. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of these additional comparisons based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that additional comparisons with other works that focus on the same questions would be beneficial to demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental section. However, the comment could be more helpful if it included specific examples of works that should be considered or detailed guidance on how to conduct these additional comparisons. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a subjective opinion about the content of the paper, suggesting that the zeroshot version and its connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or whether it should be included in the paper. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of the zeroshot version and its connection to density estimation, suggesting that it distracts from the main point of the paper. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by explaining the perceived distraction, but without clear grounding, the authors cannot confidently determine where to make changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the content of the paper, suggesting that the zeroshot version and its connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. It lacks specific examples or detailed explanations of how these elements are distracting or how they could be improved. Without such support, the claim remains 1, as it does not provide the authors with a clear understanding of the issue or guidance on how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a subjective opinion about the content of the paper, suggesting that the inclusion of the zeroshot version and its connection to density estimation is distracting from the main point. However, the comment acknowledges that this is more of an aesthetic argument than a technical one, implying that it may not be a critical issue. While the comment identifies a potential distraction, it lacks actionable guidance or suggestions for the authors to address this issue. Without specific advice or examples, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information about the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. The comment specifies what information is lacking and what needs to be addressed, making it 5. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this information and how it impacts the dataset quality. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. By addressing this point, the authors can enhance the transparency and credibility of their dataset, which is crucial for the validity of their research. However, the comment could be more helpful if it provided specific suggestions on what aspects of the filtering process should be detailed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more information about the performance differences resulting from using different image sizes and variations of ResNets. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion or analysis of the performance differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the performance differences resulting from using different image sizes and variations of ResNets. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information about the performance differences resulting from using different image sizes and variations of ResNets. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more information about the performance differences resulting from using different image sizes and variations of ResNets. This feedback is clear and actionable, as it directs the authors to include a specific analysis or discussion that could enhance the comprehensiveness of their paper. However, the comment could be more helpful if it offered guidance on how to present this information or why it is important. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions or context."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not provide specific guidance on what aspects of the algorithm need detailed description or how to present it effectively. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references or clear guidance on what aspects need detailed description, the authors cannot confidently determine the exact part of the paper being addressed. This makes the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what aspects of the algorithm should be described or how to improve the presentation. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on what aspects of the algorithm need detailed description or how to present it effectively. The comment does not offer any concrete suggestions or examples, leaving the authors with a general idea of what might need attention but without a clear path for improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should consider adding a runtime comparison but are not given specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Chebyshev polynomials, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular aspect that could be explored further: a runtime comparison at test time. This provides clear guidance on what the authors could add to enhance their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the paper\"s content and relevance. However, the comment could be more helpful if it offered guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether there is existing work that offers a way to approximate the contribution of FFNs, given that a linear decomposition cannot be obtained. It suggests that if no such work exists, the authors should add a statement indicating that it is an open problem. This feedback is explicit in its request for additional information and provides a clear direction for the authors to follow. The suggestion to add a line or two to address the issue is concrete, as it specifies what the authors should do to improve the readability and clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider existing work that might offer a way to approximate the contribution of FFNs, and if not, to acknowledge the lack of a solution and label it as an open problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, and it suggests that the authors should consider whether existing work offers a way around this limitation. The comment implies that the absence of such work is a gap in the paper, but it does not provide specific references or detailed reasoning to support this claim. While the suggestion to acknowledge the lack of a solution and label it as an open problem is reasonable, the comment lacks sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a relevant question about the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider whether existing work offers a way to approximate the contribution of FFNs, and if not, to acknowledge the lack of a solution and label it as an open problem. This feedback is helpful as it prompts the authors to address a potential gap in their work and provides a clear direction for improvement. By acknowledging the limitation and the absence of a solution, the authors can enhance the readability and clarity of their paper, giving the reader a more comprehensive understanding of the challenges involved. However, the comment could be more helpful if it provided specific examples or references to existing work that might offer approximations. Overall, the comment is 4, as it offers actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the impact of the number of images on the model performance and another about the explanation of BYOL in the abstract. While the questions are clear and imply that the authors should address these points, they do not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and report on the impact of image numbers and provide a detailed explanation of BYOL. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on the model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image numbers and the explanation of BYOL, but without clear references to specific sections or parts of the paper, the authors may find it challenging to pinpoint where these issues need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on the model performance and requests clarification on the explanation of BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two important questions about the paper. First, it questions how the number of images impacts the model performance, which is a critical aspect of understanding the robustness and generalizability of the model. Second, it requests clarification on the explanation of BYOL in the abstract, which is a relevant point for readers who may not be familiar with the acronym. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their explanation. While it identifies areas for improvement, the feedback is 3 as it points out important aspects that need clarification but does not provide detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that while the observed effects are strong, the paper lacks clarity on why the method works, particularly regarding the L_pixel component. It explicitly recommends providing stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and justification of the method\"s effectiveness. The comment provides a specific and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the clarity of the paper regarding the effectiveness of the method, specifically the L_pixel component. It suggests that while the observed effects are strong, the paper lacks explanation on why the method works, particularly for this component. The comment provides a clear direction for improvement by recommending stronger arguments or intuitions to explain the benefits of the particular losses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, so it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding why the method works, particularly for the L_pixel component. It suggests that stronger arguments or intuitions are needed to explain why these particular losses are beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the explanation of why the method works, particularly for the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and justification of the method\"s effectiveness. By addressing this issue, the authors can improve the clarity and comprehensiveness of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the baseline metric but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. The reviewer provides a logical reasoning for their skepticism, suggesting that binary classification may not be suitable for evaluating models\" understanding of finegrained errors. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. This is a valid point that highlights a potential limitation in the evaluation approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their baseline metrics. While it identifies a weakness, it lacks actionable feedback, making it 3. The authors are given some insight into a potential area for improvement but are not provided with detailed steps to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. It implies that the authors should provide a clearer understanding of when to use SynTextBench over other metrics. While the comment explicitly suggests a comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to make a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and \"the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of SynTextBench with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. The comment provides a clear direction for improvement by suggesting a comparison and highlighting the need for clarity on when to use SynTextBench over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. The reviewer acknowledges that some metrics may not satisfy the proposed desiderata but emphasizes the importance of comparing SynTextBench with existing metrics. This claim is 3 as it provides a logical reasoning for the comparison, but it lacks specific examples or references to support the claim. The authors would need to conduct their own research to fully understand the comparison, making the comment 4.", "helpfulness_rationale": "The review comment suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. It highlights the importance of understanding under what conditions SynTextBench should be used over other metrics. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing a gap in the evaluation of their metric. However, the comment could be more helpful if it offered examples or specific criteria for comparison. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific guidance or suggestions on how to improve the clarity or readability of the text. There is no explicit or implicit action for the authors to take, such as revising certain sections or providing additional explanations. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations\" as being \"a little hard to follow,\" but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it refers to the introduction, methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic, such as unclear sentences, missing explanations, or inadequate labeling. Without clear guidance on where to focus improvements, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"poor writing and annotations are a little hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to particular sections or issues, the authors may find it challenging to understand and address the problem. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing and annotations being \"a little hard to follow,\" which is a common problem in academic papers. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their text. Without detailed guidance or examples, the authors are left without a clear understanding of what changes to make or where to focus their efforts. As a result, the comment is 1, as it does not offer any actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under the \"Twitter2017 \u2192 Twitter2015\" setting. While the comment highlights areas of concern, it does not provide explicit instructions or suggestions for the authors to address these issues. The authors are left to infer that they should investigate and clarify these discrepancies, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for further investigation but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\"s performance, noting that only 8 out of 14 evaluation metrics achieve stateoftheart performances. Additionally, it raises a question about the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. While the comment highlights areas of concern, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This feedback is 3 as it identifies a potential issue with the method\"s performance and prompts the authors to investigate and clarify these discrepancies. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns. To be more helpful, the comment could include recommendations for improving the method or suggestions for further analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should reconsider their approach, but it lacks concrete details on how to implement this change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the rationale behind only considering ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology, making it weakly grounded. The comment is specific in its critique, as it clearly outlines the concern about the labeling approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind only considering ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, the comment does not provide any supporting evidence, reasoning, or references to justify why including all reports would be easier or more beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the methodology used in the paper, specifically why only ECG segments with one label are considered. It suggests that including all reports might be more beneficial, implying that the current approach might be limiting. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or why including all reports would be advantageous. While it identifies a potential area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it prompts the authors to consider an alternative approach but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This implies that the authors should increase the complexity of their instances to better test the capabilities of LLMs. However, the comment does not provide specific guidance on how to achieve this or what specific constraints or variables should be added. While the action is implicit, it is somewhat concrete in suggesting a direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This implies a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in suggesting the need for more complex instances, but without clear grounding, the authors may struggle to identify the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This claim is based on the observation that the instances in the paper are limited in complexity, which raises concerns about the ability of LLMs to model problems with larger instance sizes. However, the comment lacks specific examples or references to support the claim that instances with more than 7 variables are necessary or beneficial for testing LLMs. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is considered 2, as it provides some justification but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, specifically noting that the instances used have fewer than 8 variables, which raises concerns about the ability of LLMs to model problems with larger instance sizes. This feedback is 3 as it points out an area where the authors could improve their experimental setup by generating instances with more constraints and variables. However, the comment lacks specific guidance on how to achieve this or what specific variables or constraints should be added, which limits its usefulness. To be more helpful, the comment could include suggestions or examples of how to increase the complexity of instances. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines or perspectives should be included or how to implement these suggestions. The action is explicit but lacks concrete details, making it 3. The authors know they need to involve other baselines but may not be entirely sure how to execute this suggestion effectively.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines, but without clear grounding, the authors may find it challenging to determine where to incorporate these suggestions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. The comment references specific references (16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45) that could support this claim, indicating that the authors should consider these references for their work. However, the comment does not provide detailed reasoning or examples of how these references relate to the suggestion, making it 3. The authors would need to consult the referenced works to fully understand the basis of the suggestion, which adds a layer of complexity to the verification process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper by considering additional baselines and perspectives. However, the comment could be more helpful if it included examples or references to specific baselines or studies that the authors could draw upon. Despite this, the suggestion is valuable and offers a clear direction for improvement, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of the paper\"s contributions. This is a clear and direct action that the authors can take to improve their draft. The comment specifies exactly what needs to be added, providing concrete guidance on how to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions are needed. However, it does not specify which part of the paper this should be included in, such as the abstract, introduction, or conclusion sections. Without explicit references to these sections, the authors may find it challenging to determine where to make these additions. The comment is specific in its request for a conclusion and summary but lacks grounding due to the absence of specific references. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions are necessary. However, it does not provide any reasoning, examples, or references to support why these elements are missing or why they are important. Without additional context or justification, the authors may find it challenging to understand the significance of this feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a clear gap in the paper by pointing out the need for a brief conclusion and a summary of the paper\"s contributions. This feedback is actionable and provides a specific direction for the authors to enhance their draft. By addressing this suggestion, the authors can better conclude their work and highlight its significance, which is crucial for readers and reviewers. However, the comment could be more helpful if it offered guidance on what aspects to include in the conclusion or how to effectively summarize the contributions. Overall, the comment is 4 as it directs the authors toward a necessary improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is explained in relation to the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide an explanation, but it lacks concrete details on what kind of explanation is needed or how to present it. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how the data distribution illustrated in Figure 1 is explained in relation to the network model, particularly in the context of a nonseparable case. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the explanation of the data distribution illustrated in Figure 1 in the context of a nonseparable case, suggesting that the nonlinear expression ability of neural networks should be considered. However, the comment does not provide specific reasoning, examples, or references to support why this is a problem or how it relates to the network model. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is explained in relation to the network model. This feedback highlights a specific area where the authors might need to provide more detailed explanations or justifications, particularly considering the nonlinear expression ability of neural networks. However, the comment does not offer specific suggestions or guidance on how to address this issue, leaving the authors with a general direction but without actionable steps. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion to elaborate on Theorem 4.1. The first part is explicit in pointing out a specific line in the paper that needs clarification, but it does not provide detailed guidance on how to address the issue. The second part suggests elaborating on Theorem 4.1, but it lacks specific instructions on what aspects to focus on or how to provide the additional explanation. While the comment implies that the authors should clarify the statement and provide more detail on Theorem 4.1, the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the statement on line 134 should be clarified, and Theorem 4.1 should be elaborated upon, particularly regarding the intuitive reasoning behind why the RNN will converge to the nearest fixed point. This level of detail helps the authors understand exactly what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion to elaborate on Theorem 4.1. The first part is a factual observation about the sigmoid function, which is supported by the reference to \"1+exp(x)^1.\" The second part suggests elaborating on Theorem 4.1, providing a logical explanation for why the RNN will converge to the nearest fixed point. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct aspects of the paper. First, it points out a statement on line 134 that is only true for the standard sigmoid function and suggests that the authors should clarify this dependency. Second, it recommends elaborating on Theorem 4.1 by explaining why the RNN will converge to the nearest fixed point, particularly in comparison to the URNN. This feedback is clear and actionable, as it directs the authors to address specific areas of their work that require further explanation or clarification. By following this feedback, the authors can enhance the clarity and comprehensiveness of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment encourages the authors to perform this exercise, it does not provide specific guidance on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the suggested experiment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the use of a single heldout test set in nearly all experiments. It suggests that standard practice involves using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The comment is fully grounded as it explicitly mentions the experimental setup, allowing the authors to identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experimental setup and encourages the authors to use multiple train/test splits or folds. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the standard practice in papers on Gaussian Processes (GPs) involves using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. The reviewer acknowledges that the size of the datasets might make this process timeconsuming but encourages the authors to conduct this exercise. The comment is based on common knowledge and practice in the field, providing a logical reasoning for the suggestion. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single heldout test set, which is not standard practice in papers on Gaussian Processes (GPs). It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. The comment acknowledges the potential timeconsuming nature of this process due to the size of the datasets but encourages the authors to conduct this exercise. This feedback is clear and actionable, providing the authors with a specific suggestion for improving the robustness and comprehensiveness of their experimental results. However, it could be more helpful if it offered guidance on how to implement this suggestion or discussed potential benefits. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests toning down a specific statement regarding the neural network memorizing critical points, which is a clear and direct instruction. Second, it advises compressing the method section to focus on essential definitions, which is a concrete suggestion for improvement. Additionally, it requests the authors to doublecheck for grammatical errors, particularly with plurals and articles, providing a specific example (\"e.g. l\"). These actions are explicit and provide concrete guidance, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"to force the neural network to memorize them\" and references TopoNet 24, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests toning down a particular statement and provides feedback on the method section, suggesting it could be compressed and pointing out grammatical errors. Additionally, it offers a specific example of a grammatical error to check. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network memorizing critical points is supported by a reference to TopoNet 24, which provides some basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from TopoNet to fully substantiate the claim. The suggestion to tone down the statement is logical but lacks specific guidance on how to do so. The second part of the comment, regarding the method section being wordy and suggesting compression, is a general suggestion without specific examples or reasoning. The third point, about grammatical errors, is factual and does not require verification. Overall, the comment is 4, as it provides some support but lacks detailed examples or references to fully substantiate the claims. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides several actionable points for improvement. It suggests toning down a statement regarding the neural network memorizing critical points, which could help clarify the authors\" understanding of their model\"s behavior. Additionally, it advises compressing the method section to focus on essential definitions, which could enhance the clarity and concision of the paper. The comment also points out grammatical errors, specifically mentioning plurals and articles, and provides an example, which is helpful for the authors to address these issues. However, the comment could be more helpful if it provided specific examples of wordy sections or suggested ways to improve the clarity of the method section. Overall, the feedback is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the initial rationale selector being \"perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what aspect of the paper needs clarification or further explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the initial rationale selector is \"perfect,\" suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"perfect\" in the context of the initial rationale selector, suggesting that if it were perfect, no additional work would be needed. This feedback identifies a potential ambiguity or confusion in the paper and prompts the authors to clarify their rationale. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it highlights a point that needs attention, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate comments. The first part raises a question about whether the authors experimented with domain ontologies to avoid placeholder generation in the evaluated responses. This is an implicit action, as it suggests that the authors should consider this aspect in their experiments. However, it lacks specificity and does not provide concrete guidance on how to implement this suggestion. The second part of the comment asks for specific details about the number of questions created for the zeroshot intent classifier and its accuracy. This is an explicit request for additional information, making it 3. Overall, the comment provides some guidance but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the experimentation with domain ontologies to avoid placeholder generation and the details about the zeroshot intent classifier, such as the number of questions created and its accuracy. This provides clear guidance on what aspects of the paper require further clarification or elaboration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim questions whether the authors experimented with domain ontologies to avoid placeholder generation in the evaluated responses. This claim is 3 as it raises a logical question about the experimental setup, but it lacks specific evidence or references to support the suggestion that domain ontologies should be used. The second claim asks for specific details about the number of questions created for the zeroshot intent classifier and its accuracy. This part of the comment is verifiable as it requests factual information that could be easily provided by the authors. However, the first part of the comment is less verifiable due to the lack of supporting evidence or references. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas that need clarification or expansion. First, it questions whether the authors experimented with the use of domain ontologies to avoid the generation of placeholders in the evaluated responses. This is a relevant point that could enhance the comprehensiveness of the study. Second, it requests specific details about the number of questions created for the zeroshot intent classifier and its accuracy. This feedback is actionable as it prompts the authors to provide additional information that could strengthen the paper. However, the comment could be more helpful if it offered suggestions on how to address these points or provided examples of how domain ontologies could be applied. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a missing aspect in the paper, which is the lack of citations to contextualize the work within the broader field of MultiAgent Reinforcement Learning (MARL). It specifically mentions recent papers on selfplay and populationplay, providing examples of relevant works like https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This feedback is clear and actionable, as it instructs the authors to include these citations to better situate their work within the existing literature. The authors know exactly what needs to be done to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the work in the context of other MARL work, specifically referencing recent papers on selfplay and populationplay. It provides specific examples of papers that should be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail allows the authors to accurately identify the parts of the paper that need revision and understand what is missing. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to contextualize it within the broader field of MultiAgent Reinforcement Learning (MARL), specifically mentioning recent papers on selfplay and populationplay. The reviewer provides specific examples of papers that should be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail provides a clear and specific justification for the claim, making it 5. The authors can easily understand what is missing and how to address it by incorporating these references. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, which is the lack of citations to contextualize the work within the broader field of MultiAgent Reinforcement Learning (MARL). It suggests including recent papers on selfplay and populationplay, such as those referenced in https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, to provide a more comprehensive understanding of the work. This feedback is clear and actionable, as it directs the authors to specific references that can enhance the context and relevance of their paper. By incorporating these citations, the authors can better position their work within the existing literature, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify which specific methods should be compared or how the comparison should be conducted, leaving some room for interpretation. Despite this, the action is concrete in its suggestion to explore alternative selfsupervised learning methods. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods not based on contrastive learning. However, it does not specify which part of the paper this suggestion should be applied to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding which alternative methods should be considered or how the comparison should be conducted. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the work with other selfsupervised learning methods not based on contrastive learning. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is a clear and actionable suggestion that could help the authors broaden the scope of their study and provide a more comprehensive evaluation of their approach. By considering alternative methods, the authors can better understand the strengths and weaknesses of their work and potentially identify areas for further improvement. However, the comment could be more helpful if it specified which specific methods should be considered or how the comparison should be conducted. Overall, the feedback is 4 as it provides a clear direction for enhancing the paper, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment raises valid points and questions, it does not provide explicit instructions or concrete actions for the authors to take. The questions are implicit and require the authors to infer the need for clarification or further explanation. Therefore, the comment is 3, as it provides guidance but lacks detailed instructions on how to address the issues.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the claim of parameter efficiency for COCOLM. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This provides specific feedback on the comparison and the claim of parameter efficiency. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is \"a little overrated\" and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This claim is 3 as it provides a logical reasoning based on the similarity in performance and model sizes. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider this feedback and potentially provide more detailed comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This critique questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment identifies a potential issue with the comparison and raises questions for further clarification, it lacks detailed guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement but could be more comprehensive with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines despite mentioning various model criticism techniques. The reviewer suggests that the authors could compare with a chainofthought prompting approach. This feedback is explicit and provides a concrete suggestion for improvement, indicating that the authors should consider adding more robust baselines to their comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of meaningful baselines and suggests a particular approach, such as comparing with a chainofthought prompting method, to enhance the comparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests that the authors could compare with a chainofthought prompting approach, providing a specific example of a more meaningful baseline. This suggestion is supported by logical reasoning and a concrete example, making the claim 4. However, the comment could be strengthened by explaining why the current baselines are insufficient or how the suggested baseline would improve the analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that despite mentioning various model criticism techniques in Section 2, the authors only compare with simple naive baselines. The reviewer suggests a specific alternative, such as comparing with a chainofthought prompting approach, which could provide a more robust and meaningful comparison. This feedback is clear and actionable, offering the authors a concrete suggestion for improving the depth and relevance of their comparisons. By addressing this issue, the authors can enhance the validity and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. While the comment implies that the authors should clarify their pretraining approach and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about their pretraining method and its generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or methodology description. Without explicit references or clear indications of where this information is discussed, the authors may find it challenging to identify the exact part of the paper being addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and aim to gather information, making the comment a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. This feedback is 3 as it prompts the authors to clarify their methodology and its implications, which could be an important aspect of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address these questions, leaving the authors with a general direction but not a detailed path forward. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential dependency or what specific aspects of the design might be affected. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects are hardware or software dependent. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, noting that some observations and design decisions might be hardware and software dependent. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples, the authors are left without a clear understanding of how to improve their draft. The comment highlights a potential concern but does not offer any constructive steps for resolution, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of new evaluation metrics and the need for an indepth exploration of the reasons behind the experimental results. While the comment identifies these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they should consider proposing new evaluation metrics and conducting a more detailed analysis of their experimental results. However, the comment lacks concrete details on how to implement these suggestions, making it 3. The authors know they need to address these issues but may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the need for an indepth exploration of the experimental results. It mentions the experimental analysis section, providing some grounding by specifying the part of the paper being addressed. However, it does not specify which specific results or aspects of the experimental analysis need further exploration, making it weakly grounded. The comment is specific in its request for an indepth exploration of the reasons behind the experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons behind the results. While the comment identifies a potential issue with the lack of new evaluation metrics, it does not provide specific examples or references to support this claim. Additionally, the suggestion for an indepth exploration of the experimental results is vague and lacks detailed guidance. Therefore, the comment is 3, as it provides some justification but lacks key elements to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of new evaluation metrics and the need for a more indepth exploration of the experimental results. It points out that only existing evaluation metrics are used and suggests that the authors should have explored the reasons behind their experimental results. This feedback is clear and actionable, as it directs the authors to consider proposing new evaluation metrics and conducting a more detailed analysis of their findings. However, the comment could be more helpful if it provided specific examples or suggestions on how to implement these improvements. Overall, the comment is 4, as it offers valuable guidance for enhancing the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the notation \"K\" being used inconsistently in the paper, where it represents both a known kernel function and the number of layers. However, the comment does not provide explicit guidance on how to resolve this inconsistency or suggest a specific action for the authors to take. The authors are left to infer that they need to clarify or standardize the notation, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L166 and L176) where the notation \"K\" is used inconsistently, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that \"K\" is used for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused in the paper, used for both a known kernel function and the number of layers. This claim is verifiable as it provides specific line numbers (L166 and L176) where the notation is used inconsistently, allowing the authors to verify the issue directly. The mention of specific lines provides clear evidence supporting the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K\" being used inconsistently in the paper, where it represents both a known kernel function and the number of layers. This feedback is clear and actionable, as it directs the authors to clarify or standardize the notation to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or offered examples of how to rephrase the notation. Despite this, the comment still provides valuable guidance for improving the clarity and consistency of the paper, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the weak recovery problem studied is of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived limitation or improve the practical impact of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the weak recovery problem studied in the paper and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its critique of the theoretical interest and practical impact of the work, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion about the limited practical impact. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical impact of the AMP algorithm for nonGaussian problems, suggesting that the weak recovery problem studied is primarily of theoretical interest. While it identifies a potential limitation, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the practical utility of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\" statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison. However, it does not explicitly instruct the authors to make these clarifications or provide specific guidance on how to incorporate additional citations. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" statement about the problem being fairly reductionist and the reference to \"Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition and suggests that the authors need to clarify their claim and provide more citations for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of connections to human cognition in the context of the paper, specifically the statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR. The reviewer challenges the authors\" claim by pointing out that the problem is described as fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that it would be surprising if a behavioral economist studying this problem would ignore these aspects and requests more citation for comparison. While the comment raises a valid point, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\" statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison against \"previously appreciated\" effects. This feedback is 3 as it identifies a potential confusion in the paper and prompts the authors to clarify their argument. However, it could be more helpful if it provided specific suggestions on how to address the issue or offered examples of relevant literature for comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment implies that the authors should conduct such comparisons to prove the effectiveness of their proposed approach, but it lacks concrete details on how to implement this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification for why such comparisons are necessary or how they would impact the paper\"s effectiveness. Without this information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. This is a critical observation that highlights an important gap in the paper\"s evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular baselines to include or suggesting ways to integrate them into the evaluation framework. While the comment points out a key area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific information should be included or how to present it. Therefore, the comment is 3, as it points out areas for clarification but does not fully direct the authors on how to improve their draft.", "grounding_specificity_rationale": "The comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. The mention of \"separate embedding and addition with positional encoding\" provides some grounding, as it suggests a specific aspect of the paper being addressed, such as the methodology or implementation details. However, the comment does not specify which part of the paper discusses these embedding and addition methods, making it weakly grounded. The comment is specific in requesting clarification on the combination and feeding of embeddings into the CSCM. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It also requests clarification on how embeddings are combined and fed into the CSCM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, particularly in the context of differences in sequence lengths. It highlights the need for clarification on how embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations on this aspect of their methodology. By addressing this point, the authors can improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of similar approaches. Overall, the comment is 4, as it effectively guides the authors toward enhancing the clarity of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether fast SMP is less expressive than SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide guidance on what aspects of the architectures should be discussed. The authors may infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or justify the need for additional discussion. Without specific examples or context, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for what aspects of the architectures should be discussed or how the discussion could be enhanced. As a result, the authors are left without clear direction on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This comment implies that the authors should consider using different trainvaltest splits in their evaluation, but it does not explicitly instruct them to do so. While the action is clear, it is not explicitly stated, making it 3. The authors can infer the need to explore different splits, but the comment lacks specific guidance on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. Without explicit references to specific sections or elements, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what needs to be changed or how to implement the suggested evaluation approach. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This claim is based on a logical reasoning that different splits can provide a more comprehensive evaluation of the methods\" robustness. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this suggestion and potentially conduct additional experiments to fully understand the impact of different splits on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This feedback is clear and provides a specific suggestion for improving the robustness of the results. However, it lacks further guidance on how to implement this suggestion, such as which specific splits to use or how to incorporate them into the evaluation process. While the comment identifies a potential area for improvement, it does not offer detailed actionable steps, making it 3. The authors can infer the need to explore different evaluation approaches, but the comment could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on how to combine these bullets or what changes should be made to ensure clarity and coherence. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions\" at the end of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to combine these two bullets, which gives the authors a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any reasoning or justification for why this combination is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests combining the first two bullets about contributions at the end of the introduction. While this feedback identifies a potential improvement in the organization and clarity of the contributions section, it lacks depth and does not provide specific guidance on how to effectively combine these bullets or what benefits this change might bring. The comment is 3 as it points out a possible improvement, but it does not offer detailed suggestions or rationale to support the change, leaving the authors with limited actionable feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s unique contribution to the neuroscience community but raises a question about its potential improvement over existing solutions. It suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. While the comment implies that the authors should refer to more recent trends in the vision community, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate these trends or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s unique contribution to the neuroscience community but raises a question about its potential improvement over existing solutions. It suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. The comment implies that the authors should refer to more recent trends in the vision community, but it does not specify which part of the paper this feedback pertains to. While the authors can infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in suggesting what needs to be addressed, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the paper\"s potential improvement over existing solutions and suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries. The comment implies that this is particularly important for bottomup methods. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the current paper lacks in this regard. The lack of concrete evidence or detailed justification makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s unique contribution to the neuroscience community and its potential benefits. However, it raises a critical question about the paper\"s ability to improve over existing solutions, particularly in terms of finding closed contours and robustness against weak boundaries. The comment suggests that the authors need to demonstrate these capabilities, especially for bottomup methods, and recommends referring to more recent trends in the vision community. While the feedback identifies a key area for improvement, it lacks specific guidance on how to address the issue or what recent trends to consider. The suggestion to refer to recent trends is vague and does not provide actionable steps for the authors. Therefore, the comment is 3, as it points out a critical area for improvement but does not offer detailed guidance or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It notes that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could be improved, it does not provide explicit guidance on how the authors should address these issues or what specific insights are needed to enhance the paper. The action is implicit and somewhat vague, as the authors are left to infer what changes are necessary without clear instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It mentions the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones, and notes the proposed modifications like different penalty coefficients for users and items. However, the comment lacks specific references to sections or parts of the paper where these issues are discussed, making it weakly grounded. The comment is specific in identifying the lack of insights into the unique challenges of overcorrelation in recommender systems, but without explicit references, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. The reviewer provides some justification by mentioning the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim of limited novelty. While it highlights the modifications proposed, such as different penalty coefficients for users and items, it does not provide enough evidence or references to support the assertion that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. Therefore, the claim is 3, as it provides some basis for the critique but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It highlights the contribution as mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also notes the proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment points out areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it directs the authors\" attention to the lack of novelty and the need for deeper insights, but it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the pretraining method in the main paper, as it is a key factor in the performance gain. While the comment implies that the authors should provide a more detailed discussion on the unsupervised pretraining, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a more detailed discussion on the pretraining method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining and its importance compared to other modules. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. It also suggests that the main paper lacks a detailed discussion on this aspect, which is a problem. The reviewer further supports this claim by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or references to support the claim about the importance of unsupervised pretraining. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. However, it points out that there is no detailed discussion on this aspect in the main paper, which could be a problem. The reviewer further supports this by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This feedback is clear and actionable, as it suggests that the authors should focus more on the pretraining method in the main paper. By highlighting this critical aspect, the comment provides valuable guidance for the authors to improve their draft. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should consider integrating a gender detection model into their pipeline, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is 3, as it highlights a potential issue but does not provide detailed instructions on how to resolve it.", "grounding_specificity_rationale": "The comment raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of ELM choice and its implications, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. The comment suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. This claim is 3 as it provides a logical reasoning about the potential drawback of the current approach. However, it lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of ELM (male/female) and whether it requires prior knowledge of the speaker\"s gender. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. This feedback is 3 as it identifies a potential drawback in the current approach and provides a direction for improvement. However, it lacks specific suggestions or detailed guidance on how to integrate a gender detection model into the pipeline or address the issue of prior knowledge of the speaker\"s gender. To be more helpful, the comment could include examples or more detailed advice on how to resolve this concern. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several improvements, including providing intuition for the proof of Theorem 1, exploring how the invertible function $f^*$ depends on the fixed $P^*$, and determining which distributions $P^*$ make it easier to determine $f^*$. It also raises a practical question about how to choose $P^*$. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to do so. The actions are concrete but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific questions and suggestions for improvement, such as seeking intuition for the proof of Theorem 1 and exploring the relationship between the invertible function $f^*$ and the fixed $P^*$. The comment further asks about the practical implications of choosing $P^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for improvement, such as seeking intuition for the proof of Theorem 1 and exploring the relationship between the invertible function $f^*$ and the fixed $P^*$. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should include an intuition for the proof of Theorem 1. It also raises questions about the relationship between the invertible function $f^*$ and the fixed $P^*$, and how certain distributions $P^*$ might make it easier to determine $f^*$. Additionally, it asks for practical guidance on how to choose $P^*$. These suggestions are clear and provide the authors with concrete areas to address, making the comment 5. The feedback is detailed and actionable, offering a comprehensive guide for improving the draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to resolve the inconsistency. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly questions the inconsistency in the use of variables between these two equations, asking for an explanation of why one uses \"X\" and the other uses \"H^(1).\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the use of variables between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". This is a factual observation that does not express an opinion or make a subjective claim. It is a request for clarification, which is a normal statement and does not require verification. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inconsistency in the use of variables between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this inconsistency or clarify the use of these variables. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\"s ability to capture these phenomena. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the empirical evidence or what specific aspects of the model should be tested. The action is implicit and somewhat vague, as the authors need to infer that they should conduct empirical studies to validate the model\"s applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\"s ability to capture these phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for empirical evidence, but without clear grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate its effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the model is not applicable in realworld scenarios. This lack of evidence or detailed justification makes the claim 3, as the authors would need to infer the basis of the concern and address it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the proposed model to realworld diffusion processes. It acknowledges the interest and elegance of the problem but emphasizes the need for empirical evidence to demonstrate the model\"s ability to capture realworld diffusion phenomena. This feedback is clear and actionable, as it directs the authors to provide empirical evidence to validate the model\"s applicability. However, the comment could be more helpful if it suggested specific experiments or data sources that could be used to demonstrate this applicability. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in Section 4.2 regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests clarifying these points and raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback provides explicit actions for the authors to take, such as clarifying the description and addressing the potential numerical instability issue. The guidance is clear and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in this section, particularly the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description in Sec. 4.2 does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests that the equation might be illconditioned and numerically unstable due to the multiplication of two sigmoid activations. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to infer the exact nature of the problem and how it affects the equation. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, where the use of the question to learn an attention on the image feature is not clearly explained. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer also raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides specific guidance on what needs to be clarified and addressed in the paper. By highlighting these issues, the comment helps the authors improve the clarity and accuracy of their work, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or how they could enhance their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which section of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the perceived lack of novelty, particularly regarding the ENCODE part and the decomposition contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part. However, the comment does not provide any supporting evidence or detailed reasoning to substantiate the claim about the limited novelty. Without specific examples or references to demonstrate how the decomposition part is not novel, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part. However, it does not provide any specific suggestions or guidance on how the authors might address this perceived lack of novelty or enhance their contribution. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify the domain of the inputs, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include information about the domain of the inputs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification about the domain of the inputs, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location where this information should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. This is a factual observation that does not contain a subjective claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. While it implies that the authors should include a performance comparison, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a performance comparison but are not provided with specific guidance on how to do it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the CLN is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its request for a performance comparison, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. However, it does not provide any supporting evidence, reasoning, or references to justify why a performance comparison is necessary or how it would impact the paper. The comment lacks specific details or examples, making it difficult for the authors to understand the basis of the request. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable advice or insights that could help the authors improve their draft. As a result, it is 2, as it points out a potential gap but does not provide any meaningful direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues with the presentation: it is too equationdriven and the notation is convoluted, particularly in Chapter 3. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment implies that the authors should consider simplifying the presentation and adding visual aids, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3\" and \"section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the presentation being too equationdriven and the notation being convoluted, suggesting that an illustrative figure would be helpful. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. The suggestion to include an illustrative figure of key concepts in Section 3 is provided to help clarify the content. However, the comment lacks specific examples or detailed reasoning to support the claim about the equationdriven nature of the presentation and the complexity of the notation. This makes it 3, as the authors would need to infer the exact issues and how to address them based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the presentation: it is too equationdriven and the notation, particularly in Chapter 3, is convoluted and hard to follow. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the content. By addressing these issues, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to simplify the notation or provided examples of effective visual aids. Overall, the comment is 4, as it directs the authors toward a specific improvement that can enhance the quality of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the visual presentation of Figure 3, particularly the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide specific guidance on how to achieve this improvement, such as suggesting alternative formatting or design elements. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the visual presentation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the visual presentation, specifically suggesting enhancements for better readability and aesthetic appeal, such as improving the subscripts. This level of detail helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of Figure 3 could be enhanced for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or reasoning to support why the current presentation is inadequate or how it could be improved. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the potential issues and solutions based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of Figure 3, suggesting that the subscripts could be enhanced for better readability and aesthetic appeal. While the comment highlights a potential issue, it lacks detailed guidance or suggestions on how to achieve this enhancement. It does not provide specific examples or recommendations for improving the visual presentation, leaving the authors with a general idea of what needs to be addressed but without actionable steps to take. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the formatting to meet the page limit. The comment lacks concrete details on what specific changes should be made to rectify the problem, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, including crammed equations and captions too close to figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the formatting issues. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples of where the whitespace has been reduced or how it affects the page count. Without such details, the claim remains 1, as the authors may not be able to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in crammed equations and captions that are too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the 9page paper limit. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to improve the layout or suggesting alternative formatting options. Despite this, the comment effectively points out a critical area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this concept in their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify the concept of local interactions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of \"local interactions,\" but it does not specify which part of the paper this concept is discussed in. This makes it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the concept, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions,\" specifically whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it affects the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a potential area of confusion regarding the concept of \"local interactions,\" specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it highlights a specific point that needs clarification, prompting the authors to provide more detailed explanations or examples to ensure the clarity of their concept. However, the comment lacks depth and does not offer specific suggestions on how to address the issue or improve the clarity of the concept. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in the paper, specifically regarding the Molecule generation experiment (Table 3). It suggests that the proposed constrained method may actually lead to lower validity and diversity, contradicting the paper\"s claim of better results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The action is implicit, as the authors need to infer that they should investigate and potentially revise their claims or methods. The feedback lacks concrete details on how to implement changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, namely that the proposed constrained method yields lower validity and diversity, contradicting the paper\"s claim of better results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results in the Molecule generation experiment (Table 3) are contradicted by the fact that the proposed constrained method yields lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results presented in the paper, specifically regarding the Molecule generation experiment (Table 3). It suggests that the proposed constrained method may actually lead to lower validity and diversity, contradicting the paper\"s claim of better results. This feedback is 3 as it points out a specific area where the results may be misleading or incorrect. However, it lacks depth and does not provide actionable suggestions on how the authors might address this issue or improve their results. To be more helpful, the comment could include specific guidance or examples of how to resolve the discrepancy or improve the validity and diversity of the results. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialization, specifically asking for clarification on how the archetype positions are updated after being initialized with the FurthestSum procedure. While the comment does not explicitly instruct the authors to make changes, it implies that the authors should provide additional information or clarification on this process. The action is implicit, as it requires the authors to infer that they need to address the lack of clarity in their paper. However, the comment is 3 because it provides a clear direction for the authors to follow, which is to clarify the process of updating archetype positions. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how archetype positions are updated after initialization. This provides clear guidance on what needs to be clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the process of updating archetype positions after initialization. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking additional information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the process of updating archetype positions after initialization, which is an important aspect of the algorithm. By asking for clarification on this point, the reviewer highlights an area where the paper could be improved in terms of clarity and comprehensiveness. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several areas that are missing from the empirical study and suggests that they should be included in the supplement or main text. It specifies the types of information that are missing, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. Additionally, it suggests mentioning the number of regions in the parcellation in the main text. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to implement the changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that important information about the empirical study is missing, specifically regarding the recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also requests a brief explanation of the harmonization technique and the number of regions in the parcellation. While the comment identifies areas that could be improved, it does not provide specific examples or references to support the claim that this information is crucial or missing. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, as it specifies what information is lacking and how it could be included to enhance the clarity and comprehensiveness of the paper. By addressing these points, the authors can improve the transparency and detail of their study, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It suggests that crossdataset experiments could be a good way to test the generalization of such work, as the paper currently lacks. While the comment implies that the authors should conduct crossdataset experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific experiments needed to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units and the need for crossdataset experiments to test generalization. The comment provides a clear example of how the relationships between action units can differ across datasets, such as the cooccurrence of AU6 in pain and happiness expressions. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may not generalize well across datasets due to differences in cooccurrence patterns. It provides a specific example of AU6 occurring in both pain and happiness expressions, which could have different cooccurrence patterns in different datasets. The comment also references Figure 1, which supports the claim by showing different cooccurrences of AU1 and AU12. This logical reasoning and reference to specific data points make the claim 4, as it provides a clear explanation and evidence for the concern. However, the comment could be strengthened by providing more detailed examples or references to existing literature on this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk in methods that exploit relationships between action units, noting that these relationships can vary across different datasets. It provides a specific example of AU6 occurring in both pain and happiness expressions, highlighting the potential for different cooccurrence patterns in various datasets. The comment suggests that crossdataset experiments could be a good way to test the generalization of such work, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to conduct these experiments or what datasets to use. Overall, the feedback is 4 as it points out a critical area for improvement and provides a direction for further research, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not specify what aspects of the environment should be described or how detailed the description should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting where the additional information could be included, but without explicit references to sections or figures, the authors may still find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks a detailed description of the Starcraft environment, implying that this is a necessary addition. However, the comment does not provide specific examples or reasoning to support why this description is crucial or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more detailed description of the Starcraft environment. While it implies that this information could be included in an appendix, it does not provide specific guidance on what aspects of the environment should be described or how this would enhance the paper. The comment identifies a potential area for improvement but lacks depth and actionable suggestions, making it 3. The authors are given a general direction but no detailed guidance on how to implement the suggested change, limiting the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the timeconsuming nature of the shape model training, which is due to the pixellevel training and the independent training of the model on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or specific examples of existing work to compare with. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on processing efficiency and comparisons with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the shape model training, which is due to the pixellevel training and the independent training of the model on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in its request for a description and comparison of processing efficiency with existing work. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its pixellevel training and independent training on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment provides some rationale for the timeconsuming nature of the model, it lacks specific examples or references to existing work for comparison. This makes the claim 3, as the authors would need to conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the shape model training, which is due to its pixellevel training and independent training on all font images and characters. It also highlights the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. This feedback is 3 as it points out areas where the authors could improve their paper by providing more detailed information on processing efficiency and comparisons with existing work. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these issues. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for combining existing techniques without innovation, specifically mentioning that the domain adaptation method used is old and simple. The reviewer suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. While the comment implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which methods to consider or how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for combining existing techniques without innovation, specifically mentioning the use of an old and simple domain adaptation method. It suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. However, the comment does not specify which part of the paper discusses the combination of techniques or the specific domain adaptation method used, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting the use of more effective domain adaptation methods, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors combine existing techniques without innovation, specifically mentioning that the domain adaptation method used is old and simple. The reviewer suggests that more effective domain adaptation methods should be considered to improve performance. While the comment provides a logical reasoning for the claim, it lacks specific references or examples of the \"many effective domain adaptation methods\" proposed in recent years. This makes the claim 3, as the authors would need to conduct additional research to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically that the authors combine existing techniques without innovation. It points out that the domain adaptation method used is old and simple, suggesting that more effective methods proposed in recent years could be considered to improve performance. This feedback is 3 as it highlights an area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific examples of alternative domain adaptation methods or provided guidance on how to integrate them into the framework. Overall, the comment provides some actionable insights but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of their work. Without actionable advice or concrete steps for improvement, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is causing this difficulty or provide any details on what aspects of the motivation are unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is \"very difficult to follow the motivation of this paper\" and labels it as an \"incremental engineering paper.\" However, the comment lacks any supporting evidence, reasoning, or examples to justify why the motivation is difficult to follow or why it is considered incremental. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment indicates that the motivation of the paper is difficult to follow and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of their work. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, the comment is 1, as it lacks actionable insights or constructive suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests conducting an ablation study on the weighting method of the crossentropy loss. It provides a specific example from the paper where the authors mention that their method underperforms in a particular scenario, suggesting that weighting might have helped improve performance. This feedback is explicit and concrete, as it clearly instructs the authors to conduct an ablation study on the weighting method and provides a rationale for why it could be beneficial. The authors know exactly what action to take and how to apply it, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the weighting method of the crossentropy loss and references a specific scenario mentioned in the paper where the authors note that their method underperforms due to repetitive background sounds in the \"Atlantis\" game. This provides full grounding as it explicitly mentions the specific part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what needs to be addressed, namely the ablation study on the weighting method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the weighting method of the crossentropy loss, providing a specific example from the paper where the authors mention underperformance in a scenario with repetitive background sounds. The reviewer implies that weighting might have helped improve performance in this scenario, offering a logical reasoning for the suggestion. However, the comment lacks detailed references or examples to fully substantiate the claim, making it 3. The authors would need to consider the suggestion and potentially conduct the ablation study to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which is a specific and actionable piece of feedback. It provides a rationale for why this study could be beneficial, referencing a scenario where the authors mention underperformance due to repetitive background sounds. This feedback is clear and offers a concrete suggestion for improving the paper, making it 5 for the authors. By addressing this suggestion, the authors can gain a deeper understanding of their method\"s performance and potentially improve it. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty or incremental nature of the work, or how to improve the dataset or benchmark. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it references another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the lack of novelty and incremental nature of the work, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature. It provides specific details about the work, such as addressing a particular problem of column operations in designing semantic parsers for TexttoSQL and the use of a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. This level of detail provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by including references to specific studies or works that demonstrate the lack of novelty, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. This feedback is 3 as it points out a significant issue with the paper\"s originality and suggests that the authors should consider how their work contributes to the existing literature. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Therefore, it is rated as 3, as it provides insight but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback is clear and provides a direct action for the authors to take, making it 5. The authors know exactly what they need to do to improve their draft, which is to provide examples to justify the importance of this contribution. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain the importance of removing certain assumptions, such as bounded variance and bounded gradients, by providing solid examples. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for examples to support the claim, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors need to explain the importance of removing certain assumptions, such as bounded variance and bounded gradients, by providing solid examples. However, the comment does not provide any reasoning or evidence to support why these assumptions are significant or how their removal contributes to the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification for their work. It points out the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that this should be supported by solid examples. This feedback is clear and actionable, as it directs the authors to enhance the clarity and justification of their contributions. However, the comment could be more helpful if it provided specific examples or guidance on how to present these examples. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no suggestion for improvement, such as optimizing the implementation or discussing potential reasons for the slow performance and low accuracy. Without any guidance or direction, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not specify which part of the paper this claim is made in, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the issue with the implementation, including the time it takes to test an ImageNet picture and the accuracy achieved. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the implementation of ImageNet is slow and has low accuracy, citing specific times (\"1 day and 2.5 days\") and accuracy (\"around 70%\") for testing an ImageNet picture using AlexNet and ResNet18. This provides concrete evidence to support the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or references to similar implementations for better context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time it takes to test an ImageNet picture using AlexNet and ResNet18, as well as the accuracy achieved. This feedback is valuable as it highlights a specific area where the authors may need to improve their implementation or discuss potential reasons for the observed performance. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues. Overall, the comment is 3 as it identifies a weakness but lacks actionable advice for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. While the comment implies that the authors should consider using labeled data for consistency training, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the potential benefit and the references provided, but it lacks direct action or detailed guidance on how to implement this suggestion. Therefore, the comment is 4, as it provides a clear direction for the authors to consider but does not specify the exact steps to take.", "grounding_specificity_rationale": "The comment raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. However, the comment does not explicitly mention a specific part of the paper, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but this inference is not direct. The comment is specific in suggesting the use of labeled data and referencing relevant literature, which provides a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. The inclusion of references to \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation\" provides some support for the claim, as these papers are likely to discuss the use of labeled data in consistency training. However, the comment could be strengthened by providing more detailed reasoning or examples from these references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment raises a thoughtful question about the potential benefits of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, which is a valuable insight for the authors to consider. The comment references specific papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide additional context and guidance for the authors. However, the comment could be more helpful if it provided a clearer explanation of how labeled data could be integrated into the consistency training process or offered specific suggestions for implementation. Despite this, the comment offers a relevant and actionable direction for the authors to explore, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. It implies that the current content is not effectively communicated, and the authors should reorganize it to better showcase the method\"s advantages. However, the comment does not provide specific guidance on how to reorganize the content or what changes should be made. While the authors can infer that they need to reorganize the experimental section, the lack of concrete details on how to achieve this makes the action vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. It implies that the current content is not effectively communicated, and the authors should reorganize it to better showcase the method\"s advantages. However, the comment does not specify which part of the paper is being addressed, such as a particular section or figure, making it weakly grounded. The comment is specific in suggesting that the experimental content should include certain aspects, but it does not provide detailed guidance on what those aspects are. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support this claim. The comment mentions that the experimental content listed in the main text does not effectively showcase the method\"s advantages, but it lacks concrete evidence or references to substantiate this assertion. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to fully substantiate the need for reorganization. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to reorganize and enhance the experimental section to better highlight the superiority of the method. It suggests that the current content does not effectively communicate the method\"s advantages and provides a general direction for improvement by recommending the inclusion of specific experimental suggestions. However, the comment lacks detailed guidance on how to reorganize the content or what specific aspects should be emphasized. While it provides some direction, it could be more helpful with additional specifics or examples. Therefore, the comment is 3, as it offers a clear area for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the training time issue and consider publishing the code. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiment 2\" and \"ERM and plugin,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. Additionally, it suggests that the code should be published, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage is its computation time. However, the comment lacks specific evidence or references to support the claim that the training times are unreasonable or to substantiate the suggestion for publishing the code. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. This feedback is 3 as it points out a potential inconsistency in the experimental results and suggests a way to improve the paper by making the code available. However, the comment could be more helpful if it provided additional context or examples to clarify the issue or suggested specific ways to address the computation time advantage. Overall, the comment offers some guidance but lacks depth, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information CD captures beyond Predictive Uncertainty. It also questions why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides specific areas for improvement, such as explaining the additional information CD captures and justifying the choice of measure. While the action is implicit, it is concrete in terms of what needs to be addressed, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 115\" and \"line 113,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for alternate formulations for Confidence Diversity (CD) and the explanation of why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should describe alternate formulations for Confidence Diversity (CD) and questions the choice of entropy as a measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current formulation and suggesting an alternative perspective. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to consider the feedback and provide additional context or evidence to fully address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the current formulation, specifically asking why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment highlights a potential gap in the explanation of CD and its relationship with Predictive Uncertainty, offering a clear direction for improvement. However, it could be more helpful if it provided additional context or examples to further clarify the issues. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear path forward, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that it only follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\"s weakness. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the human baseline. The action is implicit and vague, as the authors are left to infer that they need to address the discrepancy and potentially revise the abstract to accurately reflect the comparison. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline and the discrepancy in the duration of speech recordings, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline is weaker due to only following a little more than 1 hour of speech recordings, rather than the full 15 hours. Additionally, it references Section 4.1, which further grounds the comment. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings, rather than the full 15 hours. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\"s weakness. However, the comment does not provide specific examples or detailed reasoning to support the claim that the 1hour limitation significantly impacts the baseline\"s performance. While it highlights a potential issue, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only follows a little more than 1 hour of speech recordings, which makes it considerably weaker than the model baseline. This observation is critical, as it highlights a potential flaw in the comparison between the human and model baselines. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\"s weakness, providing some context for the issue. However, the comment could be more helpful if it offered suggestions on how to address this discrepancy or improve the human baseline. Despite this, the feedback is 3 as it points out a critical area for improvement, prompting the authors to reconsider their baseline comparisons. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the assumption for termination states of instructions being quite strong and notes that labeling a large number of data manually can be very expensive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods for labeling data or ways to reduce the expense. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment highlights the issue of labeling a large number of data manually being expensive, but it does not provide specific guidance or suggestions on how to address this concern. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong\" and notes that labeling a large number of data manually can be very expensive. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the strength of the assumption or the expense of manual labeling. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment highlights a concern about the assumption for termination states of instructions being quite strong, which can be expensive to label manually. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their work. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as Reinforcement Learning (RL) methods, but none of these methods are used as a baseline. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, how to incorporate them, or what specific aspects of the RL methods should be explored. Without any actionable advice or suggestions, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This provides clear guidance on what needs to be addressed in the related work section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This claim is 3 as it highlights a potential gap in the paper\"s methodology. However, the comment lacks specific examples or references to the RL methods mentioned, which would strengthen the justification. Providing more detailed information or examples of these methods would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a gap in the related work section by noting that it discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This feedback is 3 as it identifies an area where the authors could improve their draft by considering additional methods as baselines. However, the comment lacks specific suggestions or guidance on how to incorporate these methods or why they are relevant, which would make the feedback more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a confusion in the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" However, it does not provide explicit guidance or suggestions on how to clarify this ambiguity in the draft. The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" but it does not offer concrete steps for the authors to take to resolve this issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the confusion regarding whether the authors are referring to a particular efficient proxy or a general category of efficient proxies. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" which suggests that the authors may be referring to a family of efficient proxies. However, the comment does not provide any additional context, examples, or references to support this claim or clarify the confusion. As a result, the claim is 3, as it highlights an issue but lacks detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text regarding the reference to \"efficient proxy.\" It points out the ambiguity in whether the authors are referring to a particular proxy or a general category, and it highlights the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy.\" This feedback is clear and actionable, as it prompts the authors to clarify their intention and ensure consistency in their terminology. However, the comment could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of how to clarify the text. Overall, the comment is 4, as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the model appears overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the model should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered simple or how this simplicity affects the model. Without explicit references to sections, figures, or specific elements of the model, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is \"overly simple,\" both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the model are considered simple or how this simplicity affects the model, the claim remains 1. The authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes could be made to enhance their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not contribute to the authors\" ability to improve their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential limitations or suggestions for expanding the scope of the work. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not specify which part of the paper this observation is based on, nor does it provide details on how the authors might address this limitation. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the work should be expanded or how the broader impact could be increased. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the work, noting that its focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. While this observation is valid, the comment lacks specificity and does not provide actionable feedback or suggestions for the authors to address this limitation. It does not offer guidance on how to expand the scope of the work or suggest alternative approaches that could enhance its broader applicability. As a result, the comment provides minimal value to the authors in terms of improving their draft, making it 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of runtimes from the experiments to aid readers who might apply the method. This feedback is explicit and provides concrete actions for the authors to take, such as including a brief mention of computational cost and providing examples of runtimes. The suggestions are clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only discussed in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes from the experiments to aid readers who might apply the method. The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of computational cost information and examples of runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that mentioning the negligible computational cost of CHR in the main paper could help motivate the method. It also recommends providing a rough example of runtimes from the experiments to aid readers. However, the comment does not provide specific examples or detailed reasoning to support why this information is crucial or how it would enhance the paper. The suggestion is logical but lacks concrete evidence or references to substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion to enhance the paper by recommending that the authors mention the negligible computational cost of CHR in the main paper. This would help motivate the method and provide readers with a clearer understanding of its practical implications. Additionally, the comment suggests including a rough example of runtimes from the experiments to aid readers who might apply the method. This feedback is clear and actionable, offering specific ways for the authors to improve the clarity and applicability of their work. However, while the comment is 4, it could be more comprehensive by explaining why this information is important or how it would impact the reader\"s understanding. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends that the authors provide more detailed elucidation of the EEG token quantization process, specifically regarding the role of the spatial arrangement of EEG sensors. This suggestion is clear and provides a concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The comment is 5 as it offers specific guidance on how to enhance the clarity and interpretation of the results presented in Figure 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of ambiguity in interpretation and suggests that the authors provide more detailed elucidation of the EEG token quantization process, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots that lead to ambiguity in interpretation, recommending that the authors provide more detailed elucidation of the EEG token quantization process. The comment is 3 as it identifies a potential issue with the interpretation of the results but lacks specific examples or references to support the claim of ambiguity. While the suggestion for further explanation is reasonable, the comment could be strengthened by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It provides a clear and actionable suggestion for the authors to elucidate this procedure in greater detail, specifically asking whether the spatial arrangement of EEG sensors played a role in the process. This feedback is valuable as it directs the authors to clarify a critical aspect of their methodology, potentially enhancing the understanding and reproducibility of their results. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested specific ways to address the ambiguity. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on their selection criteria and potentially explore other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context and potentially conduct further evaluations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses the evaluation on MTEB, making it weakly grounded. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting that the authors should provide more information on their selection criteria and consider alternative datasets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. The comment provides a logical reasoning by questioning the representativeness of the results based on the limited evaluation scope. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully substantiate the claim, hence the score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and potentially expand their evaluation to other datasets or tasks. By addressing this concern, the authors can enhance the robustness and applicability of their findings. However, the comment could be more helpful if it provided specific examples of alternative datasets or tasks that could be considered. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the introduction, the second paragraph discusses modelling curves, but it is unclear what is being modelled. However, it does not provide explicit guidance or suggestions on how to clarify this point or what specific information should be added to make it clear. The action is implicit and vague, as the authors can infer that they need to provide more context or clarification but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"second paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that it is not immediately clear what is being modelled, presumably tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction discusses modelling curves but does not clarify what is being modelled. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, where the second paragraph discusses modelling curves but does not clearly specify what is being modelled. This feedback is 3 as it points out a potential area for clarification, allowing the authors to improve the clarity and coherence of their introduction. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific details to include or examples to provide. Overall, the comment offers a clear direction for improvement but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected outcome, particularly regarding the optimization strategies and their results. It explicitly mentions the need for a discussion on what happens when minimizing both inter and intra terms in Eq 3 or only the first term. This feedback is clear and provides specific guidance on what the authors should address in their paper. The action is explicit and concrete, as it directly instructs the authors on what additional information should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected outcome and discussing different optimization strategies and their results. The comment provides a concrete example of what should be discussed, such as the impact of minimizing both inter and intra terms in Eq 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected outcome, particularly regarding the optimization strategies and their results. It questions what happens when minimizing both inter and intra terms in Eq 3 or only the first term. However, the comment does not provide any specific reasoning, examples, or references to support why this explanation is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanation is needed to clarify the expected outcome. It highlights the importance of discussing different optimization strategies and their results, particularly in relation to the CBR (CaseBased Reasoning) contribution. The comment provides a concrete example of what should be discussed, such as the impact of minimizing both inter and intra terms in Eq 3 or only the first term. This feedback is clear and actionable, offering the authors a specific direction for enhancing the clarity and comprehensiveness of their paper. However, it could be more helpful if it included additional suggestions or examples to further guide the authors. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include a formal or intuitive definition of treewidth, as it is central to all the proofs in the paper. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies the need for a definition, which gives the authors a concrete step to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or chapter. This makes it difficult for the authors to pinpoint the exact location where the definition should be added. The comment is specific in its suggestion to include a definition, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. However, the comment does not provide any reasoning or evidence to support why this definition is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the clarity and comprehensibility of the paper. By addressing this suggestion, the authors can ensure that their readers, particularly those unfamiliar with the concept of treewidth, have a better understanding of the theoretical foundations of their work. However, the comment could be more helpful if it offered additional guidance on how to present the definition or its implications. Overall, the comment is 4, as it directs the authors to a critical area that requires clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the paper analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This comment implies that the authors should expand their analysis to include the quality of the local minima, but it does not provide specific guidance on how to conduct this analysis or what assumptions to consider. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the analysis of the quality of local minima, including the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that while it analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This feedback is clear and actionable, providing the authors with a specific direction to enhance their analysis and potentially improve the comprehensiveness of their results. However, the comment could be more helpful if it offered suggestions on how to approach this analysis or what specific assumptions to consider. Overall, the comment is 4 as it guides the authors toward a meaningful expansion of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and that the supplementary material is necessary for understanding large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the source code, it does not provide specific guidance on how to improve the selfcontainment of the paper or how to make the source code accessible. The action is explicit but somewhat vague, as it lacks detailed instructions on implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being selfcontained, noting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which parts of the paper are not selfcontained or how the supplementary material could be improved to address this issue. While it provides a clear request for the source code, the lack of specific guidance on the paper\"s content makes it weakly grounded. The comment is specific in requesting the source code, but the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not selfcontained, which is a subjective opinion. It provides a logical explanation by noting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. The request for the authors to release the source code is also a logical suggestion to enhance reproducibility. However, the comment lacks specific examples or references to support the claim about the paper\"s lack of selfcontainment. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the supplementary material is necessary for understanding large parts of the main paper. It also highlights the importance of reproducibility by requesting the authors to release the source code of their experiments. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for enhancing the paper\"s quality. However, the comment could be more helpful if it offered additional guidance on how to improve the selfcontainment of the paper or suggestions for making the source code more accessible. Overall, the comment is 4, as it directs the authors to important aspects of their work that need attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. It also references a specific sentence regarding the robustness of Cans and the information redundancy in the weight pool. However, the comment does not provide explicit instructions or suggestions on how the authors should address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or elaborate on the information redundancy aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and references a specific sentence regarding the information redundancy and the robustness of Cans. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and references a specific sentence for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, specifically referencing a sentence about the robustness of Cans. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the need for clarification on this point. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, which is a relevant and specific area of interest. It also references a specific sentence regarding the robustness of Cans and the information redundancy in the weight pool, providing a clear context for the inquiry. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies a potential area for clarification, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training instead of PPO. It implies that the choice might be related to the attention model paper being iterated upon, but it does not explicitly state this connection. While the action is implicit, it is concrete in suggesting that the authors should explain their choice of algorithm. The authors can infer that they need to provide a rationale for their selection, which makes the comment 4.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training versus PPO. It implies that this choice might be related to the attention model paper being iterated upon, but it does not specify which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training versus PPO. The comment implies that this choice might be related to the attention model paper being iterated upon, but it does not provide specific evidence or references to support this claim. The suggestion is logical and reasonable, but the lack of detailed reasoning or examples makes it 3. The authors would need to infer the connection to the attention model paper and provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of algorithms, specifically why they chose REINFORCE over PPO for training. It implies that this choice might be related to the attention model paper being iterated upon, but it does not explicitly state this connection. While the comment identifies a potential area for improvement by suggesting that the authors should explain their methodological choices, it lacks specificity and does not provide detailed guidance on how to address this issue. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. The comment specifies the exact action and provides a concrete suggestion, making it 5. The authors know exactly what needs to be done to address the feedback, which is to conduct additional experiments and report the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that experimental results should exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results excluding the mixup technique to demonstrate the pure contribution of the proposed method. This claim is based on a logical reasoning that by excluding the mixup technique, the authors can isolate the contribution of their method. However, the comment does not provide specific examples or references to support why this exclusion is necessary or how it would impact the results. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup of the proposed method. It suggests that the authors should include experimental results that exclude the mixup technique to demonstrate the pure contribution of their method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental design and analysis. By following this advice, the authors can better isolate the impact of their method and provide a more comprehensive understanding of its effectiveness. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or why it is important for the paper. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features. It implies that the authors should provide more theoretical support for the merits of Fourier features, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this theoretical aspect. However, the comment provides a clear direction by specifying the area of concern, which is the theoretical support for Fourier features. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for theoretical support but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question or the importance of addressing it. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. While it identifies a potential gap in the theoretical analysis, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors with a general idea of what might be missing but without a clear path to improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details about this process, but it lacks concrete instructions or examples on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of fitting the residual, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the network\"s architecture, specifically the lack of details on how it fits the residual instead of directly learning the inputoutput mapping. This is a relevant observation that could help the authors clarify their methodology and improve the clarity of their paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional details could be included. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the experiment setup in Section 3.3, specifically requesting information about data augmentation methods and learning rates. This is a direct and concrete action for the authors to take, as it clearly specifies what information is needed to improve the draft. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides additional context and guidance on how to address the request. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the experiment setup, including data augmentation methods and learning rates. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides additional context and guidance on how to address the request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual question about the experiment setup in Section 3.3, along with a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks.\" The inclusion of the reference provides context and supports the request for clarification. However, the comment does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that lacks clarity, namely the experiment setup in Section 3.3. By asking for details about data augmentation methods and learning rates, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Additionally, the inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides some context but does not fully address the need for detailed guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, it does not provide explicit guidance or suggestions on how the authors should investigate or address this issue. The comment implies that the authors should look into the calibration steps, but it lacks concrete steps or actions for the authors to take. As a result, the comment is 3, as it identifies a potential area for investigation but does not provide clear guidance on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, the comment does not provide any evidence, examples, or references to support this claim. It lacks specific details or reasoning to substantiate the suggestion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback, leaving the authors with a general direction but no clear path for improvement. Therefore, the comment is 3, as it points out a potential area for investigation but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or discuss the effect of emission distributions on inference tasks. However, the comment does not specify how to conduct this analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or question. It lacks specific examples or detailed explanations that would help the authors understand the issue or provide a basis for addressing it. As a result, the claim is 1, as it does not offer any actionable guidance or justification for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. This question highlights a potential gap in the paper, prompting the authors to clarify or discuss the effect of these distributions on inference. By asking for specific examples or explanations, the comment encourages the authors to provide more detailed insights into their methodology, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of similar approaches in the literature. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, it does not explicitly instruct the authors to perform this analysis or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a deeper analysis but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, suggesting that the authors should provide an analysis of the underlying reasons for this outcome. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this analysis and how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient analysis of experimental results. It points out that the authors mention the poor performance of the scope prompting method on GPT3.5turbo but do not provide any analysis of the underlying reasons for this outcome. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, the comment could be more helpful if it suggested specific methods or approaches for conducting this analysis. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the decision to only consider 10 out of 120 datasets for comparison between batch and greedy methods, as mentioned in references 7 and 12. It suggests that the authors should compare these methods in the remaining 110 datasets. While the comment implies an action\u2014comparing batch and greedy methods in more datasets\u2014it does not provide specific guidance on how to conduct this comparison or which datasets to use. The action is implicit and somewhat vague, as the authors would need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific datasets (10 out of 120) and references 7,12, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the decision to only consider a subset of the datasets and suggests comparing batch and greedy methods in the remaining datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the decision to only consider 10 out of 120 datasets for comparison between batch and greedy methods, as mentioned in references 7 and 12. The comment suggests that the authors should compare these methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the decision to only consider 10 out of 120 datasets for comparing batch and greedy methods, as mentioned in references 7 and 12. It suggests that the authors should compare these methods in the remaining 110 datasets, which could provide a more comprehensive understanding of the methods\" performance. This feedback is clear and actionable, as it identifies a potential area for expansion and improvement in the analysis. However, it could be more helpful if it provided specific guidance on how to conduct these additional comparisons or what benefits might be expected from them. Overall, the comment is 4, as it directs the authors to a meaningful area for further exploration, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the clarity of the paper. The authors are left without a clear understanding of what changes or additions are needed to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines (Page 9, lines 310313, and Page 8, lines 281285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to external works, which adds to its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to external works, such as 1 Yuri Burda et al, Exploration by Random Network Distillation, ICLR 2019, 2 Deepak Pathak et al, Curiositydriven Exploration by Selfsupervised Prediction, ICML 2017, and 3 Roberta Raileanu et al, RIDE: Rewarding ImpactDriven Exploration for ProcedurallyGenerated Environments, ICLR 2020, which could help support the claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides specific references to external works, which could help the authors better understand the context and address the issues raised. However, the comment lacks detailed guidance or suggestions on how the authors might improve their explanation or address the concerns. While it identifies areas for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, asking which alternating direction method is employed. However, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable details, such as suggesting which methods should be considered or how to clarify this information in the paper. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the specific alternating direction method used to solve the minmin problem, but it does not specify which part of the paper this information is mentioned in. The authors may need to review the entire paper to identify where this method is discussed. The comment is specific in its request for clarification but lacks grounding as it does not direct the authors to a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the specific alternating direction method used to solve the minmin problem. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific alternating direction method used to solve the minmin problem, indicating a lack of clarity in the paper. While it identifies a potential area for improvement by pointing out the need for more detailed information, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment is 3 as it prompts the authors to clarify their methods, but it lacks depth and actionable advice, making it incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also notes a potential issue with overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The authors are left to infer that they need to investigate and address these issues, but without concrete steps or recommendations, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MsPacman of Figure2\" and specific environments like \"WizardOfWor, Zaxxon RoadRunner, and BattleZone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the effectiveness of lower bound double qlearning, including a slight performance decrease in MsPacman and convergence into the same solutions in other environments. Additionally, it points out a potential issue with overestimating the true maximum value. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, citing specific examples from the paper, such as a slight performance decrease in MsPacman and convergence into the same solutions in other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. It also mentions a potential issue with overestimating the true maximum value. While the comment provides some evidence and examples, it lacks detailed reasoning or references to support the claim fully. The authors would need to delve deeper into the paper and possibly external literature to fully understand and address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically pointing out a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also mentions a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues or improve their work. The feedback is 3 as it highlights potential weaknesses, but it does not provide actionable steps for improvement, leaving the authors with a general understanding of what needs attention. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the paper is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or suggestions for enhancing the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, specifically mentioning the interpretation of deep neural networks using a linear model. However, it does not specify which part of the paper discusses this novelty or where the authors could improve it. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the novelty, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, specifically pointing out that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might enhance the novelty or originality of their work. Without actionable feedback or specific recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a concern but does not offer any meaningful direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below, but instead, it becomes worse. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what changes might be necessary to clarify the performance trend. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and it provides an expectation of how the performance should behave. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below but instead becomes worse. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this trend should be expected or why it is unexpected. Without additional context or explanation, the claim remains 1, as it lacks the necessary justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It points out a discrepancy in the expected behavior, suggesting that the performance should approach vanilla methods from below but instead becomes worse. This feedback is 3 as it identifies a potential issue in the analysis or presentation of results, prompting the authors to reconsider their interpretation or presentation of the data. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional analysis or clarification in the figures. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so in the author response. The comment suggests that the authors have compared their results to earlier systems with worse performances, which is noted as a point of interest. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their comparisons or provide a more comprehensive evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of not comparing results with earlier research work from 2020 and references the authors\" response regarding stateoftheart systems. It also provides a specific example of earlier systems with worse performances (Taghipour and Ng, 2016) that the authors have compared their results to. This allows the authors to accurately identify the part of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so. The comment highlights a potential inconsistency in the comparison, noting that the authors have compared their results to earlier systems with worse performances. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to delve deeper into the paper and the author response to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a specific issue with the paper\"s comparison to earlier research work, noting that the authors have not compared their results with some of the earlier research from 2020. The comment acknowledges the authors\" explanation for not doing so, which is based on the claim that those systems are not stateoftheart. However, it highlights a potential inconsistency by mentioning that the authors have compared their results to earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is 3 as it identifies a potential gap in the comparison and encourages the authors to reconsider their evaluation methodology. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of relevant earlier work to include in the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to elaborate on the Hoeffding inequality and its application in stochastic algorithms, specifically regarding the samples being drawn independently and the conditioning on previous iterates. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is 5 as it offers a specific and concrete suggestion for improvement, leaving no ambiguity about how to implement the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 124125, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the Hoeffding inequality and suggests that the authors elaborate on it, particularly regarding the independence of samples and the conditioning on previous iterates. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding bound holds true as long as samples are drawn independently and that stochastic algorithms impose additional conditions that guarantee the Hoeffding inequality. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. While the authors may be familiar with the Hoeffding inequality and its application in stochastic algorithms, the lack of detailed justification or examples makes it difficult for them to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could provide more elaboration. It points out the relevance of the Hoeffding inequality in the context of stochastic algorithms and suggests that the authors elaborate on how this inequality holds true under certain conditions. This feedback is clear and actionable, as it directs the authors to a particular section of the paper where they can enhance the explanation and clarity. However, the comment could be more helpful if it provided additional context or examples to guide the authors in their elaboration. Overall, the comment is 4 as it offers a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. While the comment implies that the authors should consider incorporating this approach, it does not provide explicit instructions on how to do so or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the potential benefits and implementation details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. However, it does not specify which part of Table 1 this suggestion pertains to, nor does it provide detailed guidance on how to incorporate this approach. The authors can infer that it relates to the experimental setup or results section, but the lack of specificity and explicit references make it difficult to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. However, the comment does not provide any reasoning, examples, or references to support why this approach would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. While it provides a specific suggestion for improvement, it lacks detailed guidance on how to implement this approach or why it would be beneficial. The comment does not offer a clear rationale for why this addition would enhance the paper or provide examples of how it could be integrated. As a result, the feedback is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This implies that the authors should conduct an ablation study to provide a clearer understanding of their method. However, the comment does not specify how to conduct this study or what specific aspects should be included. While the action is implicit, it is somewhat concrete in suggesting the need for an ablation study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This implies that the authors should provide more detailed analysis or experiments to justify their methodological choices. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in its suggestion for an ablation study, but without clear grounding, the authors may find it challenging to identify the exact area needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This claim is 3 as it provides a logical reasoning for the need of an ablation study to justify the methodological choice. However, the comment lacks specific examples or references to support the claim that fewshot examples might improve performance. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of an ablation study to explain the choice of prompt. It suggests that an ablation study could help clarify why the authors chose the prompt in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s methodology and clarity. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, distinguishing them from \"temporal relationship.\" This feedback is direct and provides a clear action for the authors to take, ensuring that they use these terms accurately in their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of using the terms \"causal mechanisms\" and \"causality\" carefully, distinguishing them from \"temporal relationship.\" This provides clear guidance on what needs to be addressed in the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of terms \"causal mechanisms\" and \"causality,\" suggesting that they should be used carefully to distinguish them from \"temporal relationship.\" This is a factual statement asking for precision in terminology, rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, pointing out a potential confusion in the use of terms related to causality and temporal relationships. It provides a direct suggestion to use these terms carefully, which is actionable for the authors. However, the comment could be more helpful if it offered additional guidance on how to differentiate between these concepts or provided examples of how to apply the suggestion. Despite this, the feedback is still 3 as it highlights a specific area for improvement and offers a clear direction for the authors to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels\". While the comment implies that the authors should address this relationship, it does not provide specific guidance on how to do so or what aspects of the results should be discussed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on the relationship between the results and the lower bounds, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this discussion should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for improvement by suggesting a connection to existing work. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper. While it points out a relevant topic, it does not offer actionable steps for the authors to follow, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach. The reviewer questions the assumptions underlying the use of PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information or justification regarding the assumptions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and provide more detail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, questioning the assumptions underlying this approach. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique, suggesting that the authors should clarify how well the assumptions are met, but it lacks explicit references to specific sections or elements of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach. The reviewer questions the assumptions underlying the use of PCA and references a specific paper, \"Towards robust explanations for deep neural networks\" by Dombrowski et al., to support the idea that PCA aims to retain maximum information in the data with reduced dimensionality. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the novelty and significance of the approach. The reference to the external work provides some context but does not fully address the claim. Therefore, the comment is 3, as it provides some support but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach rather than a novel contribution. The reviewer questions the assumptions underlying the use of PCA and asks for clarification on how well these assumptions are met. This feedback is 3 as it prompts the authors to consider the justification and assumptions behind their methodology, which could lead to a more robust discussion in the paper. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns or improve the clarity of the paper. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the fewshot RC models considered in the paper are not stateoftheart models and questions how their performance compares to relation extraction/generation models in fewshot settings. While the comment raises a concern and asks for a comparison, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the fewshot RC models considered in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison of the models to stateoftheart models and relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, providing references to support this claim. However, the comment lacks detailed reasoning or specific comparisons to demonstrate how these models are not stateoftheart. The references provided are external sources, which could be useful for further investigation, but the comment does not fully substantiate the claim within the context of the paper. Therefore, the claim is 4, as it provides some support but could be strengthened with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart models. It provides references to support this claim, which could help the authors understand the context better. Additionally, the comment raises a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is clear and actionable, as it prompts the authors to consider a more comprehensive evaluation of their models against current benchmarks. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is 4 as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the results in Section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors might expand their results to other types of networks or what specific changes they should make to their analysis. Without any guidance or direction, the authors are left without a clear understanding of how to address this limitation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation of the results, which is that they only apply to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed or expanded upon in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific limitation of the results presented in Section 4, noting that they only apply to shallow fullyconnected ReLU networks. While this feedback identifies a potential constraint of the study, it lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to other types of networks. Without actionable advice or further elaboration, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. It explicitly asks the authors to speak about what was observed, indicating a clear action for the authors to take. The comment is direct and provides a specific request for additional information, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion of using sequential MCB vs a single MCT layers for the decision head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors provide results or observations regarding this discussion, which is a clear and actionable request for additional information. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or additional information regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for more information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the discussion by noting that the results for using sequential MCB vs a single MCT layer for the decision head are not presented. It requests that the authors provide some insight into what was observed, which could be valuable for the reader\"s understanding of the decisionmaking process. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific aspects of the observation should be highlighted. Despite this, the feedback is 3 as it directs the authors to a specific area that needs further elaboration, providing some guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify or address these concerns, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or clarification regarding the choice of distribution sets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the distribution sets are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its questioning of the choice and control of distribution sets, but without clear grounding, it is challenging for the authors to determine where to make changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specificity and does not provide any suggestions or guidance on how the authors might address these questions. The feedback is 3 as it prompts the authors to consider these issues, but it does not offer actionable advice or detailed insights to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct perplexity experiments using more current language models, specifically transformerbased (masked) language models, to better align their paper with current NLP trends. This is an explicit action with concrete guidance on how to improve the draft by specifying the type of models to use. The authors know exactly what needs to be done to enhance their work, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"perplexity experiments\" and \"obsolete language models (ngram HMM, RNN),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the use of transformerbased (masked) language models to align the paper with current NLP trends. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the perplexity experiments are conducted on outdated language models (ngram HMM and RNN) and recommends using transformerbased models instead. This claim is 3 as it provides a logical reasoning for the suggestion, noting that the current models are rarely used. However, the comment lacks specific examples or references to support the claim that transformerbased models are more appropriate or current in NLP trends. Providing such examples or references would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments being conducted on outdated language models (ngram HMM and RNN), which are no longer commonly used in NLP. It suggests that the authors should instead use transformerbased (masked) language models to better align their paper with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement that can enhance the relevance and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to implement this change or why it is important for the paper. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of \"mu,\" which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion of \"muestimation\" in the paper, implying that it is related to the proportion of missing observations. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of \"mu,\" but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the estimation of \"mu,\" which is described as the proportion of missing observations. The comment highlights a lack of clarity regarding how \"mu\" can be estimated, suggesting that the authors have not provided sufficient information on this aspect. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim of lack of clarity. This makes the claim 3, as it points out an area that needs clarification but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the estimation of \"mu,\" which is described as the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might clarify this issue or improve the discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific action for the authors to take: presenting the performance as a function of the distance of initialization to the groundtruth. It provides a clear and concrete method for implementing this suggestion, including specific steps such as varying the distance c and reporting the performance accordingly. The comment also offers an expectation of the outcome, which further guides the authors on what to expect. This level of detail and explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. It provides a clear and actionable suggestion, but it does not specify which part of the paper this analysis should be included in. While the authors can infer that it relates to the experimental or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific, as it outlines a method for analyzing sensitivity to initialization, but the lack of explicit grounding limits the comment to being 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. The suggestion is supported by logical reasoning, as it is based on the expectation that the mean error and variance would increase as the quality of initialization decreases. However, the comment lacks specific examples or references to existing literature that might support this claim, making it 3. The authors would need to consider the rationale and potentially conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by analyzing the sensitivity to initialization. It proposes a method to present performance as a function of the distance of initialization to the groundtruth, which could help in understanding how the quality of initialization affects the results. This feedback is clear and offers a concrete way for the authors to enhance their analysis, making it 5 for improving the draft. However, the comment could be more helpful if it included additional context or examples to further guide the authors in implementing this suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, providing a clear direction for the authors to address this point. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that since tensor entries are real, taking the absolute value does not add any value to the calculation. The comment provides a clear and straightforward explanation, making it 5. The authors can easily understand and address this point by removing the unnecessary operation. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can be easily implemented by the authors. However, the comment could be more helpful if it explained why this operation is unnecessary or how it might affect the calculations. Despite this, the comment is 4 as it directs the authors to a precise area for improvement, making it a valuable addition to the review process. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should consider providing highprobability bounds, specifically mentioning the use of ensemble methods as performed in the experiments. It also suggests adding a measure of robustness to the experiments, such as error bars or standard deviation, in addition to the mean error. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment suggests providing highprobability bounds and mentions ensemble methods as a possible approach, referencing the experiments. It also suggests adding a measure of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion is specific in terms of what needs to be addressed, such as providing highprobability bounds and adding measures of robustness. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and asks if it would be possible to obtain highprobability bounds. It mentions ensemble methods as a potential approach and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that ensemble methods could be used to achieve highprobability bounds. This makes the claim 3, as it provides a direction for improvement but requires further elaboration or evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by noting that only bounds in expectation are provided, and it suggests that highprobability bounds could be beneficial. It offers a specific suggestion to achieve this by using ensemble methods, as demonstrated in the experiments. Additionally, the comment recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to enhance their work. However, it could be more helpful if it included examples or further explanation of how to implement these suggestions. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the motivation as \"quite good\" but expresses skepticism about the results, suggesting that they should be evaluated from more aspects, such as actual latency, memory consumption, and network size. While the comment implies that the authors should consider these additional aspects, it does not provide explicit guidance on how to incorporate them into the evaluation or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation and results of the paper, specifically mentioning that the results seem less impressive. However, it does not specify which part of the paper these results are presented in, making it weakly grounded. The comment suggests evaluating the results from more aspects, such as actual latency, memory consumption, and network size, which provides some specificity about what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses skepticism about the results, suggesting that they are less impressive and should be evaluated from more aspects, such as actual latency, memory consumption, and network size. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the motivation of the paper as \"quite good\" but expresses skepticism about the results, suggesting that they are less impressive. It further suggests that the results should be evaluated from more aspects, such as actual latency on the target device, memory consumption during inference time, and the actual network size. While the comment identifies a potential area for improvement by suggesting additional evaluation criteria, it lacks specific guidance on how to implement these suggestions or what specific metrics to use. The feedback is 3 as it points out a gap in the evaluation but could be more actionable with detailed suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper, questioning whether it offers significant differences from an existing work. The reviewer asks for clarification on how the paper differs from the referenced work and whether it merely applies a similar methodology to a new task. While the comment implies that the authors should provide a clear explanation of their contributions and how they differ from existing work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the novelty and differences from the referenced work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper and asks for clarification on how it differs from a specific existing work, \"https://aclanthology.org/2021.findingsacl.57.pdf.\" While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or discussion sections where novelty and contributions are typically highlighted. The comment is specific in its request for clarification on the differences and whether the methodology is merely applied to a new task. However, because it does not explicitly mention a section or part of the paper, the comment is weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a claim about the novelty of the paper, suggesting that it is incremental and similar to an existing work. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it offers significant differences from an existing work. It prompts the authors to clarify how their paper differs from the referenced work, specifically asking if it merely applies a similar methodology to a new task. This feedback is 3 as it encourages the authors to reflect on their contributions and provide a clearer explanation of their work\"s originality. However, the comment could be more helpful if it offered suggestions on how to address the perceived lack of novelty or provided examples of potential differences. Overall, the comment provides a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer questions the logic behind this observation, asking \"Why?\" However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what steps they should take to improve their draft. The authors are left without a clear understanding of what needs to be done to resolve the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation studies, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The comment raises a question about the logic behind this observation, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer asks \"Why?\" but does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. This observation raises a logical question about the rationale behind these results, prompting the authors to reconsider their approach or provide a clearer explanation. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential problem, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the statement in the abstract is unclear and suggests that it should be more highlevel, avoiding technicalities. This provides a direct action for the authors to revise the abstract to make it more accessible and less technical. The feedback is clear and concrete, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract\" and the specific statement that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that it should be more highlevel. However, the comment does not provide specific examples or detailed reasoning to support why the statement is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, pointing out that a particular statement is unclear. It suggests that the abstract should be more highlevel and avoid technicalities, providing a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of the technicalities should be avoided. Despite this, the feedback is still valuable as it directs the authors to simplify their abstract, making it more accessible to a broader audience. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced comment about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. While the comment implies that the authors should expand their results to include other modalities, it does not provide explicit instructions on how to do so or which specific modalities to consider. The suggestion is concrete in terms of the modalities to explore but lacks detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced comment about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results section, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in suggesting the inclusion of results in other modalities and the consideration of OOD performance, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including results in other modalities, such as languagerelated tasks, would be beneficial. It also notes that for languagerelated tasks, outofdistribution (OOD) performance is important, which might make expected test loss less meaningful. However, the comment lacks specific examples or references to support the claim that including results in other modalities would be valuable or that OOD performance is particularly relevant for language tasks. This makes the claim 3, as it provides a general suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced observation about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. This feedback is 3 as it identifies a potential area for expansion and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered guidance on how to incorporate these additional modalities or provided examples of languagerelated tasks that could be explored. Overall, the comment provides some direction but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically in the context of fewshot learning. It highlights the need to explain how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to provide more justification and details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically in the context of fewshot learning for graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the authors should provide this additional justification. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, particularly in the context of fewshot learning. It provides a logical reasoning by explaining that the paper defines a fewshot situation for graph link prediction but does not address how to effectively use \"fewshot\" instances or guarantee generalizability to new tasks. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the motivation behind the work. It highlights the importance of explaining how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to enhance the justification or provide additional details. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their use of GP or address the critique. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area needing revision. Additionally, while the comment provides some context about the GP community, it does not specify what aspects of the GP usage are considered naive or how the authors could improve their approach. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The reference to NIPs 2005 is a general reference and does not provide direct evidence or context that would help the authors address the issue. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might improve their approach or address the critique. Without actionable advice or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized. The comment raises a specific concern about the application of dropout to both embeddings and hidden states. While the comment identifies a potential issue and provides a reference, it does not explicitly instruct the authors to address the concern or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the regularization practices in their models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement regarding the necessity of smaller architectures for language models compared to GAN models, and it provides a counterexample from Zaremba et al. (2014) to support the claim. Additionally, the comment raises a question about the application of dropout to both embeddings and hidden states, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. The comment also raises a question about the application of dropout to both embeddings and hidden states. This provides some justification for the claim, as it references a specific study and raises a potential issue with the regularization practices. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. This feedback is 3 as it points out a potential issue with the regularization practices in the paper and raises a question about the application of dropout to both embeddings and hidden states. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or improve the regularization practices. Overall, the feedback is 3, as it identifies a weakness and prompts the authors to consider their regularization methods, but it lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content. It suggests that the writing could be improved in this part. However, the comment does not provide specific guidance on how to improve the writing or which ablations are particularly problematic. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without clear instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are hard to locate in the following content, indicating a need for improvement in the writing. However, it does not specify which sections or ablations are being referred to, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in its suggestion to improve the writing but lacks grounding as it does not provide clear references to the sections or content being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following content. However, it does not provide specific examples or details about which ablations are difficult to find or how the writing could be improved. This lack of detailed information makes it challenging for the authors to understand and address the issue effectively. As a result, the comment is considered 1, as it lacks sufficient evidence or justification to support the claim.", "helpfulness_rationale": "The comment identifies a specific issue with the organization of the paper, noting that some ablations mentioned in previous sections are difficult to locate in the subsequent content. This feedback is 3 as it points out a potential problem with the paper\"s structure, which the authors can address by revising the content to improve clarity and coherence. However, the comment lacks specificity and does not provide detailed guidance on how to resolve the issue or which sections are particularly problematic. While it highlights an area for improvement, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the differential privacy application is not fully developed and encourages the authors to think it through more clearly. It also highlights the novelty of the online algorithm and robustness, and recommends moving the experimental results from the appendix to the main paper. While the comment provides some guidance on areas for improvement, it lacks specific instructions on how to enhance the differential privacy application or what aspects need more clarity. The action is implicit and somewhat vague, as the authors are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given 2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the differential privacy application, suggesting that it is \"halfbaked\" and encouraging the authors to think it through more clearly. Additionally, it highlights the novelty of the online algorithm and robustness and recommends moving experimental results from the appendix to the main paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think it through more clearly. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The mention of the online algorithm and robustness being \"significantly interesting and novel\" is a positive statement but does not contribute to the verifiability of the claim about the differential privacy application. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a mixed assessment of the paper, acknowledging the novelty of the online algorithm and robustness but expressing concerns about the differential privacy application being \"halfbaked.\" It encourages the authors to think through this aspect more clearly. Additionally, it suggests moving experimental results from the appendix to the main paper, which could enhance the paper\"s clarity and impact. However, the comment lacks specific guidance on how to improve the differential privacy application or what aspects need more attention. While it identifies areas for improvement, the feedback is 3 as it provides a general direction but lacks detailed actionable suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what changes or clarifications are needed to resolve the ambiguity. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of methodology specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be tailored to bimanual manipulation and that robotic manipulation alone could be more appropriate. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. This feedback is 3 as it identifies a potential issue with the methodology\"s applicability, prompting the authors to consider whether their approach is indeed specific to bimanual manipulation. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this concern or improve the methodology. While it points out an area for improvement, it does not offer actionable guidance, making it 3 but incomplete."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, noting that the paper examines each objective independently and in isolation. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the comparability of their results. The comment implies that the authors should consider a more comprehensive approach to comparing Geffect values, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, noting that the paper examines each objective independently and in isolation. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the concern and potentially conduct additional analysis to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically noting that the examination of Geffects for each unlearning objective independently and in isolation may raise concerns about the comparability of Geffect values across different approaches. This is a valid observation that could impact the interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the comparability of their results. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It questions whether the authors have a theory explaining why the method is less effective in this setting. While the comment identifies an area for further explanation or theory development, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a theoretical explanation for the observed inconsistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the tables\" and \"the 1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting, and asks for a theoretical explanation for this observation. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. The comment also raises a question about whether the authors have a theory explaining why the method is less effective in the 1shot setting. While the comment provides some evidence by referencing the tables, it lacks detailed reasoning or specific examples to fully substantiate the claim. The request for a theoretical explanation adds to the need for further justification. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or reasoning to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It points out that the tables show UNIFORM does not always offer a clear advantage, prompting the authors to consider why this might be the case. The comment also acknowledges that the clarity and design of the experiments and results are well done. However, it lacks further guidance or suggestions on how the authors might address the inconsistency or improve their analysis. While it highlights an important area for consideration, the comment could be more helpful with additional actionable advice or specific recommendations for improvement. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider the reason behind the information value being a \"stronger predictor\" for dialogue, specifically referencing the complementarity discussed on page 7 or the discussion on page 8. It implies that adding an explanation or reference to an existing linguistic theory could strengthen the paper. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them to add the explanation or reference. The action is implicit and somewhat vague, as the authors need to infer that they should include additional information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the information value being a \"stronger predictor\" for dialogue and suggests that the authors should consider existing linguistic theories that could explain this. The comment provides a clear direction for improvement by recommending the inclusion of such theories to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the information value being a \"stronger predictor\" for dialogue could be explained by existing linguistic theories. However, it does not provide specific references or examples of such theories, making the claim 3. The authors would need to conduct additional research to identify relevant theories and incorporate them into their work. While the comment provides a direction for improvement, it lacks detailed justification or evidence, making it 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider the reason behind the information value being a \"stronger predictor\" for dialogue. It references specific pages (7 and 8) where the complementarity is discussed, implying that an explanation or reference to existing linguistic theories could strengthen the paper. This feedback is clear and actionable, as it directs the authors to explore theoretical foundations that could enhance their work. However, the comment could be more helpful if it provided specific examples of linguistic theories or suggested how to integrate them into the discussion. Overall, the comment is 4, as it offers a constructive direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived gap in the paper regarding the potential benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. The reviewer suggests that the authors should have spent more time discussing these aspects and provides an example by asking about the biggest takeaways from the found architecture. However, the comment does not explicitly instruct the authors to address this gap or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the potential for future network architecture design but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" discussion of AutoML approaches and their potential benefits, specifically the extraction of hints for future network architecture design. However, it does not specify which part of the paper this discussion is lacking in, making it weakly grounded. The comment is specific in suggesting that the authors should have spent more time on this aspect and provides an example by asking about the biggest takeaways from the found architecture. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should have discussed the potential benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. The reviewer provides a logical reasoning by stating that this aspect is important for improving raw performances and future design. However, the comment lacks specific examples or references to support the claim that the authors did not adequately address this aspect. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the discussion of AutoML approaches and their potential benefits, specifically the extraction of hints for future network architecture design. It highlights the importance of this aspect and suggests that the authors should have spent more time on it. The comment provides a specific example by asking about the biggest takeaways from the found architecture, which gives the authors a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address this gap. Overall, the feedback is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the definition of \"T_a(t)\" between Section 3.1, where it is used, and Section 4, where it is defined. This comment explicitly identifies the issue and suggests that the authors should ensure consistency in the definition and usage of variables across different sections of the paper. However, it does not provide specific guidance on how to resolve this inconsistency, such as suggesting a reorganization of the sections or a clarification of the definition. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely clear on how to implement the change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of \"T_a(t)\" being used without being defined until Section 4. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of \"T_a(t)\" in the paper. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"T_a(t)\" is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper, which could confuse readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their work. While it points out a problem, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that the author only tested the ReBeL performance on two typical games and did not explore more complex problems. It suggests that the performance on games with bigger depth, which would result in larger inputs for the value and policy functions, is not evaluated. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experimental scope but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments, specifically mentioning that the author only tested on two typical games and did not explore more complex problems, particularly those with bigger depth. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental scope and the potential impact on the value and policy functions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and did not explore more complex problems, particularly those with bigger depth. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim is not 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope of the paper, noting that the authors only tested the ReBeL performance on two typical games and did not explore more complex problems, particularly those with bigger depth. This feedback highlights an area where the authors could expand their experimental evaluation to better understand the robustness and applicability of their method. However, the comment lacks specific suggestions or guidance on how to address this limitation or what additional experiments might be beneficial. While it points out a potential weakness, it does not provide actionable advice for improvement. Therefore, the comment is 3, as it offers some insight but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach and that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide explicit guidance on what specific evidence or arguments are lacking or how the authors might address this issue. The action is implicit and vague, leaving the authors to infer that they need to provide more substantial evidence or arguments but without clear direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, specifically mentioning the incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the significance of this contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific issues or areas where more evidence is needed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, suggesting that it may be an incremental advancement over the TACTiS approach rather than a significant contribution to the field. It highlights the need for more substantial evidence or arguments to establish the significance of this contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. While it points out a potential weakness, it does not offer actionable advice for improvement, making it 3. The authors are left with a general direction but without detailed steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it lacks concrete details on what specific aspects should be covered or how to present the discussion. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the missing discussion on theoretical guarantees, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it directs the authors to include a discussion on this theoretical aspect, which could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to focus on. Overall, the comment is 4 as it points out a significant gap in the paper and encourages the authors to address it, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative measures to evaluate the generated VCEs, with evaluation primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is mainly performed through visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation of generated VCEs lacks quantitative measures, relying mainly on visual inspection. This is a subjective opinion that requires justification, as it implies that the current evaluation method is insufficient. However, the comment does not provide specific examples or references to support why quantitative measures are necessary or how they could be implemented. Without detailed reasoning or evidence, the claim remains 3, as the authors would need to infer the importance of quantitative measures based on general knowledge of evaluation practices. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it relies heavily on visual inspection without quantitative measures. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should incorporate more robust evaluation methods to assess the quality and effectiveness of the generated VCEs. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used for evaluation. Despite this, the feedback is clear and actionable, making it 4 for guiding the authors in enhancing their evaluation process."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper claims to show improvements over baselines, but the actual results are only marginally better and often within the error bar range. This suggests that the performance differences between methods are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The feedback implies that the authors should reconsider their claims or provide more detailed analysis, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim of marginal improvements over baselines, noting that the error range is high, which suggests that the performance differences between methods are not significant. However, it does not specify which part of the paper this claim is based on, such as a particular section or figure that presents the results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, while the comment highlights the issue with the claim, it does not provide specific guidance on how to address it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper shows only marginal improvements over baselines, with the performance differences often within the error bar range. This claim is based on the observation that the error range is high, suggesting that the performance differences between methods are not significant. The comment provides a logical reasoning by pointing out the high error range, which supports the claim that the improvements are marginal. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is 4, as it provides a clear rationale for the claim but lacks detailed evidence or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment points out that the paper claims to show improvements over baselines, but the actual results are only marginally better and often within the error bar range. This suggests that the performance differences between methods are not significant. While the comment identifies a potential issue with the paper\"s claims, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their results. The feedback is 3 as it highlights a weakness in the paper\"s claims, but it lacks actionable advice or detailed analysis to help the authors improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how to make the new set more diverse and representative and how to select representative images. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit, as the authors need to infer that they should provide more detailed information on the selection process, but it lacks concrete steps or examples to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the diversity and representativeness of the new proposed evaluation set compared to the previous method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for clarification on how to make the new set more diverse and representative, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding how the new proposed evaluation set is more diverse and representative than the previous method. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how the new set is more diverse and representative and how to select representative images. This feedback is clear and actionable, as it prompts the authors to provide more detailed information on the selection process and criteria for the new evaluation set. However, the comment could be more helpful if it offered suggestions or examples on how to achieve this diversity and representativeness. Overall, the comment is 4 as it directs the authors to a critical area that needs clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work, specifically referencing a paper by DoshiVelez and Kim. While it implies that the authors should clarify the connection between their work and the referenced paper, the comment does not explicitly instruct the authors to make this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should address the relevance of the term \"interpretable\" in their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" in the context of the work, referencing a specific paper by DoshiVelez and Kim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work, referencing a specific paper by DoshiVelez and Kim. The comment does not make a claim or suggest changes but rather seeks clarification. It is a factual question that requires no justification or evidence, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work, specifically referencing a paper by DoshiVelez and Kim. While it prompts the authors to clarify the connection between their work and the referenced paper, it does not provide any specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable feedback, leaving the authors with a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on what additional datasets or experiments could be considered, the authors are left without a clear path for improvement. As a result, the comment lacks actionable advice, making it 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide details on what specific aspects of the experiments are lacking or how they could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might expand their experimental scope. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the validity of the results. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this observation highlights a potential weakness in the study, it does not provide any suggestions or guidance on how the authors might address this limitation or expand their experimental scope. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in reference 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference 10, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. The comment implies that the proposed method may not be novel or innovative, as it seems to be similar to an existing approach. However, the comment does not provide any specific evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the comparison. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the proposed method by pointing out its similarity to an existing approach in reference 10. It suggests that the method in 10 could also be equipped with scoring causal predictions and interventional data, questioning why the proposed method cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the existing approach. The feedback is 3 as it prompts the authors to consider the novelty of their method, but it could be more helpful with additional details or constructive advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors can infer that they need to consider adding a sparsity constraint but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s incentivization to use fewer factors, but it lacks grounding as it does not direct the authors to a particular section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation with more tasks. The comment provides a logical reasoning for this claim by explaining the potential consequence of not having a sparsity constraint. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to consider the implications of this lack of sparsity constraint and potentially include additional details or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the model\"s efficiency and scalability. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or implement a sparsity constraint. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. While it implies that these experiments are necessary, it does not provide explicit instructions or detailed guidance on how to conduct them. The authors can infer that they need to add these experiments, but the comment lacks concrete details on what specific aspects of distributed deployment and larger models should be explored. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to identify where to incorporate these suggestions. Additionally, the comment lacks specificity regarding what aspects of distributed deployment and larger models should be explored. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper, suggesting that experiments on distributed deployment and a larger model should be included. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the evaluation\"s scope and depth. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects of distributed deployment and larger models should be explored. Despite this, the comment is 4 as it directs the authors to a meaningful area for expansion, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which can be easily satisfied due to the smoothness of neural models. While the comment implies that the authors should expand on this aspect, it does not specify what kind of explanations are needed or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to add more detail but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper discusses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that the authors provide more explanations on this topic, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, suggesting that this consistency can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference. It points out that the paper mentions this aspect multiple times (Lines 9597 and 308310) but does not elaborate on it. This feedback is clear and actionable, as it directs the authors to expand on a particular topic that may be unclear or underdeveloped in the draft. However, the comment could be more helpful if it offered specific suggestions on what aspects of the consistency should be elaborated upon or how to present the explanations. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should provide evidence or experiments to support their claim by testing their model with larger word embedding and LSTM parameters. While the comment suggests an action\u2014testing the model with larger parameters\u2014it does not provide explicit instructions on how to conduct these tests or what specific parameters to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the authors\" claim about achieving superior performance with fewer parameters compared to the baseline. It mentions specific aspects of the model, such as the word embedding size and LSTM size, which are directly related to the claim. The comment also specifies what needs to be addressed by asking for improvements when the proposed model uses larger word embedding and LSTM parameters. This provides clear guidance on what the authors need to consider to support their claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. The reviewer asks for evidence or experiments to support the claim by testing the proposed model with larger word embedding and LSTM parameters. This request for additional evidence or experiments provides a clear direction for the authors to substantiate their claim, making the comment 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving superior performance with fewer parameters compared to the baseline model. It suggests that the baseline model might have been tested with standard parameter settings, implying that the authors should provide evidence or experiments to support their claim. The comment is specific in its request for additional testing with larger word embedding and LSTM parameters, which could help substantiate the claim. However, it does not provide detailed guidance on how to conduct these experiments or what specific parameters to test. While the comment identifies a potential weakness in the authors\" claim, it could be more helpful with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the application of regularization between the LN model and the GLM presented by pillow et al. It suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. However, the comment does not provide explicit instructions on how to achieve this or what specific features should be replicated. The action is implicit and somewhat vague, as the authors can infer that they need to align their approach with the previous model, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of regularization to both LN models and GLMs, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the GLM presented by pillow et al., suggesting that the authors should try to reproduce the main features of this model to make the comparison fair. This level of specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should try to reproduce the main features of the previous model presented by pillow et al. to make the comparison fair. The reviewer provides a specific example of how the previous model used L1 regularization for filters and a lowrank approximation to the spatial filter, contrasting it with the current approach of cropping the stimulus. This comparison is based on logical reasoning and provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by including references to the specific work by pillow et al. or more detailed explanations of the differences in methodology. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM presented by pillow et al. It points out that the authors apply regularization in the form of a cropped stimulus to both models, whereas the previous model used L1 regularization for filters and a lowrank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. This feedback is 3 as it highlights a specific area where the authors might need to adjust their approach to ensure a fair comparison. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific features of the previous model should be replicated. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include some failure cases and related discussion in their paper. While it implies that the authors should add this information, the comment does not provide specific guidance on what constitutes a \"failure case\" or how to structure the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to include additional content but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including \"some failure cases and related discussion,\" but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit guidance, it is difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the inclusion of failure cases and discussion, but it lacks grounding as it does not clearly identify the section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including \"some failure cases and related discussion\" would be beneficial. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what constitutes a \"failure case\" or how to structure the discussion. The authors are left with a general idea of what to address but without detailed instructions on how to implement it. This makes the comment 3, as it points out a potential area for enhancement but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting an ablation study to determine the necessity of the base layer GNN encoding in the proposed method. This is a clear and direct action for the authors to take, providing a specific step to improve their draft. The comment also specifies what the ablation study should focus on, which adds to the concreteness of the action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the necessity of the base layer GNN encoding and suggests conducting an ablation study to determine its importance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. This is a logical suggestion that requires no additional evidence or references, as it is based on a straightforward request for further analysis. The comment does not contain subjective opinions, judgments, or suggestions that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty in the proposed method, namely the necessity of the base layer GNN encoding. It suggests conducting an ablation study to determine whether this component is essential or can be removed without affecting the overall performance. This feedback is clear and actionable, providing the authors with a concrete step to take to improve their draft by clarifying the role of the base layer GNN encoding. However, the comment could be more helpful if it offered additional context or examples of how such an ablation study might be structured or what insights it could provide. Overall, the comment is 4 as it directs the authors to a meaningful area of investigation, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"explicitly add the upper bounds of counting\" and potentially elaborate on empirical runtimes. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a clear path forward for the authors. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of inadequate discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, specifically mentioning a brief statement in the paper. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential gap in the discussion, it lacks specific examples or references to support the claim about the inadequacy of the current discussion. The suggestion for improvement is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion of computational complexity in counting homomorphisms. It points out that the current statements are brief and suggests that the authors should explicitly add upper bounds and potentially elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. By addressing this gap, the authors can enhance the comprehensiveness and rigor of their paper. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as correcting a typo (\"f\" to \"g\") in line 108 and removing an extra period in line 115. Additionally, it poses a question about the convergence of the baseline MCL with deep learning, which implies that the authors should address this concern in their draft. The comment is clear and direct in its instructions, providing concrete steps for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (\"line 108\" and \"line 115\") where corrections need to be made, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as a typo and an extra period, which need to be corrected. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing a clear direction for the authors to address this concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, without any subjective claims or opinions that require verification. It points out specific errors in the text, such as a typo and an extra period, and asks a question about the convergence of the baseline MCL with deep learning. Since it does not contain any claims or suggestions that need justification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out two errors in the text: a typo in \"f\" to \"g\" in line 108 and an extra period in line 115. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, which is a critical aspect of the methodology. This question prompts the authors to address a potential issue that could impact the ensemble performance. By identifying these specific issues and raising a relevant question, the comment is 5 as it guides the authors in improving the clarity and robustness of their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a study on inference time and suggests comparing the inference speed of the proposed pose estimation method with previous topdown and bottomup methods. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis of inference time and compare it with existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks a study on inference time and implies that it would be beneficial to compare the inference speed of the proposed pose estimation method with previous topdown and bottomup methods. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in suggesting a comparison with existing methods, but without clear grounding, the authors may find it challenging to identify the exact area needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is no study on inference time and suggests comparing the inference speed of the proposed pose estimation method with previous topdown and bottomup methods. However, the comment lacks specific examples or references to support the claim that such a comparison is necessary or beneficial. Without detailed reasoning or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some justification but lacks key elements to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of a study on inference time, which is relevant for a pose estimation method. It suggests that comparing the inference speed of the proposed method with previous topdown and bottomup methods could be beneficial. This feedback is 3 as it points out a potential area for improvement and provides a direction for further analysis. However, it lacks specific guidance on how to conduct the comparison or what metrics to use, which would make the feedback more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss the limitations of the claim about evolutionary dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some lowvariance units. It also mentions that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be explicitly discussed. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how to discuss these limitations or what specific aspects should be included in the discussion. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the claim about evolutionary dropout,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, noting that it can only increase the variance of some lowvariance units and suggesting that Batch Normalization standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the discussion of evolutionary dropout. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This comparison provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it can only increase the variance of some lowvariance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. The comment suggests that these limitations should be discussed explicitly, providing a clear and actionable direction for the authors to improve their draft. By highlighting a specific area for discussion and offering a comparison with another technique, the comment is 5 as it guides the authors in enhancing the depth and accuracy of their analysis. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. While it explicitly states an action, it lacks specific guidance on what aspects of the contribution should be elaborated or how to present them. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description, making it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide specific guidance on what aspects of the contribution should be elaborated. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated or how to present them. This makes it difficult for the authors to understand what changes are needed to enhance their draft. The comment is 3 as it points out a gap in the paper, but it could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections (2.3 and 2.4) where the description of the layerwise attention mechanism is scattered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests organizing the main contributions into a separate section and then describing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, specifically regarding the description of the main contributions and the referencing of certain techniques. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. This recommendation would help improve the paper\"s structure and make it easier for readers to follow. Additionally, the comment suggests referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper\"s comprehensiveness. However, the comment could be more helpful if it provided examples or further elaboration on how these suggestions would benefit the paper. Overall, the feedback is 4 as it offers clear guidance for improving the paper\"s organization and clarity, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments. It provides a clear rationale for why this is important, noting that the scale of the datasets (~100k images) suggests that full annotation is likely available, making a supervised baseline informative for comparison. The comment also highlights the value of including a fully supervised pretrained network as a baseline for evaluating the performance of selfsupervised methods. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of supervised baselines in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that including supervised baselines would be informative for comparing the performance of selfsupervised methods to a fully supervised pretrained network. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a missing aspect in the experiments. It provides a logical reasoning by suggesting that the scale of the datasets (~100k images) implies that full annotation is likely available, making a supervised baseline informative for comparison. However, the comment could be strengthened by providing specific examples or references to studies that have used supervised baselines in similar contexts. While the reasoning is sound, the lack of detailed examples or references makes the claim 4, as it requires the authors to infer the importance of including supervised baselines based on the provided rationale.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why including these baselines is important, noting that the scale of the datasets suggests that full annotation is likely available, making a supervised baseline informative for comparison. The comment also suggests that a fully supervised pretrained network would be a valuable baseline for evaluating the performance of selfsupervised methods. This feedback is actionable and provides specific guidance on how the authors can enhance their draft by including these baselines. However, it could be more helpful if it offered suggestions on how to implement these baselines or provided examples of similar studies that have used supervised baselines. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the method\"s effectiveness on the Hopper environment, which has deterministic dynamics, and suggests that it might be equivalent to actionconditional masking. It also questions the absence of BEAR from the baselines and suggests evaluating the method on domains with nondeterministic dynamics to assess its empirical efficacy. While the comment implies that the authors should address these concerns, it does not provide explicit instructions or concrete steps on how to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the method\"s benefits and consider additional domains for evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on the Hopper environment, which has deterministic dynamics, and suggests that it might be equivalent to actionconditional masking. It also questions the absence of BEAR from the baselines and suggests evaluating the method on domains with nondeterministic dynamics. While the comment does not explicitly mention specific sections or parts of the paper, the authors can infer that it relates to the experimental evaluation or methodology sections. The comment is specific in detailing what needs to be addressed, such as the method\"s efficacy on different domains and the inclusion of BEAR in the baselines. However, the lack of explicit references to specific sections or parts of the paper makes it weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and concerns about the method\"s effectiveness, particularly in the context of deterministic dynamics and the absence of BEAR from the baselines. While the comment provides some logical reasoning by questioning the method\"s benefit in deterministic environments, it lacks specific examples or references to support the claim that the method does not have much benefit. The suggestion to evaluate the method on domains with nondeterministic dynamics is a logical step, but it is not fully substantiated with evidence or detailed reasoning. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the method\"s effectiveness, particularly in the context of deterministic dynamics and the absence of BEAR from the baselines. It questions why the method is beneficial on Hopper, which has deterministic dynamics, and suggests that it might be equivalent to actionconditional masking. The comment also recommends evaluating the method on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it points out the omission of BEAR from the baselines, which could be a significant oversight. While the comment identifies important areas for improvement and provides some guidance, it lacks specific suggestions on how to address these issues or improve the draft. The feedback is 4 as it highlights critical aspects that need attention, but it could be more comprehensive with additional guidance or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should provide this justification or what aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be included in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for a justification but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that such a justification is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. While it identifies a potential area for improvement by highlighting the importance of justifying these methods, the comment lacks specificity and does not offer detailed guidance on how to provide this justification. It does not provide examples or suggest specific aspects to focus on, leaving the authors with a general idea but without actionable steps to improve their draft. Therefore, the comment is 3, as it points out a gap but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details are missing, it does not explicitly instruct the authors to include them. The action is implicit and somewhat vague, as the authors can infer what needs to be added but may not be entirely sure of the exact details required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that these details are missing or necessary. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more details about the proposed method should be presented. It highlights the need for clarification on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides the authors with a specific direction for enhancing the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered examples or suggestions on how to present these details effectively. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the challenge of identifying shared information for consistency checking in responses to prompts like \"introduce a sports celebrity to me.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this challenge or improve their method. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific scenario of detecting hallucinations in openended responses, such as the prompt \"introduce a sports celebrity to me.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the challenge of identifying shared information for consistency checking in responses to such prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the challenge of identifying shared information for consistency checking in responses to prompts like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by explaining the potential difficulty in detecting hallucinations in such scenarios, which is a plausible concern. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this critique and potentially provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, specifically its ability to detect hallucinations in openended responses. It provides a specific example, such as the prompt \"introduce a sports celebrity to me,\" where the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider how to address this challenge. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\"s ability to detect hallucinations in such scenarios. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional verification, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct further verification but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to verify the conclusion, but without clear references to specific sections or elements of the paper, the authors may find it challenging to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models, specifically questioning the conclusion about label noise and model size on MNIST and CNN. The comment suggests verifying these conclusions, which is a logical request for further investigation. However, it does not provide specific examples or references to support the claim that the findings are unclear or need verification. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the theoretical findings in relation to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN, which is a specific and actionable piece of feedback. By recommending verification, the comment provides a clear direction for the authors to improve the robustness and applicability of their theoretical findings. However, the comment could be more helpful if it included additional guidance on how to conduct this verification or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The comment implies that the authors should consider reporting cosine similarities for larger weight decay strengths, but it does not specify how to do so or what specific changes are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the application of weight decay to all layers, the expected impact on training loss, and the absence of reported cosine similarities for large weight decay parameters. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that applying weight decay to all layers would lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. It suggests that the absence of reported cosine similarities for such large weight decay strengths is convenient, implying that the authors might be avoiding reporting suboptimal results. However, the comment lacks specific examples or references to support the claim about the expected impact of weight decay on training loss and cosine similarities. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that the authors might be avoiding reporting suboptimal results. This feedback is 3 as it highlights a specific area for improvement and encourages the authors to consider reporting cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional insights into the potential impact of weight decay on the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant omission in the title, abstract, introduction, and discussion regarding the results being for unsupervised random forests. The reviewer emphasizes that this is a serious issue that needs to be addressed to prevent casual readers from drawing incorrect conclusions. The comment explicitly states that this must be fixed for publication, indicating a clear and direct action for the authors to take. Additionally, the reviewer suggests that it would be straightforward to make these changes. The feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not adequately explain that the results are for unsupervised random forests, which could lead to incorrect conclusions. The reviewer emphasizes the importance of this clarification, suggesting it is a \"fairly serious omission.\" However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the exact issues and how to address them based on the general feedback provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the title, abstract, introduction, and discussion do not clearly indicate that the results are for unsupervised random forests. This omission could lead to incorrect conclusions by casual readers. The reviewer emphasizes the importance of addressing this issue for publication, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful by offering specific guidance on how to incorporate this clarification into the paper. Despite this, the feedback is 4 as it highlights a significant weakness and directs the authors to a necessary correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any specific steps to address the issue. The authors are left without guidance on how to respond to this question or what changes might be necessary to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a comparison of computational complexity, which provides clear guidance on what the authors need to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. However, it does not provide any evidence, reasoning, or references to support this claim. The lack of supporting information makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable advice or insights that could help the authors improve their draft. Therefore, it is 2, as it points out a potential area for improvement but does not provide sufficient detail or direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. While the comment implies that this analysis could provide valuable insights, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this analysis further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. The comment also provides a logical explanation of how the roles between \"winners\" and \"cooperators\" might emerge based on the cost to reward the other agent. However, it does not explicitly mention which part of the paper this analysis should be added to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the impact of varying \u03b1 on reward incentives and collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a logical explanation of how the cost affects the roles of \"winners\" and \"cooperators\" and how this might impact the collective return. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the analysis and its potential outcomes based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return, which could provide insights into how the roles between \"winners\" and \"cooperators\" emerge. The comment offers a logical explanation of how the cost affects these roles and suggests that a lower cost might lead to less distinguished roles and a lower collective return. This feedback is clear and actionable, as it identifies a specific area for further analysis and provides a rationale for why it is important. However, it could be more helpful if it included specific suggestions on how to conduct this analysis or what metrics to focus on. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly highlights the lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer suggests that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of these claims. This feedback is explicit and provides a clear action for the authors to take, which is to conduct significance testing to support their claims. The suggestion is concrete, as it specifies the need for statistical analysis to validate the differences between methods. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing to support claims about the differences between certain methods. The reviewer provides a concrete example from the paper, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors make assertions about the differences between certain methods without providing significance testing to support these claims. The reviewer provides a specific example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT4, and contrasts it with other methods like FeedME2 and PPO. The reviewer argues that the differences are minimal and that proper testing, including distribution checks and multiple comparisons, is needed to determine significance. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including specific references or examples of how significance testing should be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer points out that the differences between the methods are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is 5 as it clearly identifies a gap in the paper and provides specific guidance on how to address it. By suggesting the need for statistical analysis, the comment empowers the authors to improve the rigor and validity of their claims. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what kind of evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more evidence but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment specifies what is missing in terms of evidence and analysis, it does not provide detailed guidance on how to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper lacks evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific areas that require more evidence or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be most beneficial or how to present it effectively. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 5 is difficult to comprehend and requests more details about the two baselines presented. It also points out that the authors only studied CATER for Englishcentric datasets, suggesting that they could extend their work to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending their work to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely that it is hard to comprehend, and requests more details about the two baselines presented. Additionally, the comment points out the limitation of the study being confined to Englishcentric datasets and suggests extending the work to other languages. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented. It also points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests extending the work to other languages. However, the comment lacks specific examples or detailed reasoning to support why Figure 5 is difficult to comprehend or how the baselines could be improved. The suggestion to extend the work to other languages is based on common knowledge about text generation APIs, but it does not provide a clear rationale or evidence for why this is necessary. Therefore, the claim is 3, as it provides a general direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It provides a clear and actionable suggestion by requesting more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests that the authors could extend their work to other languages in the future. This feedback is valuable as it highlights a potential area for improvement and offers a concrete suggestion for enhancing the clarity and scope of the paper. However, the comment could be more helpful if it provided specific examples or guidance on how to present the baselines or extend the work to other languages. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by making it more explicit and comparative. The suggestion is concrete, as it specifies what needs to be done to improve the literature review. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the literature review section, indicating that it needs improvement to clarify the main contribution of the proposed method and its distinction from existing work, particularly regarding the utilization of GFlowNet for sequence generation. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be improved, such as providing a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the claim highlights a potential issue with the literature review, it lacks specific examples or detailed reasoning to support the assertion. The authors may find it challenging to address the comment without additional guidance or examples. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the literature review. It points out that the current literature review lacks clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear and actionable suggestion to enhance the literature review by making it more explicit and comparative. This feedback is valuable as it guides the authors on how to improve the clarity and comprehensiveness of their literature review, which is essential for readers to understand the novelty and significance of their work. However, the comment could be more helpful if it offered specific examples or references to illustrate the improvements needed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and concrete, providing the authors with specific actions to take to improve their draft. The use of specific examples, such as the MUSE paper, further enhances the actionability of the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as adding performance metrics on word similarity and sentence translation tasks, and including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and detailed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests two improvements for the experiments: (i) adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages. The first suggestion is supported by referencing the MUSE paper, which provides a clear basis for the recommendation. The second suggestion is also logical and aligns with common practices in language evaluation. However, the comment could be strengthened by providing specific examples or references for the second point. Overall, the claim is 4, as it provides a solid basis for the first suggestion and logical reasoning for the second, but lacks detailed examples for the latter. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experiments, which is valuable feedback for the authors. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. This is a clear and actionable suggestion that can help the authors demonstrate the robustness and effectiveness of their framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This is a minor point but still provides a direction for further exploration. The comment is 4 as it offers concrete and actionable feedback that can guide the authors in enhancing their experimental setup and results. However, it could be more helpful if it provided additional context or examples to support the suggestions. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the applicability of node importance in a 1shot scenario and another about the absence of a 1shot setting in the experiment section, despite related works like RALE having it. While the comment identifies areas of confusion and potential gaps in the paper, it does not provide explicit or implicit actions for the authors to take. The questions are more exploratory in nature, seeking clarification rather than suggesting specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address these issues. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises questions about the consideration of node importance in the paper, specifically in the context of the 1shot scenario and the absence of a 1shot setting in the experiment section. It also mentions related works like RALE that have a 1shot setting. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections that need attention. The authors can make an educated guess about the sections being referred to, but the comment lacks full grounding. The questions are specific in terms of what needs to be addressed, such as the applicability of node importance in a 1shot scenario and the inclusion of a 1shot setting in the experiment. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the applicability of node importance in a 1shot scenario and the absence of a 1shot setting in the experiment section, despite related works like RALE having it. The comment does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, seeking clarification on specific aspects of the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two distinct questions that could help the authors improve their draft. First, it questions the applicability of node importance in a 1shot scenario, which could prompt the authors to clarify or expand their discussion on this aspect. Second, it points out the absence of a 1shot setting in the experiment section, despite related works like RALE having it. This observation could encourage the authors to consider including a 1shot setting in their experiments to enhance the comprehensiveness of their study. While the comment identifies areas for improvement, it lacks specific suggestions or detailed guidance on how to address these issues. Therefore, it is 3, as it provides insight into potential weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to conduct these discussions or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but may not know exactly how to approach it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to discuss the challenges and potential solutions but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that there should be more discussion about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these problems. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional insights and analysis. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach these discussions or what aspects to focus on. Despite this, the feedback provides a valuable direction for the authors to enhance their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should highlight the observations and conclusions made in the experimental section, as this would be beneficial for understanding the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place the highlighted observations or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to make the observations more visible but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section these observations and conclusions are located in, making it weakly grounded. The comment is specific in suggesting that the paper should highlight these observations and conclusions, which would improve clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are important or how they relate to the tradeoffs. This lack of detailed justification makes the claim 3, as the authors would need to infer the significance of the observations and conclusions themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and accessibility of the paper. However, it could be more helpful if it offered specific guidance on how to present these observations and conclusions, such as suggesting where to place them or how to structure the presentation. Overall, the comment is 4, as it directs the authors to a significant improvement in the clarity and impact of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This is an explicit action that provides a clear direction for the authors to take, as it specifies what needs to be done to improve the draft. The comment is also concrete, as it provides a specific suggestion for experimentation that the authors can follow. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments on the modifications mentioned in this section to further validate the model\"s performance. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model\"s performance, given that several modifications were mentioned in Section 3.4. This claim is 3 as it provides a logical reasoning for why ablation experiments would be beneficial. However, it lacks specific examples or references to support the necessity of these experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness of their results. By conducting these experiments, the authors can better understand the impact of each modification and provide more comprehensive evidence for their claims. However, the comment could be more helpful if it included suggestions on how to design or interpret these experiments. Overall, the feedback is 4 as it offers a concrete way to improve the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It also references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this comparison without specific guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to \"Remark 1,\" which suggests that the authors can identify the specific part of the paper being addressed. However, the comment does not explicitly mention the section or figure number, making it weakly grounded. The comment is specific in suggesting a comparison of performance on datasets with a decision space beyond binary, which could help the authors address a potential limitation of their approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, referencing a specific work by Zhang et al. The comment suggests comparing the performance on datasets with a decision space beyond binary, which is a logical suggestion for further exploration. However, the comment does not provide detailed reasoning or examples to support the claim that this comparison is necessary or beneficial. While it points out a potential area for improvement, the lack of specific evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. This feedback is 3 as it identifies a potential area for improvement and suggests a specific comparison that could be made to enhance the paper. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment offers a clear direction for further exploration but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide explicit or implicit actions for the authors to take. There are no suggestions on how to address these issues, such as conducting additional experiments or analyzing the artifacts. The lack of guidance or specific instructions leaves the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what is meant by \"unexpected artifacts\" or how they relate to the pipelining method. Without clear guidance on where to address these issues, the comment is 1 and lacks specificity. Therefore, this comment is categorized as 1.", "verifiability_rationale": "The review point raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two distinct concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any specific guidance or suggestions on how the authors might address these issues. Without actionable feedback or detailed analysis, the authors are left without a clear understanding of what needs to be improved or how to improve it. This lack of direction makes the comment unhelpful, as it does not offer any meaningful insights or steps for the authors to take to enhance their draft. Therefore, the comment is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans and notes the absence of a \"proof.\" While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should fill in Appendix A and clarify the purpose and proof of Proposition B.1. However, the lack of concrete guidance on how to improve these sections makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, namely the blank Appendix A and the unclear purpose of Proposition B.1, which is questioned in relation to the classic partitioning principle of Kmeans. The comment further points out the absence of a \"proof,\" providing detailed guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and questions the purpose of Proposition B.1 in Appendix B, suggesting it might be an illustration of the classic partitioning principle of Kmeans. The reviewer also notes the absence of a \"proof.\" While the comment raises valid points about the clarity and completeness of the appendices, it lacks specific examples or references to support the claim that the \"proof\" is missing or that the purpose of Proposition B.1 is unclear. This makes the claim 3, as it provides a general critique but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans, suggesting that this is a wellknown concept in machine learning. The comment also points out the absence of a \"proof,\" which is a critical component of the paper. By highlighting these issues, the comment provides clear and actionable feedback that can help the authors improve their draft by addressing these gaps. However, the comment could be more helpful if it offered suggestions on how to clarify the purpose of Proposition B.1 or provide a proof. Overall, the comment is 4 as it directs the authors to important areas needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the approximations introduced in the paper, specifically mentioning lines 107110 where the assumption of attacks being in the feasible set is made. The reviewer suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to expand on the vulnerability. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability related to the approximations introduced and suggests that this issue needs to be expanded upon to reassure readers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approximations introduced in the paper leave \"loose ends\" and suggests that the vulnerability related to the assumption of attacks being in the feasible set needs to be expanded upon. The comment provides a specific reference to lines 107110, which helps to ground the claim. However, it lacks detailed reasoning or examples to fully substantiate the claim about the vulnerability. While the reviewer identifies a potential issue, the comment could be strengthened by providing more explicit evidence or reasoning to support the claim. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with the approximations introduced in the paper, noting that they leave \"loose ends\" and highlight a potential vulnerability related to the assumption of attacks being in the feasible set. The reviewer acknowledges that approximations are necessary for deriving clean results but emphasizes the need to address the vulnerability to reassure readers. This feedback is clear and actionable, as it directs the authors to expand on the vulnerability to provide reassurance. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provide additional context. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not specify exactly how to do so or what specific aspects of the evaluation procedures need more detail. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SoTA) scores. It also mentions the need for a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. However, the comment does not specify which benchmarks are being referred to or where in the paper these issues are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in suggesting the need for more detailed analysis and evaluation procedures, but it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new stateoftheart scores, but suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment implies that the evaluation procedures could be improved by providing more details. However, it lacks specific examples or references to support the claim about the \"old\" benchmarks or the need for a more detailed analysis. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on various benchmarks, noting that it sets new stateoftheart scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. This feedback is 3 as it points out a potential issue with the evaluation process and recommends providing more details about the evaluation procedures. While the comment identifies a relevant area for improvement, it lacks specific guidance on how to conduct this analysis or what additional details are needed. Therefore, it is 3, as it provides a direction for improvement but does not fully support the authors in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is an explicit suggestion, as it clearly indicates what the authors should do to improve their draft. However, the comment does not provide specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While the action is clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a suggestion for improvement rather than a claim that requires verification. It does not express an opinion, judgment, or subjective statement that needs justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a valuable suggestion as it could provide a more comprehensive understanding of the methods\" performance in different scenarios. However, the comment lacks specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes them difficult to be convincing. However, it does not provide explicit guidance on what specific information should be included in the experimental settings or how the authors should present it. The action is implicit, as the authors need to infer that they should add the missing information, but it is vague because it lacks concrete details on what exactly should be included. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing experimental settings, which makes it difficult for the figures to be convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes them hard to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing. This is a critical piece of information that is essential for understanding and evaluating the results presented in the figures. By pointing out this omission, the comment highlights a key area where the authors can improve their draft by providing the necessary context for the experimental settings. However, the comment could be more helpful if it suggested specific ways to present or describe the experimental settings, such as providing detailed descriptions or examples. Despite this, the feedback is clear and actionable, making it 4 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the ambiguity in the proposed method\"s ability to avoid impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide explicit guidance on how the authors should clarify this issue or what specific steps they should take to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify the method\"s impact on learning new task knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It mentions the proposed pathway protection method based on sparsity in activation channels and notes that some parameter isolation methods are tailored to leverage this sparsity. However, the comment highlights the ambiguity in how the proposed method avoids impeding the learning of new task knowledge. While the authors can infer that this relates to the methodology or results sections, the comment does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing the issue of ambiguity regarding the method\"s impact on learning new task knowledge. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is unclear regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to delve deeper into the literature or provide additional context to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s rationale, specifically the ambiguity surrounding how the proposed pathway protection method avoids impeding the learning of new task knowledge. It highlights a relevant issue by noting that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide specific suggestions or examples on how the authors might clarify this ambiguity or address the issue. While it points out a critical area for improvement, the feedback lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by specifying the need to integrate benchmark comparisons against stateoftheart fairness algorithms. This would enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. The comment provides specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking comparisons with existing fairness algorithms and suggests integrating benchmark comparisons against stateoftheart fairness algorithms. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper by providing evidence of the proposed method\"s performance. The comment logically reasons that such comparisons are necessary for positioning the ManyFairHPO framework within the existing FairML research landscape. However, it does not provide specific examples of existing fairness algorithms or detailed reasoning on why these comparisons are crucial. While the claim is 4, it could be strengthened with more detailed justification or references to specific algorithms. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section of the paper, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method\"s performance. This feedback is highly valuable as it guides the authors on how to strengthen their experimental section and position their work within the existing research landscape. The comment is specific and actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the supervised pretraining method based on the prediction of the homolumo gap, suggesting that it may lead to negative transfer. It provides an example from the QM9 dataset, where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. The comment also questions the claim of the paper being a \"generalpurpose neural network model.\" While the comment identifies a potential issue and provides an example, it does not explicitly instruct the authors to address this concern or suggest specific changes to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the potential negative transfer issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and references the \"QM9\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue of negative transfer and provides an example from the QM9 dataset, where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This specificity helps the authors understand what needs to be addressed in their paper, particularly regarding the claim of being a \"generalpurpose neural network model.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of the homolumo gap may lead to negative transfer, citing an example from the QM9 dataset where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This claim is supported by the specific example from the QM9 dataset, which provides a concrete instance of the potential issue. However, the comment could be strengthened by providing more detailed analysis or references to similar cases in the literature. Overall, the claim is 4, as it offers a clear example but lacks comprehensive evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the supervised pretraining method based on the prediction of the homolumo gap, suggesting that it may lead to negative transfer. It provides a specific example from the QM9 dataset, where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This example challenges the claim of the paper being a \"generalpurpose neural network model,\" as it highlights a limitation in the model\"s performance. The comment is 4 as it points out a specific area for improvement and provides a concrete example to support the claim. However, it could be more helpful if it offered suggestions on how to address this issue or improve the model\"s generalizability. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state it is not insightful for discriminating model defenses but then use it in Figure 4 A&B. The reviewer is seeking clarification on why this metric was found useful in this context but not elsewhere. While the comment does not explicitly instruct the authors to revise their draft, it implies that the authors should provide a clearer explanation or justification for their use of the metric. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency and provide a rationale. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082 and figure 4 A&B, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in the authors\" use of the center correlation metric, asking for clarification on why it was found useful in figure 4 but not elsewhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the authors\" use of the center correlation metric, noting that it is initially stated as not insightful for discriminating model defenses but is then used in Figure 4 A&B. The reviewer seeks clarification on why this metric was found useful in this context but not elsewhere. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of inconsistency. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state that the metric is not insightful for discriminating model defenses, but then use it in Figure 4 A&B. The reviewer questions why the metric was found useful in this context but not elsewhere, seeking clarification on the authors\" reasoning. This feedback is 3 as it highlights a specific area of confusion that the authors need to address. However, it lacks depth and does not provide specific suggestions on how to resolve the inconsistency or improve the clarity of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a detailed explanation of why this term might be misleading, noting that it implies the total variation between test and train distributions of the network\"s outputs vanishing to zero, which may not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide specific guidance on how to rephrase it. While the authors can infer that they should reconsider the term, the feedback lacks concrete action steps, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the term, explaining that it might be too strong to capture the empirical phenomenon presented and that it implies a conclusion that may not be supported by the data. The comment provides a clear critique of the terminology used, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented, as it implies the total variation between test and train distributions of the network\"s outputs vanishing to zero, which may not be the case. The reviewer provides a logical explanation of why this term might be misleading, noting that it is based on a few test functions where the outputs match. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the term \"distributional generalization\" used in the paper, suggesting that it might be too strong to accurately describe the empirical phenomenon presented. The reviewer explains that the term implies a conclusion about the total variation between test and train distributions of the network\"s outputs vanishing to zero, which may not be supported by the data, especially considering the limited number of test functions on which the outputs match. This feedback is clear and actionable, as it prompts the authors to reconsider their terminology and potentially provide more nuanced descriptions of their findings. However, the comment could be more helpful if it offered suggestions for alternative terms or further clarification on how to address this issue. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" for easier interpretation. This is an explicit suggestion, as it clearly states what action the authors should take to improve their draft. However, the comment does not provide detailed guidance on how to implement this change, such as whether to add a thin gray diagonal to the plot or how to label it. While the action is explicit, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment suggests a change in terminology from \"above/below 45 degree\" to \"above/below diagonal\" for easier interpretation. However, it does not specify which part of the paper this suggestion pertains to, such as a figure or table where this terminology is used. Without explicit references to specific sections or elements, the authors may find it challenging to identify where this change should be made. The comment is specific in suggesting a change in terminology but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the term \"above/below 45 degree\" is less intuitive than \"above/below diagonal\" for interpreting a plot. The reviewer provides a logical explanation by comparing the two terms, noting that \"above/below 45 degree\" might be misinterpreted as a local property, whereas \"above/below diagonal\" is more straightforward. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a change in terminology from \"above/below 45 degree\" to \"above/below diagonal\" for easier interpretation of a plot. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity of the paper. However, the comment could be more helpful if it explained why the original terminology might be confusing or provided additional context on how the change would benefit the reader. Despite this, the suggestion is valuable and could enhance the readability of the paper, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the exact change needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the phrase \"is sufficient\" and provides a possible interpretation of what the authors might mean, suggesting that they should clarify the context. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide any evidence or references to support this interpretation, leaving the authors to infer the necessity of clarification. This makes the claim 3, as it lacks specific examples or references to fully substantiate the suggestion for improvement.", "helpfulness_rationale": "The review comment identifies a specific phrase, \"is sufficient,\" at lines 240 and 428, and questions its meaning. It provides a possible interpretation, suggesting that the authors might want to clarify that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it points out a potential ambiguity in the text and offers a possible clarification. However, it lacks depth and does not provide further guidance on how to address the issue or why this clarification is important. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their work. The feedback lacks actionable details, leaving the authors uncertain about what steps to take to clarify the scientific contribution of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear scientific insight and the need for a clearer explanation of how the model provides further understanding of nonlinear RNN models. The comment provides a detailed critique of the work, making it clear what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to clarify their contribution. However, it could be more helpful if it provided specific suggestions or examples on how to address this issue, such as proposing alternative explanations or experiments to demonstrate the model\"s unique value. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a tradeoff in the proposed method, noting that while it reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, implying that the authors should consider this aspect in their analysis. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this tradeoff further and potentially discuss it in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison to 10, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the tradeoff between computation time and the richness of the search space, noting that the output of ACI has less information compared to the output of 10. The comment raises a question about the information encoded in ancestral graphs compared to DAGs, which provides a clear direction for the authors to consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time and the richness of the search space in the proposed method. It suggests that the method reduces computation time by limiting the search space to ancestral graphs, but this comes at the cost of less information compared to the output of a method with a richer search space (DAGs). The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, implying that this is a critical aspect to consider. However, the comment does not provide specific evidence, examples, or references to support the claim or the reasoning behind it. This makes the claim 3, as the authors would need to explore the issue further to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a tradeoff in the proposed method, noting that while it significantly reduces computation time compared to a previous method, this is achieved by limiting the search space to ancestral graphs. This results in less information compared to the output of the previous method, which has a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a critical aspect to consider in the analysis. This feedback is 3 as it points out a potential limitation of the proposed method and encourages the authors to explore this tradeoff further. However, it could be more helpful if it provided specific suggestions on how to address this issue or what aspects to focus on in the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the theoretical discussions could be improved, specifically mentioning that the current theorems follow directly from the algorithm design and a wellknown property of mutual information. It implies that the authors should consider adding sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. While the comment identifies an area for improvement, it does not provide explicit guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore sample complexity results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical discussions in the paper, suggesting improvements and providing specific examples of what could be added, such as sample complexitytype results. However, it does not explicitly mention which part of the paper these discussions are located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the addition of sample complexity results for not returning NSF. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. The reviewer provides a logical reasoning by mentioning the direct relationship between the theorems and the algorithm design, as well as the wellknown property of mutual information to \u0394_DP. This reasoning supports the claim that the current theorems are not sufficient and that additional results are needed. However, the comment could be strengthened by providing specific examples or references to existing work that have addressed similar issues. Therefore, the claim is 4, as it provides a clear direction for improvement but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions of the paper. It suggests that the current theorems, which are directly related to fair representation, could be enhanced by incorporating sample complexitytype results. The reviewer provides a clear example of what could be added, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. This feedback is actionable and provides a concrete direction for the authors to enhance their theoretical discussions, making it 4. However, the comment could be more helpful if it offered additional guidance on how to approach these improvements or provided specific references for further reading. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This feedback is explicit and provides concrete guidance on what the authors should include in their discussion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. The comment provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors include a discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This suggestion is based on logical reasoning and provides a clear direction for the authors to improve their discussion. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors include a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This feedback is clear and actionable, offering a concrete suggestion for enhancing the discussion section of the paper. By addressing this point, the authors can provide a more comprehensive understanding of their methodology and its implications, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the two methods, highlighting that both methods are similar and that the literature has shown that regression methods do not significantly impact the results. The reviewer suggests that the authors clarify this issue, implying that the motivations presented in the paper may not be solid without this clarification. While the comment identifies a potential issue and suggests clarification, it does not provide explicit instructions on how to address the problem or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the two methods and suggests that the authors clarify this issue, which further specifies what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically regarding the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the two methods, comparing them to RetinaNet and ATSS, and suggests that the motivations presented in the paper may not be solid without clarification. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including specific references or examples from the literature to further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the two methods, comparing them to RetinaNet and ATSS, and suggests that the motivations presented in the paper may not be solid without clarification. This feedback is clear and actionable, as it identifies a potential weakness in the paper and offers a specific area for improvement. By asking the authors to clarify the differences between the methods, the comment provides a constructive suggestion that can help the authors strengthen their argument and improve the clarity of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper is difficult to follow and lacks a clear intuition for how the components fit together, which affects the experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. There is no explicit or implicit action for the authors to take, such as revising the presentation or adding more context to the experiments. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique that the paper is not easy to follow, lacking a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of clarity is most pronounced. The authors might infer that it relates to the experimental sections or the overall structure, but this is not explicitly stated. The comment is not specific about what needs to be addressed or how the authors might improve the clarity. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the components fit together. This feedback highlights a critical area for improvement, as it affects the overall understanding and impact of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as restructuring the presentation or adding more context to the experiments. While it points out a key weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should address the fairness of the comparison and provide additional metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed comparisons and metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously, and requests the inclusion of KID/FID metrics for the teacher network. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional metrics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the comparison might not be fair or why the requested metrics are necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It questions whether this simultaneous training affects the performance of the teacher network and suggests that the authors provide KID/FID metrics for the teacher network. This feedback is clear and actionable, as it prompts the authors to consider the impact of their training approach and to provide additional metrics that could help evaluate the performance of their model. However, the comment could be more helpful if it provided specific guidance on how to address the fairness issue or suggested alternative methods for comparison. Overall, the comment is 4, as it directs the authors to a critical area of improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of the refined region vector, specifically whether it effectively scales the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight. While the comment implies that the authors should explore this aspect further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement or test the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning its effectiveness and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the refined region vector, specifically whether it scales the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the suggestion. Without additional context or justification, the authors may find it challenging to understand the basis of the question or the potential benefit of the suggested change. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific concern about the refined region vector, questioning its effectiveness in scaling the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight, which could potentially improve the model. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks depth and does not provide detailed guidance on how to implement the suggested change or its expected impact. The feedback is 3 as it points out a specific area for improvement, but it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, namely that failures on the ALFRED benchmark are often due to goal misspecification. It explains that the LLM does not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the goal specification or how to handle ambiguities in human language. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of goal misspecification in the context of the ALFRED benchmark, specifically mentioning the LLM\"s inability to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, it does not specify which part of the paper discusses the ALFRED benchmark or the LLM\"s performance, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\"s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, specifically mentioning the LLM\"s inability to accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is 3 as it provides a logical explanation of the issue, but it lacks specific examples or references to support the assertion. The comment does not provide detailed evidence or examples of how goal misspecification leads to failures on the ALFRED benchmark, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of goal misspecification in the context of the ALFRED benchmark. It explains that the LLM\"s failure to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language, contributes to the failures on the benchmark. This feedback is 3 as it highlights a critical area for improvement, but it lacks actionable suggestions or guidance on how the authors might address this issue. While it provides insight into a potential weakness, it does not offer specific steps or strategies for enhancing the goal specification or handling ambiguities in human language. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It explicitly recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback provides a clear and concrete action for the authors to take, as it specifies what additional analysis or presentation could be included to enhance the paper. The suggestion is explicit and provides detailed guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, it implies that this analysis could be integrated into the results or discussion sections. The authors can infer that this suggestion relates to the results or analysis sections, providing weak grounding. The comment is specific in suggesting a particular aspect of the analysis that could be explored further, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a logical suggestion for enhancing the analysis, it lacks specific examples or references to support the claim that such an investigation would add nuance to the conclusions. The suggestion is based on a reasonable assumption, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the analysis and presentation of the results. By addressing this point, the authors can gain a more nuanced understanding of the models\" behavior and improve the comprehensiveness of their conclusions. However, the comment could be more helpful if it included examples or further guidance on how to conduct this analysis. Overall, the comment is 4, as it offers valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5. The authors know exactly what to do to address the feedback, which is to include the comparison results in their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests supplementing the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. However, it does not specify which part of the paper this comparison is currently presented in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for additional information but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, the comment does not provide any reasoning, evidence, or examples to support why this comparison is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to enhance their analysis by including additional comparisons. However, the comment could be more helpful if it provided specific guidance on what aspects of the comparison should be included or how the results should be presented. Despite this, the comment offers a valuable direction for improving the draft, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that it is difficult to understand what the axes represent in Figure 1. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to clarify the axes or what information should be included to make the figure more understandable. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be clarified or improved in the figure. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing a difficulty in understanding Figure 1, specifically the axes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to clarify the axes of the figure. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as labeling the axes or adding a legend. Despite this, the comment is 4 as it highlights a critical area for improvement that can enhance the clarity and understanding of the figure for readers. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. It also provides a clear reason for this requirement, noting that the proposed approach is based on implicit differentiation, which typically incurs additional computational costs. This feedback is direct and provides a concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of \"2 Direct runtime comparisons with existing methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014direct runtime comparisons\u2014and provides a reason for this necessity, noting that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are necessary. However, the comment could be strengthened by providing specific examples of existing methods or references to studies that have made such comparisons. Overall, the claim is 4, as it provides a clear rationale but lacks detailed references or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It provides a clear rationale for why these comparisons are necessary, noting that the proposed approach is based on implicit differentiation, which typically incurs additional computational costs. This feedback is actionable and constructive, as it guides the authors on a critical aspect to address in order to demonstrate the efficiency of their approach. By highlighting this specific area for improvement, the comment is 5, as it empowers the authors to make a meaningful enhancement to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, it does not provide explicit guidance or suggestions on how the authors should revise their approach or what specific changes they should make to address this concern. The comment lacks actionable details, leaving the authors uncertain about how to implement the suggested change. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this focus is odd or how it deviates from the paper\"s motivation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. This critique highlights a potential gap in the paper\"s approach and encourages the authors to reconsider their focus. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative approaches might be more suitable. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. The authors are given some insight into a possible area for improvement but are left without detailed guidance on how to implement changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss case studies and error studies to demonstrate the effectiveness of each proposed component. It provides an example of how this could be done by mentioning a specific case study related to graph pretraining for AMR parsing and generation. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of what could be included, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to demonstrate the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of a case study related to graph pretraining for AMR parsing and generation. This feedback is specific as it identifies a particular aspect of the paper that could be improved and provides a concrete example of how to address it. However, it is not fully grounded because it does not explicitly mention the section where this discussion should be included, leaving the authors to infer the relevant part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of a case study related to graph pretraining for AMR parsing and generation, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these case studies would improve the paper. The suggestion is 4, as it offers a clear direction for improvement but lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper could be strengthened by including case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of how this could be done, referencing a case study related to graph pretraining for AMR parsing and generation. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper\"s credibility and impact. However, the comment could be more helpful if it provided additional guidance on how to conduct these case studies or integrate them into the paper. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework and its potential entanglement with other evaluation metrics like explicitness (E) and size (S). It suggests that the authors need to clarify the motivation for considering these additional evaluations. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to clarify the motivation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explanation but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"traditional DCI framework\" and \"evaluation of disentanglement,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific details about the potential entanglement between DCI and ES, suggesting that changes in probing capacity or latent size could affect the evaluation. This level of specificity helps the authors understand what needs to be clarified regarding the motivation for considering explicitness (E) and size (S) as extra evaluations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that it may already consider explicitness (E) and size (S) as part of its evaluation. The reviewer provides examples to support this claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the examples provide some basis for the argument, the lack of comprehensive evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that it may already encompass explicitness (E) and size (S) evaluations. It provides examples to illustrate this point, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). The comment also highlights the potential entanglement between DCI and ES, indicating that changes in probing capacity or latent size could affect the evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the motivation for considering these additional evaluations. While it identifies a potential area of confusion, the feedback could be more actionable and detailed to be 5. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the organization and layout of the paper, including the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. It also mentions formatting issues on page 6. While the comment identifies specific problems, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to improve the organization and layout of the paper, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in Figure 1 and Figure 2, the lack of explicit drawing of these figures, the incorrect placement of Table 2, and formatting issues on page 6. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific as it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized, citing specific issues such as the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. These are factual observations that can be verified by examining the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of poor organization. While the specific issues mentioned are verifiable, the overall claim could be strengthened with more comprehensive evidence or explanation. Therefore, the comment is 4, as it provides some support but could be more robust with additional details.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, including font size problems with annotations in figures, the lack of explicit drawing of figures, and incorrect placement of Table 2. It also mentions formatting issues on page 6. While the comment highlights these problems, it does not provide detailed suggestions or guidance on how to address them, such as recommending specific font sizes or suggesting ways to improve figure clarity. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it incomplete for the authors to fully address the issues. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider the practicality and safety of the interventions included in the paper for realworld querying. However, it does not provide explicit guidance on how to assess or address these concerns. The action is implicit, as the authors need to infer that they should evaluate the practicality and safety of their interventions. Additionally, the comment lacks concrete details on how to conduct this evaluation or what specific aspects to consider. As a result, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for realworld querying. However, it does not specify which part of the paper discusses these interventions, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider practicality and safety but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the interventions included in the paper are reasonable computationally, they may not be practical or safe for realworld querying. However, the comment does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important consideration about the practicality and safety of the interventions discussed in the paper. It encourages the authors to think beyond the computational feasibility and consider the realworld implications of their work. However, the comment lacks specificity and does not provide detailed guidance on how to assess or address these concerns. It does not offer actionable suggestions or examples of what specific aspects of practicality and safety should be considered. As a result, while the comment identifies a relevant area for improvement, it is 3 due to its lack of depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately, suggesting they can be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes might be necessary to improve the draft. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately, suggesting they can be interchangeable. However, it does not specify which part of the paper this concern relates to, such as a particular section or methodology. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed reasoning or examples to support the claim. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately, suggesting they can be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately, suggesting they can be interchangeable. However, it does not provide any specific reasoning, examples, or suggestions for how the authors might address this concern or improve their draft. Without actionable feedback or detailed guidance, the comment lacks utility for the authors, leaving them without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance gain of their proposed method by comparing it to baseline detection or parsing techniques separately. This implies an action for the authors to take, which is to conduct additional evaluations to better support their claims. However, the comment does not provide specific guidance on how to conduct these evaluations or which baseline techniques to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, specifically mentioning its two major components: the generative shape model and the word parsing model. It highlights the need for clearer evaluation of which component contributes to the performance gain. The suggestion to evaluate the approach separately from baseline detection or parsing techniques provides specific guidance on how to address the issue. However, the comment does not explicitly mention which part of the paper discusses these components, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. The reviewer suggests evaluating the approach separately from baseline detection or parsing techniques to better support the claim. However, the comment does not provide specific examples or references to support the claim that the current evaluation is insufficient. The suggestion for additional evaluation is logical, but without detailed justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the approach separately from baseline detection or parsing techniques would provide better support for the claim. This feedback is clear and actionable, as it directs the authors to conduct additional evaluations to clarify the contribution of each component. However, the comment could be more helpful if it provided specific examples of baseline techniques or detailed guidance on how to conduct these evaluations. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific alternatives. The action is implicit and somewhat vague, as the authors are left to infer that they should explore automated disentangling methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically. However, the comment does not specify which part of the paper discusses the disentangling process or the choice of the semantic segmentation network, making it weakly grounded. The comment is specific in detailing the issue with manual disentangling, but without explicit references to sections or modules, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. The reviewer suggests that it would be more interesting if everything were learned automatically. However, the comment lacks specific reasoning or evidence to support why manual disentangling is a problem or why an automated approach would be preferable. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the manual disentangling process, and questions the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore automated disentangling methods. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending additional experiments, theoretical analysis, or clarification in the text. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing clarification. The comment is specific in its concern but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption is critical or how it affects the method\"s behavior. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the method\"s behavior under different assumptions. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some pieces in the paper are using existing methods, such as equation (12), and that their presentation is vague, requiring the reader to refer to the original paper for understanding. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting ways to clarify the presentation or provide additional context. The action is implicit and vague, leaving the authors to infer that they need to improve the clarity of their presentation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the presentation of existing methods is vague and requires the reader to refer to the original paper for understanding. This provides clear guidance on what needs to be improved in the presentation of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that their presentation is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence renders the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some sections are using existing methods without providing clear explanations. It highlights that the presentation of these methods is vague and requires the reader to refer to the original paper for understanding. This feedback is 3 as it points out a potential area for improvement, specifically the need for clearer explanations of existing methods used in the paper. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered examples of how to present these methods more effectively. Overall, the comment provides some direction for the authors to enhance their draft, but it could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, such as revising certain sections or clarifying specific points. Without actionable advice or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not specify which parts of the paper are affected or provide any details on what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need improvement. Without specific examples or references to particular sections, tables, or figures, the comment lacks grounding and specificity. Therefore, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to particular sections of the paper, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges a perceived issue with the writing or presentation of the paper, noting that it can be \"a bit jumbled at times.\" However, it does not provide any specific examples, details, or suggestions on how to improve the clarity or organization of the content. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes are needed to address the issue. This lack of specificity and actionable advice makes the comment 2, as it does not effectively assist the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. While the comment implies that the authors should consider and report on the computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this aspect but are not provided with specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and potential power demand, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support these claims. The lack of detailed reasoning or supporting information makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the computational complexity of the proposed method, particularly in the context of mobile devices. It questions the total computational complexity compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand. This feedback is 3 as it prompts the authors to consider and address the computational efficiency of their method, which is an important aspect for practical applications. However, the comment lacks specific guidance or suggestions on how to evaluate or improve the computational complexity, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible for large datasets without a distributed version. However, it does not provide explicit guidance on how to address this issue or suggest specific steps for developing a distributed version. The comment implies that the authors should consider scalability, but it lacks concrete details on how to implement this, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the method, suggesting that it may not be feasible for large datasets without a distributed version. However, it does not specify which part of the paper discusses the scalability issue or how it relates to the training data. The authors can infer that it might be related to the experimental setup or results section, but this is not explicitly stated. The comment lacks specificity as it does not provide detailed guidance on how to address the scalability issue or what specific aspects need improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is not scalable, suggesting that a distributed version would be necessary to handle large datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim is considered 2, as it provides some insight but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the method, suggesting that it may not be feasible for large datasets without a distributed version. This is a relevant point that could impact the practicality and applicability of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability issue or develop a distributed version. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice for improvement. Therefore, the comment is 3, as it highlights an important consideration but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two distinct comments. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks, and references a literature example and a leaderboard. This feedback is explicit and provides a concrete suggestion for improvement by referencing specific literature and resources. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the first part is 5, the second part is 3 as it provides a clear critique but lacks detailed guidance on how to improve the analogy. Overall, the comment is 4 due to the explicit and concrete suggestions in the first part, but the second part adds some vagueness. Therefore, it aligns with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 15 and 1618, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the vagueness of the statement at line 15 and suggests that the reinforcement learning/agent analogy is out of place. The comment further specifies that generalization capabilities are better illustrated by examples given later in the paper. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of two parts. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, providing some support for the claim. However, the reference to the leaderboard is not fully elaborated, making the claim 3. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This part lacks specific examples or references, making it 2. Overall, the comment is 3, as it provides some support but lacks detailed evidence or examples to fully substantiate the claims. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part critiques the vagueness of a statement at line 15, suggesting that it lacks specificity regarding the performance of certain RNNs in natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, offering a concrete example to support the critique. This feedback is clear and actionable, as it directs the authors to provide more specific information about the performance of RNNs in natural language reasoning tasks.  The second part of the comment critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place in the current context. It suggests that generalization capabilities are better illustrated by examples provided later in the paper. This feedback is 3 as it identifies a potential issue with the analogy but does not provide detailed guidance on how to improve it. While it points the authors in the right direction, it could be more helpful with specific suggestions or examples.  Overall, the comment is 4 as it provides clear and actionable feedback on the first point, but the second point adds some vagueness. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of significant difference between the proposed sensitivelayer selection and randomized selection in terms of StableDiffusion, and the absence of mathematical or theoretical justification for Algorithm.1. While the comment identifies these areas for improvement, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to discuss the observation and provide mathematical or theoretical justification, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. It also points out the lack of mathematical or theoretical justification for Algorithm.1. While the comment highlights these issues, it does not provide specific examples, detailed reasoning, or references to support the claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. This observation highlights a potential weakness in the experimental results. Second, the comment notes the lack of mathematical or theoretical justification for Algorithm.1, which is a critical aspect of the paper that needs further explanation. By addressing these points, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to enhance the justification for Algorithm.1. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change the representation of triples from sets to a tuplelike structure, specifically mentioning line 122. This feedback is clear and direct, providing the authors with a precise action to take. The comment leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the representation of triples as sets instead of a tuplelike structure. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change in the representation of triples from sets to a tuplelike structure, providing a specific and actionable recommendation. However, it does not offer any reasoning or justification for why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a clear action but lacks supporting evidence or reasoning.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By recommending that triples denoted as $(e_1, r, e_2)$ be represented as a tuplelike structure instead of sets, the reviewer offers a clear and concrete way for the authors to enhance the readability and structure of their work. This feedback is direct and provides the authors with a precise action to take, making it 5 for improving the draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that optimal quantization is not scalable, even with clustering, and that it is costly in terms of both the number of data points (N) and the dimension (M). It also mentions that the paper aims to speed up Variational Inference (VI) by achieving fast convergence, which is crucial for big data/big model settings, but that quantization is a bottleneck that undermines this goal. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The action is implicit and vague, as the authors are left to infer that they need to find ways to improve scalability, but without concrete steps or examples, it is difficult for them to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of optimal quantization not being scalable, even with clustering, and how it affects the paper\"s goal of speeding up Variational Inference (VI) for big data/big model settings. It also references the abstract and introduction, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing the problem with quantization and its impact on the paper\"s objectives. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, even with clustering, and that it is costly in terms of both the number of data points (N) and the dimension (M). The reviewer also mentions that the paper aims to speed up Variational Inference (VI) by achieving fast convergence, which is crucial for big data/big model settings, but that quantization is a bottleneck that undermines this goal. The claim is 3 as it provides a logical explanation of the issue with quantization and its impact on the paper\"s objectives. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that optimal quantization is not scalable, even with clustering, and that it is costly in terms of both the number of data points (N) and the dimension (M). It also highlights that this scalability issue undermines the paper\"s goal of speeding up Variational Inference (VI) for big data/big model settings. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s approach and suggests that the authors should address this scalability issue to maintain the paper\"s relevance and impact. However, the comment could be more helpful if it provided specific suggestions or examples on how to improve scalability. Overall, the comment is 4, as it directs the authors to a key area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. It also mentions that issues should be addressed and implies that the work should be considered for a more applicationoriented venue. However, the comment does not provide specific guidance on how to conduct the comparison or address the issues, leaving the authors with a vague understanding of the actions needed. While the suggestion to compare against existing methods is explicit, the lack of concrete details on how to execute this makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"notations issues,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests comparing the effectiveness of the methodology against existing methods, such as contrastive decoding, and implies that the paper should be considered for a more applicationoriented venue if the issues are not addressed. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. However, it does not provide specific examples or references to support why this comparison is necessary or how it would improve the paper. The claim is 3 as it highlights a potential area for improvement but lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding. This is a clear and actionable suggestion that could enhance the paper\"s contribution and relevance. Additionally, the comment mentions \"issues mentioned above\" that should be addressed, implying that the reviewer has previously pointed out specific problems that need to be resolved. However, the comment does not elaborate on what these issues are, which limits its helpfulness. Overall, the feedback is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and limitations, particularly regarding its reliance on the entire training dataset. It suggests that the authors should consider how the algorithm operates when the training dataset is not fully perceptible. Additionally, the comment critiques the comprehensiveness of the validation experiments, the analysis of time complexity and efficiency, and the focus on the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to address these concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several aspects of the paper, including the algorithm\"s effectiveness, its reliance on the entire training dataset, the comprehensiveness of validation experiments, the analysis of time complexity and efficiency, and the focus on the technical contribution. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. While the comment provides specific feedback on the content, it lacks grounding as it does not explicitly mention specific sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several claims about the paper, including the algorithm\"s reliance on the entire training dataset, the comprehensiveness of validation experiments, and the focus on the technical contribution rather than the form of the attack. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the algorithm\"s reliance on the entire training dataset, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. It also suggests that the authors should focus more on the technical contribution rather than the form of the attack. While the comment highlights important issues, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the representation of kernel functions by neural networks (NNs). It points out that while it is claimed that every kernel can be described by a feature space parameterized by a NN, this is not true for infinitedimensional RKHSs, such as the RBF kernel. The reviewer suggests that this limitation should be made more clear. While the comment identifies a specific issue that needs clarification, it does not provide explicit guidance on how to address it or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors know they need to clarify the limitation but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, providing a counterexample with RBF kernels and their infinitedimensional RKHS. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, particularly for RBF kernels. The reviewer provides a logical explanation by noting that the RKHS for RBF kernels is infinitedimensional, requiring an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that demonstrate this limitation, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear and logical explanation by citing the example of RBF kernels, which have an infinitedimensional RKHS, requiring an NN with infinite width to represent it. This critique highlights a limitation in the paper that should be addressed to improve its accuracy and clarity. The comment is actionable as it suggests that the authors should make this limitation more clear, offering a specific area for improvement. However, it could be more helpful if it provided additional guidance on how to present this limitation or suggested ways to clarify the discussion. Overall, the comment is 4, as it effectively points out a critical issue that needs attention, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, particularly in the context of inference. It points out a potential limitation where only limited tokens are used for generating the next token, questioning whether there are benefits for inference. While the comment highlights a concern, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit and vague, leaving the authors to infer that they need to clarify or address the concern, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It points out a potential limitation where only limited tokens are used to generate the next token, questioning whether there are benefits for inference. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the concern about the autoregressive decoding process but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It points out a potential limitation where only limited tokens are used to generate the next token, questioning whether there are benefits for inference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It lacks specific examples or detailed explanations that would help the authors understand the issue or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It points out a potential limitation where only limited tokens are used to generate the next token, questioning whether there are benefits for inference. This feedback is 3 as it identifies a specific area of concern that the authors should address to clarify the effectiveness of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important consideration, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also implies that the authors should discuss the suitability of this approach for modeling pattern separation tasks, for which behavioral data is available. While the comment provides some direction, it lacks explicit instructions or concrete steps on how to address these points. The authors are left to infer that they need to conduct additional analyses or discussions, but the comment does not specify what these analyses should entail or how to structure the discussion. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of GPI with noise added and suggests additional measures to demonstrate its limitations. Furthermore, it provides a suggestion to discuss the suitability of the approach for modeling pattern separation tasks, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also suggests discussing the suitability of this approach for modeling pattern separation tasks. However, the comment lacks specific examples or references to support the claim that GPI cannot have a good fit with behavioral data. The suggestion to discuss pattern separation tasks is more of a request for additional content rather than a claim that requires verification. Therefore, the comment is 3, as it provides a basis for further exploration but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the performance of GPI with noise added in Fig. 4, suggesting that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also points out the potential suitability of this approach for modeling pattern separation tasks, for which behavioral data is available, and suggests that the authors should discuss this aspect. While the comment identifies a potential area for improvement and provides a direction for further analysis, it lacks specific guidance on how to conduct these analyses or what specific measures to consider. Additionally, the suggestion to discuss pattern separation tasks is not fully developed, leaving the authors with some insight but incomplete guidance. Therefore, the comment is 3, as it provides some direction but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors consider comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, if resources are available. However, it does not provide explicit instructions or concrete steps on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this comparison and figure out how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this suggestion is based on, making it weakly grounded. The comment is specific in suggesting a particular comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this suggestion should be integrated. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any reasoning, evidence, or references to support why this comparison would be beneficial or how it might impact the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While it highlights an interesting area for exploration, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. It does not offer actionable steps or suggestions for improvement, leaving the authors with a general idea but without clear direction on how to implement it. Therefore, the comment is 2, as it identifies a potential area of interest but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions why the distribution cannot have changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to clarify the matter. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments or provide further clarification, but they are not given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and asking about the disentanglement of changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide specific examples or references to support the claim that the debate was previously left open or that the distribution might have changed. This lack of detailed justification makes the claim 3, as the authors would need to conduct further analysis to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential weakness in the paper\"s argument and encourages the authors to consider alternative explanations. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of experiments that could be conducted to clarify the matter. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the comparison methods using the same setting as the proposed method, specifically with AdamW and cosine learning rate, to ensure a fair comparison. This is a clear and direct action for the authors to take. The comment also provides a rationale for why this is necessary, noting that most recent methods have their code released. The suggestion is concrete and provides a specific step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific method used for training, \"AdamW with cosine lr,\" and the comparison methods, \"adam with fixed lr.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the unfairness of the comparison and suggests that the authors should reproduce the results using the same setting to ensure a fair comparison. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the proposed method and other methods is unfair due to the use of different optimizers and learning rates. The reviewer suggests that the authors should reproduce the results using the same setting as the comparison methods to ensure a fair comparison. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for the authors to take. However, the comment lacks specific references or examples of the comparison methods or their codes, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the comparison methods use Adam with fixed learning rate. The reviewer suggests that the authors should reproduce the results using the same setting as the comparison methods to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific step to take to improve the validity of their comparisons. However, the comment could be more helpful if it included additional guidance on how to access the code of the comparison methods or how to implement the suggested changes. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the plots are \"terrible\" due to several issues, including their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are crucial for presenting experimental results and should be clearer. This feedback provides a direct and concrete action for the authors to improve their draft by revising the plots to make them more readable and informative. The comment specifies the issues and suggests that the authors should address these problems to enhance the clarity of their presentation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to several issues, including their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of the problems, such as the difficulty in distinguishing between \"pink vs red\" and the lack of clarity in axis labels. This detailed critique supports the claim, making it 4. However, the comment could be strengthened by suggesting specific improvements or alternatives for enhancing the plots. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, including the small size of the plots, difficulty in distinguishing between colors, poorly labeled axes, and visually similar labels. By highlighting these problems, the comment helps the authors understand what needs to be improved to enhance the clarity and effectiveness of their presentation. The feedback is clear and direct, offering a concrete path for the authors to follow in revising their plots. However, while it identifies specific areas for improvement, it could be more helpful if it suggested specific solutions or alternatives for addressing these issues. Overall, the comment is 4, as it provides valuable guidance for improving the draft but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It asks for performance metrics without each of these types of information and with just natural language feedback. While the comment implies that the authors should provide these performance metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its inquiry about the performance metrics but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the performance of the feedback network with different types of information. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It prompts the authors to consider the impact of these elements on the performance of the feedback network and to provide performance metrics without each of these types of information and with just natural language feedback. This feedback is clear and actionable, as it directs the authors to conduct specific analyses that could enhance their understanding of the feedback network\"s capabilities. However, the comment could be more helpful if it provided additional guidance on how to approach these analyses or what specific metrics to consider. Overall, the comment is 4, as it offers valuable insights and prompts for further investigation, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that Table 1 lacks standard deviations and suggests that the experiments could be more extensive to strengthen the submission. However, it does not provide explicit guidance on how to address the issue of missing standard deviations or how to make the experiments more extensive. The comment implies that the authors should consider adding standard deviations to Table 1 and expanding their experiments, but it does not specify what specific changes or additions would be beneficial. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of standard deviations in the table. Additionally, the comment suggests that the experiments could be more extensive, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 lacks standard deviations and suggests that more extensive experiments would strengthen the submission. However, the comment does not provide specific examples or references to support why the absence of standard deviations is a significant issue or how more extensive experiments would improve the submission. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of standard deviations and the potential impact of more extensive experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. This is a clear and actionable piece of feedback that the authors can use to improve their draft. Additionally, the comment suggests that more extensive experiments would strengthen the submission, providing a direction for further improvement. However, the comment could be more helpful if it offered specific suggestions on how to expand the experiments or what additional data or analyses could be included. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and suggests comparing the performance of LinearTop and NLTop to a better Unary baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. The comment references a specific work (14) that used a different and probably better neural network, which provides some context and support for the claim. However, the comment lacks detailed analysis or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the referenced work and their own results to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. This feedback is 3 as it prompts the authors to consider alternative baselines and their impact on performance. However, the comment could be more helpful if it provided specific suggestions or examples of better baselines to use or how to evaluate the performance boost more effectively. The authors gain some insight into potential areas for improvement but need further guidance to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions to improve the paper\"s clarity and structure. It explicitly recommends rearranging the sections in a more logical order (introduction>method>experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. Additionally, it suggests improving the visualization of Figs. 7 and 8. These suggestions are clear and provide concrete steps for the authors to take to enhance their draft. The feedback is explicit and actionable, as it directly instructs the authors on how to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests improving the structure of the paper by rearranging the sections in a more logical order (introduction>method>experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. It also suggests improving the visualization of Figs. 7 and 8. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the overall structure and content of the paper. The suggestion to focus on the IEM in Fig. 3 provides some specificity, but the comment lacks detailed guidance on how to improve the visualization of Figs. 7 and 8. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is \"a bit hard to follow\" and suggests improvements to the structure and focus on specific figures. However, it does not provide specific examples or detailed reasoning to support these claims. The suggestion to improve the structure and focus on the IEM in Fig. 3 is vague and lacks concrete evidence or references to substantiate the need for these changes. As a result, the comment is considered 1, as it does not offer sufficient justification or evidence to support the claims made.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including its structure and clarity. It suggests rearranging the sections in a more logical order (introduction>method>experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. Additionally, it recommends improving the visualization of Figs. 7 and 8. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the readability and impact of their paper. However, the comment could be more helpful if it included specific examples or detailed feedback on how to improve the visualization of the figures. Overall, the feedback is 4 as it offers constructive suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should report the final used learning rates, but it lacks concrete guidance on how to ensure that the optimal learning rate was within the tested interval. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for information about the learning rates but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. The comment provides a logical reasoning by pointing out that searching only 4 different learning rates might not capture the optimal rate, which could affect the results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of this limitation and potentially expand their search for optimal learning rates to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. This is a valid point as it highlights a potential limitation in the experimental setup that could impact the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional learning rates to test or suggesting alternative methods to ensure the optimal learning rate is captured. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment implies that the authors should address this concern, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to identify the exact section that needs attention. The comment provides a specific critique of the transformer\"s design choice but lacks grounding in terms of the specific part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment raises a valid point, it lacks specific examples or references to support the claim. The reasoning is somewhat logical but could be strengthened with additional evidence or detailed reasoning. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer questions the rationale behind this design choice and requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. This feedback is 3 as it identifies a potential issue with the design choice and prompts the authors to clarify their reasoning. However, it could be more helpful if it provided specific suggestions or examples to support the authors in addressing this concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern about the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that additional experiments or a more indepth analysis are needed to better justify the claims made in the paper. While the comment implies that the authors should conduct more experiments or analysis, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment further specifies that additional experiments or a more indepth analysis are necessary to justify the claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as they only outperform the baselines in one setup and lack a consistent trend. The reviewer suggests that additional experiments or a more indepth analysis are necessary to justify the claims. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the results are insufficient. This makes the claim 3, as the authors would need to conduct further analysis to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is crucial as it highlights a potential weakness in the paper\"s claims of effectiveness. The comment provides a clear and actionable suggestion by recommending additional experiments or a more indepth analysis to better justify the claims made in the paper. This guidance empowers the authors to address a critical area of concern, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the action is explicit, it lacks concrete guidance on how the authors should clarify this impact, such as specific questions to address or aspects to focus on. The feedback provides a clear direction for improvement but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure\" and the \"sophisticated filtering template,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of the heuristic components. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. It suggests that the authors clarify the impact of these heuristic components. However, the comment does not provide specific examples or detailed reasoning to support the claim about the effectiveness of the method or the impact of the heuristic components. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of these components based on the provided information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. It suggests that the authors clarify the impact of these heuristic components, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided specific guidance on how to address this issue, such as suggesting additional analysis or examples to illustrate the impact of these components. Overall, the comment is 3 as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their method. The comment implies that the authors should clarify or address this issue, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly questions the feasibility of the proposed method without camera information, specifically addressing the issue of ray marching and the knowledge of CAD model correspondences. The comment provides a clear critique of the method\"s reliance on camera information, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer provides a logical reasoning by pointing out the need for camera information to determine the origin of the ray, which is a critical aspect of the method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider this critique and provide additional information or clarification to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It points out the importance of knowing the viewpoint for performing ray marching and highlights a potential issue with the method\"s reliance on CAD model correspondences. This feedback is clear and actionable, as it prompts the authors to address a significant weakness in their approach. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or offered alternative methods for addressing the problem. Overall, the comment is 4 as it identifies a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add a more detailed comparison but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its suggestion for improvement but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it included examples of how such a comparison might be structured or suggested specific related works to consider. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to conduct additional experiments on various datasets and to include results from the full dataset. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where experimental results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its suggestion, it is 1, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 1 but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. However, the comment does not provide specific examples of datasets that could be used or any reasoning as to why these additional experiments would be beneficial. This lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of these additional experiments based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the robustness and comprehensiveness of the experimental results. However, the comment could be more helpful if it included specific suggestions on which datasets to use or how to present the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\" claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their work. The feedback lacks actionable details, such as recommending additional explanations, clarifications, or modifications to the experimental setup. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\" claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit references to sections, figures, or specific elements of the paper results in weak grounding. Additionally, while the comment highlights issues with clarity and the experimental setup, it does not provide specific guidance on how to address these concerns. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task do not clearly prove the authors\" claims, and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 1 due to the lack of supporting details or references.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the generic argument task and the random argument task, questioning how they support the authors\" claims. It also describes the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights areas that need improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, providing a specific action for the authors to take. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an analysis of the impact of these factors for a fair comparison with the baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline. However, the comment does not provide specific examples or detailed reasoning to support the claim that this analysis is crucial or how it would impact the comparison. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it highlights a specific area where the paper could be improved and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is unclear if this trend holds across different model architectures and lacks theoretical evidence. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their analysis. The comment implies that the authors should consider exploring this trend further and providing theoretical evidence, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, suggesting that it is underwhelming and lacks theoretical evidence. However, it does not specify which part of the paper this analysis is presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning the lack of theoretical evidence, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It suggests that the trend may not hold across different model architectures and lacks theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and lacks clarity regarding whether this trend holds across different model architectures. Additionally, the comment notes the absence of theoretical evidence to support this correlation. While the comment highlights important issues that need attention, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is 3 as it directs the authors to areas needing further exploration and justification, but it could be more helpful with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not provide explicit instructions on how to address these issues, such as suggesting ways to remove duplicates or indicating how to verify the publication information. The actions are implicit and somewhat vague, as the authors can infer that they need to check and correct the references list but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not specify which part of the paper the references list is located in, making it weakly grounded. The comment is specific in detailing what is wrong with the references, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. This is a factual observation that can be verified by checking the references list. The comment does not require any additional evidence or reasoning beyond the observation itself, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. This feedback is clear and actionable, as it provides the authors with concrete areas to address in order to improve the quality and accuracy of their references. By pointing out these issues, the comment helps the authors ensure that their references are properly formatted and complete, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it suggested ways to resolve these issues, such as providing guidance on how to remove duplicates or verify publication information. Overall, the comment is 4 as it directs the authors to important aspects of their references that need attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It also provides a clear action for the authors to take: \"The authors need to analyze and compare the theoretical results to other comparable methods.\" This feedback is direct and provides a concrete step for the authors to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound, and suggests that the authors should analyze and compare the theoretical results to other comparable methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear and weak. It highlights the lack of clarity regarding the error bound, which is a critical aspect of the theoretical results. The comment also provides a clear suggestion for improvement by recommending that the authors analyze and compare their theoretical results with other comparable methods. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it offered specific examples or references to guide the comparison. Overall, the comment is 4, as it effectively points out a weakness and offers a constructive suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This comment implies that the authors should provide a justification or explanation for this limitation in their study. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The authors can infer that they need to address this issue, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This implies that the comment is addressing the section where the authors discuss the performance of their model on different types of noise. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in its request for a justification or explanation for the limitation in the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This is a logical observation that prompts the authors to provide a justification for their choice of noise type. However, the comment does not provide any specific evidence or reasoning to support the claim that the model should be tested on other types of noise. The lack of detailed justification or examples makes the claim 3, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why the authors only show results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This feedback prompts the authors to consider expanding their evaluation to include other types of noise, which could enhance the comprehensiveness and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative noise types or methods for evaluating robustness. While it identifies a potential area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This is a clear and explicit action that the authors need to take to enhance their draft. The comment provides a specific suggestion on how to improve the paper, which is to include visualizations to support the research motivation. This makes the comment 5, as the authors know exactly what step to take to address the feedback.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the performance decline of existing PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial, particularly since it is the research motivation of the paper. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. It is specific in suggesting the need for visualization to support the research motivation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors assert the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect would be beneficial, particularly since it is the research motivation of the paper. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the draft by including visualizations to support the research motivation. However, the comment could be more helpful if it offered additional guidance on how to effectively visualize this effect or provided examples of similar visualizations in related work. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a specific line in the paper, pointing out that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their draft. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 180182, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Corollar 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim made in Corollar 10, suggesting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. The comment provides a logical reasoning by questioning the assumption that uncertainty sampling is not minimizing the expected convex surrogate, based on the information provided in Corollar 10. However, it does not provide specific examples or references to support the claim further, which could strengthen the argument. Therefore, the comment is 3, as it provides a logical basis for the critique but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific critique of the paper by questioning the interpretation of Corollar 10. It points out that the corollar only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean it is not minimizing the expected convex surrogate. This feedback is 3 as it prompts the authors to reconsider their interpretation and potentially clarify or expand on this aspect in their paper. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the proposed model: first, it notes that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. Second, it points out that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to improve the model or what specific changes could be made to enhance its dynamics or complexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, namely the production of only one node changing cluster per time step due to the reassignment probability being 1/n, and the simplicity of the evolution model in changing only edges with the (on average) 1 node changing cluster. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the model, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. It also notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment provides a logical explanation for the claim, it lacks specific examples or references to support the assertion about the model\"s dynamics and simplicity. This makes the claim 3, as the authors would need to further investigate and provide evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model. First, it points out that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, which leads to slow dynamics. Second, it notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. This feedback is 3 as it highlights areas where the model could be improved, such as enhancing its dynamics and complexity. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues, which would make it more helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. It suggests that these details should be added. The comment provides a clear and concrete action for the authors to take, which is to include these details in their draft. This makes the comment 5, as the authors know exactly what needs to be done to improve their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the numbers and the method used for division, and suggests that these details should be added. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, specifically regarding the numbers and the method used for division. However, the comment does not provide any supporting evidence or reasoning to justify why these details are crucial or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the division of the dataset into training and test sets. It highlights the importance of including numbers and the method used for division, such as whether it was done randomly or with other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is crucial for the paper. Overall, the comment is 4, as it directs the authors to a critical aspect of their methodology that needs clarification."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the challenges of building text descriptions for each task, which requires human labor, and notes the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these challenges or improve the scalability of the framework. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it highlights the challenges and potential limitations, it does not provide specific guidance on how to address these issues. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights two main issues: the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. While the comment identifies important challenges and limitations, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is 3, as it provides insight into areas needing attention but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the significance of the performance improvement shown in Figure 3, noting that the biggest improvement in the bank dataset was only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the presentation of their results but are not given specific guidance on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the performance improvement of the proposed methods seems not significant, particularly highlighting the ~0.02 improvement in the bank dataset. Additionally, the comment suggests using tables to show key improvements, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, citing a specific example from Figure 3 where the biggest improvement in the bank dataset is only ~0.02. The comment also suggests using tables to show key improvements, which could enhance the clarity and detail of the results. However, the claim about the lack of significance is based on a single example and lacks broader context or comparison with other datasets or methods. While the suggestion to use tables is logical, the claim itself is 3 due to the limited evidence provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the biggest improvement in the bank dataset is only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed, providing a clear and actionable suggestion for enhancing the presentation of results. This feedback is valuable as it highlights a potential weakness in the paper and offers a concrete way for the authors to improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it provided additional context or examples of how to effectively use tables to present the results. Overall, the comment is 4, as it directs the authors to a specific area for improvement while offering a constructive suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of theoretical results or suggestions for potential improvements. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what theoretical results are expected or missing. This makes it difficult for the authors to identify the exact sections that need attention or improvement. The comment lacks both grounding and specificity, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the work does not provide any new theoretical results, despite the introduction of a new type of loss in the setting. This feedback is 3 as it highlights a potential gap in the paper, suggesting that the authors should focus on developing theoretical contributions to enhance the work. However, the comment lacks specificity and does not provide actionable guidance on how to address this issue or what specific theoretical results could be explored. While it identifies a weakness, it does not offer detailed suggestions for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is an explicit action that provides a clear direction for the authors to enhance their draft. The suggestion is concrete, as it specifies what needs to be added to the table, giving the authors a direct path to implement the recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This provides specific guidance on what needs to be addressed, which is the addition of fullysupervised baselines to Table 1. However, it does not specify which small models are being referred to or why this addition is necessary, making it somewhat vague in terms of the models and the reasoning behind the suggestion. The comment is fully grounded as it explicitly mentions Table 1, allowing the authors to identify the part of the paper being addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. The comment provides a logical reasoning for the suggestion, as it aims to enhance the understanding of the performance gap between full supervision and SSL for small models. However, the comment lacks specific examples or references to support the claim that this addition would be useful. While the reasoning is sound, the absence of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is a clear and actionable suggestion that could significantly enhance the paper by providing a more comprehensive comparison of the models. By including these baselines, the authors can gain a deeper understanding of the performance differences between full supervision and SSL, which could lead to valuable insights and improvements in their work. The comment is specific and provides a concrete direction for the authors to follow, making it 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the repeated calculation of the hypervolume for promising region selection. It also suggests that this computation could be timeconsuming for problems with many objectives. While the comment implies that the authors should address the time complexity issue, it does not provide explicit guidance on how to do so. The authors are left to infer that they need to analyze or discuss the time complexity of their algorithm, but without specific instructions or examples, the action remains somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of time complexity and the potential impracticality of the algorithm for problems with many objectives. The comment provides a detailed analysis of the problem, suggesting that the repeated calculation of the hypervolume could be timeconsuming and potentially impractical for certain types of problems. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It suggests that this computation could be timeconsuming, especially for problems with many objectives. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s efficiency, but it lacks specific examples or references to support the claim. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It highlights a potential issue that could impact the practicality of the algorithm for problems with many objectives. This feedback is valuable as it points out a specific area where the authors might need to address the computational efficiency of their method. However, the comment could be more helpful if it provided suggestions or examples on how to mitigate this issue or offered guidance on how to analyze or discuss the time complexity. Despite this, the comment is 4 as it directs the authors to a critical aspect of their work that requires further consideration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be conducted on medium or large datasets, such as ImageNet, to make the results more convincing. However, it labels this as a \"minor issue\" and notes that it will not affect the overall quality of the paper. While the comment implies that the authors should consider using larger datasets, it does not provide explicit guidance on how to implement this suggestion or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the importance and method of addressing this issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment mentions that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in suggesting the use of larger datasets, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of small datasets in the experiments makes the results less convincing and recommends using medium or large datasets like ImageNet. However, the comment does not provide specific examples or detailed reasoning to support why larger datasets would be more convincing or how they would impact the results. The suggestion is based on a general assumption about the importance of dataset size, but it lacks concrete evidence or references to substantiate the claim. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, noting that the datasets used in the experiments are small. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. However, the comment labels this as a minor issue and does not provide specific guidance on how to address it or why it would be beneficial to include larger datasets. While the feedback highlights an area for improvement, it lacks depth and actionable suggestions, making it 3. The authors are given a general direction but no detailed instructions on how to enhance their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests that they should delve deeper into the limitations of evolutionary methods, specifically regarding leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, particularly regarding the title, which is deemed too generic and vague. Additionally, the reviewer questions the meaning of \"brittle convergence properties\" and suggests that DeepRL methods are widely adopted, encouraging the authors to consider the landscape 10 years ago. These suggestions are explicit and provide concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses several specific aspects of the paper, including the limitations of evolutionary methods, the need for a more precise title, and the explanation of \"brittle convergence properties.\" However, it does not explicitly mention which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as delving deeper into the limitations and being more precise in the critique. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, but it lacks specific evidence or references to support these claims. The comment suggests that the authors should delve deeper into the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. It also critiques the title as too generic and vague, and questions the meaning of \"brittle convergence properties.\" However, without additional context or references, the claims are difficult for the authors to address or verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the need for a more indepth discussion of the limitations of evolutionary methods, particularly regarding state, reactiveness, and learning during an episode. It also suggests being more precise in the critique and title, which is currently deemed too generic and vague. Additionally, the reviewer questions the meaning of \"brittle convergence properties\" and notes that DeepRL methods are widely adopted, suggesting a consideration of the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful by offering specific examples or references to support the suggestions. Overall, the comment is 3 as it highlights areas for improvement but lacks depth and detail to be fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from empirical justification of its claimed contribution regarding the proposed algorithm not requiring as many points or prior knowledge about dimensions of subspaces. While the comment implies that the authors should provide empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include empirical justification without specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, which is about the proposed algorithm not requiring as many points or prior knowledge about dimensions of subspaces. However, it does not specify which part of the paper this contribution is discussed in, making it weakly grounded. The comment suggests that empirical justification would be beneficial, but it does not provide specific guidance on what kind of empirical evidence is needed or how it should be presented. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is not adequately justified, specifically regarding the claim that the proposed algorithm does not require as many points or prior knowledge about dimensions of subspaces. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the empirical justification of the claimed contribution regarding the proposed algorithm. It suggests that the paper would benefit from empirical evidence to support this claim, which is a valuable observation. However, the comment lacks specific guidance on how the authors might provide this empirical justification or what kind of evidence would be most relevant. While it points out an area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), implying that the novelty of the proposed method is limited. It explicitly states that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a concrete action to take: they should include a detailed discussion comparing their algorithm with RMED. The comment is explicit and provides specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of the proposed method is limited. The reviewer supports this claim by referencing RMED, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed comparisons or specific examples of similarities between the two algorithms. This would enhance the verifiability of the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, suggesting that it is too similar to RMED (Komiyama et al. 2015). This is a valuable observation that could help the authors improve their draft by highlighting the need for a more detailed comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the proposed algorithm from RMED or offered guidance on what aspects of the comparison should be emphasized. Despite this, the feedback is 4 as it directs the authors to address a critical aspect of their work, making it a 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors lack a comprehensive discussion of previous work on the topic. However, it does not provide any explicit or implicit guidance on how to address this issue. There is no suggestion on what specific aspects of previous work should be included or how the discussion should be structured. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the lack of a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or chapter where previous work should be discussed. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of previous work are missing or how they should be integrated into the discussion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it lacks specific examples or references to support this claim, making it difficult for the authors to understand the scope of the missing discussion or how to address it. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a significant omission in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical area for improvement, as it can help establish the novelty and context of the current work. However, the comment lacks specificity and does not offer guidance on how the authors might address this issue, such as suggesting specific previous works to include or how to structure the discussion. Without actionable advice, the authors are left with a general understanding of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it identifies an important area for improvement but does not provide detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it does not explicitly instruct the authors to provide a detailed explanation, it implies that the authors should clarify this point to improve the understanding of their work. The action is implicit, as the authors need to infer that they should provide more detailed information. However, the comment is 3 because it provides a clear direction for improvement, even if it does not specify exactly how to address the issue. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difference between similarity and exit times, providing a clear direction for the authors to clarify this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the novelty of the authors\" approach to unsupervised feature selection from a diffusion perspective and expresses confusion about the difference between similarity and exit times. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of novelty or the confusion about the concepts. Without additional context or explanation, the authors may find it challenging to understand the basis of the feedback or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area of confusion in the paper regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to understand the distinction. This feedback is 3 as it points out a specific area where the authors might need to clarify their work, but it does not provide detailed guidance on how to address the issue or suggest specific improvements. The authors are left with a general direction for improvement but without actionable steps, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not explicitly instruct them to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these limitations further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any evidence, reasoning, or references to support this inquiry. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment highlights a gap in the paper but does not offer actionable advice for improvement, making it 3. The authors are left to infer that they should consider these limitations, but without detailed guidance, the feedback is incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It suggests that the authors could consider using the Kialo dataset instead, which is cleaner and more established. However, the comment does not explicitly instruct the authors to use the Kialo dataset or provide specific guidance on how to integrate it into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using the Kialo dataset but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset and the use of the Kialo dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the dataset creation, noting that the Kialo dataset is wellstudied and cleaner, and suggests that the dataset created in the paper could be used as additional data. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional and suggests using the Kialo dataset instead. It provides a logical reasoning by stating that the Kialo dataset is wellstudied and cleaner, with no automatic processes to construct it. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting the use of the Kialo dataset, which is wellstudied and provides pairs of short claims and their counters. It highlights that the dataset created in the paper could be considered as additional data to learn from. This feedback is clear and actionable, as it provides a specific alternative to the dataset creation and suggests a way to enhance the paper. However, the comment could be more helpful if it offered further guidance on how to integrate the Kialo dataset into the paper or discussed potential benefits of using it. Overall, the comment is 4 as it offers a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the transformer modification and its impact on machine learning insights. It also questions the significance of the improvement brought by the selfcross attention in the ablation study. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their work. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ablation study (table4 and 5),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the novelty of the transformer modification, the limited improvement brought by the selfcross attention, and the suggestion that the main improvements come from using a na\u00efve transformer. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the transformer modification is no longer novel and does not bring significant insights in machine learning. It also questions the significance of the improvement brought by the selfcross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer. The comment provides some reasoning by mentioning the limited improvement (<1%) and the lack of novelty in the transformer modification. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the paper to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the paper, questioning the novelty of the transformer modification and its impact on machine learning insights. It points out that the selfcross attention brings limited improvement (<1%) in the ablation study, suggesting that the main improvements may come from using a na\u00efve transformer rather than the proposed modification. This feedback is 3 as it highlights a potential weakness in the paper and encourages the authors to reconsider the significance of their contributions. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or improve the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This provides a clear and concrete action for the authors to take, as it specifies the additional tasks they should consider for their experiments. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments conducted in the paper, specifically mentioning the focus on sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other tasks that involve sentence pairs, such as sentence inference tasks like MNLI and RTE. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section. The suggestion to include additional tasks is specific, providing clear guidance on how to enhance the experimental scope. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited because they only focus on sentence similarity tasks and open domain QA tasks, suggesting that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out the omission of other relevant tasks in the NLP field, which supports the claim. However, it lacks specific examples or references to these tasks, which would strengthen the argument. Therefore, the claim is 4, as it provides a clear direction for expansion but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope of the paper, noting that the authors have only conducted evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other tasks that involve sentence pairs, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the comprehensiveness and relevance of their experiments. By suggesting additional tasks, the comment offers a constructive way for the authors to improve the depth and breadth of their study, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. While it highlights a potential issue with the analysis, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the motivation for their choice of analysis. However, the comment lacks concrete details on how to improve the draft, making it 3. The authors know they need to address the issue but may not be entirely sure how to do so without further guidance.", "grounding_specificity_rationale": "The comment raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in its questioning of the motivation and the reasoning behind the choice of analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity would not appear in earlier layers. This is a logical question that prompts the authors to clarify their reasoning, but it does not contain a claim that requires verification. It is a request for clarification rather than an opinion or suggestion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This prompts the authors to clarify their reasoning and potentially reconsider their analysis approach. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the draft. While it identifies a potential weakness, it lacks depth and actionable feedback, making it 3. The authors are given some insight into a potential area for improvement but are left without detailed guidance on how to enhance their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a human evaluation component but are not given concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section where caption generation is discussed. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation should be considered or how it would improve the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. This claim is 3 as it provides a logical reasoning for why human evaluation might be more convincing. However, the comment lacks specific examples or references to support the claim that automatic metrics are misleading, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a reasonable basis for the claim but could be improved with more detailed evidence or examples.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it identifies a potential weakness in the evaluation methodology and suggests an alternative approach that could provide more robust insights. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the human evaluation or what aspects to focus on. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the convergence proof as trivial, suggesting that it lacks substantial novelty and rigor. It implies that the authors should address this issue by providing a more substantial and rigorous proof. However, the comment does not explicitly instruct the authors to revise the proof or provide specific guidance on how to enhance its novelty and rigor. The action is implicit and somewhat vague, as the authors can infer that they need to improve the proof but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Triviality of Convergence Proof,\" indicating that it addresses the theoretical proof for convergence. It also references \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" providing clear references to specific parts of the paper. The comment is specific because it details the issue with the convergence proof, explaining that it appears trivial due to the i.i.d. nature of $X$ and the straightforward adaptation of previous theorems. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial, suggesting that the paper\"s claim of noni.i.d. data is contradicted by Assumption 4.1, which indicates that $X$ is i.i.d. The reviewer provides a logical explanation by pointing out that the covariance matrix for $Z$ can be easily determined as $A^\top A / np$, and that previous theorems can be adapted with straightforward modifications. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the convergence proof, suggesting that it appears trivial due to the i.i.d. nature of $X$ and the straightforward adaptation of previous theorems. It points out the inconsistency between the paper\"s claim of noni.i.d. data and the assumption that $X$ is i.i.d., which leads to a clear covariance matrix for $Z$. The comment also references Modification 1 in Appendix C, indicating that the previous theorems can be adapted with minor modifications. This feedback is clear and actionable, as it highlights a specific weakness in the paper and suggests a way to address it by providing a more rigorous and novel convergence proof. However, the comment could be more helpful if it offered additional guidance on how to enhance the proof or suggested alternative approaches. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a conflict between two statements in the paper regarding the performance of the multienv model compared to the singleenv model. It explicitly requests clarification to resolve this apparent contradiction. The action is direct and clear, as the authors are instructed to clarify the conflicting statements. This provides a concrete and explicit action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment identifies a conflict between two statements regarding the performance of the multienv model compared to the singleenv model. It explicitly mentions the issue of conflicting statements, which allows the authors to pinpoint the sections where these statements are made. However, it does not specify which sections or parts of the paper these statements are located in, making it weakly grounded. The comment is specific in detailing the conflict and requesting clarification, aligning with a score of 3.", "verifiability_rationale": "The review point identifies a conflict between two statements in the paper regarding the performance of the multienv model. It points out that the model is described as having an inevitable performance loss and also as outperforming the singleenv model due to knowledge sharing. The comment requests clarification to resolve this apparent contradiction. However, it does not provide any additional context, evidence, or reasoning to support why these statements are conflicting or how they should be clarified. As a result, the claim is considered 1, as it lacks the necessary justification or evidence to guide the authors in addressing the issue.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically a conflict between two statements regarding the performance of the multienv model. It points out that the model is described as having an inevitable performance loss and also as outperforming the singleenv model due to knowledge sharing. This conflict needs to be clarified to ensure the paper presents a consistent and accurate representation of its findings. The comment provides a clear and actionable suggestion for improvement by requesting clarification, which is a valuable contribution to the authors. However, it could be more helpful if it offered specific guidance on how to resolve the conflict or suggested potential explanations. Overall, the comment is 4 as it directs the authors to address a significant issue in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing the source of the metrics. This feedback is explicit, as it clearly states what needs to be done to improve the draft. However, it lacks concrete details on how to execute these actions, such as which specific metrics require explanation or how to properly cite them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the description of metrics in the paper, suggesting that it is limited and recommends either providing an explanation of the metrics or citing their source. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in its suggestion to provide an explanation or citation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation would be beneficial. However, the comment does not provide specific examples of which metrics are lacking in description or how they could be improved. This lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific issues and potential solutions based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the description of the metrics used is limited. It provides a clear and actionable suggestion by recommending that the authors either explain the metrics used or provide a citation to their source. This feedback is valuable as it directs the authors to enhance the clarity and transparency of their work by addressing the metrics used. However, the comment could be more helpful if it specified which metrics are particularly unclear or suggested ways to improve the explanation. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should better motivate the applications where such algorithms are necessary. However, the comment does not provide explicit guidance on how to achieve this motivation or what specific aspects should be included to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem being studied, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the paper does not spend time motivating the applications where such algorithms are needed and that all datasets used are static. This provides a clear indication of the issue, but it does not specify which part of the paper should be revised to address this concern. The authors can infer that the introduction or motivation section might need revision, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. The comment suggests that the problem should be wellmotivated for the paper to be useful. However, the review does not provide specific examples or references to support the claim that the problem is not wellmotivated or that the datasets used are inappropriate. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the datasets used in the empirical analysis are static, which contradicts the objective of the paper. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to better motivate the problem and its relevance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending examples of applications where such algorithms are needed or suggesting ways to incorporate dynamic datasets into the analysis. Despite this, the comment is 4 as it directs the authors to a key area that needs attention, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Tables 2 and 3. While the comment identifies the need for clarification and additional information, it does not explicitly instruct the authors to include these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional information but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the underspecification of the study\"s scope and the missing CoT baselines for incontext learning of Large Language Models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also mentions the absence of relevant CoT baselines for incontext learning of Large Language Models in Tables 2 and 3. However, the comment does not provide specific examples or references to support the claim about the scope or the missing baselines. This lack of detailed evidence or reasoning makes the claim 3, as the authors would need to infer the missing information or seek additional context to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of relevant CoT baselines for incontext learning of Large Language Models in Tables 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and to include additional relevant baselines. However, the comment could be more helpful if it provided specific examples or references to support the suggestion for additional baselines. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment indicates that Figure 3 is difficult to read, but it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might enhance the readability of the figure, such as suggesting changes to the font size, color scheme, or layout. Without actionable advice, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the figure is \"very hard to read,\" which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the figure is difficult to read. Without additional context or explanation, the claim remains unsubstantiated, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable suggestions or guidance on how the authors might improve the figure\"s readability. Without specific advice on font size, color scheme, or layout adjustments, the authors are left without a clear path to address the issue. This feedback is 3 as it points out a problem but does not provide enough detail to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific steps they should consider to improve their draft. As a result, the authors are left without a clear understanding of what actions to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the introduction, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate observations. The first part suggests replacing a specific mathematical expression with an arbitrary parameter, which is an explicit action. However, it does not provide guidance on how to choose this parameter or why it would be beneficial. The second part questions the choice of the SGD learning rate, noting that it differs from the Adam default value and lacks justification. While this is an implicit suggestion to provide a justification, it is not explicitly stated. The comment lacks concrete details on how to address these issues, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the use of an arbitrary parameter `lambda` and the choice of the SGD learning rate, noting that it differs from the Adam default value and lacks justification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim questions the replacement of a mathematical expression with an arbitrary parameter, but it does not provide any reasoning or justification for why this change might be problematic. The second claim points out that the SGD learning rate is set to ~0.1, which is different from the Adam default value, and suggests that the justification for this choice is unclear. However, the comment does not provide any evidence or references to support the claim that the choice of learning rate is inappropriate or that it lacks justification. Without additional context or reasoning, the claims are difficult for the authors to address, making them 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter `lambda`, which could be a potential concern for clarity and consistency. Second, it questions the choice of the SGD learning rate, noting that it differs from the Adam default value and lacks justification. This feedback is clear and actionable, as it prompts the authors to reconsider their choices and provide a rationale for them. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative approaches. Overall, the comment is 4, as it directs the authors to areas that require clarification and justification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests analyzing the domain gap and discussing the differences between datasets. It implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. Additionally, it suggests that if the method can finetune a pretrained model on synthetic data, it would enhance the value of the approach. While the comment provides a clear direction for analysis and discussion, it does not specify how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the differences between datasets, which implies that the authors should address this issue in the paper. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that the authors discuss the gap between datasets and the potential for adaptation issues, as well as the value of the approach if it can finetune a pretrained model on synthetic data. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discusses the potential for adaptation issues based on the proximity of datasets. It also mentions the value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides some logical reasoning and suggestions, it lacks specific examples or references to support the claims. The reasoning is 3, as it provides a general framework for analysis, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap and discussing the differences between datasets, which is a relevant and important aspect of the paper. It provides a clear direction for the authors to explore, such as considering the proximity of datasets and the potential for adaptation issues. Additionally, it highlights the value of the approach if it can finetune a pretrained model on synthetic data, offering a specific area for improvement. However, the comment could be more helpful if it provided specific examples or references to guide the authors in their analysis. Overall, the feedback is 4 as it offers actionable suggestions for enhancing the paper, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This comment provides a clear and explicit action for the authors to take, which is to include an NCEbased method in their comparison. The reference to a specific study provides concrete guidance on how to implement this suggestion, making the action 5. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a study that shows the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion should be made in, nor does it provide detailed guidance on how to incorporate this comparison. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to a study that supports the idea of including NCEbased methods. However, the comment lacks specific details or examples of how this comparison would be beneficial or how it relates to the current work. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include at least one NCEbased method for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing a specific suggestion for enhancing the paper by broadening the scope of comparisons. However, the comment could be more helpful if it offered additional guidance on how to incorporate this comparison or why it is important for the paper. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs, noting that the research gap and limitations of existing methods are not discussed. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to discuss the limitations of existing methods and justify the need for a new approach, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a gap but does not fully direct the authors on how to fill it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on the limitations of existing methods. The comment provides a clear direction for the authors to address the gap in their paper by discussing the limitations of existing methods and justifying the need for a new approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified and that the research gap is not discussed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence leaves the authors without a clear path to address the issue, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the justification for designing a new curriculum learning method for text graphs. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the gap in their justification and provide a more comprehensive discussion of the limitations of existing methods. However, the comment could be more helpful if it offered suggestions on how to structure this discussion or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that powerful pretrained language models, such as BERT and XLNet, can be used as the base encoder for all methods to overcome the domainshift problem in NLP. It implies that the authors should use these models instead of the simplest ngram features and then compare the efficacy of the transfer parts. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specific guidance on integrating the pretrained models or how to compare the efficacy of the transfer parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods to address the domainshift problem in NLP. It implies that the authors should compare the efficacy of the transfer parts instead of using the simplest ngram features. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its suggestion but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods to address the domainshift problem in NLP. The claim is based on the general knowledge that these models can overcome the domainshift problem to some extent. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to look into the literature to understand the effectiveness of these models in domain adaptation, which adds a layer of effort to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for improving the approach to domain adaptation in the NLP field. It recommends using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, which could help overcome the domainshift problem. This is a clear and actionable piece of feedback that could significantly enhance the draft by offering a more robust approach to addressing the domainshift issue. However, the comment could be more helpful if it included specific guidance on how to integrate these models or compare their efficacy with the current ngram features. Overall, the comment is 4 as it provides a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the explanation of a specific section (lines 196197) and suggests that more detail is needed to understand why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide explicit guidance on how to address this issue or what specific information should be added. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explanation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 196197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for more explanation regarding the difference between the two quantities and how they capture the difference in learning settings. The comment also includes a personal opinion about the acceptance of the paper, but this does not detract from the specificity of the feedback regarding the explanation needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the explanation of a specific section (lines 196197) and suggests that more detail is needed to understand the difference between the two quantities and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would improve the paper. The claim is based on a subjective opinion and lacks verifiable evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 196197) where more explanation is needed. It questions the rationale behind the difference between two quantities and how they capture the difference in learning settings. While the comment highlights an area that requires clarification, it does not provide specific guidance on how to address this issue or suggest alternative explanations. The comment also includes a personal opinion about the acceptance of the paper, which, while interesting, does not directly contribute to improving the draft. Overall, the feedback is 3 as it points out a need for clarification but lacks depth and actionable suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and direct, providing the authors with a specific action to take. The comment also specifies what needs to be addressed, which is the sensitivity of these parameters. Therefore, the comment is 5, as it gives the authors a concrete and explicit instruction on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly refers to \"4.\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the sensitivity of fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should address in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information or discussion, rather than a claim or opinion. It does not express a subjective judgment, suggestion, or deduction that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific in its request for the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is actionable and provides a clear direction for the authors to enhance their draft by addressing a specific aspect of their methodology. By highlighting this area, the comment helps the authors to improve the comprehensiveness and robustness of their work. Therefore, the comment is rated as 5, as it offers valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests an interesting direction for further exploration, which is to test the proposed framework with different policy gradient approaches. However, it does not provide explicit guidance on how to conduct this exploration or what specific approaches to consider. The second part asks a question about the number of random seeds used for learning policies, which is an explicit request for clarification. While the first part is vague, the second part is clear and actionable. Overall, the comment is 4 because it provides a concrete request for clarification but lacks detailed guidance on the first suggestion.", "grounding_specificity_rationale": "The comment suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The second part of the comment asks about the number of random seeds used for learning policies, which is specific but still does not provide clear grounding as it does not specify the exact section or context where this information is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: a suggestion to explore the proposed framework with different policy gradient approaches and a question about the number of random seeds used for learning policies. The first part is a suggestion and does not contain a claim that requires verification. The second part is a factual question seeking clarification, which is not a claim. Therefore, the entire comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two distinct points. The first part suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. This is a valuable suggestion that could enhance the paper\"s scope and applicability. However, it lacks specific guidance on how to conduct this exploration or which approaches to consider, making it 3. The second part of the comment is more specific and actionable, as it requests clarification on the number of random seeds used for learning policies, which is a critical detail for reproducibility. This part of the comment is clear and provides a specific action for the authors to take. Overall, the comment offers some helpful insights but could be more comprehensive and detailed in its suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that there are areas where the writing could be improved, specifically mentioning the definition 2.1 and the interpretation of \"relevant\" auxiliary model weights. However, it does not provide explicit guidance on how to improve the writing or clarify the definition. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that there are areas where the writing could be improved, specifically mentioning \"definition 2.1\" and the interpretation of \"relevant\" auxiliary model weights. This provides full grounding as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it points out a particular issue with the definition, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved in certain places, specifically mentioning a difficulty in interpreting \"definition 2.1\" regarding \"relevant\" auxiliary model weights. However, the comment does not provide any further explanation or justification for why this interpretation is challenging or how it could be clarified. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area where the writing could be improved, namely in the definition of \"relevant\" auxiliary model weights in section 2.1. It points out that the current definition is difficult to interpret, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to clarify the definition or suggested alternative ways to present the information. Despite this, the feedback is 4 as it directs the authors to a specific area that needs attention and provides a starting point for improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests using ULiRA instead. While the comment implies that the authors should consider alternative methods for privacy guarantees, it does not explicitly instruct them to make this change. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other methods for robustness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing via Ulira as a metric for unlearning effectiveness. It raises a concern about the robustness of MIA testing for privacy guarantees and suggests using ULiRA instead. However, the comment does not specify which part of the paper discusses MIA testing or where the suggestion to use ULiRA should be incorporated. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its critique of MIA testing and the suggestion to use ULiRA, but without explicit references to sections or parts of the paper, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA (Membership Inference Attack) testing is not sufficiently robust for privacy guarantees. It suggests using ULiRA as an alternative. However, the comment lacks specific examples or detailed reasoning to support the claim about the limitations of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification or references makes the claim 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the effectiveness of MIA testing itself may not be robust enough for privacy guarantees. This is a valuable observation that could impact the validity of the paper\"s conclusions. The comment also provides a specific suggestion to use ULiRA, which is a more robust method for privacy guarantees. However, the comment could be more helpful if it included additional context or examples of how ULiRA might be integrated or compared to MIA testing. Overall, the feedback is 4 as it highlights a critical area for improvement and offers a concrete suggestion, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While the comment implies that the authors should explore this connection, it does not provide explicit instructions or concrete steps on how to incorporate this idea into the paper. The action is implicit and somewhat vague, leaving the authors to infer that they should consider this connection but without clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting an alternative presentation, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, the comment lacks specific reasoning, examples, or references to support the claim that the considerations should be applicable to kernel regression. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While it identifies a potential connection that could enhance the paper\"s relevance, it lacks specific guidance or suggestions on how to incorporate this idea or explore its implications. The comment provides some insight but does not offer actionable steps for improvement, making it 3. The authors are left with a general direction but without detailed instructions on how to address the suggestion. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This implies that the authors should include specific settings or comparisons to enhance the paper\"s contribution and clarity. However, the comment does not provide detailed guidance on how to implement this suggestion, such as which specific knobs to focus on or how to present the comparisons. While the action is clear, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a way to improve the paper by providing a single review of the various advances in this area, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where this improvement should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution and clarity. However, the comment lacks specific examples or references to prior work, which would strengthen the justification. The authors would need to infer the relevance of these suggestions and how they align with the prior work mentioned. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper\"s contribution and clarity. By following this suggestion, the authors can better align their work with existing literature and provide a more comprehensive review of the advances in this area. However, the comment could be more helpful if it included examples of how to present these settings or comparisons, which would further guide the authors in implementing the suggested improvement. Overall, the comment is 4, as it offers a clear and actionable suggestion for enhancing the paper\"s impact and relevance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their examples. The comment implies that the authors should consider providing more context or analysis to establish the generalizability of these examples, but it does not specify how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding the generalizability of specific examples presented in the paper. The comment highlights the need for more context or analysis to establish the generalizability of these examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases in target statistics and prediction shift of gradient values, but it does not provide a clear explanation of why these examples are unclear or how they could be improved. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. It points out that while the paper provides examples, it does not establish the generalizability of these situations. This feedback is 3 as it highlights a potential weakness in the paper and prompts the authors to consider providing more context or analysis to address this issue. However, the comment could be more helpful if it offered specific suggestions or guidance on how to improve the clarity and generalizability of the examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of a few more datasets would be beneficial, particularly in the context of crosstask transferability. However, it does not specify which datasets should be included or how they would enhance the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks concrete guidance on which datasets to choose or how to integrate them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including a few more datasets, especially concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. This makes it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment lacks specificity regarding which datasets should be included or how they would enhance the study. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why these additional datasets are necessary or how they would enhance the study. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1.", "helpfulness_rationale": "The comment suggests that including a few more datasets, particularly those concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the study. The feedback is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of images or plots. The reviewer provides a specific example of an interleaved imagetext task, such as Question Answering from images, which could be considered. While the comment implies that the authors should consider adding more diverse tasks, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of a task that could be added, but it is implicit in the sense that it does not directly tell the authors to make these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the tasks presented in the paper, specifically mentioning \"Figure captioning\" and \"matching figures/subfigures to appropriate captions.\" It suggests that the tasks are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of images or plots. The reviewer provides a specific example of an interleaved imagetext task, such as Question Answering from images. This provides clear guidance on what could be improved, making the comment specific. However, it does not explicitly mention which part of the paper discusses these tasks, so the authors might need to infer the relevant sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of images or plots. The reviewer provides a specific example of an interleaved imagetext task, such as Question Answering from images, which could be considered. This suggestion is supported by logical reasoning, as it highlights a potential area for expansion and diversification of the tasks. However, the comment could be strengthened by providing more detailed reasoning or examples of how these unique tasks could be integrated. Overall, the claim is 4, as it provides a clear direction for improvement but lacks specific examples or references to fully substantiate the suggestion. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the tasks presented are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of images or plots. It provides a specific example of an interleaved imagetext task, such as Question Answering from images, which could be considered. This feedback is clear and actionable, as it suggests a way to expand the scope of the paper and make it more comprehensive. However, the comment could be more helpful if it offered additional guidance on how to implement these unique tasks or provided more detailed examples. Overall, the comment is 4, as it offers a valuable suggestion for improving the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify whether their work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the work in this section includes any novel efforts beyond following the previous work, \"Luciddreamer.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" However, it does not provide any specific examples, references, or detailed reasoning to support the claim that the work is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the work presented in Section 3.1, specifically regarding the generation of 3D Gaussians. It questions whether the work merely follows the previous work, \"Luciddreamer,\" without any additional novel efforts. This feedback prompts the authors to clarify the novelty of their approach, which is an important aspect of academic integrity and originality. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate or highlight any novel contributions. Overall, the comment is 3 as it directs the authors to address a critical aspect of their work, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, suggesting it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors might address these concerns or suggest potential improvements. The feedback is 3 as it points out areas for improvement but lacks concrete steps for the authors to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the upper bound provided in the theorem, such as the crude nature of the bound and the dropping of the nonnegative constraint on the distribution. Additionally, it critiques the assumption that the loss function belongs to the RKHS, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, stating that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. The comment also questions the assumption that the loss function belongs to the RKHS. While the reviewer provides a logical critique of the method, the comment lacks specific references or detailed examples to fully substantiate the claims. The reasoning is 3, as it highlights potential issues with the method, but it could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, pointing out that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, the comment questions the assumption that the loss function belongs to the RKHS, as already pointed out by the authors. This feedback is 4 as it highlights specific weaknesses in the method and provides a clear direction for the authors to address these issues. However, it could be more helpful if it offered suggestions on how to improve the tractability or provided examples of how to address the issues with the upper bound. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an experiment where the trained models are sparsified to reduce the number of selected features and compared to the proposed model in terms of accuracy. This is an explicit action with concrete details on how to implement it, as it provides a specific experiment to conduct. The authors know exactly what needs to be done to address the suggestion, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an experiment where the trained models are sparsified to reduce the number of selected features and compares the accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a suggestion for an additional experiment, asking the authors to consider sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. This suggestion is not a claim or opinion but rather a request for further exploration. It does not require verification as it is a factual statement asking for an additional analysis. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment suggests an additional experiment that could enhance the paper by exploring the effect of sparsifying the trained models on the number of selected features and comparing the accuracy to the proposed model. This feedback is clear and actionable, providing the authors with a specific direction for further analysis that could strengthen the paper. However, the comment could be more helpful if it explained why this experiment is important or how it might impact the overall findings. Despite this, the suggestion is valuable and offers a concrete way for the authors to improve their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. The reviewer suggests that more details are needed to reproduce the work, such as specifics about the RNN implementation. While the comment identifies the need for additional details, it does not provide explicit guidance on what specific details should be included or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more technical details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pseudocode given in the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing for reproducibility, such as details about the RNN implementation and other technical details. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. The reviewer suggests that more details are needed, such as specifics about the RNN implementation, to facilitate reproduction. However, the comment lacks specific examples or references to support the claim that the current details are insufficient. While the reviewer provides a logical reasoning for the need for more details, the absence of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite providing pseudocode in the supplementary material, the paper lacks sufficient details for reproduction. It highlights the need for more technical details, such as specifics about the RNN implementation, to facilitate reproducibility. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the reproducibility and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present these additional details or provided examples of what specific information should be included. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment does not offer any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to mitigate these biases or improve the approach. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach to determining chunk significance in FIITED, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The comment is specific in detailing the potential issue of biases introduced by basing eviction decisions solely on utility scores and provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. The reviewer provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This example offers a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing additional evidence or references to support the assertion about biases. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks could gain a temporary high utility, leading to premature evictions of other valuable chunks. This feedback is clear and highlights a critical area for improvement, allowing the authors to consider alternative approaches or mitigations to address the potential bias. However, the comment could be more helpful if it offered suggestions or examples of how to address this issue. Overall, the comment is 4 as it provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms to provide a clearer understanding of the framework\"s performance. The comment also implies the need for more detailed explanations of the presented results. While the action is implicit, it is concrete in suggesting specific improvements, such as conducting quantitative experiments and comparisons. The authors can infer that they need to enhance the experimental section to address the reviewer\"s concerns. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"methodology\" and \"result section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding how different parts of the framework perform and contribute to the final result. The comment suggests the need for quantitative experiments and comparisons between algorithms, as well as more detailed explanations of the presented results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the results section provides promising visual stimuli but lacks quantitative experiments and comparisons between algorithms. The comment implies that this lack of detail makes it unclear how the framework performs compared to other solutions. However, the review does not provide specific examples or references to support the claim, making it 3. The authors would need to conduct additional experiments or provide more detailed explanations to address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contributions. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments and comparisons between different algorithms. The comment suggests that this lack of detail makes it unclear how the framework performs compared to other solutions. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to improve the comprehensiveness and clarity of their paper. By suggesting the inclusion of quantitative experiments and comparisons, the comment offers a concrete path for the authors to enhance their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the paper need to be clarified or improved. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s capabilities are unclear or how they could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear understanding of what changes are needed to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests presenting a simplified version of Theorem 2 for a general audience, similar to Theorem 1. This implies that the authors should consider making their explanation more accessible to a broader audience. However, the comment does not provide specific guidance on how to simplify the theorem or what aspects to focus on. While the action is implicit, it is somewhat concrete in suggesting a direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, and mentions that Definition 2 and Theorem 2 are hard to digest on their own. This provides specific guidance on what needs to be addressed, namely the complexity of Theorem 2 and Definition 2. However, it does not explicitly mention which part of the paper these theorems and definitions are located in, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult for a general audience to understand and proposes simplifying it, similar to Theorem 1. However, the comment does not provide any specific reasoning, examples, or references to support why Theorem 2 is hard to digest or how it could be simplified. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, to make it more accessible. This feedback is clear and actionable, as it provides a specific direction for improving the clarity and readability of the paper. By suggesting a simplification, the reviewer offers a concrete way for the authors to enhance the understanding of their work for a broader audience. However, the comment could be more helpful if it included specific suggestions on how to simplify the theorem or what aspects to focus on. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting experiments with a larger image resolution to see how it affects performance. While the comment implies that the authors should consider this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which resolution to use or how to implement the change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1, All the experiments are conducted using images under 224*224 resolution,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting experiments with a larger image resolution to see how it affects performance. This provides clear guidance on what the authors could do to enhance their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be interesting to see how performance changes with a larger image resolution. However, it does not provide any reasoning, evidence, or references to support why this would be beneficial or how it might impact the results. The comment lacks specific examples or logical reasoning to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for further experimentation by proposing the use of larger image resolutions in the experiments. This feedback is 3 as it provides a potential area for improvement and expansion of the study. However, it lacks specific guidance on how to conduct these experiments or what benefits might be expected from using larger resolutions. To be more helpful, the comment could include suggestions on how to implement this change or what specific aspects of performance might be affected. As it stands, the feedback offers a general direction but does not fully support the authors in making significant improvements to their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking for clarification on the keypoint mask averaged feature vector. It implies that the authors should provide a detailed explanation or justification for this aspect of their work. However, the comment does not explicitly instruct the authors to make any changes or provide specific guidance on how to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should clarify this part of their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"keypoint mask averaged feature vector\" and suggests that it might be a simple multiplication of each feature map elementwise by H_psi. This provides clear guidance on what needs to be addressed in the KeyQN section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the KeyQN section, specifically regarding the keypoint mask averaged feature vector. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the KeyQN section, asking for clarification on the keypoint mask averaged feature vector and suggesting that it might be a simple multiplication of each feature map elementwise by H_psi. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the concept in their draft. The comment is 3 as it points out a potential area of confusion, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the central contribution of the paper, specifically the use of ODEs to model weight evolution, due to concerns about the inaccuracy of neural ODEs when recomputing activations. The reviewer suggests that a previous paper may have first reported this issue, but the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment identifies a potential issue with the paper\"s contribution, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more evidence or analysis to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the problem of neural ODEs exhibiting inaccuracy when recomputing activations. It mentions that a previous paper may have first reported this issue, but the current paper lacks a convincing analytical argument or empirical evidence. This provides some specificity by detailing what is missing in the paper. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s central contribution, modeling weight evolution using ODEs, is based on an issue with neural ODEs exhibiting inaccuracy when recomputing activations. The reviewer suggests that a previous paper may have first reported this issue, but the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment references a potential issue, it does not provide specific references to the previous paper or detailed reasoning to substantiate the claim. This makes the claim 3, as the authors would need to investigate further to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the central contribution of the paper, specifically the use of ODEs to model weight evolution, due to concerns about the inaccuracy of neural ODEs when recomputing activations. It suggests that a previous paper may have first reported this issue, and the current paper lacks a convincing analytical argument or empirical evidence to support this claim. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and highlights the need for more evidence or analysis. However, it does not provide specific guidance on how the authors might address this issue or improve their draft. While it points out a critical area for improvement, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is an explicit action that provides clear guidance on what the authors should add to their draft. The comment is specific and concrete, as it directly instructs the authors on what additional information should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is a specific and actionable piece of feedback that could enhance the clarity and completeness of the paper. By addressing this suggestion, the authors can provide additional context and depth to their explanation, which could improve the reader\"s understanding of the methodology. However, the comment could be more helpful if it provided further context or explanation of why this information is important or how it relates to the overall discussion. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger data sets, acknowledging that compute resources might be a limiting factor. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of batch size on probability maintenance without specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Additional experiments on larger data sets,\" which allows the authors to identify the specific part of the paper being addressed. It also provides specific feedback on the potential issue of maintaining probabilities at large batch sizes, offering a clear direction for improvement. However, the comment does not specify which section of the paper should include these additional experiments or how to address the issue of maintaining probabilities. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger data sets, acknowledging potential compute resource limitations. It also mentions concerns about maintaining probabilities at large batch sizes, but notes that this aspect is not critical. The comment provides a logical reasoning for the suggestion of additional experiments and acknowledges the potential issue with batch size, but it does not offer specific examples or references to support the claim. This makes the claim 3, as it provides a basis for the suggestion but lacks detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for additional experiments on larger data sets, acknowledging the potential issue of compute resources. It also addresses a concern about maintaining probabilities at large batch sizes, noting that this aspect is not critical. The comment acknowledges the author\"s response to the initial concern and provides a nuanced perspective on the issue. However, it lacks specific guidance or actionable steps for the authors to address the suggested improvements. While it offers some insight, the feedback is incomplete and does not fully support the authors in enhancing their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. This feedback is clear and actionable, as it directs the authors to compare their results with those of more recent models and to consider how their performance can be improved. The inclusion of specific references (GLaMM and UNINEXT) and their respective results provides concrete guidance on what the authors need to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT, and providing specific results from these models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. The inclusion of references to these models and their respective results provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or explanations of why the current performance is considered \"behind\" recent models. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by comparing the performance of the paper on REC and RES with more recent models, such as GLaMM and UNINEXT. It highlights that the current performance is behind these recent models, offering a clear direction for the authors to improve their results. By referencing specific models and their achievements, the comment gives the authors concrete examples to consider for enhancing their draft. This level of detail and specificity makes the comment 5, as it empowers the authors to make targeted improvements. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the method\"s weakness would be more apparent in images with multiple objects or cluttered scenes. It implies that the authors should consider comparing their approach to previous methods on a dataset with such characteristics. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes and recommends comparing the approach to previous ones on a fewshot classification dataset. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular area for comparison, which is addressing the method\"s weakness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more apparent in images with multiple objects or cluttered scenes, and it recommends comparing the approach to previous ones on a fewshot classification dataset. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The suggestion is based on a logical inference but lacks concrete evidence or detailed justification, making it 3. The authors would need to infer the relevance of this suggestion and potentially conduct additional research to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method being discussed, suggesting that its effectiveness might be more pronounced in images with multiple objects or cluttered scenes. It provides a specific and actionable suggestion to compare the approach with previous methods on a fewshot classification dataset in such scenarios. This feedback is clear and offers a concrete direction for the authors to explore and strengthen their work. By addressing this suggestion, the authors can gain a deeper understanding of their method\"s limitations and potential applications, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what aspects of the bounds need further explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in suggesting that additional explanation is needed, particularly in the appendix. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. However, it does not provide any specific reasoning or evidence to support why this additional explanation is necessary or how it would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment acknowledges the space limitations in the paper but suggests that the authors could benefit from providing more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on what aspects of the bounds need further explanation or how this could be achieved. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. This provides a clear and direct action for the authors to take, which is to omit the detailed explanation. The comment is explicit and concrete, as it specifies exactly what action should be taken and why. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels using OpenAI\"s Triton instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this implementation is discussed in, making it weakly grounded. The comment is specific in its suggestion to omit the detailed explanation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these improvements are wellknown or why a fullpage explanation is unnecessary. This lack of supporting evidence makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment points out that the implementation of kernels using OpenAI\"s Triton instead of CUDA does not require a fullpage explanation, as the engineering improvements are wellknown. This feedback is 3 as it highlights an area where the authors might be overexplaining a point that is already understood in the field. However, the comment could be more helpful if it provided specific guidance on how to condense the explanation or suggested alternative ways to present the information. Overall, the feedback is clear but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. The reviewer implies that the paper should clarify these points to avoid misleading the reader. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to make these clarifications. The action is implicit and somewhat vague, as the authors need to infer that they should address these points in the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. However, the comment does not explicitly mention which part of the paper these examples are based on, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the transferability and the difficulty of tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support their claim. However, the comment lacks detailed reasoning or references to substantiate the claim fully. While the examples provide some insight, the lack of comprehensive justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiment and the transferability of the policy. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support the claim that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer suggests that the paper should clarify these points to avoid misleading the reader. This feedback is clear and actionable, as it identifies specific areas that need clarification and provides examples to guide the authors in improving their draft. However, it could be more helpful if it offered suggestions on how to present this information in the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their analysis. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks. This provides clear guidance on what needs to be addressed in the analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also suggests that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique. The absence of concrete evidence or references leaves the claim 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific critique regarding the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks. While the comment highlights a potential weakness in the analysis, it lacks actionable suggestions or guidance on how the authors might address these issues or improve their work. Without specific recommendations or examples, the feedback is 3 as it provides insight into a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This provides a clear and explicit action for the authors to explore a particular approach. The second part points out a potential inconsistency in the text, noting that \"relatively inexpensive\" is mentioned in the abstract, while \"expensive to evaluate\" is used in the introduction. This feedback is explicit and provides a clear action for the authors to clarify or reconcile these statements. However, the comment could be more actionable if it suggested specific ways to address the inconsistency. Overall, the comment is 4 as it provides a clear direction for the authors to follow, but it could be more detailed in its guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g. probabilities of threshold exceedance)\" and \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the text, noting the inconsistency between \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests that the authors consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This claim is 4 as it provides a specific reference to support the suggestion. However, the second part of the comment points out a potential inconsistency in the text regarding the cost of evaluation, but it does not provide further explanation or evidence to substantiate this claim. Overall, the comment is 4 due to the reference provided, but it could be strengthened with additional details or examples to fully support the claim.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part suggests that the authors consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This is a valuable suggestion that could enhance the paper by introducing a relevant approach. However, the comment could be more helpful if it explained how this approach might be applied or integrated into the current work. The second part of the comment points out a potential inconsistency in the text, noting that \"relatively inexpensive\" is mentioned in the abstract, while \"expensive to evaluate\" is used in the introduction. This feedback is clear and actionable, as it prompts the authors to clarify or reconcile these statements. Overall, the comment is 4 as it provides a specific suggestion for improvement and highlights a need for clarification, but it could be more comprehensive in its guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit and vague, as the authors are left to infer what needs to be done without clear instructions on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment does not specify which part of the paper discusses the sparse reward problems or the experiments, making it weakly grounded. The comment is specific in its critique of the method\"s approach to sparse rewards, but without explicit references to sections or experiments, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim that the method does not address sparse reward problems effectively. The lack of supporting evidence or detailed analysis makes the claim difficult for the authors to address, rendering it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a critical question about the effectiveness of the proposed method in addressing sparse reward problems. It points out that the experiments do not provide sufficient support for this claim and suggests that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to reconsider their approach to addressing sparse reward problems. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might improve their method or experiments to better address this issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and if other methods, such as HMR and SPIN, have access to this data during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide clarification but are not given specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset, specifically whether it is used for training and if other methods like HMR and SPIN have access to it. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset\"s use and access by other methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the AH36M dataset, specifically whether it is used for training and if other methods like HMR and SPIN have access to it. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the use of the curated AH36M dataset, specifically whether it is used for training and if other methods, such as HMR and SPIN, have access to it during training for a fair comparison. This question highlights a potential issue with the experimental setup and fairness in comparisons, which is an important consideration for the authors to address. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their experimental design. While it identifies a relevant concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their final results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. This provides clear and concrete guidance on what action the authors should take to improve their draft. The comment also suggests comparing to specific approaches that have won the challenge, which adds a level of detail to the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leaderboard for the blind test set, providing a specific link. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely comparing results on the official leaderboard and referencing specific approaches that have been evaluated on this set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. The comment provides a logical reasoning by pointing out the importance of comparing results on the official leaderboard, especially since other approaches have been evaluated and improved upon. However, the comment could be strengthened by providing more specific examples or references to the approaches that have been evaluated on the blind test set. Overall, the claim is 4, as it provides a clear direction for improvement but lacks detailed examples or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out that the paper only compares results on a nonofficial test set or dev set for the captioning experiment. It suggests that the authors should compare their results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been evaluated and improved upon. This feedback is clear and constructive, offering a concrete path for the authors to enhance the validity and relevance of their results. By suggesting a comparison to specific approaches that have won the challenge, the comment provides a detailed and actionable suggestion for improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a need for clarification regarding the terms \"good,\" \"bad,\" and \"wrong\" explanations at line 248. It suggests that the authors should clarify these concepts before using them, which provides a direct and concrete action for the authors to take. The comment is explicit and specific, offering clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of needing clarification on the terms \"good,\" \"bad,\" and \"wrong\" explanations. The comment provides a clear direction for improvement by suggesting that the authors should clarify these concepts before using them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests that the paper should clarify the concepts of \"good,\" \"bad,\" and \"wrong\" explanations before using them. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by clarifying the meaning of \"wrong\" at line 248. It suggests that the authors should provide a clear explanation of what is meant by \"good,\" \"bad,\" and \"wrong\" explanations before using these terms. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and coherence of their draft. However, the comment could be more helpful if it offered additional suggestions on how to present this clarification or provided examples of how similar concepts have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The comment implies that the authors should conduct additional experiments to demonstrate the superiority of their method over the baseline and Mid Vision Feedback. However, it does not provide explicit instructions on how to conduct these experiments or what specific comparisons should be made. While the action is implicit, it is concrete in suggesting the need for additional experimental comparisons. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely, a comparison with the image classification result of Mid Vision Feedback (MVF). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by explaining that without these comparisons, it is not possible to prove that the schema searched by ELF is better than the schema in Mid Vision Feedback (MVF). This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the paper lacks a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a critical area for improvement that could strengthen the paper\"s claims and demonstrate the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what additional experiments could be included. Overall, the comment is 4 as it directs the authors to a key area for enhancing the experimental section of their paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand on this topic, but it lacks concrete details on what specific aspects to cover or how to present them. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspectives of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more depth and analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional data or analysis to include. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions\" in the paper. It suggests that more elaboration is needed to clarify this concept. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address the issue or what specific information should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions,\" providing a clear direction for the authors to elaborate on this concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the concept of \"state\" is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It questions whether \"elements\" is equivalent to \"states\" or \"actions,\" indicating a need for clarification. This feedback is 3 as it points out a specific area where the authors need to provide more detailed explanation to ensure clarity for the reader. However, the comment could be more helpful if it offered suggestions on how to clarify the concept or provided examples of how to differentiate between these terms. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for the comparison but may not be entirely sure of the specific metrics or methods to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this suggestion should be applied to, such as the results section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a particular comparison, but without clear grounding, it is challenging for the authors to implement the suggestion effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, it does not provide any reasoning or evidence to support why this comparison would be beneficial or how it would enhance the paper. The comment lacks specific examples or references to existing literature that would justify the suggestion. As a result, the claim is not verifiable, as it does not provide sufficient information for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an interesting comparison between the proposed scheme and baseline methods, specifically recommending the use of a Jaccard index. This feedback is 3 as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to implement this comparison or what specific aspects of the Jaccard index should be considered. While it points out a potential area for improvement, it does not fully address the authors\" needs for actionable feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what specific aspects need to be clarified or how the authors might improve the theoretical comparisons. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of unclear theoretical comparisons, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"Theoretical comparisons to adaptive learning of GPRGNN is not clear.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the comparisons are unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any suggestions or guidance on how the authors might improve this aspect of their paper. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 2, as it highlights a potential weakness but does not offer any actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of using only yes/no responses to measure object hallucination. It highlights a potential limitation where a \"yes\" response does not necessarily indicate that the model comprehends the object\"s presence, as it may still produce incorrect objects in other tasks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what alternative methods could be used to measure object hallucination. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of using yes/no responses to measure object hallucination, specifically noting that a \"yes\" response does not necessarily indicate comprehension of the object\"s presence. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in detailing the concern about the measurement method, but without explicit references to specific parts of the paper, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the sufficiency of using yes/no responses to measure object hallucination, suggesting that a \"yes\" response does not necessarily indicate comprehension of the object\"s presence. This claim is 3 as it provides a logical reasoning about the limitations of the measurement method. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a reasonable basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of using yes/no responses to measure object hallucination. It points out that a \"yes\" response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects in other tasks. This feedback is 3 as it highlights a potential limitation in the measurement approach, prompting the authors to consider alternative methods or more nuanced evaluations. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, it does not provide explicit guidance on what specific details should be included or how the authors should present the innovative aspects. The action is implicit and somewhat vague, as the authors can infer that they need to elaborate on the innovative parts but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a specific part of the paper. However, it does not specify which part of the paper discusses the FRM, making it weakly grounded. The comment suggests that the innovative aspects should be given in detail, which provides some level of specificity regarding what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not verifiable, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. While this feedback identifies a potential area for improvement by highlighting the need for more detailed explanation of the innovative aspects, it lacks specific guidance or suggestions on how the authors might enhance their explanation. The comment provides some insight into what the authors could focus on, but it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide specific guidance or suggestions on how the authors might improve this clarity or address the issue. The comment implies that the authors should clarify the relationship between these concepts, but it does not offer concrete steps or details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment provides some specificity by mentioning the lack of clarity, but without explicit references to sections or specific elements of the paper, it remains weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that this issue is due to poor clarity, which is a valid observation. However, the comment does not provide specific guidance or suggestions on how the authors might improve this clarity or address the issue. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors. While the comment implies that the authors should conduct these analyses, it does not provide specific guidance on how to approach these analyses or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include theoretical analyses or extensive experiments to understand why certain methods outperform others. It implies that the authors should investigate the reasons behind the performance of simple greedy selection and deterministic MLP predictors compared to more principled acquisition functions and robust probabilistic predictors. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include theoretical analyses or extensive experiments to understand why certain methods outperform others. It implies that the current empirical results are strong but lacks a deeper understanding of the reasons behind these results. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the simple greedy selection approach outperforms more principled acquisition functions or that deterministic MLP predictors outperform probabilistic predictors. This lack of detailed justification makes the claim 3, as the authors would need to conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that despite the strong empirical results of the proposed method, a more novel and interesting contribution could be made by conducting theoretical analyses or extensive experiments to understand why certain approaches outperform others. It highlights the lack of rigorous analyses in the paper, specifically mentioning the comparison between simple greedy selection and more principled acquisition functions, as well as the performance of deterministic MLP predictors versus probabilistic predictors. This feedback is clear and actionable, as it identifies areas for further investigation and improvement, providing the authors with a direction to enhance their work. However, it could be more helpful if it included specific suggestions on how to conduct these analyses or what aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the discussion of the \"kmax problem\" elsewhere. This request is clear and direct, providing the authors with a specific action to take: to provide a citation. The action is concrete, as it specifies exactly what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment asks for a citation regarding the discussion of the \"kmax problem\" elsewhere, implying that the authors should provide evidence or references to support this claim. However, it does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a citation but lacks grounding, as it does not identify the specific part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the absence of a citation for the \"kmax problem\" and requests a citation for its discussion elsewhere. This is a factual request for clarification or evidence, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment requests a citation for the discussion of the \"kmax problem\" elsewhere, indicating that the authors should provide evidence or references to support their claims. While this feedback is clear and actionable, it does not offer any additional insights or suggestions for improvement beyond the request for a citation. The comment is specific in its request but lacks depth and does not provide broader guidance on how to enhance the paper. Therefore, it is 3, as it directs the authors to a specific area for improvement but does not fully address their needs for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or details on what specific information should be included or how the authors should estimate the reliability of the model. As a result, the authors are left with an implicit action that is vague and lacks clarity, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This is a critical issue that needs to be addressed to ensure the validity and credibility of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap, such as suggesting additional experiments or analyses to validate the model\"s reliability. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues: forward referencing in the paper and the need for clearer explanations of contributions in the Introduction. It suggests that the material supporting the main contributions should be included in the main sections rather than the appendix. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues, such as specifying which sections should be revised or how to reorganize the content. The actions are implicit and somewhat vague, leaving the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as forward referencing and the need for clearer explanations of contributions, and suggests that material supporting the main contributions should be included in the main sections rather than the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in subsequent sections. It also suggests that the main contributions need to be written more clearly in the Introduction and that material supporting these contributions is in the appendix rather than the main sections. While the comment identifies specific issues, it lacks detailed examples or references to support the claims, making it 3. The authors would need to infer the exact sections and contributions being referred to, which could lead to confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: forward referencing and the need for clearer explanations of contributions in the Introduction. It points out that material is introduced without proper explanation and is later explained in subsequent sections, such as Figure 1. The comment also notes that the material supporting the main contributions is in the appendix rather than the main sections, specifically mentioning the deeprag algorithm and discussion on high concurrency. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper\"s structure and clarity. However, it could be more helpful if it offered suggestions on how to reorganize the content or provide more detailed explanations in the Introduction. Overall, the comment is 4, as it effectively directs the authors to address significant issues in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the presentation of results, specifically noting that Table 1 only shows results for the discriminative setting, while there are two test settings in visual dialog. The reviewer questions the absence of results for the generative setting, which is known to be less applicable in realworld applications. This comment implies that the authors should include results for the generative setting to provide a more comprehensive understanding of their work. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The suggestion is concrete in terms of what needs to be addressed, but the lack of explicit instruction makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of results for the generative setting, which is known to be less applicable in realworld applications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of results for the generative setting in Table 1, noting that the discriminative setting is less applicable in realworld applications. This claim is 3 as it provides a logical reasoning for why the generative setting results should be included. However, the comment lacks specific examples or references to support the claim that the discriminative setting is less applicable, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the presentation of results, noting that Table 1 only includes results for the discriminative setting, while there are two test settings in visual dialog. It questions the absence of results for the generative setting, which is known to be less applicable in realworld applications. This feedback is clear and actionable, as it prompts the authors to include results for the generative setting to provide a more comprehensive understanding of their work. However, the comment could be more helpful if it suggested how to present these results or why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional information or examples should be included to achieve this. The action is implicit and vague, as the authors are left to infer what specific steps to take without clear guidance on how to implement the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more convincing evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. This is a valid point, as the feasibility of such a query is crucial for the paper\"s credibility. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or what specific evidence or examples would be most effective. While it highlights an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, indicating that this aspect remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider to evaluate the approach\"s effectiveness across different language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the discussion or results sections, but without explicit mention, it is weakly grounded. The comment is specific in identifying the issue of unknown effectiveness across language families, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, suggesting that this aspect remains unknown. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant gap in the evaluation of the proposed approach, noting that its effectiveness for other language families remains unknown. This is a critical observation that could impact the generalizability and applicability of the work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or analyses to evaluate the approach across different language families. Without actionable advice, the comment provides a general insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about providing these descriptions. The action is implicit and somewhat vague, as the authors can infer that they need to add more detail but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, it does not specify which part of the paper this relates to, such as a particular section or table, making it weakly grounded. The comment is specific in its suggestion to improve the description of related works, but without clear references to specific works or sections, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, the comment does not specify which works are named but not described or how the current descriptions are insufficient. This lack of specific examples or detailed reasoning makes it difficult for the authors to understand and address the issue effectively. As a result, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the related work section. It suggests that while some related works are mentioned, their differences are not described in sufficient detail. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their related work discussion. However, the comment could be more helpful if it provided specific examples of works that need more detailed descriptions or suggestions on how to present these differences effectively. Overall, the comment is 4 as it guides the authors toward improving the quality of their related work section."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, but the article does not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at the PPP maps. This feedback is explicit and provides a clear action for the authors to take, which is to provide a detailed explanation of the PPP maps and their implications. The action is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It questions the lack of explicit explanation or understanding provided in the article regarding the type of understanding one reaches by looking at PPP maps. However, the comment does not specify which part of the paper discusses PPP metrics or maps, making it weakly grounded. The authors can infer that it relates to the sections discussing PPP effects, but the exact location is not clearly identified. The comment is specific in its request for an explicit explanation, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks, noting that the article does not provide an explicit explanation or understanding of this concept. The reviewer asks for clarification on what type of understanding is gained from looking at PPP maps. While the comment raises a valid point about the lack of explanation, it does not provide specific examples or references to support the claim that the explanation is missing. The reasoning is somewhat logical but lacks detailed evidence or examples, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of PPP metrics and their importance for understanding PPP effects in different tasks. It points out that while the authors mention the importance of these metrics, the article lacks an explicit explanation or understanding of what type of insight is gained from looking at PPP maps. This feedback is 3 as it highlights an area where the authors could provide more clarity and depth to their discussion. However, it does not offer specific suggestions or guidance on how to address this gap, leaving the authors with a general direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with stateoftheart methods like SpanBERT for spanrelated tasks, which affects the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific methods to compare or how to incorporate these comparisons into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with stateoftheart methods like SpanBERT for spanrelated tasks, which affects the credibility of the paper. However, it does not specify which part of the paper this issue is addressed in, such as the methodology or results sections. The authors can make an educated guess that it relates to the evaluation or comparison sections, but the comment lacks full grounding. It is specific in identifying the issue of lacking credibility due to the absence of comparisons, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with stateoftheart methods like SpanBERT for spanrelated tasks. However, the comment does not provide specific examples of these stateoftheart methods or detailed reasoning on why such comparisons are necessary. This lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these comparisons and potentially conduct additional research to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of comparisons with stateoftheart methods like SpanBERT for spanrelated tasks. This is a critical oversight that affects the credibility of the paper. However, the comment does not provide specific suggestions on which stateoftheart methods should be compared or how to incorporate these comparisons into the paper. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a key issue but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the results, specifically regarding the sublinearity of regret. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. The comment is purely a clarification question, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding sublinearity, prompting the authors to clarify whether the prediction error over the entire horizon T cannot be sublinear. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification regarding the interpretation of the results. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of the results regarding sublinearity, specifically asking if the prediction error over the entire horizon T cannot be sublinear. While it identifies a potential confusion in the paper, it does not provide any suggestions or guidance on how to address this issue or clarify the results. The comment is 3 as it points out a potential misunderstanding, but it lacks actionable feedback or detailed guidance for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which should be redrawn to better represent the forward prediction model. The comment also mentions that it was difficult to connect the text with the figure and equations. This feedback provides a clear and direct action for the authors to take: redraw Figure 2(b) to improve the clarity of the forwardprediction model representation. The action is explicit and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the forwardprediction model, and suggests that the figure should be redrawn to better represent the model. Additionally, it points out the difficulty in connecting the text with the figure and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, specifically mentioning Figure 2(b) as an example. The reviewer suggests that the figure should be redrawn to better represent the model. While the comment identifies a potential issue with the clarity of the model\"s representation, it lacks specific examples or detailed reasoning to support the claim. The suggestion to redraw the figure is a logical step, but without further elaboration, the comment remains 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, particularly in Figure 2(b), which is not well explained. It suggests that the figure should be redrawn to better represent the model, and it highlights the difficulty in connecting the text with the figure and equations. This feedback is clear and actionable, providing the authors with a direct suggestion to improve the presentation of their work. By addressing this issue, the authors can enhance the comprehensibility of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their training process. The suggestion to provide a stronger baseline is implicit and lacks concrete details on how to implement it. Therefore, the comment is 3, as it identifies a potential issue but does not provide clear instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment further suggests that this could be a significant factor contributing to the better performance of FP + RBI and recommends providing a stronger baseline to prove the usefulness of FP. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer implies that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this point and potentially provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This observation is relevant and could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. The comment suggests that the authors should provide a stronger baseline to prove the usefulness of FP, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to implement this baseline or what aspects of the training process should be improved. Overall, the comment is 4 as it highlights a critical area for improvement and offers a direction for further analysis, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the multiscale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. It implies that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the statement. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the multiscale statement and its benefits. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"multiscale statement\" in the paper, which implies that it is referring to a specific part of the paper where this statement is made. However, it does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in detailing the issue with the statement, explaining that the slow and fast RNNs operate on a logical time scale rather than a physical one, and suggesting that the only benefit is the reduction of the gradient path. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical explanation for this claim, suggesting that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reviewer\"s reasoning and potentially provide additional context or evidence to fully address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement in the paper, suggesting that it might be misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, which could lead to confusion. This feedback is 3 as it points out a specific area where the authors might need to clarify their statement. However, the comment could be more helpful if it provided suggestions on how to rephrase the statement or offered additional context to clarify the distinction between logical and physical time scales. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the weakness of the baseline methods and the lack of discussion on limitations. It also suggests that the authors should discuss the similarity and difference between their work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their baseline methods, discuss limitations, and explore the generalizability of their results, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, noting that they are weak and not stateoftheart, and lacks discussion on limitations. It also suggests discussing the similarity and difference between the work and reinforcement learning in the conclusion, along with the generalizability of the results to RL settings. While the comment does not explicitly mention a specific section, it implies that the discussion on baseline methods and limitations is relevant. The authors can infer that this relates to the introduction or discussion sections, providing some level of grounding. However, the comment is specific in detailing what needs to be addressed, such as discussing limitations and the comparison with reinforcement learning. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests that the paper lacks a discussion on limitations. It also questions the difference between the work and reinforcement learning, suggesting a discussion on similarity and difference in the conclusion. However, the comment does not provide specific examples or references to support the claim about the baseline methods being weak or outdated. Additionally, it lacks detailed reasoning or evidence to substantiate the suggestion for discussing limitations and the comparison with reinforcement learning. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or detailed justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not stateoftheart, which is a critical issue that needs to be addressed. Additionally, it notes the lack of discussion on limitations, which is essential for providing a comprehensive understanding of the work. The comment also suggests discussing the similarity and difference between the work and reinforcement learning, as well as the generalizability of the results to RL settings. These suggestions are clear and actionable, providing the authors with specific directions to enhance their draft. However, the comment could be more helpful if it offered examples or specific references to support the claims or suggestions. Overall, the feedback is 4 as it guides the authors toward significant improvements in their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the definition of $e_l$ in Eq. (3) and points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also mentions that the performance is getting worse than standard random features, as shown in Figure 1, which may indicate a weakness in the proposed approaches. While the comment identifies areas that need clarification or further investigation, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of $e_l$ and investigate the implications of the exponential dependence on $M$. However, the lack of specific guidance on how to address these points makes the comment 3. Therefore, this comment is rated as a 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3),\" \"Corollaries 1, 2, and 3,\" and \"Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the exponential dependence on the diameter $M$ of the domain of data and its impact on the required feature size. Additionally, it references Figure 1 to support the claim that the performance is getting worse than standard random features. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for clarification of $e_l$ in Eq. (3) and the observation that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also suggests that this dependence affects the constant factor of the required feature size and references Figure 1 to support the claim that the performance is worse than standard random features. While the comment provides some logical reasoning and references a figure, it lacks specific examples or detailed explanations to fully substantiate the claims. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed evidence to be fully convincing. This aligns with a score of 3.", "helpfulness_rationale": "The review comment raises several points that are relevant to the authors. It questions the definition of $e_l$ in Eq. (3), which is a clear and specific request for clarification. Additionally, it points out the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, and Theorem 4, which could impact the required feature size. The comment also references Figure 1 to illustrate that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. While the comment identifies important areas for clarification and improvement, it could be more helpful by providing specific suggestions on how to address these issues or by offering alternative approaches to mitigate the exponential dependence. Overall, the comment is 4 as it directs the authors to critical areas that need attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues in their draft. While it points out areas for consideration, it lacks actionable steps or concrete recommendations for improvement. As a result, the authors are left with a general understanding of the potential issues but without clear direction on how to address them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential issues. It also suggests that oversmoothing could be another factor, referencing a specific paper for further context. However, the comment does not specify which part of the paper discusses DGNs or their modeling abilities, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issues with DGNs, such as oversquashing and oversmoothing, and provides a reference for further exploration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the poor longrange modeling ability of DGNs could be due to oversquashing and vanishing/exploding gradients, and also mentions oversmoothing as another potential factor. The claim is supported by a reference to a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a basis for the suggestion. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. This feedback is 3 as it points out a specific area for improvement and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on how to incorporate the referenced paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not provide specific guidance or suggestions on how to clarify the formulation. The authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. Without explicit instructions or concrete examples, the authors cannot effectively address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not specify which specific examples or sections of the paper are causing the confusion. This makes it difficult for the authors to pinpoint the exact parts that need clarification. The comment lacks grounding as it does not identify a specific part of the paper, and it is also not specific about what aspects of the formulation are unclear. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is \"somewhat unclear\" in the statement and introduction examples. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in both the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 2, as it highlights a problem but does not offer any direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides specific models for the authors to consider, making it 5. The authors know exactly what experiments to conduct to improve their draft, and the suggestion is concrete in its guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion should be implemented in, making it weakly grounded. The comment is specific in suggesting the types of experiments that could be conducted, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. The claim is based on the assumption that conducting such experiments would provide valuable insights into the method\"s applicability and generalizability. However, the comment does not provide specific examples or references to support why these experiments are necessary or how they would enhance the paper. The reasoning is somewhat logical but lacks detailed justification or evidence, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the lack of experiments on different LLM families, such as OPT, BLOOM, or other alternatives. It suggests conducting trials with these models to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to a specific area for improvement that could enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4, as it offers a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer suggests that the connection between these two parts is weak and that their initial expectation of the approach was not met. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen the connection between these parts or clarify their approach. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the connection between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it weakly grounded. The comment is specific in detailing the reviewer\"s initial expectation and how it was not met, providing some guidance on what might be missing or unclear. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE parts are weak. However, it does not provide specific examples or detailed reasoning to support this claim. The comment mentions an initial expectation that was not met, but it lacks concrete evidence or references to substantiate the claim. This makes the comment barely verifiable, as the authors would need to infer the basis of the claim and potentially seek additional information to fully understand the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer shares their initial expectation of the approach, which was not fully met, suggesting that the connection between these parts is weak. However, the comment lacks specificity and actionable guidance on how the authors might strengthen this connection or clarify their approach. Without detailed suggestions or examples, the feedback provides limited value to the authors in terms of improving their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization combined with the SOTA heuristic solver (Concorde) for a better comparison, given that the Pareto front is not highly nonconvex. This is an explicit action with concrete details on how to implement it, as it specifies the exact results that should be included for a more comprehensive comparison. The authors know exactly what needs to be done to enhance their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Competitive Baselines\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the experimental results, noting that the learningbased solvers are better than the heuristicbased solvers but that the SOTA heuristic solver (Concorde) usually performs best for the singleobjective TSP. The comment further specifies that the results for linear scalarization combined with Concorde should be included for a better comparison, given the nonconvexity of the Pareto front. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers based on the experimental results. However, it also notes that for the singleobjective TSP, the SOTA heuristic solver (Concorde) usually performs best. The comment suggests including the results for linear scalarization combined with Concorde for a better comparison, given the nonconvexity of the Pareto front. While the claim about the performance of learningbased versus heuristic solvers is supported by the experimental results, the suggestion to include additional results is logical and provides a clear direction for improvement. However, the comment could be strengthened by providing specific examples or references to support the claim about Concorde\"s performance. Therefore, the comment is 4, as it provides a solid basis for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment provides a specific observation about the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers but that the SOTA heuristic solver (Concorde) typically achieves the best results for the singleobjective TSP. It suggests that including the results for linear scalarization combined with Concorde would enhance the comparison, given the nonconvexity of the Pareto front. This feedback is clear and actionable, offering a concrete suggestion for improving the draft by providing a more comprehensive comparison. However, it could be more helpful if it included additional context or examples to further clarify the importance of this comparison. Overall, the comment is 4 as it provides valuable guidance for enhancing the experimental section of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that while the proposed method is grounded in neuroscience, some of its general ideas are already present in other methods for exploration. It specifically mentions methods that use the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, as well as curiositydriven exploration. The comment suggests that the paper should discuss the proposed method in relation to these existing methods. While the action is implicit, as it does not explicitly instruct the authors to include a discussion, it is concrete in suggesting specific methods to compare with. The authors can infer that they need to discuss the novelty and differentiation of their method from existing approaches. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and references specific methods such as the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, which are discussed in the graphbased SLAM appendix section. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: a discussion of the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas in the proposed method are already present in other methods for exploration, such as reasoning topologically using generalized Voronoi graphs or semantic maps, and longterm storage through pose graphs in SLAM. The reviewer provides specific examples and references to existing methods, which supports the claim. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies. Overall, the claim is 4, as it offers a clear rationale and examples, but lacks comprehensive references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the proposed method, noting that some of its general ideas are already present in other methods for exploration. It specifically mentions methods that use the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, as well as curiositydriven exploration. The comment suggests that the paper should discuss the proposed method in relation to these existing methods, which could help clarify its novelty and contributions. While the comment highlights an important area for improvement, it could be more helpful by providing specific guidance on how to structure this discussion or what aspects to focus on. Overall, the feedback is 3 as it points out a critical area for enhancement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about considering finer grouping for quantization instead of pertensor and perchannel approaches. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what specific actions they should take. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure discussing quantization methods. Without explicit references or context, the authors may find it challenging to determine where this comment should be addressed. The comment is specific in its questioning of the quantization approach but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point is a question asking for justification or explanation regarding the choice of quantization approach. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. While it identifies a potential area for improvement, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable advice or insights that would help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on performance and provides an example of how the performance varies with different ratios of unseen classes. This feedback is explicit and concrete, as it clearly instructs the authors to investigate a specific aspect of their work and provides a concrete example of what to consider. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on performance and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion should be addressed in, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a particular area for investigation, but without clear grounding, it is challenging for the authors to know where to make the changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the impact of the ratio of unseen classes on performance should be studied. It provides an example of how performance varies with different ratios of unseen classes, which is a logical and specific suggestion. However, the comment lacks detailed reasoning or references to support why this aspect is important or how it relates to the broader context of the paper. While the suggestion is clear, the lack of additional justification or evidence makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific area for further investigation, namely the impact of the ratio of unseen classes on performance. It provides an example of how the performance varies with different ratios of unseen classes, which is a clear and actionable suggestion. This feedback is valuable as it directs the authors to a potentially significant aspect of their work that could be explored in more depth, potentially leading to a more comprehensive understanding of their results. However, the comment could be more helpful if it offered additional guidance on how to approach this investigation or what specific metrics or analyses might be relevant. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. While it highlights a potential inconsistency or choice in the methodology, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should clarify or justify their choice of architectures. However, the comment lacks concrete details on how to execute this action, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this choice is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed in terms of the choice of architectures. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or how it affects the results. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. This question highlights a potential inconsistency or choice in the methodology that could impact the effectiveness of the approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify their choice of architectures. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider their methodology but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper\"s theory is not applicable to the used model, which is not explicitly mentioned in the limitations section. It also points out the vagueness of \"structural assumptions\" that are only provided in the appendix, making it difficult to identify the theoretical limitation. The reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitations and provide additional discussion on societal impact. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the theory\"s inapplicability to the used model and the vagueness of \"structural assumptions\" provided in the appendix. Additionally, the comment suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s theory is not applicable to the used model and that this limitation is not honestly mentioned in the limitations section. It also suggests that the authors underestimate the current use of graph neural networks in industry and should provide more elaboration on potential negative societal impacts. The comment provides some logical reasoning by pointing out the lack of mention of the theory\"s inapplicability and the vagueness of \"structural assumptions.\" However, it lacks specific examples or references to support the claim about the widespread use of graph neural networks or the potential negative societal impacts. This makes the claim 3, as it provides a basis for the argument but requires further evidence or details to be fully substantiated.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, specifically addressing the applicability of the theory to the used model and the lack of mention of this limitation in the limitations section. It also points out the vagueness of \"structural assumptions\" provided in the appendix, which makes it difficult to identify the theoretical limitation. Additionally, the reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. This feedback is actionable and provides clear guidance on areas for improvement, such as clarifying the limitations and expanding the discussion on societal impact. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of potential negative impacts. Overall, the comment is 4, as it effectively identifies areas for improvement and provides direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, it does not provide explicit guidance or suggestions on how the authors should clarify or address this point in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the use of epsilongreedy exploration. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, indicating that the authors should clarify whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, the comment does not provide any supporting evidence, reasoning, or references to clarify the confusion or justify the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be addressed. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide a clear answer or guidance on how to address this issue. The comment implies that the authors should clarify this aspect, but it lacks explicit instructions or concrete steps on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for a clear discussion on the use of CLIP, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to related work, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work, implying that this aspect could be a key contribution. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the discussion should be clarified. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or whether the authors should consider alternative approaches or modifications. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the applicability of the proposed methodology, specifically mentioning dynamic precision control during training and its potential limitations on bitserial accelerators. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment provides some insight into the potential implications of the methodology but lacks specificity in terms of what needs to be addressed or how the authors might improve their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. The comment provides a logical reasoning by contrasting the proposed methodology with the more commonly used bitparallel fixedpoint numbers in existing ML accelerators. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this point and potentially conduct further analysis or provide additional context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the proposed methodology, specifically questioning whether dynamic precision control during training would only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. This observation highlights a potential limitation of the proposed approach and encourages the authors to consider the broader implications of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. While it identifies a relevant area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. While the comment highlights specific issues with the analysis, it does not provide explicit guidance on how the authors should address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors can infer that they need to address the issues raised but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 45\" and \"Fig1(b) v.s. Fig5(b) for Block.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis of vit quantification, including the claim that the proposed approach does not improve the information distortion phenomenon and that the quantization of MHSA introduces a large loss of precision. The comment provides specific examples and references to external works, such as QBERT and BinaryBERT, to support its claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification is incomplete and that the proposed approach does not improve the information distortion phenomenon. It provides specific examples from the paper, such as the comparison of values in Fig1(b) and Fig5(b) for Block.3, to support this claim. Additionally, it references external works in the NLP field, like QBERT and BinaryBERT, to demonstrate that the issue of quantization loss of precision is not unique to the ViT model. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. This feedback is valuable as it highlights specific areas where the analysis could be improved and provides concrete examples to support the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues or improve their analysis. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes the use of a variant of STN in PointNet. While the comment points out the lack of novelty and comparisons, it does not provide explicit guidance on how the authors should address these issues or suggest specific comparisons to include. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the novelty and include comparisons, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a main weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It provides specific examples of existing works that apply STN in a local pixel neighborhood and mentions PointNet using a variant of STN. However, the comment does not explicitly mention which part of the paper discusses the proposed Xtransformation or the comparisons to STN, making it weakly grounded. The comment is specific in detailing the issue with the lack of novelty and comparisons, but without explicit references to specific sections, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that the proposed Xtransformation is similar to STN but applied locally. It also mentions existing works that apply STN in a local pixel neighborhood and PointNet using a variant of STN. While the comment provides some context and references to existing works, it lacks specific examples or detailed comparisons to substantiate the claim of limited novelty. The reasoning is 3 as it highlights the similarity to existing works, but it could be strengthened with more detailed comparisons or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes the use of a variant of STN in PointNet, further emphasizing the limited novelty of the work. The comment also points out the absence of empirical or conceptual comparisons to STN, which is crucial for evaluating the work. While the comment effectively identifies areas for improvement, it could be more helpful by suggesting specific comparisons or experiments that the authors could conduct to enhance the novelty and relevance of their work. Overall, the feedback is 4 as it provides clear guidance on areas needing improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two explicit actions: correcting a typographical error (\"Fig.7\" to \"Fig.12\") in the supplementary material and attaching theorems and corollaries in the main paper to their corresponding proof links. These actions are clear and concrete, providing the authors with direct guidance on how to improve their draft. Additionally, the comment suggests addressing concerns related to motivation, methodology soundness, and experiment persuasion, which are also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the typo (\"Fig.7\" should be \"Fig.12\") and provides a clear suggestion to attach theorems and corollaries to their corresponding proof links. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, providing specific feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as correcting a typographical error and attaching theorems and corollaries to their corresponding proof links. It also provides an overall assessment of the paper, noting its novelty, theoretical guarantees, and empirical results. However, the comment does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a typographical error in the supplementary material and suggesting that theorems and corollaries in the main paper should be linked to their corresponding proofs. This feedback is clear and directly guides the authors on how to improve the readability and clarity of their work. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, which are important aspects of the paper. However, the comment could be more helpful if it provided more detailed suggestions or examples for addressing these concerns. Overall, the feedback is 4 as it offers concrete steps for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential area for improvement in the proposed invariant learning module, specifically suggesting that the feature selection could be enhanced by considering representation learning. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The authors are left to infer that they should explore incorporating representation learning into the feature selection process, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the feature selection in Section 4.2 could be improved by considering representation learning, as discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions the discussion about representation learning in the appendix but does not elaborate on how this relates to the feature selection in Section 4.2. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support for the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the proposed invariant learning module, specifically focusing on the feature selection aspect. It points out that the feature selection could be further enhanced by considering representation learning, as discussed in the appendix. This feedback is clear and actionable, as it suggests a specific direction for the authors to explore in order to improve their work. However, the comment could be more helpful if it provided additional guidance or examples on how to incorporate representation learning into the feature selection process. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the draft, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details are missing, specifically mentioning that the design of rewards is not fully understandable. However, it does not provide explicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors to infer that they need to provide more information about the reward design. Since the action is implicit and vague, the authors may struggle to determine exactly what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically referencing the design of rewards, which is not fully understandable. However, it does not specify which part of the paper discusses the reward design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the missing details but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any specific details or examples of what is missing or how the design of rewards is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1 as it lacks sufficient evidence or justification to support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where details are missing, namely the design of rewards. It highlights a particular aspect that needs clarification, which is the lack of understanding regarding how rewards are designed. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific details should be included to improve the clarity of the reward design. While it points out a weakness, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. It suggests that the experimental design is good but criticizes the lack of code release, which could be a significant issue if not addressed. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting the release of code or providing alternative solutions. The action is implicit and somewhat vague, as the authors are left to infer that they should consider releasing their code to improve the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and experimental design of the paper, specifically mentioning the incremental improvement over KNN based MT approaches. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the lack of novelty and the importance of code release, but it is 1 as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. The reviewer acknowledges that the experimental design is good but criticizes the lack of code release, which could be a significant issue. However, the comment does not provide specific examples or references to support the claim of incremental improvement or the importance of code release. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. It highlights the importance of experimental design but criticizes the lack of code release, which could be a significant issue if not addressed. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve the novelty of their work. While it identifies areas for improvement, the feedback lacks depth and actionable advice, making it 3. The authors gain some insight into the need for code release and the importance of novelty, but the comment could be more comprehensive and constructive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for MLbased emulators. While the comment implies that the authors should include a discussion on runtime, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss runtime and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for MLbased emulators. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion of Prithvi WxC, which should be identifiable by the authors. The comment is specific in suggesting that the runtime should be discussed as a limitation. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count, which might be a limitation for applications where computational cheapness is a selling point for MLbased emulators. This claim is 3 as it provides a logical reasoning based on the characteristics of Prithvi WxC. However, the comment lacks specific examples or references to support the claim about the runtime being a limitation. Therefore, it is rated as 3, as it provides a reasonable basis for the suggestion but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential limitation of Prithvi WxC, which is its large parameter count, and suggests that the runtime should be discussed as a limitation for applications where computational cheapness is a selling point for MLbased emulators. This feedback is 3 as it points out an area that could be explored further in the paper, providing the authors with a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to discuss the runtime or its implications. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper \"oversells\" the method, which makes the contribution less clear. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to revise their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper \"oversells\" the method, making the contribution less clear. However, it does not specify which part of the paper this issue pertains to, such as a particular section or claim. Without explicit references or detailed examples, the authors cannot confidently determine where in the paper this critique applies. Additionally, the comment lacks specificity regarding what aspects of the contribution are unclear or how the method is being oversold. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper \"oversells\" the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper may be overstating its contributions, which could make the contribution less clear. However, it does not provide specific examples or details on how the paper is overselling the method or what aspects need clarification. Without actionable guidance or detailed feedback, the authors are left without a clear understanding of how to address this issue. The comment identifies a potential problem but lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to break down the generative process into more detailed steps and simplify the notation, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps and reducing the use of symbols and notation tables. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestions for improvement, but without clear grounding, it is challenging for the authors to implement the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, the comment does not provide specific examples or detailed reasoning to support why these changes would enhance understanding. The lack of concrete evidence or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the model description. It suggests that the generative process could be better understood if presented in separate steps and that the use of symbols and notation tables should be minimized. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the clarity and readability of the model description. However, the comment could be more helpful if it included specific examples or guidance on how to present the generative process in a more detailed and accessible manner. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further testing and determine the specific models to use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting additional experiments, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be tested on nonLLMbased models like HiTeA and InternVideo to verify its universality. The claim is 3 as it provides a logical reasoning for the suggestion, implying that the current application to LLMbased models may not fully demonstrate the framework\"s capabilities. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. This feedback is clear and actionable, as it identifies a potential limitation in the current application of the framework and provides specific models for further testing. By addressing this suggestion, the authors can enhance the robustness and generalizability of their work, making the comment 5. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the writing could be improved, as it took the reviewer a significant amount of effort to understand the main idea and the theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The comment lacks concrete details or suggestions for the authors to follow, leaving them without a clear understanding of what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, as it took the reviewer a lot of effort to understand the main idea and the theoretical analysis. However, it does not specify which parts of the paper are unclear or need improvement, making it difficult for the authors to pinpoint the exact areas that require attention. The comment lacks grounding as it does not identify specific sections or elements of the paper being addressed. Additionally, it is not specific about what aspects of the writing need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, as it took the reviewer a lot of effort to understand the main idea and the theoretical analysis. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to identify and address the issues. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing could be improved, as it took the reviewer a significant amount of effort to understand the main idea and the theoretical analysis. However, it does not provide specific guidance or suggestions on how to enhance the clarity or structure of the paper. Without actionable feedback or detailed recommendations, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, the comment is 1, as it lacks actionable insights or constructive suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the proposed method\"s lack of theoretical novelty, as it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific aspects of the method need improvement. The action is implicit and vague, leaving the authors uncertain about how to respond effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific existing methods, such as ClopperPearson intervals and Gaussian elimination, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the lack of theoretical novelty, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer supports this claim by referencing specific existing methods, such as ClopperPearson intervals and Gaussian elimination, which are wellestablished in the literature. The inclusion of these references provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method relies on these existing methods. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the lack of theoretical novelty in the proposed method, which primarily builds upon existing methods like ClopperPearson intervals and Gaussian elimination. While the comment identifies a potential weakness, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the theoretical contribution of their work. The mention of references to existing methods is helpful in framing the critique, but the comment lacks actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific sentence in the abstract (lines 1217) as being cumbersome and suggests that it can be made clearer. While the comment implies that the authors should revise this sentence, it does not provide explicit guidance on how to improve it. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the sentence for clarity. However, the comment does point out a specific area that needs attention, which is a step towards actionability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the sentence in lines 1217 of the abstract. It also specifies the issue, which is that the sentence is cumbersome and can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 of the abstract is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that a particular sentence is cumbersome and could be clarified. While it points out a potential area for improvement, it lacks detailed guidance or suggestions on how to rephrase the sentence for better clarity. The comment provides some direction by indicating that the sentence is problematic, but it does not offer specific advice or examples to help the authors improve it. As a result, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or specific suggestions for further investigation. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the tradeoff for baselines and potentially explore hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple Kang et al. and that the tradeoff between head and tail categories has not been fully investigated for the baselines. The comment suggests that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, as shown in Table 3. It also suggests that the tradeoff between head and tail categories has not been fully investigated for the baselines, implying that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The claim is supported by the reference to specific results in Table 3 and the logical reasoning provided about the potential impact of hyperparameter changes on the baselines. However, the comment could be strengthened by providing more detailed examples or references to substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a significant weakness in the paper and provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to explore the tradeoff for baselines. Overall, the comment is 4 as it directs the authors to a critical area needing further investigation and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation, noting that it is mostly based on 4 OCR QA datasets and suggests that this may lead to unreliable results. It further recommends including more scenarios, such as the LLaVA benchmark, especially in ablation studies. While the comment identifies a specific issue and suggests a potential solution, it does not provide explicit instructions on how to implement these changes. The authors can infer that they need to expand their evaluation to include more diverse datasets, but the comment lacks concrete guidance on which datasets to use or how to integrate them into the ablation studies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is mostly based on 4 OCR QA datasets, and suggests that this may lead to unreliable results. The comment further recommends including more scenarios, such as the LLaVA benchmark, especially in ablation studies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that this may lead to unreliable results. The comment references Figure 4(5), where the authors admit to this limitation. However, it does not provide specific examples or detailed reasoning to support the claim that more scenarios like the LLaVA benchmark are necessary. While the comment highlights a potential issue, it lacks sufficient evidence or detailed justification to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, noting that it is primarily based on 4 OCR QA datasets. It acknowledges that the authors have already recognized this limitation in Figure 4(5) and suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for improving the robustness and reliability of the evaluation. However, the comment could be more helpful if it offered additional guidance on how to incorporate these additional scenarios or provided examples of how they might enhance the evaluation. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or simplify the tasks. The action is implicit and vague, as the authors are left to infer that they should consider alternative approaches but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the abstract visual reasoning tasks, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment raises concerns about the complexity and interpretability of the tasks, it does not provide specific suggestions or details on how to address these issues. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment lacks specific examples or references to support the claim that these tasks are overly difficult or confusing. Without detailed justification or evidence, the claim remains 3, as it provides a general critique but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. The reviewer also expresses confusion about the multiple rows and changing factors between frames, which they believe could lead to difficulties in interpreting the models\" learning patterns. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or simplify the tasks. While it identifies a potential issue, it does not provide actionable feedback, making it 3. The authors are left with a general understanding of the problem but without detailed advice on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic scenario. Additionally, it notes that the generation of authors is not realistic due to the use of averaged artificial tweets. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific changes to make the evaluation more realistic. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the realism of the evaluation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific details about the issues with the evaluation, such as the prompt requiring all structured elements for perspectives to be present in the generated tweets and the generation of authors not being realistic. This level of specificity helps the authors understand what needs to be addressed in their evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It provides specific examples, such as the prompt requiring all structured elements for perspectives to be present in the generated tweets and the use of averaged artificial tweets for author embeddings. These examples offer a clear rationale for why the evaluation might not be realistic, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, questioning the realism of the evaluated tweets. It provides detailed feedback by pointing out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be the most realistic scenario. Additionally, it critiques the generation of authors, noting that the use of averaged artificial tweets for author embeddings is not realistic. This feedback is clear and actionable, as it directs the authors to consider more realistic scenarios in their evaluation. However, the comment could be more helpful if it offered suggestions on how to enhance the realism of the evaluation or provided examples of more realistic approaches. Overall, the comment is 4, as it effectively guides the authors toward improving their evaluation methodology."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of essential visualization of intermediate processes and comparisons, but it does not provide specific guidance on how to address this issue. It does not suggest what kind of visualizations should be included or how the comparisons should be presented. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit mention, it is difficult to pinpoint the exact area needing attention. The comment is specific in identifying the need for visualization and comparisons but lacks grounding due to the lack of specific references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance their draft by including visualizations that could help readers better understand the intermediate steps and comparisons. However, the comment could be more helpful if it provided suggestions on what specific visualizations or comparisons would be most beneficial or how they could be effectively integrated into the paper. Despite this, the comment offers a valuable direction for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The comment lacks explicit instructions or concrete details on how to resolve the problem, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the expected counterfactual violating a condition stated in the definition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. This feedback is clear and actionable, as it points out a potential problem that needs to be addressed. However, it lacks further guidance or suggestions on how the authors might resolve this issue or what specific changes they should make to their draft. While it highlights a critical area for improvement, the comment could be more helpful if it provided additional context or advice on how to rectify the violation. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and detail."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. However, it does not provide explicit guidance or suggestions for the authors to address this issue. The comment implies that the authors should clarify the nature of these relations, but it lacks concrete steps or actions for them to take. As a result, the comment is vague and does not offer a clear path for the authors to improve their draft. Therefore, it is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. However, the comment does not provide any evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the question. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. This feedback is 3 as it prompts the authors to clarify the nature of these relations and potentially address any inconsistencies or misunderstandings. However, the comment lacks depth and does not provide specific guidance on how to address the issue or what additional information might be needed to clarify the matter. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides a critique of the output quality, stating that it is reasonable but not realistic compared to recent GAN works. It suggests that there is room for improvement in result quality, but it does not offer specific guidance or suggestions on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirements, which could be areas for improvement, but it does not provide concrete actions for the authors to take. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is room for improvement. However, it does not specify which part of the paper discusses the output quality, making it weakly grounded. The comment is specific in detailing the issues with the output quality, such as its lack of realism and the high hardware requirements, but it does not provide guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic compared to recent GAN works. It supports this claim by referencing the advancements in GAN works, which have shown improved quality in synthesized results. However, the comment lacks specific examples or references to these recent GAN works, making it 3. The authors would need to look into the literature to understand the basis of the comparison and the specific improvements that have been made. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critique of the output quality, noting that it is reasonable but not realistic compared to recent GAN works. It highlights the need for improvement in result quality, particularly in terms of realism. Additionally, the comment mentions the limited novelty, low resolution output, and high hardware requirements, which are valid concerns. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues or improve the output quality. While it identifies areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the authors\" decision not to extend the curve further. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The feedback is vague and lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels\" and \"CRM and Cross entropy,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific concerns about the use of subpar hyperparameters and the decision not to extend the curve further, which gives the authors clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the authors\" decision not to extend the curve further. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns. The lack of detailed reasoning or evidence renders the claims 3, as the authors would need to infer the issues from the general statements provided.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the authors\" decision not to extend the curve further, which could provide additional insights. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their approach. While it identifies potential issues, it does not provide actionable feedback or detailed recommendations for improvement. Therefore, the comment is 3, as it points out areas for consideration but does not fully support the authors in enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the small number of images (20) in the VioT dataset, which the reviewer feels is insufficient to validate the approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should collect more data, how to increase the dataset size, or any other potential solutions. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images (20) in each of the 4 categories, which the reviewer feels is insufficient to validate the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses a concern about the small number of images (20) in the VioT dataset, questioning its sufficiency for validating the approach. However, the comment lacks specific reasoning or evidence to support why 20 images are insufficient or how this impacts the validity of the approach. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a potential issue with the VioT dataset, specifically noting that only 20 images are provided for each of the 4 categories. The reviewer expresses a concern that this small number of images may not be sufficient to validate the approach. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or providing alternative methods for validation. Without actionable advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a specific and concrete action for the authors to take. This feedback provides clear guidance on what additional analysis could be beneficial for the paper, allowing the authors to know exactly what to do to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in its suggestion, but without clear grounding, the authors may struggle to identify where this change should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a claim requiring justification. However, the comment does not provide any reasoning or evidence to support why this study would be interesting or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the number of layers versus performance, which could provide valuable insights into the impact of layer depth on the model\"s performance. This is a specific and actionable suggestion that could help the authors improve their draft by offering a more detailed analysis of their results. However, the comment could be more helpful if it provided additional context or explanation for why this study would be beneficial or how it might address specific questions or concerns raised in the paper. Overall, the feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the difficulty in following the mathematical derivations, the need for more intuitive explanations, and the lack of figure captions and legends. It specifically mentions that Figure 1 and 2 did not contribute much to the understanding and suggests that the text had to be read multiple times. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more intuitive explanations, add figure captions, and clarify the legends. However, the lack of specific guidance on how to enhance the explanations or improve the figures makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (\"Fig. 1 and 2\") and provides detailed feedback on the need for more intuitive explanations of the mathematical derivations and additional explanations and legends for the figures. It also highlights the lack of contribution from these figures to the understanding of the paper. This level of detail allows the authors to accurately identify the parts of the paper that need revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions and legends, stating that they require additional explanations and that Figures 1 and 2 did not contribute much to the understanding. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references to similar works or standards further limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the difficulty in following the mathematical derivations and the need for more intuitive explanations. It also points out the lack of figure captions and legends, specifically mentioning that Figure 1 and 2 did not contribute much to the understanding. The comment provides actionable feedback by suggesting the need for additional explanations and legends, which could help the authors improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanations or provided examples of how to improve the figure captions. Overall, the feedback is 4 as it directs the authors to areas that require improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing that incorrect choices could negate any potential improvements from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a sensitivity analysis or provide more information on hyperparameter choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of empirical results to hyperparameter choices, which is an important issue for the paper. However, it does not specify which part of the paper this concern relates to, such as specific sections or results that need to be addressed. The authors can infer that it might relate to the experimental setup or results sections, but this is not explicitly stated. The comment is specific in its request for information on sensitivity to hyperparameter choices, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\"s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The suggestion to investigate this issue is logical, but without further elaboration, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of empirical results to hyperparameter choices, which is a crucial aspect of evaluating the robustness and reliability of the method. It highlights the potential impact of incorrect hyperparameter choices on the results, emphasizing the need for the authors to address this issue. The comment also expresses a willingness to reconsider the rating if this issue is resolved, providing a clear incentive for the authors to address the concern. However, the comment could be more helpful if it offered specific suggestions or guidance on how to conduct the sensitivity analysis or address the issue. Overall, the comment is 4 as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, as it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. While the comment implies that the authors should address the lack of novelty, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer justification for the novelty of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and contribution of the proposed method, suggesting that it is similar to using the transferability of adversarial examples directly and that the authors need to further claim the novelty of their work. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the authors discuss their method. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique of the novelty and contribution, but it is 1, as it does not provide a clear reference to the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that it is similar to using the transferability of adversarial examples directly. The reviewer implies that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim that the work is similar to existing methods. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. This feedback is 3 as it points out a gap in the paper\"s claims regarding originality and contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. To be more helpful, the comment could provide examples of how other works have addressed similar issues or suggest ways to differentiate the proposed method. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point consists of multiple separate issues, each of which is explicit and concrete. The first point explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to take. The second point identifies a missing gradient symbol in Algorithm 1, line 4, which is also a direct and concrete action for the authors to correct. The third point references specific papers for further reading, which is an explicit suggestion for the authors to consider. Each of these points provides clear and actionable steps for the authors to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" \"Algorithm 1,\" and specific references, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1, the missing gradient symbol in Algorithm 1, and provides references for further reading. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple factual statements and references, which are verifiable through the provided references. The claim about the text size in Table 1 being too small and hard to read is supported by the explicit mention of the issue. The reference to missing symbols in Algorithm 1 and the references to specific papers for further reading provide additional evidence. However, the comment does not include any subjective claims or opinions that require justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing multiple issues in the paper. It points out that the text in Table 1 is too small and hard to read, which is a clear and tangible issue that the authors can easily address. Additionally, it identifies a missing gradient symbol in Algorithm 1, line 4, which is a straightforward correction to make. The comment also references specific papers for further reading, offering additional context and resources for the authors. This level of detail and specificity makes the comment 5, as it provides the authors with clear guidance on how to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It also points out that the algorithm requires solving several LPs in high dimensions, which involves parameters that are not easily calculable. The comment suggests that the experiments are performed on very smallscale datasets, implying that this might be a limitation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the computational aspects of their work. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed discussions on computational aspects and potentially explore ways to make their methods more practical for high dimensions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It mentions that the algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. The comment also notes that the experiments are performed on very smallscale datasets. While the comment does not explicitly mention specific sections or parts of the paper, the authors can infer that it relates to the methodology and results sections, where computational aspects and experimental details are typically discussed. The comment is specific in detailing the issues with computational aspects and the limitations of the experiments, but it lacks full grounding as it does not explicitly reference these sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods in high dimensions. It highlights the requirement to solve several LPs in high dimensions, each involving a parameter that is not easily calculable, and notes that the experiments are performed on very smallscale datasets. While the comment provides some reasoning and observations, it lacks specific examples or references to support the claim about the computational aspects or the limitations of the experiments. The lack of detailed evidence or examples makes the claim 3, as the authors would need to delve deeper into the paper to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects, particularly in high dimensions. It points out that the proposed methods may not be practically useful due to the complexity of solving LPs in high dimensions, which involves parameters that are not easily calculable. The comment also notes that the experiments are conducted on very smallscale datasets, which may not be representative of realworld applications. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to provide more detailed discussions on computational aspects and potentially explore ways to make their methods more practical for high dimensions. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4, as it provides clear guidance on areas that need further exploration and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking about parameter sharing in the ResNet experiments and suggests a potentially interesting baseline for comparison. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be interesting or equivalent. The suggestion lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet experiments in section 7.1, asking whether the ResNet shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for exploration and suggests a specific direction for improvement. However, it lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. Therefore, the comment is rated as 3, as it offers some insight but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, stating that it does not \"ignore crossentity comparison\" as claimed. However, it acknowledges that the architecture \"attends to all candidates at once\" to obtain final matching scores. The comment highlights a potential issue with the motivation but does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their motivation without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison.\" However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this claim is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides some specificity by explaining the issue with the motivation, it does not offer detailed guidance on how to address it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture does not \"ignore crossentity comparison\" as stated, but instead \"attends to all candidates at once\" to obtain final matching scores. This claim is 3 as it provides a logical reasoning for the discrepancy between the claimed and actual behavior of the architecture. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the motivation behind the crossencoder architecture, pointing out that it does not \"ignore crossentity comparison\" as claimed. Instead, it \"attends to all candidates at once\" to obtain final matching scores. This critique highlights a potential misrepresentation of the architecture\"s capabilities, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or improve the motivation, leaving the authors with a clear issue to address but without detailed steps to take. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth in its feedback."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should reconsider their design choice. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and does not incur significant computational costs for longer sequences. This provides clear guidance on what aspect of the paper needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This claim is 3 as it provides a logical reasoning for questioning the design choice, but it lacks specific examples or references to support the assertion that trimming questions is unnecessary. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This feedback identifies a potential issue with the experimental design and provides a rationale for why the trimming might not be necessary. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or whether they should reconsider their design choice. While it highlights a potential area for improvement, the feedback is incomplete and does not fully support the authors in making changes. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement, such as recommending more modern alternatives or suggesting ways to update the methods. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the models or methods are considered antiquated or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an \"antiquated\" GNN model and method, which negatively impacts the performance of the framework. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not offer any constructive feedback or direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be needed to extract shared motifs, implying that the authors should clarify or address this issue. While the comment identifies a potential problem, it does not provide explicit instructions on how to resolve it or what specific steps the authors should take. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the explanation process but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, questioning how the proposed method produces the type of explanation shown and suggesting that additional adhoc postanalysis might be necessary. The comment provides a clear direction for the authors to clarify or address this aspect of their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. The reviewer suggests that additional adhoc postanalysis might be necessary to extract shared motifs, implying that the proposed method may not fully address this need. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear or that additional analysis is required. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, questioning the clarity of how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, which could explain a set of instances. This feedback is clear and actionable, as it points out a potential weakness in the explanation process and suggests a possible solution. However, the comment could be more helpful if it provided specific guidance on how to improve the explanation or if it offered examples of how to implement the suggested postanalysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a concern with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the results. The reviewer suggests that the experiment could be strengthened in two ways, but does not specify what these ways are. While the comment implies that the authors should address the issues related to the use of pseudo feature importance and the perturbation value, it lacks explicit guidance on how to do so. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"One experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of pseudo feature importance and the reliance on Proposition 3.2 and a large enough perturbation value, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is problematic due to its reliance on Proposition 3.2 and the choice of a large enough perturbation value. However, the comment does not provide specific details or examples to support this claim, such as how the pseudo feature importance affects the results or how the perturbation value impacts the experiment. This lack of detailed justification makes the claim 3, as the authors would need to infer the potential issues and address them on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment that estimates the quality of uncertainty estimates, noting that it uses pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the results. The comment suggests that the experiment could be strengthened in two ways, implying that the authors should address these concerns. However, it does not provide detailed guidance on how to strengthen the experiment or what specific changes could be made. While the comment points out a critical issue, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to change two lines in red to green in the Supplemental Material. It provides specific line numbers and references to the Supplemental Material, making it clear and concrete. The authors know exactly what needs to be done to address the comment, which is to change the color of these lines. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplemental Material (SuppMat, L502, L507, and L509) and references to figures or tables (Table 4 and Algorithm 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the color of the lines from red to green. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding specific lines in the Supplemental Material that should be changed from red to green. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, pointing out a straightforward error in the formatting of the Supplemental Material. It provides precise instructions on which lines should be changed from red to green, allowing the authors to make a direct correction. This feedback is actionable and will help the authors improve the presentation of their work. However, it is limited in scope, as it only addresses a minor formatting issue and does not provide broader insights or suggestions for improving the content or structure of the paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but acknowledges that this is not feasible given the paper\"s short length. While the comment implies that the authors should consider a more extensive analysis, it does not provide specific guidance on how to achieve this or what aspects of the analysis should be expanded. The action is implicit and vague, leaving the authors without clear direction on how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper lacks this analysis or what specific aspects need more data. The authors cannot confidently determine which sections or elements of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on what a more comprehensive analysis would entail or how it could be achieved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but acknowledges that this is not feasible given the paper\"s short length. The comment provides a logical reasoning for the suggestion, noting that a more extensive analysis would enhance the paper\"s value. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the potential benefits of a more comprehensive analysis based on the reviewer\"s general statement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it acknowledges that this is not feasible given the paper\"s short length. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might achieve this more comprehensive analysis within the constraints of their paper. The feedback is 3 as it points out a potential enhancement but lacks actionable details to assist the authors in implementing the suggestion. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should cite works related to metalearning, even though they do not directly target continual learning. It also advises the authors to distinguish between different approaches in metalearning. Additionally, it recommends a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work, as it seems to be an application to continual learning. While the comment provides explicit actions, it lacks detailed guidance on how to implement these suggestions, such as specific examples of metalearning approaches to cite or how to effectively link the RL work to the current study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper connection to metalearning, which has several approaches that should be cited and distinguished. It also recommends a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work, as it seems to be an application to continual learning. However, the comment does not specify which parts of the paper should include these citations or links, making it weakly grounded. The authors can infer that it relates to the sections discussing related work or methodology, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in suggesting the need for citations and links, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that there is a deeper connection to metalearning, which has several approaches that should be cited and distinguished. It also recommends a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work, as it seems to be an application to continual learning. However, the comment lacks specific examples or references to support the claim about the connection to metalearning or the RL work. This makes the claim 3, as the authors would need to conduct further research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential connection between the work and metalearning, suggesting that the authors should explore and cite related approaches. It also recommends distinguishing between different metalearning approaches and more heavily linking the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. This feedback is 3 as it points out areas for expansion and clarification, but it lacks specific guidance on how to integrate these suggestions into the paper. The authors are given a general direction but need to figure out the details themselves, making the comment 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make the feedback more realistic. While the comment identifies a potential issue and suggests a possible solution, it does not provide explicit instructions on how to implement these suggestions. The action is mostly inferred, and the authors know what needs to be done, but the comment lacks concrete details on execution. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make the feedback more realistic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment where teacher feedback is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with the feedback, suggesting ways to improve it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. The reviewer questions whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make the feedback more realistic. This claim is 3 as it provides a logical reasoning for the potential issue with autogenerated feedback. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It raises a question about whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make the feedback more realistic. This feedback is 3 as it points out a potential weakness in the study and prompts the authors to consider improving the diversity of their feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this diversity. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not provide explicit instructions on how to achieve this clarification or what specific aspects of the results should be summarized. The action is implicit and somewhat vague, as the authors can infer that they need to add a summary of the supplementary experiments but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not specify which part of the paper this should be addressed in, such as a particular section or figure. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting what needs to be clarified and summarized, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not provide any specific examples, reasoning, or references to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should clarify the presence of additional experiments in the supplement and summarize their results. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their paper by including a summary of the supplementary experiments. However, the comment could be more helpful if it provided specific guidance on what aspects of the results should be highlighted or how to effectively integrate the supplementary material into the main text. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes should be made to support the claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of effectiveness, questioning whether the slight improvement supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why the slight improvement is insufficient to support the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts, citing the slight improvement observed in Table 6 and Table 7. While it identifies a potential issue with the claim, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"Cycle FC align features\" and suggests that the analysis is insufficient. It implies that the authors should consider different designs, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC align features, making it weakly grounded. The suggestion for additional analysis is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. However, the comment lacks specific examples or references to support the claim that the analysis is insufficient or to justify the need for additional experiments. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a potential weakness in the analysis of the Cycle FC align features, suggesting that the current analysis is insufficient. It proposes that the authors consider different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out an area for improvement and provides a specific suggestion for enhancing the analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of how different sampling intervals and sample sizes could impact the analysis. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. This feedback implies that the authors should include standard deviations to provide a clearer understanding of the results. However, it does not explicitly instruct the authors to add standard deviations or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not know exactly how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. However, it does not specify which part of the paper this issue pertains to, such as a particular table or figure where the results are presented. Without explicit references to specific sections or results, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique of the lack of standard deviations but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performances. This claim is 3 as it logically reasons that standard deviations are necessary for a comprehensive understanding of the results. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment points out a significant omission in the presentation of results, specifically the lack of standard deviations. This is a critical issue because it makes it difficult for the reader to understand the variability and reliability of the results. By highlighting this gap, the comment provides a clear and actionable suggestion for improvement, encouraging the authors to include standard deviations to enhance the clarity and robustness of their findings. However, the comment could be more helpful if it suggested specific ways to present the standard deviations or provided examples of how this would improve the paper. Overall, the feedback is 4 as it identifies a crucial area for improvement and guides the authors toward enhancing their results presentation."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dimensionality of each region and the feature extractor used, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on how to address the question or what information should be added to clarify this aspect of the paper. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the dimensionality of each region and the feature extractor used, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is a clear and actionable point for the authors to address. By asking for clarification on this aspect, the comment provides a direct way for the authors to improve their draft by ensuring that the information is accurate and complete. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context. Overall, the comment is 4 as it identifies a specific area for improvement and guides the authors toward enhancing their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which aspects of the computation, algorithm, or implementation should be detailed or how these details should be presented. The action is implicit and somewhat vague, as the authors are left to infer what specific information is needed and how to present it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what specific details should be provided or how they would enhance the paper. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks depth and justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what specific details should be included or how they should be presented. This makes it 3, as the authors gain insight into a potential enhancement but are left without detailed instructions on how to implement it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, implying that the authors should provide an explanation or justification for this selection. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the choice of p, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of how the value of p < 0.4 was chosen, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable point for the authors to address. By asking for an explanation of this choice, the reviewer prompts the authors to provide additional context or justification for their methodological decisions. This feedback is valuable as it directs the authors to clarify an important aspect of their work, potentially enhancing the transparency and comprehensibility of their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to address the question. Overall, the comment is 4, as it identifies a specific area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It provides specific references to support the suggestion for comparison, such as 1 and 2, which gives the authors concrete examples of methods to consider. This feedback is explicit and provides clear guidance on how to enhance the analysis and comparison in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lack of Analysis\" and refers to the insufficient analysis of the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, which provides specific guidance on what needs to be addressed. The comment is specific in detailing what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a \"lack of analysis\" regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to external works, such as 1 and 2, which supports the suggestion for comparison. However, the claim about the lack of analysis is not fully substantiated with specific examples or detailed reasoning, making it 3. The authors would need to delve deeper into the references to fully understand the context and implications of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of evaluation of the effectiveness of each data augmentation method. It provides a clear suggestion to compare the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, which would help clarify the unique advantages of the proposed method. The inclusion of specific references, like 1 and 2, offers concrete examples for the authors to consider. This feedback is actionable, detailed, and constructive, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider or investigate this aspect, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario, but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance are being questioned or how this might relate to the broader discussion. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of a specific model configuration. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting aspect of the model\"s behavior, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate it into their analysis. The comment identifies a potential area of exploration but does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. While the comment identifies a potential area of concern and raises a question, it does not provide explicit guidance or suggestions on how the authors might address this issue or conduct further research. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the scalability of RLCD to larger models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, and it raises a question about the scalability of RLCD to larger language models. This provides clear guidance on what needs to be addressed or explored further in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, as observed in Table 2. It also raises a question about the scalability of RLCD to larger language models. The comment provides some logical reasoning by pointing out the trend observed in the data, but it lacks specific examples or references to support the claim fully. Additionally, the question about scalability is more of an inquiry than a claim, as it does not make a definitive statement. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential limitation in the paper\"s findings and encourages the authors to consider the scalability of their approach. However, it lacks specific suggestions or guidance on how the authors might address this issue or conduct further research. While it provides some insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of quantitative analysis on computational gains, specifically mentioning the need for specific measurements or comparisons to substantiate the claimed benefits. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements in DQ V2. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, which allows the authors to identify the specific part of the paper being addressed. It also specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. This provides clear guidance on what needs to be addressed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the claimed computational benefits of replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. This claim is 3 as it highlights a gap in the paper\"s analysis but lacks specific examples or references to support the need for such quantitative analysis. The authors would need to consider this feedback and potentially include additional data or comparisons to strengthen their claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of quantitative analysis on computational gains. It highlights the need for specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNNbased data augmentation strategy. The comment provides a clear and actionable suggestion by recommending a quantitative analysis, such as GPU hours, memory usage, or training time, to strengthen the evidence of efficiency improvements in DQ V2. This feedback is valuable as it directs the authors to a critical aspect of their work that requires further development. However, it could be more helpful if it included examples or references to guide the authors in conducting the quantitative analysis. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or comparisons. The action is implicit and somewhat vague, as it lacks specific instructions on how to address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would affect its efficiency for certain scenes. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how to address the issue of efficiency. The authors might infer that it relates to the experimental results or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the method, suggesting that the time for COLMAP and scenebyscene finetuning should be considered. This is a relevant point that could impact the efficiency of the method for certain scenes. However, the comment lacks specificity and does not provide detailed guidance on how the authors should incorporate this consideration into their analysis or comparisons. Without actionable suggestions or examples, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the timing of the results presentation, suggesting that the authors should also report on the agent\"s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the learning process should be reported. The action is implicit and vague, leaving the authors to infer that they should include additional information about the learning process but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the timing of the results presentation, suggesting that the authors should also report on the agent\"s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or experiments, making it weakly grounded. The comment is specific in detailing the concern about the timing of results and the potential impact of the planning component, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the timing of the results presentation in the paper, suggesting that the authors should also report on the agent\"s behavior during the learning process. The reviewer speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. However, the comment is based on speculation and lacks specific evidence or references to support the claim. The reasoning is logical but not fully substantiated, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the timing of the results presentation in the paper, suggesting that the authors should also report on the agent\"s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. This feedback is 3 as it prompts the authors to consider additional aspects of their results, such as the agent\"s behavior during learning. However, the comment lacks specific suggestions or guidance on how to address this issue, which limits its usefulness. To be more helpful, the comment could include recommendations on what specific aspects of the learning process should be reported or how to analyze the early stages of training. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a subjective opinion that the contribution is marginal, suggesting that the methods used are welldesigned and demonstrated. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or address the perceived lack of novelty. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, suggesting that it is marginal because the methods used are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as a particular section or methodology. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. Additionally, the comment is specific in its critique of the contribution, but it does not provide detailed guidance on how to enhance the contribution or address the perceived lack of novelty. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the contribution is marginal, suggesting that the methods used are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion that the contribution of the paper is marginal, as the methods used are welldesigned and demonstrated. It suggests that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their contribution or address the perceived lack of novelty. Without actionable advice or detailed critique, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution and questions the motivation behind the PBSD component, given that the paper is primarily motivated by supervised contrastive learning (DSCL). It suggests that the performance gain is mostly attributed to PBSD, but it does not provide explicit guidance on how the authors should address this issue or clarify the contribution. The comment implies that the authors should provide additional motivation or explanation for the PBSD component, but it does not specify what kind of information or analysis would be helpful. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It references the ablation study to highlight the performance gain attributed to PBSD. However, the comment does not specify which part of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in its request for additional motivation for PBSD beyond improving discriminative representation on tail classes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). The reviewer points out that the performance gain is mostly attributed to PBSD, but the paper is mostly motivated by DSCL. The comment suggests that the authors should provide additional motivation for PBSD beyond improving discriminative representation on tail classes. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the motivation for PBSD is unclear. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It points out that the performance gain is mostly attributed to PBSD, but the paper is mostly motivated by DSCL. The comment suggests that the authors should provide additional motivation for PBSD beyond improving discriminative representation on tail classes. This feedback is 3 as it identifies a potential area of confusion and prompts the authors to clarify their contributions. However, it could be more helpful if it provided specific suggestions or examples of how to address this issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. While the comment highlights a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or address the issue but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which allows the authors to accurately identify the part of the paper being addressed, likely referring to a specific section or part of the manuscript. It is also specific because it questions whether the tester for the spread parameter immediately yields an (\u03f5, \u03b4)identity tester and provides an example of how it might not handle certain (\u03c0, \u03d5) pairs. This level of detail helps the authors understand what needs to be clarified or addressed in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This example is a logical deduction based on the information provided, but it does not include specific references or detailed reasoning to fully substantiate the claim. The comment is 3 as it provides a clear example of the issue but lacks comprehensive evidence or references to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the tester for the spread parameter, specifically whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This feedback is 3 as it identifies a potential issue with the tester and prompts the authors to clarify or address this concern. However, the comment lacks specific guidance or suggestions on how to resolve the issue, which limits its usefulness. To be more helpful, the comment could include recommendations or examples of how to improve the tester or address the specific scenario mentioned. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the distribution or what specific information should be included. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors may find it challenging to identify the exact area needing clarification. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it lacks depth and does not provide any guidance or suggestions on how the authors might clarify this aspect of their work. Without actionable feedback or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not explicitly instruct the authors to implement a selfsupervised approach or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for a different approach but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of the current approach. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion for a selfsupervised approach but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method requires annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples, references, or detailed reasoning to support why a selfsupervised approach would be more appealing or how it could be implemented. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the potential benefits of a selfsupervised approach based on general knowledge. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it points out a potential limitation and offers a suggestion for improvement. However, it lacks specific guidance on how to implement a selfsupervised approach or what benefits it might offer. The comment provides a direction for the authors to consider but does not fully address the need for detailed actionable steps. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that to fully demonstrate the scalability of LFF, the authors should conduct experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies the type of tasks that should be included, offering concrete guidance on how to enhance the demonstration of LFF\"s scalability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion should be addressed in, making it weakly grounded. The comment is specific in suggesting the types of tasks that should be included to demonstrate scalability, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, which is based on the common practice of evaluating continuous control experiments on simple tasks. However, the comment lacks specific examples or references to existing literature that have successfully applied LFF to such challenging tasks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It points out that most continuous control experiments are conducted on simple and lowdimensional tasks, such as cartpole or mountain car, and suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, like locomotion of ants or humanoids. This feedback is specific and offers a concrete direction for the authors to enhance the paper\"s scope and demonstrate the full potential of LFF. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for considering MULT as the only deep learningbased baseline that considers crosssensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or suggest alternative baselines. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific papers (MISA, M2FNet, and MMDFN) and references their publication years and venues. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it critiques the paper for considering MULT as the only deep learningbased baseline, noting that it was proposed in 2019 and is \"out of fashion.\" This provides clear guidance on what aspect of the paper needs improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is \"out of fashion.\" This claim is 3 as it provides a logical reasoning about the relevance of the baseline, but it lacks specific examples or references to support the assertion that MULT is outdated. The comment could be strengthened by including more detailed reasoning or references to recent works that supersede MULT. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for considering MULT as the only deep learningbased baseline that considers crosssensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" This feedback highlights a potential weakness in the paper\"s selection of baselines, suggesting that the authors should consider more recent or relevant works. However, the comment lacks specific suggestions or guidance on which alternative baselines or approaches the authors should consider. While it identifies an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It provides a clear action for the authors to take: they must compare the tensor completion results for all models with the same number of model parameters. The comment also suggests a method for computing the number of model parameters by adding the number of entries of all core tensors for each model. This feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the comparison against other models in the experiments, specifically the omission of value ranks for all models. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: comparing tensor completion results for all models with the same number of model parameters. The suggestion to compute the number of model parameters by adding the number of entries of all core tensors for each model provides concrete guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It suggests that to show the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models with the same number of model parameters. The comment provides a logical reasoning by explaining that the number of model parameters can be computed by adding the number of entries of all core tensors for each model. This reasoning is clear and provides a specific suggestion for improvement, making the claim 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models with the same number of model parameters. This feedback is highly valuable as it directs the authors to a specific area where the paper can be strengthened, offering a concrete step towards enhancing the draft. The comment also includes a suggestion for computing the number of model parameters, which further supports the authors in making the necessary adjustments. Overall, the comment is 5 as it provides detailed and actionable feedback that can significantly improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and a specific issue with Figure 4 regarding overlapping symbols. It also mentions minor textual issues. While the comment identifies several areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to clarify the normalization module, standardize pictograms, and resolve the issue with Figure 4, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the normalization module, figures, and a particular figure (Fig. 4), allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the normalization module, the need for standardization of pictograms, and the confusion in Figure 4. Additionally, it mentions minor textual issues, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several issues, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and a specific issue with Figure 4 regarding overlapping symbols. However, the comment does not provide detailed reasoning or evidence to support these claims, such as explaining how the normalization module differs or how the standardization of pictograms would improve the figures. Additionally, it mentions minor textual issues without specifying what those issues are. Without sufficient justification or examples, the claims are difficult for the authors to address, making the comment barely verifiable.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and a particular issue with Figure 4 regarding overlapping symbols. It also mentions minor textual issues. While the comment highlights these areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are given some direction but are left to infer the specific actions needed to resolve the problems. Therefore, the comment is 3, as it provides some insight into areas that need attention but could be more comprehensive in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning how the proposed algorithm removes subdivision splines and whether it incurs an extra computation cost. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should provide more detailed information about the algorithm and its computational costs. However, the comment lacks concrete details on how to implement this improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theoretical part\" of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue by questioning the detailed explanation of how the proposed algorithm removes subdivision splines and whether it incurs an extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the removal of subdivision splines and the potential extra computation cost for space partition building. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical part of the paper, questioning the authors\" claim about the removal of subdivision splines and the potential extra computation cost for space partition building. This feedback highlights a potential gap in the explanation of the proposed algorithm, prompting the authors to provide more detailed information about how the algorithm operates and its computational implications. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to clarify the theoretical part. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment implies that the authors should clarify whether 300WLP is used in all experiments or just some, and if so, how this affects the fairness of the comparison. While the comment identifies an issue, it does not explicitly instruct the authors to clarify this point, leaving the action implicit. The authors can infer that they need to provide more information about the experimental setup, but the comment lacks concrete guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the experimental methodology, specifically the use of the 300WLP dataset in training the model. It points out a potential inconsistency in the paper, where it is claimed that the same procedure is used as for the baselines, but most baselines do not use the 300WLP dataset. This provides clear guidance on what needs to be clarified or addressed in the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental methodology section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment provides a logical reasoning by highlighting the potential inconsistency in the experimental setup, but it lacks specific examples or references to support the claim. While the authors are given a direction to clarify the use of the 300WLP dataset, the comment could be strengthened with more detailed evidence or examples. Therefore, the claim is 3, as it provides a basis for the concern but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment raises a valid concern about the fairness of the comparison and prompts the authors to clarify whether 300WLP is used in all experiments or just some. This feedback is clear and actionable, as it directs the authors to address a specific methodological concern that could impact the validity of their results. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative approaches to ensure fairness. Overall, the comment is 4, as it effectively highlights a critical area for improvement in the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their techniques. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper these techniques are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these techniques are not novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of certain techniques used in the algorithm, such as computation offloading and gradient augmentation. However, it does not provide specific examples or detailed feedback on how these techniques could be improved or made more novel. Without actionable guidance or suggestions, the authors are left with a general indication of a potential problem but without a clear path forward for addressing it. This makes the comment 3, as it highlights an area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. While the comment implies that the authors should conduct an analysis, it does not specify what aspects of the analysis are missing or how to approach it. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this is not explicitly stated. The comment is specific in suggesting the need for an analysis, but without clear grounding, it is challenging for the authors to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance their work by providing a deeper understanding of the observed phenomenon. However, the comment could be more helpful if it offered guidance on how to approach this analysis or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or address the assumption, but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of iid data and how it affects the application of the theorems. The comment provides a detailed critique of the assumption and its implications, offering a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. The comment provides a logical reasoning by pointing out the potential issue with the assumption and its impact on the application of the theorems. However, it lacks specific examples or references to support the claim that the assumption is unjustifiable in practice. Therefore, the comment is 3, as it provides a clear critique but requires additional evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. This feedback is 3 as it highlights a critical assumption that may impact the validity of the results. However, it lacks specific suggestions or guidance on how the authors might address this issue or provide evidence to support the assumption. To be more helpful, the comment could include recommendations for alternative approaches or additional analysis to justify the assumption. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the comprehensiveness of the analyses of the method and experimental outcomes, noting that the experiments primarily focus on presenting results. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their analysis. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the analyses of the method and experimental outcomes, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis. It also questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not specify which sections or experiments are lacking in analysis, making it weakly grounded. The authors can infer that the issue relates to the experimental sections, but the comment lacks specificity regarding what aspects of the analysis are insufficient. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the analyses of the method and experimental outcomes are not comprehensive enough, particularly given that the authors\" method underperforms the baseline in some instances. The comment questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are insufficient or that the performance improvement is questionable. This makes the claim 3, as it provides a general critique but lacks concrete evidence or references to substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the analyses in the paper, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis of the method and experimental outcomes. It also questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to enhance their analysis and provide more detailed insights into the effectiveness of their method. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of what additional analysis could be included. Overall, the comment is 4, as it directs the authors to a key area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for expanding the scope of the paper. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide details on how the focus on multitask models restricts applicability. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how the focus could be broadened. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s focus on explaining multitask models limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the paper, noting that its focus on explaining multitask models may limit its applicability. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the literature review ignores several papers that are seemingly relevant, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not explicitly instruct the authors to include these papers in the literature review or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors can infer that they need to add these papers but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies specific papers (VRMARINA and DASHAMVR) that are missing from the literature review and suggests that they satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what needs to be addressed in the literature review. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide detailed reasoning or evidence to support why these papers are relevant or how they compare to QSGD. The reference to \"See Question\" implies that the reviewer is seeking clarification, but it does not provide sufficient justification for the claim. Therefore, the comment is considered 2, as it lacks specific examples or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are seemingly relevant, including VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to include these papers in the literature review, which could enhance the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these papers or why they are relevant. Overall, the comment is 4 as it highlights a significant gap in the literature review and offers a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point consists of two questions: one about additional insights into modest performance gains on Clothing1M and another about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. While the questions imply that the authors should provide more information or insights, they do not explicitly instruct the authors to do so. The lack of explicit guidance and the vague nature of the questions make it difficult for the authors to know exactly what actions to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about additional insights into modest performance gains on Clothing1M and the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not provide explicit references to sections, tables, or figures. Additionally, while it specifies what needs to be addressed, it does not provide detailed guidance on how to address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions seeking additional insights into the performance of the algorithm on specific datasets. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of two questions seeking additional insights into the performance of the algorithm on specific datasets. While it prompts the authors to provide more information, it lacks actionable feedback or suggestions for improvement. The questions are relevant to the paper\"s content but do not offer guidance on how to address the issues or enhance the draft. As a result, the comment is 2, as it provides minimal value to the authors in terms of actionable feedback or insights for improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks information on the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback provides clear and concrete actions for the authors to take, such as including the hyperparameters used and explaining their derivation, and conducting an evaluation that optimizes hyperparameters against the attack. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding hyperparameters used by each defense and how they are derived. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it provides clear guidance on what needs to be addressed, such as describing the hyperparameters and their derivation, and suggests a maximally charitable evaluation approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. The comment provides a logical reasoning for the claim by suggesting a specific approach for evaluation, which is a common practice in the field. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to consider the suggestion and provide evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their evaluation methodology. By addressing this critique, the authors can improve the comprehensiveness and rigor of their defense evaluation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications but suggests that the authors could provide more takeaway points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but notes that it is unclear if this is a novel finding in the paper. While the comment provides a concrete suggestion, it lacks guidance on how to determine if this is a novel contribution or how to present it effectively. The action is explicit but somewhat vague, as the authors need to infer how to address the issue of novelty and practical implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the authors provide more takeaway points for practitioners. It mentions a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. However, the comment does not specify which part of the paper discusses these theoretical results or where the suggestion is made, making it weakly grounded. The comment is specific in suggesting a potential takeaway point and questioning its novelty, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. However, the reviewer suggests that more takeaway points for practitioners would be beneficial. The comment also highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the lack of practical implications or the novelty of the suggested approach. This makes the claim 3, as it requires further elaboration to fully substantiate the critique.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and suggests that the authors provide more practical takeaway points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment identifies a potential area for improvement by suggesting practical applications, it lacks depth and does not provide detailed guidance on how to incorporate these takeaway points or address the issue of novelty. The feedback is 3 as it points out a direction for improvement but could be more comprehensive and actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the introduction of separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the introduction of separators and asking for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. It is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the introduction of separators in section 4. It questions the rationale behind their inclusion and asks for clarification on what additional information they provide beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to provide a justification for the introduction of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to effectively explain the role of separators. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which alternative strategies to consider or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies, providing a clear direction for the authors to explore alternative methods. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any supporting evidence, reasoning, or references to justify why mean pooling might not be the best choice or to suggest alternative strategies. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for exploration, it lacks depth and does not provide specific guidance or examples of alternative strategies that could be used. This limits the usefulness of the feedback, as the authors are left without clear direction on how to address the issue. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about missing training details, specifically whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but are not given specific guidance on how to present this information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about missing training details, specifically asking if the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections where training details are typically discussed. The comment is specific in its request for clarification on the training process, providing clear guidance on what information is needed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about missing training details, specifically whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. However, it does not provide any supporting evidence, reasoning, or references to justify the need for this information. The comment lacks a claim or opinion that requires verification, as it is primarily a question seeking clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about missing training details, asking whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This feedback is clear and actionable, as it prompts the authors to provide necessary information about the training process. By addressing this question, the authors can enhance the transparency and comprehensiveness of their methodology section. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, suggesting that running a descent procedure for 40 different networks from the training phase may not be necessary. The reviewer proposes an alternative method, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient, as at least one of these restarts would likely reach the global minimum. This comment provides a clear and explicit suggestion for improvement, offering a concrete alternative to the current approach. However, it does not fully explain why the current method is not effective or how the proposed alternative would improve the results. Despite this, the action is explicit and provides a clear direction for the authors to consider. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not specify which part of the paper discusses the experimental setup or the descent procedure, making it weakly grounded. The suggestion for an alternative method is specific, as it provides a clear alternative approach to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental strengths of the proposed approach are not convincing and suggests an alternative method. The reviewer provides a logical reasoning by comparing the proposed algorithm with vanilla Adam, explaining that running a descent procedure for 40 different networks may not be necessary. However, the comment lacks specific examples or references to support the claim that vanilla Adam with 40 random initial points would reach the global minimum. This makes the claim 3, as it provides a logical argument but requires further evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is 3 as it identifies a potential weakness in the experimental design and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided additional context or explanation for why the current approach might not be effective or why the proposed alternative is beneficial. The authors gain some insight into a potential area for improvement, but the feedback could be more comprehensive and actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and suggestions for clarification regarding specific details in the paper. It asks for an explanation of what Omega is, suggests being more explicit about the OMD algorithm, and questions the link function and the specific theorem from reference 32 being referred to. These questions and suggestions provide clear and explicit actions for the authors to take, such as providing definitions, clarifying terminology, and specifying references. The feedback is concrete and directly guides the authors on how to improve their draft by addressing these specific points. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and suggestions for clarification, such as explaining what Omega is, being more explicit about the OMD algorithm, and specifying the link function and the theorem from reference 32. These details provide clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification, such as asking for an explanation of what Omega is, being more explicit about the OMD algorithm, and specifying the link function and theorem from reference 32. These questions are factual and seek clarification, rather than making subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the clarity of certain terms and concepts in the paper. It asks for an explanation of what Omega is, suggests being more explicit about the OMD algorithm, and requests clarification on the link function and the specific theorem from reference 32 being referenced. These questions and suggestions are clear and direct, offering the authors concrete steps to improve the clarity and comprehensiveness of their draft. By addressing these points, the authors can enhance the readability and understanding of their work for the audience. Therefore, the comment is rated as 5, as it effectively guides the authors in refining their manuscript."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the synthesized results for UCF101, noting inconsistent motion, changing color, or objects disappearing over time. It suggests that it would be interesting to see videos with a longer duration by running the LSTM over many time steps. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address the issue or specific steps to take. The suggestion is implicit and somewhat vague, as it lacks concrete details on how to implement the idea of longer video sequences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. The comment suggests exploring videos with longer durations by running the LSTM over many time steps, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point discusses the results of the paper, specifically mentioning the issue of inconsistent motion, changing color, or objects disappearing over time in the synthesized results for UCF101. It suggests that longer video sequences could be explored by running the LSTM over many time steps. The comment provides a logical reasoning for the suggestion, as it points out a limitation in the current results and proposes a potential solution. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the suggestion and provide additional evidence or experiments to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color changes, or objects disappearing over time. It suggests exploring longer video sequences by running the LSTM over many time steps, which could improve the results. The comment also acknowledges the paper\"s interesting idea and extensive experiments, while noting that the results are not perfect but show improved performance over the previous stateoftheart. This feedback is 3 as it points out a potential area for improvement and suggests a direction for further exploration, but it lacks detailed guidance on how to address the issues or specific suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might need to conduct this experiment but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of numbers of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its suggestion to explore this aspect, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. However, the comment does not provide any evidence, reasoning, or references to support this claim. The lack of justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors have explored the impact of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. While the comment identifies a potential area for exploration, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides an example reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could serve as a basis for the clarification. While the action is explicit, the comment could be more actionable by providing specific guidance on how to make this clarification, such as suggesting particular aspects to focus on or how to structure the explanation. Nonetheless, the comment is 4 as it clearly identifies the need for clarification and provides a reference for further information.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for clarification regarding the difference between these concepts, providing a specific example from Foester et al. (2016) to support the request. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between these and centralized RL where agents share weights. The comment provides a reference to Foester et al., \"Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which supports the claim by offering a relevant example. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this difference, providing a specific reference to Foester et al. (2016) as an example of related work. This feedback is clear and actionable, as it directs the authors to a specific area of improvement and offers a relevant reference to support their clarification. However, the comment could be more helpful if it provided additional guidance on how to structure the clarification or what specific aspects of the meta solvers and centralized RL should be highlighted. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s categorization of papers based on their publication years on the ACL anthology, noting that many papers are posted on arXiv earlier than their ACL publication. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the timing of arXiv postings in their categorization, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of how papers are categorized based on their publication years on the ACL anthology, noting that many papers are posted on arXiv earlier than their ACL publication. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the problem with the categorization, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s categorization of papers based on their publication years on the ACL anthology is incorrect because many papers are posted on arXiv earlier than their ACL publication. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This example supports the claim by providing a concrete instance of the issue, making the comment 4. However, the comment could be strengthened by further elaboration or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s categorization of papers based on their publication years on the ACL anthology. It highlights that many papers are posted on arXiv earlier than their ACL publication, using the BERT paper as an example. This feedback is 3 as it identifies a specific area where the paper\"s categorization might be inaccurate. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their categorization method. To be more helpful, the comment could provide recommendations or examples of how to account for arXiv postings in the categorization process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors provide examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and actionable, as it directs the authors to take a specific step to improve the clarity of their draft. The comment provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the notation used for M_T, suggesting that it is not making sense due to its definition over probabilities of atomic events. The comment further provides a clear and specific suggestion to address this issue by recommending the inclusion of examples to explain M_T. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the notation M_T is not clear because it is defined over the probabilities of atomic events. The reviewer requests examples to explain M_T, which is a reasonable request for clarification. However, the comment does not provide any specific reasoning or evidence to support why the notation is problematic or how examples would improve understanding. This lack of detailed justification makes the claim 3, as the authors would need to infer the need for clarification and examples based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used for M_T on page 3, suggesting that it is defined over the probabilities of atomic events but is not clearly explained. The reviewer provides a clear and actionable suggestion by recommending the inclusion of examples to clarify this concept. This feedback is valuable as it directs the authors to a specific area where the draft could be improved, offering a concrete step to enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or examples of how the examples should be structured. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their notation and explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific refinements could be made or how the authors might improve the performance enhancements. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the performance enhancements could be refined. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be refined or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are \"somewhat modest,\" suggesting that there is room for further refinement. However, the comment does not provide any specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment notes that the observed performance enhancements are modest, suggesting that there is room for further refinement in the future. While this observation highlights an area for potential improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might enhance the performance or what specific aspects could be refined. Without detailed feedback or recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It implies that the performance is similar to IRM, which may be due to the issues mentioned earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to improve the experimental design or analysis to better validate their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the last two datasets. However, it does not specify which datasets these are, making it weakly grounded. The comment provides some specificity by questioning the validity of the results and suggesting a possible reason for the similarity in performance to IRM. However, it lacks detailed guidance on how to address this issue or improve the experimental results. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions \"the problems mentioned above,\" but without elaboration, it is difficult for the authors to understand the basis of the critique. This lack of detailed justification makes the claim 3, as the authors would need to infer the specific issues and address them to fully understand and respond to the feedback.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically noting that the performance on the last two datasets is similar to IRM, which may indicate a lack of effectiveness in validating the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the experimental results. It lacks actionable feedback, such as recommending additional experiments, modifications to the methodology, or alternative analyses to better validate the proposed method. Without detailed guidance, the authors are left without a clear path to improve their draft, making the comment 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, questioning the added value of this detection compared to simply knowing the length of the long entity. However, it does not provide any explicit or implicit guidance on how the authors should address this concern or what changes they should make to their draft. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between this detection and simply knowing the length of the long entity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in the example of Figure 2, suggesting that knowing the length of the long entity might be sufficient. However, the comment does not provide any supporting evidence, reasoning, or references to justify why detecting both entities is unnecessary. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example presented in Figure 2, questioning the added value of this detection compared to simply knowing the length of the long entity. While it identifies a potential area of confusion or unnecessary complexity, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the purpose of detecting both entities. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there is a lack of empirical validation and suggests that experiments should be conducted to validate the bounds. This provides a clear and direct action for the authors to take, which is to include empirical validation through experiments. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment points out the lack of empirical validation and suggests conducting experiments to validate the bounds. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments that are missing. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in its request for empirical validation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of empirical validation, suggesting that experiments should be conducted to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on what kind of experiments should be conducted or how the validation should be approached. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention, allowing them to improve the robustness and credibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. While the comment identifies a potential confusion, it does not provide explicit guidance on how to address this issue or clarify the terminology. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"nonsequential information\" and \"chunks\" in their draft. However, the comment does not offer specific suggestions on how to resolve the confusion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the terminology used, specifically the phrase \"nonsequential information such as chunks,\" and asks if \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the terminology used in the paper, specifically the phrase \"nonsequential information such as chunks.\" It questions whether \"chunk\" is still considered sequential information, indicating a potential confusion in the text. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this confusion exists or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the terminology \"nonsequential information such as chunks.\" It questions whether \"chunk\" is still considered sequential information, which could be a critical clarification for the authors to make. However, the comment does not provide any suggestions or guidance on how to address this confusion or clarify the terminology. While it highlights an area that needs attention, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that needs explanation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to address the exception but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the upper bound when there is a separate node with 0 neighbors, which is a clear and specific concern. The comment raises a logical question about the exception and asks for an explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exception is problematic or how it affects the theorem. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the question, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive, asking for an explanation. While the comment identifies a potential issue, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this exception or clarify the theorem. The feedback is 3 as it prompts the authors to consider this specific case, but it could be more beneficial with additional context or direction. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, suggesting a comparison with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be improved. The comment implies that the authors should consider the similarities between their work and the previous papers, but it lacks concrete steps or suggestions on how to enhance the novelty or differentiate their work. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the paper with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper this comparison should be made in, such as the introduction, methodology, or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint where the comparison should be included. The comment is specific in identifying the issue of limited novelty and the need for comparison, but it is not fully grounded as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The reviewer provides a logical basis for the claim by noting that the idea, coattention mechanism, and architecture of the current paper are similar to those in the previous papers. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how the current paper lacks novelty. This would enhance the verifiability of the claim. As it stands, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty, suggesting that the idea, coattention mechanism, and architecture are similar to those in previous papers. It provides a basis for this claim by mentioning specific papers (Xing and Tsang, 2022a, b) that focus on graphbased approaches. However, the comment lacks actionable guidance on how the authors might address this concern or differentiate their work from the previous papers. Without specific suggestions or examples, the feedback is 3 as it points out an area for improvement but does not provide detailed direction for enhancement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis regarding the detection of rumors generated by GPT and natural rumors. It suggests that the paper should provide further analysis or solutions to address this issue. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors can infer that they need to address the gap in analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"The handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking analysis or solutions for detecting GPTgenerated rumors and questions why GPTgenerated rumors are as difficult to detect as natural rumors. The comment provides a clear direction for the authors to address this gap in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or solutions for detecting rumors generated by GPT and questions why GPTgenerated rumors are as difficult to detect as natural rumors. The comment provides a logical reasoning by pointing out the inconsistency in the experimental results, where natural rumors are easier to detect than artificial ones. However, it does not provide specific references or detailed examples to support the claim, making it 3. The authors would need to conduct further analysis or provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the analysis of rumors generated by GPT. It points out that the paper highlights the challenges of detecting such rumors but does not provide further analysis or solutions. The comment also questions the reasoning behind why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to address this gap in their analysis and provide a more comprehensive understanding of the challenges involved. However, the comment could be more helpful if it offered specific suggestions or examples of how to approach this analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it instructs the authors to adjust the font size in Figure 6 to make it more readable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed to improve the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the font size in Figure 6 being too small. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is brief and points out a specific issue with the font size in Figure 6, indicating that it is too small. While it identifies a potential problem with the figure\"s readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The authors are left with a clear problem to fix but without any actionable advice on how to improve the figure. Therefore, the comment is 3, as it highlights a specific issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in comparisons or what specific steps to consider. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment lacks specificity as it does not provide details on what aspects of the comparison are unfair or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. While it identifies a potential issue with the comparison, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their analysis. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration without detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"When training, a mono tonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific guidance by questioning whether the monotonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. The reference to a specific paper, \"Learning the Pareto Front with Hypernetworks,\" adds further specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. The comment references a specific paper, \"Learning the Pareto Front with Hypernetworks,\" which provides a basis for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve into the referenced work to fully understand the implications and potential alternatives, which adds a layer of complexity to the verification process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and encourages the authors to explain this point further. The reference to a specific paper, \"Learning the Pareto Front with Hypernetworks,\" provides a relevant context for the discussion. However, the comment could be more helpful if it offered specific suggestions or examples of alternative relationships that could be explored. Despite this, the feedback provides a clear direction for the authors to consider and potentially improve their work, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This is an explicit action with concrete guidance on how to improve the paper by suggesting a specific area of focus. The comment provides a clear direction for the authors to enhance their work by addressing a particular aspect that was not fully convincing in the introduction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of a clear picture of the paper\"s goal and the need for examples that convincingly demonstrate the problems requiring interprocess communication. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and to consider ERMbased distributed algorithms like Hogwild provides clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples provided in the paper do not convincingly demonstrate the need for interprocess communication, particularly mentioning the second paragraph where samplingbased Bayesian methods are discussed. The reviewer suggests that the paper\"s results are irrelevant for these methods, which are already embarrassingly parallel. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the reviewer provides a logical reasoning for their claim, it lacks specific examples or references to support the assertion that the current examples are insufficient. This makes the claim 3, as it requires more detailed evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, where the reviewer did not gain a clear understanding of the paper\"s goal. It suggests that the examples provided, particularly in the second paragraph, do not convincingly demonstrate the need for interprocess communication. The reviewer offers a constructive suggestion to focus on problems where the loss function does not decompose as the sum of sample losses, such as Hogwild, which could provide a clearer context for the paper\"s contributions. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the identified weaknesses. However, it could be more helpful if it included specific examples or further elaboration on how to apply the suggested focus. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. However, it does not provide any guidance or suggestions on how to resolve this issue or what steps the authors should take to fix the problem. The comment lacks explicit or implicit actions, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the functionality of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. While this is a factual observation, it does not provide any guidance or suggestions on how to resolve the issue or improve the draft. The lack of actionable feedback or suggestions makes the comment 2, as it does not offer any insights or directions for the authors to address the problem. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. The action is implicit and somewhat vague, as the authors need to infer the specific changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The mention of \"section 2\" and \"Label Embeddings\" allows the authors to identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific as it details what needs to be addressed, namely the need for a better formalization of the architecture and clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings. While the comment identifies areas for improvement, it does not provide detailed reasoning or evidence to support the claim that the current discussion is unclear. The suggestion for improvement is logical, but the lack of specific examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings, which could be misleading. By offering these specific suggestions, the comment provides clear and actionable feedback that can help the authors improve the clarity and accuracy of their work. However, it could be more helpful if it included additional guidance on how to formalize the architecture or clarify the Label Embeddings. Overall, the comment is 4 as it directs the authors to areas that need improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph, which clarifies the description. This feedback is explicit and provides a clear action for the authors to take, which is to reorder the content to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the difficulty in understanding the description of the neural network, and suggests a solution by recommending that the final paragraph of the section be used to clarify the description. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand but acknowledges that the final paragraph of the section clarifies it. The suggestion to start the section with the final paragraph is based on logical reasoning, as it implies that the clarity of the description improves as the section progresses. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact issues with the initial description and how rearranging the content would improve clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph of the section. It provides a constructive suggestion to improve the clarity by recommending that the section start with the final paragraph, which clarifies the description. This feedback is actionable and offers a clear path for the authors to enhance the readability of their draft. However, it could be more helpful if it included additional suggestions or examples on how to further clarify the initial description. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the model is limited to CTC loss and asks if it would be possible to train it towards attentionbased encdec training. While the comment implies an action\u2014exploring alternative training methods\u2014it does not provide explicit guidance on how to implement this suggestion. The authors can infer that they need to consider or experiment with attentionbased encdec training, but the comment lacks concrete details on how to proceed. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests exploring alternative training methods, specifically attentionbased encdec training, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the model or training section, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an alternative training method, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the model is limited to CTC loss and asks if it would be possible to train it towards attentionbased encdec training. However, the comment does not provide any reasoning, evidence, or references to support why the model is limited to CTC loss or why attentionbased encdec training would be beneficial. Without such support, the claim remains 1, as the authors would need to infer the basis of the suggestion themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests exploring alternative training methods for the model, specifically attentionbased encdec training, beyond the current limitation to CTC loss. This feedback is 3 as it identifies a potential area for improvement and suggests a specific direction for enhancing the model. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it might be beneficial. While it offers a starting point for the authors to consider, it could be more helpful with additional context or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address the question or what changes might be necessary. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggests that one type (the column header) should suffice. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any supporting evidence, reasoning, or examples to justify why one type should suffice. The comment lacks specific details or references that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). While it identifies a potential area of confusion or redundancy, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the purpose of the different types of tables. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the attack methods used in the paper, labeling them as \"naive\" and suggesting that other classical attack methods in NLP should be considered. The reviewer provides an example of papers that could be referenced for alternative methods. While the comment implies that the authors should consider using more sophisticated attack methods, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the specific methods to consider, but it lacks directness in its instruction. Therefore, the comment is 4, as it provides a clear direction for improvement but does not explicitly tell the authors what to do.", "grounding_specificity_rationale": "The comment critiques the attack methods used in the paper, specifically mentioning that they are \"naive\" and suggesting the use of more classical attack methods in NLP. It provides an example of papers that could be referenced for alternative methods. However, the comment does not specify which part of the paper discusses the attack methods, making it weakly grounded. The suggestion to consider other attack methods is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are \"naive\" and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example of papers that could be referenced for alternative methods, which supports the claim. However, the comment lacks detailed reasoning or examples of why the current methods are considered naive, making it 3. The authors would need to delve deeper into the literature to fully understand the critique and potential improvements. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by labeling the attack methods as \"naive\" and suggesting that more classical attack methods in NLP should be considered. It provides a specific example of papers that could be referenced for alternative methods, offering a clear direction for improvement. However, the comment could be more helpful if it provided a detailed explanation of why the current methods are considered naive or how the suggested methods could enhance the paper. Despite this, the feedback is 4 as it directs the authors to consider more robust attack methods, which could significantly improve the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative mitigation methods or ways to improve image quality. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and their impact on \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper discusses these methods or how they affect image quality. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of image quality are affected or how to improve them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"the mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may negatively impact the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear path to improve their work. Therefore, the comment is 2, as it highlights a potential problem but does not offer meaningful guidance for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how to address these concerns or suggest specific actions for the authors to take. The action is implicit and vague, as the authors are left to infer that they should consider the potential impact of prior knowledge on fairness and take steps to mitigate it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its concern about fairness and potential issues with prior knowledge, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. The comment provides a logical reasoning for the potential issue, but it lacks specific examples or references to support the claim. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue with the pretrained visual model and target dataset leaking additional information, which could skew results and lead to unfairness. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or ensure fairness in their comparisons. While it identifies an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider this aspect but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, clarification, or further analysis. The comment is purely observational and lacks any actionable guidance, leaving the authors without a clear understanding of what they should do in response. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the observation that function words dominate content words in a Japanese sentence, which is a clear and detailed observation that the authors can address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks depth and does not offer any context or examples to substantiate the observation, making it difficult for the authors to understand the basis of the surprise. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as observed in Figure 1. However, it does not provide any further analysis, explanation, or suggestions for improvement. The authors are left without actionable feedback or guidance on how to address this observation or its implications. Without additional context or suggestions, the comment lacks depth and does not offer meaningful assistance to the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using the minimal kmeans objective over multiple seeds as a baseline instead of the average of kmeans objectives. This is a specific and explicit suggestion, providing a clear action for the authors to take. The comment also includes references to support the suggestion, which adds to the actionability by providing a concrete basis for the recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests an alternative approach to using the average of kmeans objectives with multiple seeds as a baseline, recommending the use of the minimal kmeans objective instead. It provides references to support this suggestion, which adds specificity to the comment. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental or methodology section, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using the minimal kmeans objective over multiple seeds as a baseline instead of the average of kmeans objectives. It provides references to support this claim, citing two studies: \"Local maxima in the likelihood of gaussian mixture models\" by Jin et al. and \"Kmeans properties on six clustering benchmark datasets\" by Fr\u00e4nti and Sieranoja. These references offer a solid foundation for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced studies to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a minor suggestion regarding the choice of baseline for kmeans objectives. It recommends using the minimal kmeans objective over multiple seeds instead of the average, which is a specific and actionable piece of feedback. The comment is supported by references to relevant studies, offering a clear direction for the authors to consider. However, the comment could be more helpful if it explained why the minimal kmeans objective is more reasonable or provided additional context on how this change might impact the results or analysis. Despite this, the suggestion is clear and provides a valuable insight for the authors to consider, making the comment 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The reviewer asks the authors to clarify this point. Additionally, the comment suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. The feedback is explicit in asking for clarification and provides a specific issue to address, making it 4. The authors know exactly what needs to be clarified and can take concrete steps to address the confusion and the contradiction in the paper\"s motivation. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the relationship between uncertainty calibration and temperature calibration, particularly with the regularization term H. The comment further specifies the issue by pointing out the contradiction between the training regularization term requiring temperature calibration and the application of temperature calibration after training. Additionally, it highlights the contradiction between reducing entropy and the paper\"s motivation to calibrate networks that are already overconfident. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which could be confusing. Additionally, the comment suggests that reducing entropy makes predictions more confident, contradicting the paper\"s motivation to calibrate networks that are already overconfident. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the paper to understand the context and address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically with the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which could be confusing. Additionally, the comment highlights a contradiction between reducing entropy, which makes predictions more confident, and the paper\"s motivation to calibrate networks that are already overconfident. The reviewer provides specific lines of the paper where these issues are discussed, allowing the authors to clarify these points. This feedback is 4 as it identifies specific areas of confusion and provides clear guidance on how to address them, enabling the authors to improve the clarity and coherence of their draft. However, it could be more helpful if it offered suggestions on how to resolve the contradictions or clarify the relationships between these concepts. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of an important reference related to the idea of unrolling, specifically mentioning \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss its relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add the reference and discuss its context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reference \"Lista\" and provides a link to the paper by Yann LeCun, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of this reference and a discussion of the similarities and differences between the proposed work and \"Lista.\" This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning \"Lista\" by Yann LeCun. It provides a link to the reference, which is a clear and specific example of the missing reference. This level of detail supports the claim, making it 4. However, the comment could be strengthened by explaining why this reference is important or how it relates to the paper, which would further enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the lack of reference to the concept of unrolling, first proposed in \"Lista\" by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista\" to provide context. This feedback is clear and actionable, as it directs the authors to include a relevant reference and to discuss its relevance to their work. By addressing this gap, the authors can enhance the paper\"s context and relevance, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by stating that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating that the FLOT cost matrix in Algorithm 1 is not defined. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable piece of feedback that directly points out a gap in the paper\"s presentation. By addressing this issue, the authors can improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the FLOT cost matrix or its significance in the algorithm. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance or suggestions on how the authors should address this issue or what alternative terminology or explanations could be used. The action is explicit but lacks concrete details on how to implement the change, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the term \"connectivity,\" namely, that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this term is misleading or how it deviates from the intended meaning. Without additional context or explanation, the claim remains 1, as the authors may not understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not refer to the structural connections between the brain and body. This feedback is 3 as it points out a specific area where the terminology might be confusing. However, the comment lacks depth and does not provide suggestions on how to address this issue or what alternative terms or explanations could be used. While it highlights a potential problem, it does not offer actionable guidance for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers the authors to another section for more information, but this does not offer actionable steps for improvement. As a result, the comment is vague and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details or provide specific examples of what is lacking. The comment refers the authors to another section, \"Clarity, Quality, Novelty And Reproducibility,\" for more information, but this does not help the authors identify the exact issues in their current draft. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to determine what needs to be addressed. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, making it difficult for the authors to understand and address the issues. The comment refers to another section for more information, but this does not enhance the verifiability of the claim. As a result, the comment is considered 1, as it lacks the necessary details and evidence to substantiate the claim.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not provide specific examples or suggestions on how to improve these aspects. The comment refers the authors to another section for more information, but this does not offer actionable guidance for enhancing the draft. Without detailed feedback or constructive suggestions, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies areas for improvement but lacks specificity and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also provides specific details about the method used, which is padding the shorter sequence by replicating its last state. Additionally, the comment suggests that the lack of a normalization factor of 1/T can lead to a bias towards longer trajectories. The feedback is clear and provides concrete guidance on what needs to be addressed and how to address it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the equation between lines 282 and 283,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of handling comparisons between episodes of different lengths and suggests that the authors should clarify how they handle this in the equation. Additionally, it provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and points out the lack of a normalization factor of 1/T, which can lead to a bias towards longer trajectories. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes that the lack of a normalization factor of 1/T can lead to a bias towards longer trajectories. This reasoning is logical and provides a clear explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific literature or studies that support the claim about the bias towards longer trajectories. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides detailed feedback by explaining the method used to handle this issue, such as padding the shorter sequence by replicating its last state. Additionally, the comment points out the lack of a normalization factor of 1/T, which can lead to a bias towards longer trajectories. This feedback is actionable and provides clear guidance on how the authors can improve their draft by clarifying this aspect and potentially addressing the normalization issue. However, the comment could be more helpful if it suggested specific ways to address the normalization factor or provided examples of how this might impact the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a specific mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. 7. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. 7. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention a specific difference in evaluation, despite the preprocessing being identical to that in Mnih et al. 7. This claim is based on a logical observation and does not require external references or detailed reasoning. The suggestion is clear and straightforward, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement. It directs the authors to include a mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. 7. This feedback is clear and concrete, offering the authors a precise way to enhance their draft by highlighting a relevant distinction. By addressing this point, the authors can provide a more comprehensive understanding of their work and its context. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claims of efficiency advantages over previous work and the lack of metrics in the paper to support these claims. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to include metrics to demonstrate the efficiency of their proposed method, but the comment lacks concrete details on what specific metrics should be used or how to present them. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not reporting any metrics to demonstrate the efficiency of the proposed method, despite claims of advantages over previous work. However, it does not specify which part of the paper discusses these advantages or where the metrics should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the lack of metrics but lacks grounding, as it does not provide a clear reference to the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide metrics to support the claim of efficiency advantages over previous work. This is a subjective opinion that requires justification, as it challenges the authors\" assertion of efficiency. However, the comment does not provide specific examples or references to previous work that the authors could use to address this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique or how to improve their draft. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that it claims advantages over previous work in terms of efficiency but lacks any metrics to support these claims. This is a significant gap in the paper, as it undermines the credibility of the authors\" assertions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which metrics to include or how to present them. While it highlights a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a key weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details at line 81, specifically asking about the nature of the statespace (finite or continuous), the actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be more precise to provide explicit details. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing more details about the statespace, actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be more precise to be explicit. This level of detail provides clear guidance for the authors on what needs to be clarified in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more details about the statespace, actions, and the space in which theta lies. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors could provide more clarity and detail. By asking about the nature of the statespace, actions, and the space in which theta lies, the reviewer highlights a potential source of confusion in the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address these questions, such as recommending specific sections to expand or examples to include. While it points out an area for improvement, it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, contrasting with the authors\" use of object detection. It also provides a rationale for this belief, suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment does not provide explicit guidance or suggestions for the authors to consider alternative methods or address the potential limitations of their current approach. The action is implicit and vague, as the authors are left to infer that they should reconsider their choice of downstream task without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the choice of downstream task, specifically mentioning object detection and suggesting LiDARbased segmentation as a better option. It provides a rationale for this suggestion, noting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream task, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the current choice of downstream task, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion that LiDARbased segmentation is a better choice than object detection as the downstream task. The reviewer provides a rationale by suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment lacks specific examples or references to support the claim that LiDARbased segmentation is superior. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment expresses a personal opinion that LiDARbased segmentation is a better choice for the downstream task than object detection, which is currently used. It provides a rationale for this belief by suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. This feedback is 3 as it highlights a potential limitation in the current approach and suggests an alternative method. However, it lacks specific guidance or suggestions on how the authors might address this issue or explore the suggested alternative. The comment could be more helpful if it provided detailed reasoning or examples to support the claim, making it 3 but not fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. However, it does not provide explicit guidance on how to address this issue or suggest alternative notations. The action is implicit, as the authors need to infer that they should clarify or change the notation to avoid confusion. The comment lacks concrete details on how to implement this change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the potential confusion caused by using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be clarified or addressed in the algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. However, the comment does not provide any reasoning or evidence to support why this notation is confusing or how it affects the understanding of the algorithm. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it directs the authors to clarify or change the notation to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending alternative notations or explaining the context in which $p$ is used. Overall, the comment is 4 as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which tasks should be included or provide any guidance on how to implement this suggestion. The action is implicit and vague, leaving the authors uncertain about what specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where benchmarking results are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding which additional benchmarking tasks should be included or why they are necessary. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any reasoning, examples, or references to support why these additional tasks are necessary or how they would enhance the paper. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1.", "helpfulness_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on which specific tasks should be included or why they would be beneficial. This makes it difficult for the authors to understand the exact nature of the suggestion and how to implement it effectively. As a result, the comment is 3, as it points out a potential area for enhancement but does not offer detailed actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer provides a clear action for the authors to take by suggesting that they should clarify the reference to avoid confusion. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reference to \"PointNet\" and provides a clear suggestion to clarify the reference to avoid confusion. The comment also includes a reference to an external work, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which further supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to 15 as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to the original \"PointNet\" paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which supports the claim. This reference helps to clarify the confusion and provides a clear basis for the critique. Therefore, the claim is 5, as it is supported by a specific reference that addresses the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, pointing out that the name does not appear in the paper and is confused with another paper. It provides a clear suggestion to clarify the reference by mentioning the original \"PointNet\" paper by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is actionable and provides a precise direction for improvement, making it 5 for the authors to address the confusion and ensure accuracy in their references. Therefore, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, suggesting that clarification might be needed. This is an implicit action, as it does not explicitly instruct the authors to make changes but suggests a potential area for improvement. The second part provides explicit actions by pointing out unnecessary words and suggesting corrections to specific lines. While the first part is vague, the explicit actions in the second part make the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for clarification and corrections, such as clarifying the policy gradient and removing unnecessary words. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification, rather than making subjective claims or opinions. It does not contain any claims that require verification, such as judgments or suggestions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of questions and suggestions for improvement. It raises a question about the policy gradient in Eq. 6, asking whether it solves the optimal problem and whether the optimal solution to Eq. 5 is obtained after convergence. This question prompts the authors to clarify their methodology, which is a valuable contribution to the paper. Additionally, the comment points out minor errors, such as unnecessary words and formatting issues, which can be easily corrected. However, the comment could be more helpful if it provided a deeper analysis or suggestions for addressing the questions raised. Overall, the feedback is 3 as it identifies areas for clarification and minor improvements, but it could be more comprehensive to fully support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two. While the comment implies that the authors should consider this alternative, it does not provide explicit guidance on how to address the question or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and provide a response. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this assumption is discussed. Without explicit references, the authors may find it challenging to determine the exact context of the question. The comment is specific in its inquiry about the difference between the two distributions, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification on the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on whether it is possible to assume a general Gaussian distribution and what the difference is between the two. While the comment identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or its implications for their work. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a potential issue with freezing the partitioning in the first iteration, suggesting that it makes strong assumptions about the coverage of the initial data. The reviewer recommends that the authors at least discuss the limitations of this approach. This feedback is clear and provides a direct action for the authors to take, which is to address the limitations of their method. The comment is explicit and concrete, offering a specific suggestion for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential risk of freezing the partitioning in the first iteration and suggests that the authors should discuss the limitations of this approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach of freezing the partitioning in the first iteration, suggesting that it makes strong assumptions about the coverage of the initial data. It recommends that the authors discuss the limitations of this approach, which is a clear and actionable suggestion for improvement. By addressing this concern, the authors can provide a more comprehensive understanding of their methodology and its potential limitations. However, the comment could be more helpful if it offered specific suggestions on how to discuss these limitations or provided examples of alternative approaches. Overall, the feedback is 4 as it directs the authors to a critical area that needs further exploration and discussion."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the decision to use early stopping based solely on link prediction accuracy should be explained. It implies that the authors should provide a rationale for this choice, possibly by considering other metrics like type accuracy. While the comment does not explicitly instruct the authors to include this explanation, it provides a clear direction on what aspect of the paper needs clarification. The action is implicit but concrete, as the authors know they need to address the reasoning behind the early stopping criterion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the decision to use early stopping only by link prediction accuracy and suggests that the authors should explain why this choice was made, potentially by considering other metrics like type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping based solely on link prediction accuracy, suggesting that it should be explained and potentially considering the inclusion of type accuracy. However, the comment does not provide any reasoning or evidence to support why this decision might be problematic or why considering type accuracy would be beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, questioning the decision to use early stopping based solely on link prediction accuracy. It suggests that the authors should explain this choice, potentially by considering other metrics like type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their methodological choice, which could enhance the clarity and robustness of their approach. However, the comment could be more helpful if it provided additional context or examples of how other metrics might be considered. Overall, the comment is 4, as it offers a specific suggestion for improvement that the authors can act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of explanation regarding the ground truth of sensitivity, specifically noting that the authors only mention \"pruning\" without providing details on how it was done. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide more details on the pruning process. However, the comment lacks concrete instructions on what specific details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail on how the ground truth of sensitivity is achieved, particularly regarding the pruning process. The comment provides a clear direction for the authors to address this gap in their explanation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning the lack of explanation regarding the pruning process. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detailed explanation, namely the process of achieving the ground truth of sensitivity through pruning. It points out that the current explanation is insufficient, as it only mentions \"pruning\" without providing details on how it was done. This feedback is clear and actionable, as it directs the authors to expand their explanation to include the specifics of the pruning process. However, the comment could be more helpful if it suggested ways to present this information or provided examples of how similar processes have been described in other works. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers. However, the comment does not provide explicit guidance or suggestions for the authors to improve their approach or address these limitations. The feedback is implicit and lacks concrete details on how the authors might enhance their work. As a result, the authors are left without a clear understanding of what actions to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The authors can make an educated guess about the sections related to the proposed approach and the comparison with operator learning methods, but the comment lacks full grounding. It is specific in detailing the critique of the approach, but the lack of explicit references to specific sections or parts of the paper limits its grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the proposed approach by suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. The comment provides a logical reasoning by highlighting the differences between the proposed approach and existing methods, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to delve deeper into the literature to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers, noting that they are more universal but less accurate. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it points out a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific paragraph (L156166) where the reviewer struggles to understand the content, despite having a general idea of what the authors are trying to convey. The reviewer also criticizes the figure, stating that the explanation of dashed lines is too vague. While the comment identifies areas of confusion, it does not provide explicit guidance on how to clarify the paragraph or improve the figure. The action is implicit and somewhat vague, as the authors are left to infer what specific changes are needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with understanding the paragraph, including the mention of bandit algorithms and the Gittins strategy, and criticizes the figure for being hard to understand due to vague explanations. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and provides a specific critique about the explanation of bandit algorithms and the Gittins strategy. However, the comment lacks detailed reasoning or examples to support why the explanation is unclear or how it could be improved. The mention of the Gittins strategy and the reference to a figure are vague and do not provide sufficient evidence to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) where the reviewer struggles to understand the content, despite having a general idea of the intended message. It also critiques the figure, noting that the explanation of dashed lines is too vague. While the comment highlights areas of confusion, it does not provide detailed suggestions or guidance on how to clarify the paragraph or improve the figure. The feedback is 3 as it points out specific issues, but it lacks actionable advice or examples to help the authors address these concerns. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their implications for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in detailing the concern about the limitations of the approach but lacks grounding, as the authors cannot confidently determine which section or part of the paper this comment pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support the claim that the bounds would seriously limit the applications. Without additional context or evidence, the authors may find it challenging to understand the full extent of the issue or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide specific guidance or suggestions on how the authors might address this issue or explore alternative applications. The comment highlights a potential limitation but lacks actionable feedback, leaving the authors with a general understanding of the problem but without a clear path for improvement. Therefore, the comment is 2, as it identifies a weakness but does not offer constructive guidance for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of DVP\"s performance should be evaluated. Without actionable steps or suggestions, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of DVP on videos of different lengths but does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to the methodology, results, or discussion sections. Additionally, the comment lacks specificity as it does not provide any guidance on what aspects of DVP\"s performance should be evaluated or how this question could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question and does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, seeking clarification on the performance of DVP on videos of different lengths. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of their work could be improved. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the target of the paper or where to make the necessary changes. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not specify which part of the paper should be revised to address this issue, nor does it provide detailed guidance on how to clarify the target. The authors can infer that the issue is related to the introduction or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any supporting evidence, reasoning, or references to justify why this confusion exists or how it impacts the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the confusion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the paper\"s focus on singletoken or multitoken cloze queries. It highlights that the clarification is not clear until the conclusion, suggesting that the authors should provide a clearer distinction or explanation earlier in the paper. However, the comment does not offer specific suggestions or guidance on how to address this issue or where to make the necessary changes. While it points out a potential area for improvement, it lacks actionable feedback, making it 3. The authors are left with a general understanding of what needs attention but without detailed instructions on how to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology or how to enhance the theoretical analysis. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the limited connection with the methodology section and the simplicity of the theoretical analysis, which is closely related to reference 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference 1. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the limited connection between Section 2 and the methodology section, and the simplicity of the theoretical analysis, which is closely related to reference 1. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of what needs improvement but without a clear path forward. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should add a discussion on the utility of losses in specific contexts, such as specular areas. While the comment hints at a potential area for improvement, it lacks concrete details on how to execute this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests further discussion on the situations where the losses are helpful, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the utility of losses in specular areas, but without clear guidance on where this discussion should be integrated. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. This feedback identifies a potential area for improvement by encouraging the authors to provide more context and examples of how their approach applies to specific scenarios. However, the comment lacks specificity and does not offer detailed guidance on how to structure this discussion or what aspects to focus on. While it provides a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is 3, as it offers a general direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly questions the determination of \"n_t\" in Algorithm 2 and seeks clarification on the meaning of \"appropriate number\" in line 225. It also mentions that the answer cannot be found in reference 30. This feedback provides a clear and direct action for the authors to take: clarify the determination of \"n_t\" and provide a clear explanation of what \"appropriate number\" means. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of determining \"n_t\" and the ambiguity surrounding the term \"appropriate number\" in line 225. The comment provides a clear direction for the authors to clarify these aspects, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the determination of \"n_t\" in Algorithm 2 and seeks clarification on the meaning of \"appropriate number\" in line 225. It also mentions that the answer cannot be found in reference 30. This comment is 3 as it raises a specific question about the clarity of the algorithm and the meaning of a particular term. However, it lacks detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to provide additional context or clarification to fully address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, questioning how to determine \"n_t\" and the meaning of \"appropriate number\" in line 225. This feedback is clear and actionable, as it directs the authors to clarify these aspects, which are crucial for the understanding and reproducibility of the algorithm. By addressing this point, the authors can improve the transparency and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify these points. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. While the comment implies that the authors should make their code public to facilitate reproducibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for code sharing but are not given specific guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the code or results are problematic. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are hard to reproduce or why code availability is necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a critical issue regarding the reproducibility of the results, which is a significant concern in scientific research. By asking if the code will be made publicly available, the reviewer highlights a potential barrier to understanding and verifying the findings. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or improve the reproducibility of their work. Without actionable suggestions or detailed feedback, the authors are left with a general awareness of the problem but no clear path forward for improvement. Therefore, the comment is 2, as it identifies an important issue but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the lack of sufficient support for the claim that \"in practice the mixing time is even better,\" stating that the evidence provided is limited. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the support for the claim or what additional evidence might be needed. As a result, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific claims made in the paper regarding the mixing time, indicating that the evidence provided is insufficient. However, it does not specify which part of the paper these claims are made in, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact location that needs revision. The comment is specific in its critique of the evidence but lacks grounding, as it does not provide a clear reference to the part of the paper being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evidence supporting the claim \"in practice the mixing time is even better\" is insufficient. However, it does not provide specific examples or detailed reasoning to substantiate this claim. The comment lacks concrete evidence or references to support the assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. This is a clear and actionable feedback that highlights a weakness in the paper\"s evidence. However, the comment could be more helpful if it provided suggestions on how the authors might improve the support for these claims or what additional evidence could be included. Despite this, the comment still offers valuable insight into an area that needs further development, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. This is an explicit suggestion with concrete details on how to implement the action, providing the authors with a clear direction on what to do to improve their draft. The comment is 5 as it gives specific guidance on how to enhance the protected feature, allowing the authors to make a direct and concrete change to their work.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, it does not specify which part of the paper discusses feature A, making it weakly grounded. The comment is specific in suggesting a potential enhancement, but without clear grounding, the authors may find it challenging to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the protected feature A by proposing its extension to a vector form, which could represent multiple attributes. This is a clear and actionable suggestion that could improve the comprehensiveness and depth of the feature analysis. However, the comment lacks further elaboration or examples of how this extension could be implemented or what benefits it might bring. While it provides a direction for improvement, it could be more helpful with additional guidance or context. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, such as selftraining methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the novelty of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, such as selftraining methods. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment lacks specificity as it does not provide detailed reasoning or examples to support the claim of lack of novelty. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, such as selftraining methods. However, the comment lacks specific references or detailed explanations to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the reviewer\"s assertion or to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, such as selftraining methods. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the perceived lack of novelty or enhance the originality of their method. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the feature comparison with prior work is shallow and mentions that two relevant papers are missing. However, it does not provide specific guidance on which papers should be included or how to conduct a more comprehensive comparison. The action is implicit, as the authors need to infer that they should add these papers to the comparison, but it is vague because it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the feature comparison with prior work, indicating that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is presented in, making it weakly grounded. The comment is specific in identifying the issue with the feature comparison, but without explicit references to sections or specific elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific details about these missing papers or why they are relevant, nor does it offer any reasoning or evidence to support the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to expand their comparison by including these papers. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these papers into the comparison or what aspects of the papers should be highlighted. Despite this, the comment offers a clear direction for improvement, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a more cautious use of the word \"equivalent\" in the paper, particularly when the equivalence has not been verified. This is an explicit suggestion for the authors to reconsider their language and ensure that it accurately reflects the level of verification or validation of the equivalences discussed. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the word \"equivalent\" is used. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly when the equivalence has not been verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent\" in the paper, particularly when the equivalence has not been verified. This is a reasonable suggestion, as it highlights a potential issue with the language used in the paper. However, the comment does not provide specific examples or detailed reasoning to support why the current usage is problematic or how it could be improved. While the suggestion is logical, it lacks concrete evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting a more cautious approach when the equivalence has not been verified. This feedback is clear and actionable, as it directs the authors to reconsider their language and ensure that it accurately reflects the level of verification or validation of the equivalences discussed. By pointing out this potential issue, the comment helps the authors improve the clarity and precision of their draft. However, it could be more helpful if it provided examples or further guidance on how to implement this suggestion. Overall, the comment is 4, as it offers a valuable insight that can enhance the quality of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It suggests that without a more detailed analysis of the differences and similarities between these views, it is challenging to draw solid conclusions. The comment implies that the authors should conduct a more comprehensive analysis to better understand the contributions of each view. However, it does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the effectiveness of the multiview clustering approach, questioning the usefulness of views other than the paraphrase similarity view. The comment further specifies the need for a more detailed analysis of differences and similarities between these views to draw solid conclusions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. The reviewer points out that the paraphrase similarity view performs significantly better than other views and their combination, and suggests that without a more detailed analysis of differences and similarities between these views, it is challenging to draw solid conclusions. This claim is 3 as it provides a logical reasoning about the need for further analysis, but it lacks specific examples or references to support the assertion that the other views are not useful. The authors would need to conduct additional analysis to fully understand the claim, making it 3.", "helpfulness_rationale": "The review comment raises a critical point about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It highlights that the paraphrase similarity view consistently outperforms other views and their combination, leaving unclear what insights are gained from the other views. The comment suggests that a more detailed analysis of the differences and similarities between these views is necessary to draw solid conclusions. This feedback is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their analysis. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the typesetting of \"BertScore\" and \"BLEURT\" is inconsistent throughout the paper, suggesting that it would be better to maintain consistency. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset throughout the draft. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the specific parts of the paper where the inconsistency occurs. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests maintaining consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, noting that they are inconsistently typeset as \"Bertscore\" or \"Bleurt.\" This feedback is clear and actionable, as it provides a straightforward suggestion to maintain consistency in the typesetting of these terms. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it suggested specific guidelines or best practices for maintaining consistency in typesetting. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might address this question or incorporate it into their draft. As a result, the comment lacks actionability and does not offer any direction for the authors to improve their work. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups struggle with Greek, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address this question or what implications it might have for the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking additional information about the paper\"s findings or experiments. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. While it raises a relevant question, it does not provide any specific suggestions or guidance on how the authors might address this inquiry or incorporate it into their draft. The comment lacks actionable feedback or insights that could help the authors improve their work. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific section of the text (lines 293295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer suggests that this makes the point less clear for readers, implying that the authors should clarify or rephrase this section to improve understanding. However, the comment does not provide explicit guidance on how to rephrase or clarify the section, leaving the authors to infer that they need to make the language more precise or detailed. The action is implicit and somewhat vague, as the authors know they need to improve clarity but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point less clear for readers. The comment suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear and could be improved. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point less clear for readers. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the text (lines 293295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer points out that this makes the point less clear for readers, suggesting that it would be difficult for them to understand and evaluate. This feedback is 3 as it highlights a potential area of confusion in the paper and encourages the authors to clarify their explanation. However, the comment could be more helpful if it provided specific suggestions on how to rephrase or improve the clarity of the section. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This is an explicit action that provides a clear direction for the authors to improve their draft. However, the comment does not specify which realworld datasets should be used or how the experiments should be conducted, leaving some aspects of the action vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in suggesting the use of realworld datasets, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This claim is based on the assumption that realworld datasets are more representative of realistic scenarios than synthetic ones. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the rationale behind this suggestion and potentially conduct additional research to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning the experiments with more realistic scenarios. However, the comment could be more helpful if it included suggestions on which realworld datasets to use or how to adapt the experiments to better reflect realworld conditions. Despite this, the feedback is 4 as it offers a concrete way for the authors to enhance the validity and applicability of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes. The comment is vague and lacks concrete details on what needs to be clarified or how to address the issue. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a lack of clarity in the explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. This provides full grounding as the authors can accurately pinpoint the specific part of the paper being addressed. However, the comment is not specific in detailing what aspects of the explanation are vague or how they could be improved. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some explanations are \"a little vague,\" specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, pointing out the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is 3 as it directs the authors\" attention to a particular section that may need clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the explanation. While it highlights an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, specifically noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical. However, the comment does not provide explicit guidance or suggestions on how to extend the study or what specific steps the authors should take to achieve this. The action is implicit and somewhat vague, as the authors can infer that they need to consider multiple scenarios but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, specifically noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to address this issue. The authors can infer that it relates to the methodology or results section, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact area needing revision. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the scope of the study by noting that it only considers one truck and one drone, suggesting that extending it to multiple trucks and drones could be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be beneficial or how it would impact the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical, which is a relevant observation. However, the comment lacks specific guidance or suggestions on how the authors might approach this extension or what aspects of the study would need to be revised. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it prompts the authors to consider a broader scope but does not fully support them in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors should have multiple kernels and biases, as indicated by the notation \"C biases.\" It also suggests that the resulting volume should be WxHx1 and the bias should be a scalar. However, the comment does not provide specific guidance on how to implement these changes or where exactly in the paper these adjustments should be made. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, indicating that the authors should have multiple kernels and biases, and that the notation \"C biases\" is confusing. The comment provides a clear direction for the authors to clarify their notation and ensure consistency in their description of the model architecture. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"C biases\" is confusing because it suggests the authors should have multiple kernels and biases, but only found a hyperparameter for feedforward models in section 3.4. The comment provides a logical reasoning by pointing out the inconsistency in the notation and the lack of information about multiple biases. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the exact issue and potential solutions based on the provided information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, particularly with the notation \"C biases.\" It suggests that the authors should have multiple kernels and biases, which is not consistent with the notation provided. The comment points out that this inconsistency is confusing and provides a clear direction for the authors to clarify their notation. However, it does not offer detailed guidance on how to implement these changes or suggest alternative notations. While the comment highlights an important issue, it could be more helpful with additional suggestions or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors are left to infer that they should investigate or discuss these aspects in their paper, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments. Without explicit references to the paper, the authors may find it challenging to determine where these questions should be addressed. The comment is specific in its inquiry but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. By asking these questions, the reviewer prompts the authors to consider and potentially investigate these aspects further, which could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or what specific aspects of the network structure or MC samples are most relevant. While it identifies areas for exploration, the feedback is 3 as it provides a direction for further investigation but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is an explicit action with clear guidance on what needs to be done to enhance the draft. The suggestion is specific and concrete, providing the authors with a direct and actionable step to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely showing the smoothed GT shapes to improve the understanding of the reconstruction quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a suggestion for improvement rather than a claim or opinion that requires verification. It does not contain any subjective opinions, judgments, or suggestions that need to be substantiated. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It recommends showing the smoothed GT shapes in Figures 3 and 5, which would help readers better understand the quality of the reconstruction. This feedback is clear and provides a concrete step for the authors to enhance their draft. However, the comment could be more helpful if it explained why this suggestion is important or how it would impact the reader\"s understanding. Despite this, the suggestion is 4 as it offers a direct way to improve the paper\"s clarity and effectiveness. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC in both language and vision tasks. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This feedback implies that the authors should include a direct comparison of test accuracy to demonstrate whether their approach is an improvement over the baseline. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a direct comparison but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks direct comparisons with the prior approach PRANC in both language and vision tasks, despite modifying it. The reviewer highlights that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This claim is 3 as it provides a logical reasoning for the need of direct comparisons to assess the improvement over the baseline. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, the absence of a direct comparison of test accuracy makes it unclear whether the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to substantiate their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4, as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their hyperparameter tuning. The suggestion to consider the distance to the next best model is vague and lacks concrete steps for implementation. Therefore, the comment is 3, as it identifies a potential issue but does not provide clear instructions on how to resolve it.", "grounding_specificity_rationale": "The comment raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about hyperparameter tuning and the distance to the next best model, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, the comment lacks specific evidence or references to support this claim, such as detailed comparisons of hyperparameters or results from other models. Without this additional information, the claim remains 3, as it provides a logical reasoning but lacks concrete evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. This is a valid point that could indicate a potential issue with the model\"s performance. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve their hyperparameter tuning. Without actionable advice or examples, the feedback is 3, as it identifies a potential issue but does not provide a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific guidance on what aspects are unclear or how the authors might clarify them. The comment implies that the authors should address these issues, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or figures. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing clarification. Additionally, the comment does not provide detailed guidance on what aspects are unclear or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific examples or details to support this claim, making it difficult for the authors to understand and address the issues. Without additional context or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not provide detailed guidance or suggestions on how the authors might clarify or improve these aspects. The comment lacks actionable feedback, such as specific questions or areas to focus on, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not offer any meaningful insights or direction for enhancing the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and providing details about the size of each hourglass module. While the comment does not explicitly instruct the authors to include this information, it implies that the authors should provide a detailed comparison and specify the size of each hourglass module. The action is implicit but concrete, as the authors know exactly what information is needed to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the model architecture is described. The comment is specific in its request for additional information about the model size and its comparison to others. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. This feedback is valuable as it prompts the authors to provide a more comprehensive understanding of their model\"s architecture and its relation to existing work. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important for the reader. Despite this, the comment provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not direct. The comment is specific in its critique of the metric learning theory, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It suggests that the part of the paper related to metric learning does not seem to work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or comparisons, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the metric learning theory presented in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the issue or enhance their work. Without detailed analysis or constructive advice, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This feedback is explicit and provides concrete actions for the authors to take, such as moving visual results and adjusting the number of figures. The suggestions are clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to move visual results from the supplementary material to the main paper, specifically highlighting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This provides clear guidance on what needs to be addressed and where, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. The reviewer provides a logical reasoning by pointing out the imbalance in the presentation of visual results, suggesting that the authors should condense the figures illustrating the proposed network architecture to make space for additional visual results. This reasoning is clear and provides a specific suggestion for improvement, making the claim 4. However, the comment could be strengthened with examples or references to similar practices in the field, which would further support the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that some visual results currently in the supplementary material should be moved to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment, and suggests condensing the figures illustrating the proposed network architecture to make space for these visual results. This feedback is clear and constructive, offering a concrete way for the authors to enhance the presentation and clarity of their work. By addressing this suggestion, the authors can improve the visibility and impact of their findings, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of dataset, specifically suggesting the use of the WebQuestions benchmark set instead of WebQuestionsSP. It provides a rationale for this suggestion, noting that WebQuestions is more intuitive and straightforward for NSM, which only requires weak supervision, and that it would facilitate direct comparison with mainstream QA research. While the comment does not explicitly instruct the authors to make a change, it clearly implies that using WebQuestions would be a more appropriate choice. The authors can infer that they should consider switching to WebQuestions based on the reasoning provided. The action is concrete, as it specifies the alternative dataset and the reasons for its preference. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"choice of dataset\" and references \"WebQuestionsSP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the \"most popular WebQuestions (Berant et al., 2013) benchmark set\" instead of WebQuestionsSP, providing a clear rationale for the suggestion. The comment explains that using WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of dataset, suggesting that the authors use the more popular WebQuestions benchmark set instead of WebQuestionsSP. The reviewer provides a logical reasoning for this suggestion, noting that WebQuestions is more intuitive and straightforward for NSM, which only requires weak supervision, and that it would facilitate direct comparison with mainstream QA research. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by including specific references or examples to further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid point about the choice of dataset, suggesting that the authors use the more popular WebQuestions benchmark set instead of WebQuestionsSP. It provides a clear rationale for this suggestion, noting that WebQuestions is more intuitive and straightforward for NSM, which only requires weak supervision, and that it would facilitate direct comparison with mainstream QA research. This feedback is actionable and provides the authors with a specific suggestion for improving their work. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4 as it offers a clear and actionable suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits need to be demonstrated. It implies that the authors should provide evidence or examples to support their claims, particularly regarding the impact of sparsity on training speed and cost savings. However, the comment does not explicitly instruct the authors to conduct specific experiments or analyses to address these concerns. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence but are not given clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the necessity of claims about sparsity in training and suggests that any potential benefits need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by mentioning the need to demonstrate benefits and the importance of practical implementation, but it lacks full grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of claims about the desirability of sparsity in training, suggesting that any potential benefits need to be demonstrated. The reviewer provides a logical reasoning by pointing out that a larger network that cannot fit into memory without sparsity may perform better, but this needs to be demonstrated. Additionally, the comment critiques the use of FLOPs as a metric, suggesting it is meaningless without evidence of practical cost savings. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the critique of FLOPs as a metric. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the necessity of claims about the desirability of sparsity in training, suggesting that these claims are not obvious and need to be substantiated. It also critiques the use of FLOPs as a metric, pointing out that it may be meaningless without evidence of practical cost savings. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address these issues. It does not provide actionable feedback or detailed advice on how to improve the draft, leaving the authors with a general understanding of what needs attention but without a clear path forward. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It provides a clear action for the authors to take, which is to verify the effectiveness of the framework on these datasets and present the results in the main paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, such as ImageNet derivatives, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the analysis or results on these datasets, and suggests presenting them in the main paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning the importance of verifying the framework\"s effectiveness on ImageNet1k or ImageNet100. The comment provides a logical reasoning by suggesting that including results on these datasets would enhance the paper\"s comprehensiveness. However, it does not provide specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 3, as it offers a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it only presents improvements on CIFAR derivatives and lacks analysis or results on other datasets, such as ImageNet derivatives. It provides a clear and actionable suggestion to include results on these datasets, specifically mentioning ImageNet1k or ImageNet100, which would enhance the comprehensiveness of the paper. This feedback is valuable as it directs the authors to a specific area for expansion, which could significantly improve the paper\"s impact and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct the analysis or present the results. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a discrepancy between how BigFive and MBTI are referred to in the Abstract, Introduction, and Experiments sections. It suggests that these models should be consistently referred to as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Abstract, Introduction, and Experiments sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent labeling of BigFive and MBTI, suggesting that they should be referred to as datasets throughout the paper unless an extended explanation is provided. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. The reviewer suggests that it would be better to consistently refer to them as datasets throughout the paper, unless the authors provide an explanation for their current usage. This claim is 3 as it points out an inconsistency in the paper\"s terminology, but it lacks specific examples or references to support the claim. The authors would need to review their paper to understand the context and make the necessary adjustments, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, where BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. It provides a clear and actionable suggestion to address this inconsistency by recommending that these terms be used consistently throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is valuable as it helps the authors clarify their terminology and ensure consistency, which is crucial for the clarity and credibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present the explanation or suggested potential implications of the inconsistency. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim made in the paper regarding the relationship between dataset readability and question difficulty, suggesting that this relationship may depend on the method or features used for answer detection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to improve their analysis. The comment implies that the authors should consider the impact of different methods or features on their findings, but it lacks concrete details or actionable steps. As a result, the comment is 3, as it identifies an area for further exploration but does not provide clear instructions on how to proceed.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It questions the dependency of this relationship on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in detailing the issue with the claim, suggesting that the authors should consider the impact of different methods or features on their analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that \"dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty.\" It suggests that this claim may depend on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the suggestion. As a result, the claim is 3, as it highlights a potential issue but lacks sufficient detail or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that this relationship may depend on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it prompts the authors to consider the potential impact of different methods or features on their analysis, which could lead to a more nuanced understanding of the relationship between dataset readability and question difficulty. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional analysis could be conducted. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or which specific aspects of the related work should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the writing and expand the related work section but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper need improvement or where the related work section is lacking. The authors can infer that the writing quality and related work sections are the areas of concern, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space on explaining basic memory networks and the forward model. It also notes a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper: the writing quality and the related work section. It suggests that the authors should improve the writing quality by ensuring that the space allocated to explaining basic memory networks and the forward model is utilized more effectively. Additionally, it points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific guidance or examples on how to enhance the writing quality or which reinforcement learning tasks should be included in the related work section. While it highlights important areas for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of an option) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption is more relevant. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the violation of these assumptions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the replacement of the first column of Qo by vo to form P\"o, explaining how this affects the reachability of the first state. The comment further assumes that either Ass.1 or Ass.2 is violated, providing a clear direction for the authors to investigate and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of an option) is violated. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence renders the claim 3, as the authors would need to infer the relevance of the assumptions and how they relate to the issue at hand. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. It assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of an option) is violated, providing a clear direction for the authors to investigate and address the issue. However, the comment lacks detailed guidance on how to resolve the problem or which assumption is more relevant, leaving the authors with some insight but incomplete feedback. Therefore, the comment is 3, as it highlights a potential issue but could be more comprehensive in its suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is explicit and provides a concrete direction for the authors to explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks detailed reasoning or evidence to support why the authors should focus on these aspects or how they relate to the improvements in the model. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is clear and actionable, offering a direction for the authors to explore and potentially identify improvements in their work. However, the comment could be more helpful if it provided additional guidance on how to analyze or measure these improvements. Overall, the comment is 4 as it directs the authors to consider alternative aspects of their model, but it could be more comprehensive with further details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should verify this assumption, it does not explicitly instruct them to conduct a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to test the assumption but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an important assumption made in the paper, specifically whether d_e are good replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about the testing of this assumption, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. This is a claim that requires verification, as it suggests a potential gap in the paper\"s methodology or results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about an important assumption made in the paper, specifically whether the use of d_e as replacements for entity embeddings has been tested. This is a relevant and timely concern that could significantly impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific tests or evaluations could be conducted to verify the assumption. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the components of the \"scoring function\" and the threshold values/ranges used. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify these aspects, but it does not specify what information should be included or how it should be presented. As a result, the action is implicit and somewhat vague, leaving the authors to infer the necessary steps without clear direction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is unclear: the components of the \"scoring function\" and the threshold values/ranges. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the \"scoring function\" and the threshold values/ranges used. However, it does not provide any specific examples, reasoning, or references to support why this clarity is important or how it affects the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the \"scoring function\" and the threshold values/ranges used. It points out that the authors have not provided sufficient information on how these components were determined, which could be crucial for understanding the methodology and results. However, the comment does not offer any suggestions or guidance on how the authors might address this issue, such as providing additional explanations or examples. While it highlights an important area for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their work. As a result, the comment is 1, as it does not offer any direction for improvement or clarification.", "grounding_specificity_rationale": "The comment raises a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of physical interaction are being questioned or how this might impact the simulation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interaction that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interaction that can be included in one simulation. While it highlights an area of interest, it lacks specificity and does not provide any guidance or suggestions for improvement. The authors are left without actionable feedback on how to address this question or its relevance to their work. As a result, the comment is 2, as it identifies a potential area of interest but does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the model comparison section of the paper. It points out that the selection of datasets is inadequate because only one dataset has categorical features, while the others have exclusively numerical features. This is considered a limitation because categorical features are generally more challenging for deep learning models. Additionally, the authors are criticized for not using onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should consider a more diverse set of datasets and potentially adjust their methodology for handling categorical features. However, the lack of explicit instructions on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model comparison\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, while others have exclusively numerical features. This is a critical point because categorical features are generally considered more challenging for deep learning models. The comment further specifies that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively affect performance for some models. This level of detail provides clear guidance on what needs to be addressed in the model comparison section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison is inadequate due to the selection of datasets, specifically noting that only one dataset has categorical features, while others have numerical features. It suggests that this omission may affect conclusions because categorical features are generally more challenging for deep learning models. The comment also points out that the authors do not use onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This reasoning is logical and based on common knowledge about the challenges of deep learning with categorical features. However, the comment could be strengthened by providing specific examples or references to support the claim about the impact of categorical features on model performance. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the model comparison section of the paper, specifically noting that the selection of datasets is inadequate. It points out that only one dataset has categorical features, while the others are numerical, which could affect the conclusions drawn from the comparison. Additionally, the comment highlights that the authors do not use onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific areas for improvement, such as considering a more diverse set of datasets and adjusting the methodology for handling categorical features. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of datasets that could be included. Overall, the comment is 4, as it effectively guides the authors toward improving their model comparison section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the choice of IoT datasets (FlatCam Face and Headpose detection) is unusual and may make the benchmarking results difficult to evaluate. It suggests that better options for IoT benchmarking could include wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback provides a clear and concrete action for the authors to consider alternative datasets that might improve the comprehensibility and relevance of their benchmarking results. The suggestion is explicit and provides specific examples of alternative datasets, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of IoT datasets, specifically mentioning \"FlatCam Face\" and \"Headpose detection,\" and provides a rationale for why these choices might be problematic. The comment further suggests alternative datasets that could be used for benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, specifically FlatCam Face and Headpose detection, is unusual and may make the benchmarking results difficult to evaluate. The reviewer provides a logical reasoning by stating that the datasets are unpopular and not substantially followed, with the latter being outdated. However, the comment lacks specific examples or references to support the claim that these datasets are not suitable for IoT benchmarking. Additionally, the suggestion to use alternative datasets like wearable health or mobile activity recognition data is not substantiated with evidence or references. Therefore, the claim is 3, as it provides a logical basis but lacks detailed support or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, namely FlatCam Face and Headpose detection. It questions the relevance and popularity of these datasets, suggesting that they may not be the best choices for benchmarking. The reviewer provides a rationale for why these datasets might be problematic and offers alternative options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, as it directs the authors to consider more appropriate datasets for their benchmarking results. However, the comment could be more helpful if it provided specific examples or references to support the claim about the unpopularity of the chosen datasets. Overall, the comment is 4 as it offers constructive feedback for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it implies that the authors should verify this, it does not provide explicit instructions on how to check or correct the figures. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially correct the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also clearly specifies the issue by questioning whether some subfigures have been swapped by mistake. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question asking if some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the potential swapping of subfigures in Figs 1 and 2. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might verify or address this concern. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 1, as it does not contribute to the authors\" understanding of how to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this potential drawback. While the comment highlights an important consideration, it does not provide explicit guidance on how to incorporate this discussion into the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the tradeoff between sensitivity and false positives, but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the improvement in sensitivity and the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this tradeoff. While the comment highlights a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim about the risk of false positives. This makes the claim 3, as it provides a general direction for the authors to consider but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is valuable as it highlights a potential tradeoff in the methodology and encourages the authors to address this issue in their discussion. While the comment identifies an important consideration, it could be more helpful by providing specific suggestions on how to discuss this tradeoff or potential mitigations. Overall, the comment is 3 as it points out a critical aspect of the methodology that needs further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about the regret bound for the proposed minibatch method, as it could not be found in the supplementary material. While the comment highlights a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to verify the claim and potentially revise their paper to include the missing information. However, the comment lacks concrete details on how to implement this action, making it 3. The authors know they need to verify the claim and possibly add the missing information, but they may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method and its absence in the supplementary material. It also provides a specific reference to a related work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which helps the authors understand the context of the issue. This allows the authors to accurately identify the part of the paper being addressed and what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors have stated a claim about the regret bound for the proposed minibatch method, which is not supported in the supplementary material. The reviewer provides a reference to a related work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which suggests that the claim might be based on existing knowledge or literature. However, the comment lacks detailed reasoning or specific examples from the supplementary material to fully substantiate the claim. This makes the claim 3, as it provides a reference but requires more detailed evidence or explanation to be fully convincing.", "helpfulness_rationale": "The review comment points out a discrepancy between the authors\" claim about the regret bound for the proposed minibatch method and the absence of this information in the supplementary material. It references a related work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide context or a basis for the claim. However, the comment does not offer specific guidance on how the authors should address this issue or suggest ways to clarify or correct the claim. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are informed of a potential error but are not provided with detailed steps to resolve it, limiting the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include a discussion and comparison of these methods, but it lacks concrete details on how to execute this action. The authors can infer that they need to add a section discussing these methods, but the comment does not specify which methods to include or how to compare them. Therefore, the comment is 3, as it provides an implicit action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion and comparison, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the relevance of these methods and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This is a critical oversight, as it could impact the paper\"s contribution and relevance. However, the comment lacks specific suggestions on how the authors might address this issue, such as recommending which methods to include or how to compare them. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the clarity and completeness of the paper. It questions whether inference is slowed down and whether there is a way to only do inference, and it asks for the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, it points out the lack of hyperparameter details, which could impact the confidence in the results of the ablation studies. The comment also critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to improve the clarity and completeness of their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the clarity and completeness of the paper, specifically regarding the inference process, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. It also critiques the writing style, stating that it often impedes understanding. While the comment does not explicitly mention specific sections or lines, the authors can infer that it relates to the methodology or results sections, where these issues might be discussed. The comment is specific in detailing what needs to be addressed, such as the coefficient value and the need for hyperparameter details. However, it lacks full grounding as it does not explicitly mention the sections or lines where these issues are discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and concerns about the clarity and completeness of the paper, including the impact of inference, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. While the comment identifies potential issues, it does not provide specific evidence or references to support these claims. The questions posed are logical and reasonable, but the lack of detailed justification or examples makes the claims 3. The comment could be strengthened by providing more context or references to substantiate the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the impact of inference on the model, specifically whether it is slowed down and if there is a way to only do inference. It also asks for clarification on the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, the comment points out the lack of hyperparameter details, which could affect the confidence in the results of the ablation studies. Furthermore, it critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity of the writing. Overall, the comment is 3 as it highlights important areas for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed compression method or suggestions for further analysis or experimentation. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where this issue should be addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the authors might address this weakness. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as a main weakness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a clear and actionable piece of feedback that highlights a critical area for improvement. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the performance of their method. While it points out a significant weakness, it does not offer detailed advice or examples to help the authors enhance their draft. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues with the paper, including the need for subjective statements to be supported by proofs and references, and the sensitivity of image recovery performance to the choice of neural architecture. It also highlights the challenge of multiscale architecture design, specifically the question of when to fuse multiscale features. Additionally, the comment suggests that models with skip connections could be considered as using multiscale information in an implicit way. While the comment identifies several areas that need clarification or explanation, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide detailed explanations and supporting evidence for their claims. Therefore, the comment is 3, as it points out areas for improvement but lacks specific guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the need for subjective statements to be supported by proofs and references, the sensitivity of image recovery performance to the choice of neural architecture, and the challenge of multiscale architecture design. It also mentions the use of models with skip connections as an implicit form of multiscale information. However, the comment does not specify which parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique, it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some subjective statements in the paper are inappropriate and need to be supported by proofs and references. It also highlights the challenges of multiscale architecture design, particularly the question of when to fuse multiscale features. Additionally, the comment suggests that models with skip connections could be considered as using multiscale information in an implicit way. While the comment identifies areas that require further explanation, it lacks specific examples or references to support the claims. The reasoning is 3, as it provides a general framework for addressing the issues, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas that need improvement in the paper, including the need for subjective statements to be supported by proofs and references, and the sensitivity of image recovery performance to the choice of neural architecture. It also highlights the challenge of multiscale architecture design, specifically the question of when to fuse multiscale features. Additionally, the comment suggests that models with skip connections could be considered as using multiscale information in an implicit way, providing a potential direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues or provided more detailed guidance on what kind of proofs or references would be necessary to support the subjective statements. Overall, the comment is 3 as it points out areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data (e.g., Japanese, Chinese, English, Arabic, German) and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. While the comment implies that the authors should explore these analyses further, it does not provide explicit guidance on how to conduct these analyses or what specific observations to look for. The action is implicit and somewhat vague, as the authors can infer that they need to delve deeper into the analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"language/nationality\" and provides specific examples of languages/nationalities included in the data, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the potential for interesting observations by comparing biases towards different languages/nationalities. This level of detail provides clear guidance on what the authors should focus on to improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data and expresses curiosity about potential interesting observations by comparing biases towards different languages/nationalities. However, the comment lacks specific examples or references to support the claim that these analyses could be more detailed or that biases vary significantly. The suggestion is 3 as it provides a general direction for further analysis, but it requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically highlighting the \"language/nationality\" aspect. It points out that the data includes a diverse range of languages/nationalities and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. This feedback is 3 as it identifies a specific area for further analysis and suggests a potential direction for exploration. However, it lacks detailed guidance on how to conduct these analyses or what specific observations to look for, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, and suggests that it is necessary and helpful for the approach design. However, it does not provide explicit guidance or suggestions on how the authors should explore or utilize these properties. The action is implicit, as the authors need to infer that they should consider other properties, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific properties or aspects of the approach design are being questioned. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper this comment addresses. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should explore other properties. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why exploring other properties is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used besides norm, suggesting that it is necessary and helpful for the approach design. While the comment identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or utilize these other properties. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses an expectation for the paper to include a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how the authors should address this expectation. There is no suggestion on which tasks should be included, how to incorporate them, or what specific aspects of PE are relevant. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this expectation relates to, nor does it provide details on what specific tasks or aspects of PE should be included. This makes it difficult for the authors to identify the exact sections that need attention or improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an expectation for the inclusion of various tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not provide any supporting evidence, reasoning, or references to justify why this expectation is relevant or necessary. The lack of justification or explanation makes it difficult for the authors to understand the basis of the expectation, rendering the comment 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on which tasks should be included or how to incorporate them. The comment does not offer actionable advice or suggestions for improvement, leaving the authors without a clear understanding of how to address this feedback. As a result, the comment is 2, as it identifies a potential area for improvement but lacks depth and clarity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. While it does not explicitly instruct the authors to make any changes, it implies that the authors should provide a detailed explanation of how their work differs from these other papers. This inference is clear, and the authors know exactly what action to take to address the comment. The feedback is concrete, as it specifies the need to elaborate on the differences, making it 4.", "grounding_specificity_rationale": "The comment raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where these differences should be discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for elaboration on the differences, but it is 1 as it does not clearly identify the section or context where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not make a claim or provide any subjective opinion, judgment, or suggestion that requires verification. It is a factual question seeking clarification, which aligns with the \"No\" label.", "helpfulness_rationale": "The review comment raises a relevant question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. By asking the authors to elaborate on these differences, the comment encourages the authors to clarify their work\"s unique contributions and how it compares to existing research. This feedback is 3 as it prompts the authors to provide a clearer understanding of their work\"s distinct features and how it aligns with or diverges from other studies in the field. However, the comment could be more helpful if it provided specific examples or references to the works being compared, which would give the authors more direction on how to address the question. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reduce the use of footnotes in the paper, as they are \"very distracting.\" It provides a specific example by mentioning that details around parameter settings could be moved into the appendix, such as the example given at L468. This feedback is clear and actionable, as it directs the authors to make a specific change to improve the readability and structure of their paper. The comment provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes\" and provides a specific example at \"L468,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the extensive use of footnotes and suggests moving important content into the main body of the paper, while details like parameter settings could be moved to the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the extensive use of footnotes is distracting and suggests moving important content into the main body of the paper. However, the comment does not provide specific examples or detailed reasoning to support why the use of footnotes is problematic or how moving content would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the extensive use of footnotes in the paper, which it finds distracting. It provides a clear suggestion to move important content from the footnotes into the main body of the paper, which would improve the flow and readability of the draft. Additionally, it offers a concrete example by mentioning that details around parameter settings could be moved to the appendix. This feedback is actionable and provides the authors with a clear direction for improving their draft. However, it could be more helpful if it included additional suggestions on how to integrate the content effectively or addressed potential implications of this change. Overall, the comment is 4, as it offers valuable guidance for enhancing the paper\"s structure and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations would be beneficial and that a discussion about this would be appreciated. It also questions the inclusion of zeroshot generation results, suggesting that it might be unnecessary. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The suggestions are implicit and somewhat vague, leaving the authors to infer that they should consider including fewshot demonstrations and discussing their relevance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a set of fewshot demonstrations\" and \"zeroshot generation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as the inclusion of fewshot demonstrations and the discussion of their relevance. Additionally, the comment questions the inclusion of zeroshot generation results, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results is \"a bit strange\" and questions their relevance. However, the comment does not provide specific reasoning or evidence to support this claim, such as why the results are unnecessary or how they might be misleading. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting the inclusion of a set of fewshot demonstrations, which could enhance the paper. It also questions the inclusion of zeroshot generation results, suggesting that they might not be necessary. However, the comment lacks specific guidance on how to implement the suggested fewshot demonstrations or why the zeroshot results are unnecessary. While it provides some insight into areas for improvement, the feedback is incomplete and does not offer detailed actionable suggestions. Therefore, the comment is 3, as it points out potential enhancements but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference 2. While it implies that the authors should investigate this aspect, the comment does not provide explicit instructions or concrete steps on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of the GS module on the receptive field. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effective receptive field and suggests that it could be computed from reference 2. This provides clear guidance on what aspect of the GS module needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the suggestion to compute the effective receptive field. Without additional context or justification, the claim remains 1, as the authors would need to infer or seek further information to address the question. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the effective receptive field of the GS module, suggesting that it could be computed from reference 2. This prompts the authors to explore and potentially discuss the impact of the GS module on the receptive field, which could be a valuable addition to the paper. However, the comment lacks specific guidance on how to compute or discuss this aspect, leaving the authors with a general direction but not a detailed path forward. While it provides some insight, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the time complexity. The authors are left to infer that they should consider optimizing the method or reducing the computational cost, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the potential issues with the time complexity, such as the association of many users with a typical item and the expense of the elementwise function. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method seems high, citing three specific reasons: the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment provides a logical breakdown of potential issues, it lacks specific examples or references to support the claim about the time complexity. This makes the claim 3, as the authors would need to further investigate and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback highlights areas where the authors might need to optimize their approach to improve efficiency. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative methods or techniques for reducing computational complexity. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a direct and concrete action for the authors to take, which is to modify the figure labels to include this clarification. The suggestion is explicit and clear, giving the authors a precise step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many of the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the figures by specifying \"pretrained solution encoders & solution decoders,\" which would help differentiate between multiple types of autoencoders. This feedback is actionable and provides a clear direction for the authors to enhance their figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is based on a logical reasoning that specifying the type of encoders and decoders would enhance clarity. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact changes required to improve the figures based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. By recommending that the figures specify \"pretrained solution encoders & solution decoders,\" the reviewer helps the authors differentiate between multiple types of autoencoders, which could enhance the understanding and interpretation of the results. This feedback is clear and actionable, offering a direct way for the authors to enhance the clarity and readability of their figures. However, the comment could be more helpful if it provided additional context or examples of how this change would impact the overall understanding of the paper. Overall, the comment is 4, as it provides a constructive suggestion for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two specific comparisons that the authors should consider: one with NeRFbased methods, such as Zero1to3, and another with pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment implies that these comparisons and the evaluation of the occlusion experiment are necessary, it does not explicitly instruct the authors to make these changes. The actions are inferred and somewhat vague, as the authors need to determine how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not specify which part of the paper these suggestions should be made in, such as the methodology or results sections. While the authors can infer that these suggestions relate to the experimental setup or methodology, the comment lacks full grounding as it does not explicitly mention specific sections. The suggestions are specific, as they provide clear guidance on what comparisons should be made and why the occlusion experiment might be irrelevant. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how the occlusion experiment is irrelevant. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment provides some direction for improvement, it lacks depth and does not offer specific guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out areas for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide information about the computation required to implement the experiments, including the time taken and the hardware used. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is explicit and concrete, as it specifies exactly what information should be included in the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment asks for information about the computation required to implement the experiments, including the time taken and the hardware used. However, it does not specify which part of the paper this information should be included in, such as the methods or results section. This makes it difficult for the authors to pinpoint the exact location where this information should be added. The comment is specific in its request for additional details but lacks grounding, as it does not direct the authors to a specific section of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements and duration of the experiments, along with the hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computational requirements and duration of the experiments, as well as the hardware used. While it identifies a gap in the paper regarding the experimental setup, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a clear understanding of what is missing but without actionable steps to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and report on the model\"s performance under imperfect data conditions. However, the question itself is clear, and the authors know what aspects to explore. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to address this concern. The comment is specific in its inquiry but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It is purely a question seeking clarification, which does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the model when dealing with imperfect multimodal data, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors being constructed. This question is relevant and timely, as it addresses a potential limitation of the model that could impact its performance and applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or conduct further analysis. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the lack of verification of the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OGEAug\" and the \"DrugOOD\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not verifying the stability of OGEAug on OOD benchmarks, such as DrugOOD, and references SPE 2 for validation on this dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset. The comment references SPE 2 as a validation on this dataset, implying that the authors should have done the same for OGEAug. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out a potential gap in the paper, the lack of detailed justification or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of verification of the stability of the OGEAug on OOD benchmarks, such as the DrugOOD dataset. It references SPE 2 as a validation on this dataset, suggesting that the authors should have done the same for OGEAug. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide additional validation to strengthen their work. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct this validation. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting multiple seed experiments to provide a more robust evaluation of the performance differences and the impact of the proposed cycle consistency loss on convergence. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the robustness of their evaluation. The comment provides concrete guidance on how to enhance the experimental setup, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of single seed experiments, which is a specific aspect of the paper\"s methodology. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss. The comment suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it logically reasons that multiple seed experiments would offer a more comprehensive assessment of the model\"s performance and the impact of the proposed loss. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experimental setup, specifically the use of single seed experiments. It highlights the importance of conducting multiple seed experiments to provide a more robust evaluation of the performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and actionable, as it directly suggests a method to enhance the robustness of the evaluation, which is crucial for assessing the significance of the results. However, the comment could be more helpful if it provided additional guidance on how to implement multiple seed experiments or what specific aspects of the evaluation might be affected by this change. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it raises a concern about the lack of clarity in the motivation, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the reasoning behind their choice of distributions, but it does not specify what additional information or explanation would be necessary. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper discusses these distributions, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its request for clarification on the motivation but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. This is a relevant concern that could help the authors clarify their methodology and provide a clearer rationale for their choices. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires a multiGPU setup for optimizations, which may limit its accessibility to many potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or suggest alternatives that could make the method more accessible. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the accessibility of the proposed method, specifically mentioning the requirement for a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this requirement, making it weakly grounded. The comment is specific in identifying the issue of accessibility but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires a multiGPU setup for optimizations, which limits its accessibility to many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically noting that it requires a multiGPU setup for optimizations, which may limit its accessibility to many potential users. This feedback highlights a critical issue that could impact the practicality and usability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or make the method more accessible. Without actionable advice or potential solutions, the feedback is 3 as it points out a significant issue but lacks depth and direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further suggests using Ref2 as a strong baseline for comparison. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare the systems and use Ref2 as a baseline. However, the suggestion to improve is concrete, as it provides a specific reference for comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also mentions Ref2 as a potential strong baseline for comparison. However, the comment does not specify which part of the paper this suggestion should be applied to, nor does it provide detailed guidance on how to conduct the comparison or what specific aspects should be evaluated. The authors can infer that it relates to the experimental or results sections, but the lack of explicit grounding and specificity makes it challenging for them to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further suggests using Ref2 as a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further recommends using Ref2 as a strong baseline for comparison. This feedback is 3 as it provides a direction for the authors to improve their draft by considering additional comparisons that could enhance the evaluation of their system. However, the comment lacks specificity and does not offer detailed guidance on how to conduct these comparisons or what specific aspects should be evaluated. While it identifies a potential area for improvement, it does not provide enough detail to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. While it identifies an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete details on what specific information should be included or how the authors should present their data. As a result, the authors are left with an implicit action to clarify the data usage, but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its request for clarification on the data usage but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual inquiry that seeks clarification rather than an opinion or suggestion. It does not contain any subjective claims or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a critical issue regarding the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. This is an important point that the authors need to address to ensure transparency and reproducibility of their findings. However, the comment lacks specific guidance or suggestions on how the authors might clarify this information, such as recommending the inclusion of specific data sets or methodologies. While it highlights a significant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the model\"s performance in identifying true sources in the triangle dataset, asking if one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their model. The questions are implicit and lack concrete details on what actions the authors should take to resolve the problem. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the model\"s performance in identifying true sources in the triangle dataset, asking if one of the assumptions is not satisfied or if there are learning difficulties. However, it does not specify which part of the paper discusses the model\"s performance or the assumptions being referred to. The authors might infer that it relates to the results or methodology sections, but this is not explicitly stated. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. While it identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions for improvement. The authors are left with a vague understanding of what might be causing the problem and how to address it. Without detailed feedback or examples, the comment does not offer much value in helping the authors improve their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without significant difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific changes should be made to the approach. The comment lacks concrete details or suggestions, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without too much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the approach\"s limitations but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without significant difficulty. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach being restricted to only two views, suggesting that the system should be able to generalize to more views without significant difficulty. This is a valid point that could prompt the authors to consider expanding their approach to multiple views. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this limitation or what specific changes could be made to improve the generalizability of the system. Without detailed suggestions or examples, the feedback is 3 as it identifies an area for potential improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors need to infer that they should clarify or justify the current approach. However, the comment lacks concrete details on how to implement this change or what specific information should be included. Therefore, the comment is 3, as it points out an area for clarification but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the methodology but lacks grounding, as it does not provide a clear reference to the relevant section of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s reliance on information only up to time step t from the agent decoder, suggesting that it should use information from all time steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the overall performance or understanding of the model. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, suggesting that it should use information from all time steps. This feedback identifies a potential limitation or inconsistency in the methodology, prompting the authors to reconsider their approach. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this issue or why it might be beneficial to use information from all time steps. While it highlights an area for improvement, the feedback is incomplete and could be more helpful with additional guidance or context. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to include this discussion in their paper. The comment is specific about what needs to be addressed, offering concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion on arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set \u03b3 in practice for a given graph and the analysis of its sensitivity. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which would make it difficult for researchers to follow. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why this discussion is crucial. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of this discussion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion regarding the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the analysis of its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs attention to enhance the comprehensibility and usability of the paper. By addressing this gap, the authors can provide valuable insights for researchers interested in applying the methodology. However, the comment could be more helpful if it offered specific suggestions on how to approach this discussion or examples of similar analyses in related work. Overall, the comment is 4, as it directs the authors to a key area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment explicitly suggests the need for a controlled baseline, it does not provide specific guidance on how to implement this or what specific locations should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of induction heads and FV heads appearing at different locations within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include a controlled baseline is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. The reviewer implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment provides a logical reasoning for the potential confounding factor, it lacks specific examples or references to support the claim. The suggestion for a controlled baseline is a reasonable one, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the claim is 3, as it requires additional evidence or explanation to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the experiment, specifically the location of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline should be included to ablate heads at different locations in the model. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a way to control for this potential confounding factor. However, the comment could be more helpful if it offered additional guidance on how to implement this controlled baseline or what specific locations should be tested. Overall, the comment is 4 as it offers a valuable insight and a concrete suggestion for enhancing the robustness of the experiment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, which is to add a section on synonym identification. The comment is explicit and concrete, as it specifies exactly what needs to be included in the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, which allows the authors to accurately identify the part of the paper that needs attention. It specifies what is missing, namely a description of how the multiplechoice task is approached, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it directs the authors to include a section that would describe how the multiplechoice task is approached. By addressing this gap, the authors can enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided suggestions on what aspects should be included in this section or how it could be integrated into the existing structure. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. However, it does not specify what this overview should include or how it should be presented. The action is implicit, as the authors need to infer that they should add an overview section, but it is vague because it lacks concrete details on what this overview should cover. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a comprehensive understanding of the work. However, it does not specify which part of the paper this overview should be included in, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding what aspects of the workflow and model should be included in the overview. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would improve the comprehensibility of the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. This is a clear and actionable suggestion that could help the authors improve the clarity and accessibility of their paper. However, the comment lacks specificity regarding what aspects of the workflow and model should be included in the overview, which could be a limitation. Despite this, the feedback is still 4 as it directs the authors to a specific area for improvement. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, as the expected quantities are scalars but are shown as vectors. This feedback is clear and direct, providing a specific action for the authors to take. The comment also specifies the issue, which is the inconsistent representation of scalar quantities as vectors in the figure. This level of detail ensures that the authors know exactly what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are shown as vectors. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the quantities in Figure 3 should be represented as scalars instead of vectors, as they are expected to be scalar values. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out an inconsistency in the representation of quantities in Figure 3, noting that scalar values are shown as vectors. By suggesting a redefinition of the figure to accurately represent the quantities, the comment offers a clear path for the authors to enhance the presentation and clarity of their work. This feedback is direct and helpful, as it guides the authors toward a specific improvement that can enhance the overall quality of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects should be addressed. The comment implies that the authors should consider revising their experimental design, but it lacks concrete details or actionable steps. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the experiment setup are problematic or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide any specific details or examples to support this claim, such as which aspects of the experiment setup are problematic or how they could be improved. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects should be addressed. The comment raises questions but lacks actionable feedback, leaving the authors with a general idea of what might need attention but without a clear path for improvement. As a result, the comment is 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for more empirical evidence without detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further, which implies a specific area of the paper that needs attention. However, the comment does not explicitly mention which part of the paper discusses this claim, making it weakly grounded. The comment is specific in detailing what is missing, namely empirical evidence to test the hypothesis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations of lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request for additional evidence. However, the comment does not provide specific examples or references to substantiate the claim, making it 3. The authors would need to infer the importance of empirical evidence and how to address it, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what types of evidence would be most relevant. Additionally, it mentions that the explanation of improvements is not clear, which is another area for improvement. While the comment highlights important areas for enhancement, it lacks detailed guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to the numerous lines overlapping, suggesting that the authors could improve clarity by reporting additional metrics such as flops or model size. While the comment implies that the authors should include these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional metrics but may not be entirely sure of the specific metrics to report. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting the difficulty in understanding due to overlapping lines, and suggests that reporting additional metrics like flops or model size would improve the clarity. This provides clear guidance on what needs to be addressed to enhance the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the numerous lines overlapping and suggests that reporting additional metrics like flops or model size would improve the clarity. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are necessary or how they would enhance understanding. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of these metrics themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the numerous lines overlapping make it difficult to understand. It suggests that reporting additional metrics such as flops or model size would improve the clarity and concreteness of the figure. This feedback is clear and actionable, providing the authors with a direct suggestion for enhancing the presentation of their results. However, the comment could be more helpful if it offered specific guidance on how to present these metrics or suggested alternative visualizations. Overall, the comment is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any explicit or implicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks actionable advice or suggestions, leaving the authors without a clear understanding of what needs to be done to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which questions or sections are being referred to, making it difficult for the authors to identify the exact parts of the paper that need attention. This lack of specificity and grounding makes it challenging for the authors to determine what needs to be addressed, resulting in a comment that is 1 and highly unspecific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or context to support this claim. Without detailed information on what details are missing, the authors may find it challenging to address the issue. The comment lacks verifiable evidence or reasoning, making it difficult for the authors to understand and respond to the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any specific guidance or suggestions on what these missing details are or how the authors might address them. Without actionable feedback or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance their draft. This lack of specificity and guidance makes the comment unhelpful, as it does not provide any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take: they should clarify the meaning of the columns in the figure by adding an explanation in the text or caption. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment suggests that the columns are not explained in the text or caption, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing due to unclear column meanings, which is not explained in the text or caption. This is a subjective opinion based on the reviewer\"s interpretation of the figure. While the comment highlights a potential issue, it lacks specific details or examples to support the claim, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns, which is essential for the reader\"s understanding of the figure. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the column meanings or offered examples of how to improve the figure\"s explanation. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations for the observed results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to identify the exact section being addressed. The comment suggests that more explanations are needed, but it does not provide specific guidance on what aspects of the results or methods should be clarified. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any specific reasoning or evidence to support why these results are unexpected or how they compare to the mentioned methods. Without additional context or references, the claim lacks sufficient justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue with the results, it lacks specific guidance or suggestions on how the authors might address this concern or provide additional explanations. The feedback is 3 as it points out a potential area for improvement, but it does not offer detailed actionable advice, making it incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it or suggest specific components that should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct an ablation analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for ablation analysis, but without clear grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. This is a valid observation, as ablation analysis is a common method used to understand the contribution of individual components to the overall performance. However, the comment does not provide specific examples or references to support why the lack of ablation analysis is problematic or how it affects the interpretation of the results. While the claim is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to determine the source of the small performance gain. This is a critical observation that can help the authors improve their draft by suggesting a necessary addition to enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided specific suggestions on how to conduct the ablation analysis or which components to focus on. Despite this, the feedback is clear and actionable, making it 4 for the authors. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, such as revising the experimental design, providing additional data, or clarifying the results. Without any guidance or direction, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"CNN experiments\" but does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what makes the experiments not fully convincing. The authors cannot confidently determine which experiments are being referred to or what aspects need improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on what aspects of the experiments are lacking or how they could be improved. Without detailed guidance or actionable advice, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable feedback makes the comment unhelpful, as it does not provide the authors with a meaningful way to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the results with the current stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies a particular model to compare with, which gives the authors a concrete step to take in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with the current stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or the discussion. This lack of explicit reference to a specific section makes it weakly grounded, as the authors cannot confidently determine where to address the suggestion. The comment is specific in suggesting a particular model for comparison, which is a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with the current stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The comment lacks specific details or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison with current stateoftheart (SoTA) approaches, such as the HateXplain models. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by benchmarking their results against established models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s impact. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection and suggests that if the adaptive method is good, it could be used instead. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors to infer that they should reconsider their approach to MLS selection. Since the comment lacks concrete details on how to implement the suggested change, it is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or freezing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in questioning the rationale behind the use of freezing, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS (Maximum Likelihood Subset) selection and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be better or why freezing is not appropriate. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using freezing in MLS (Maximum Likelihood Subset) selection, suggesting that if the adaptive method is good, it could be used instead. This feedback identifies a potential area for improvement by questioning the choice of method and encouraging the authors to consider alternative approaches. However, the comment lacks specific guidance or suggestions on how to address this issue or what alternative methods might be more suitable. While it points out a potential weakness, it does not provide detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests performing a specific analysis similar to existing work that combines text and KG. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the type of analysis to perform, but it lacks directness in terms of action. The authors can infer that they need to conduct this analysis, but the comment could be more explicit in its guidance. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests performing an analysis similar to existing work that combines text and KG. It references a specific paper (https://arxiv.org/abs/2104.06378) and suggests a specific analysis to be conducted on the proposed model. However, it does not explicitly mention which part of the paper this issue or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular analysis to be performed, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests performing an analysis similar to existing work that combines text and KG. The comment references a specific paper (https://arxiv.org/abs/2104.06378) as an example of closelyrelated analyses, such as adding negation or changing entities in text to see if the KGaugmented method can robustly handle them. This provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed model might address these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a pertinent question about whether the issue addressed in the paper is resolved by the proposed knowledgeCLIP model. It references existing work that combines text and KG, suggesting that the authors perform a similar analysis on their proposed model. This feedback is valuable as it encourages the authors to consider additional analyses that could strengthen their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the existing work should be adapted. Overall, the comment is 4 as it offers a clear direction for further exploration, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but lacks a comprehensive discussion on the computational complexity. The reviewer suggests that the paper should include a more detailed discussion on this aspect. While the comment implies that the authors should expand their discussion on computational complexity, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detail but are not given concrete steps on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically questioning the lack of a comprehensive discussion on the computational complexity of the proposed approach. It mentions that the paper mentions the additional cost not leading to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on this aspect and wonders if the proposed approach becomes prohibitive in some settings. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion of computational costs or the methodology section. The comment is specific in its request for a more comprehensive discussion on computational complexity, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of a comprehensive discussion on the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on computational complexity and wonders if the proposed approach becomes prohibitive in some settings. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the computational cost is a significant concern. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is considered 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s discussion of computational cost, noting that while the paper mentions the additional cost does not lead to significant delays, it lacks a comprehensive discussion on the computational complexity of the proposal. The reviewer suggests that the paper should include a more detailed discussion on this aspect and questions whether the proposed approach becomes prohibitive in certain settings. This feedback is 3 as it points out a gap in the paper\"s discussion and encourages the authors to provide more detailed analysis. However, it could be more helpful if it offered specific suggestions on how to address the issue or provided examples of what a comprehensive discussion might entail. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more clarity on how novel values in the test set are handled. This is an explicit action that the authors can take to improve their draft. The comment is specific in its request, providing a clear direction for the authors to enhance the clarity of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining how novel values in the test set are handled. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more clarity on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending that the authors explain how novel values in the test set are handled. This feedback is actionable and directs the authors to a particular area where additional detail could enhance the comprehensibility of their work. However, the comment could be more helpful if it offered additional context or examples of how this explanation might be integrated into the paper. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point mentions that similar methods have already been proposed for multitask learning and notes that this has not been discussed in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper should be revised. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that similar methods have already been proposed for multitask learning and notes that this has not been discussed in the paper. However, it does not specify which part of the paper should include this discussion or which specific methods are being referred to. The authors can make an educated guess that it relates to the methodology or literature review sections, but the comment lacks full grounding. It is specific in pointing out the omission of discussing similar methods, but without explicit references or detailed guidance, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and have not been discussed in the paper. However, it does not provide any specific examples or references to these existing methods, making it difficult for the authors to understand the basis of the claim or how to address it. Without supporting evidence or detailed information, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that similar methods for multitask learning have already been proposed and are not discussed in the paper. This is a relevant observation that could help the authors improve their draft by ensuring they are aware of existing work in the field and potentially incorporating it into their discussion or methodology. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or integrate the existing methods into their work. While it highlights an important area for consideration, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of experimental results, specifically questioning why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects they should focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the experimental results, questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing what is missing, namely an indepth analysis of the experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of indepth analysis on experimental results, specifically questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of indepth analysis of experimental results. It provides a clear example of what is missing by questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. This feedback is actionable as it directs the authors to conduct a more detailed analysis of their experimental results, which could enhance the understanding and validity of their findings. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should ensure the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how to implement this action, such as which specific resources should be matched or how to conduct the tuning. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting a way to improve the comparison, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. This claim is 3 as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim. The reviewer mentions \"temperature, penalty, and threshold\" as examples of hyperparameters, which provides some context, but more detailed justification or evidence would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically the extensive hyperparameter search and the need for a fair comparison with the baseline. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could be important for a fair comparison. This feedback is 3 as it highlights a critical aspect of experimental design and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct the tuning or which resources should be matched. Overall, the comment provides valuable insight but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that the absence of standard deviations makes it difficult to assess the significance of the results. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of standard deviations or offering alternative methods for evaluating significance. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual observation that does not require additional evidence or justification, as it is a straightforward critique of the presentation of the results. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the absence of standard deviations makes it challenging to assess the significance of the findings. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations. However, the comment could be more helpful if it offered additional guidance on how to interpret or present the results with standard deviations. Despite this, the comment is 4 as it directs the authors to a critical aspect of their experimental presentation that needs attention. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived weakness in the analysis, specifically regarding the theoretical work on sampling and particlebased optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more theoretical justification but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical work on sampling and particlebased optimization methods,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issues with the analysis, such as the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and guarantees of discretization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" in light of theoretical work on sampling and particlebased optimization methods. It specifically points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. While the comment identifies a potential weakness, it does not provide specific examples or references to support the claim, making it 3. The authors would need to explore the theoretical work mentioned to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of weakness in the paper, namely the lack of theoretical analysis regarding the sampling and particlebased optimization methods. It highlights the absence of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. This feedback is clear and actionable, as it directs the authors to strengthen their theoretical foundation by addressing these gaps. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the theoretical analysis. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the realism of the generated images or suggestions for further experimentation or analysis. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the image quality but lacks grounding, as it does not provide a clear reference to the specific sections or figures being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the realism of the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights a potential weakness in the paper, prompting the authors to consider improving the realism of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how to enhance the realism of the generated images. Without actionable advice or examples, the authors may find it challenging to address this issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with the statement in lines 559560, indicating that the claim made is not entirely true. It provides a clear and concrete suggestion by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This feedback is explicit and provides a direct action for the authors to take, which is to correct the statement in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that the claim made is not entirely true and providing an alternative explanation for the Cycle Consistency loss. This level of detail helps the authors understand what needs to be corrected in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific counterexample by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This detailed explanation supports the claim, making it 5. The reviewer has provided a clear and logical reasoning to substantiate the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement in lines 559560, indicating that it is not entirely true. It provides a clear and detailed explanation by suggesting that in Cycle Consistency loss, one can iterate between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This feedback is actionable and provides the authors with a precise direction to correct their draft. By offering a specific alternative explanation, the comment empowers the authors to make a meaningful improvement to their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use the correct term \"hyperspectral imaging.\" The comment provides a concrete action for the authors to take, ensuring they use the correct terminology in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and providing a definition of hyperspectral imaging. This feedback is clear and actionable, guiding the authors on how to improve their terminology. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. This claim is supported by the explanation of what hyperspectral imaging entails, which helps the authors understand the issue. However, the comment does not provide specific examples or references to further substantiate the claim. While the reasoning is clear, the lack of additional evidence or examples makes the claim 4. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, pointing out that \"hyperspectral\" is confusing and providing a clear explanation of what hyperspectral imaging is. This feedback is actionable and provides a precise suggestion for improvement, helping the authors to correct their terminology and enhance the clarity of their work. By addressing this issue, the authors can improve the accuracy and readability of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the role of visual information in the paper, specifically questioning the effectiveness of the ablation study in verifying the contribution of the knowledgegraph memory and visualdriven reasoning. It highlights that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it suggests that the improvements observed are unlikely to be significant given the sample size of 1000 users. While the comment identifies areas of concern and potential issues with the experimental results, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the role of visual information and potentially conduct further experiments or analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the ablation study, particularly regarding the role of visual information, and highlights the similarity in performance between \"w/o perception module\" and \"w perception.\" Additionally, it points out the lack of implementation details for \"w/o perception\" and questions the significance of the improvements given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific details from Table 10, noting that the performance of \"w/o perception module\" and \"w perception\" is similar, and that the implementation details of \"w/o perception\" are unknown. Additionally, it suggests that the improvements observed are unlikely to be significant given the sample size of 1000 users. While the comment provides some evidence and reasoning, it lacks specific references or detailed examples to fully substantiate the claim. The reasoning is 3, as it highlights potential issues with the experimental design and results, but it could be strengthened with more detailed analysis or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it raises concerns about the significance of the improvements observed, given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas where the authors need to clarify and improve their experimental design and results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending additional experiments or analyses. Overall, the comment is 4, as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This feedback is explicit in its request for the authors to include these references for a more comprehensive comparison. However, it does not provide detailed guidance on how to incorporate these references or what specific aspects of the previous works should be discussed. While the action is clear, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of citation or comparison with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper fails to cite or compare with previous works on Lasso screening, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" This claim is supported by the explicit mention of a specific reference, which provides a clear basis for the critique. The reviewer has identified a gap in the literature review, making the claim 4. However, the comment could be strengthened by providing more context or explaining why these references are relevant to the discussion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening. The reviewer provides a specific reference, Ren et al. \"Safe feature screening for generalized LASSO,\" which is relevant to the discussion. This feedback is clear and actionable, as it directs the authors to include these references for a more comprehensive comparison, thereby enhancing the validity and depth of their analysis. However, the comment could be more helpful if it suggested how to integrate these references or what aspects of the previous works should be discussed. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to clarify or correct the notation. The action is implicit, as the authors need to infer that they should clarify the notation, and it is somewhat vague, as it does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results\" and the specific claim about the improvement for CIFAR10, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, namely the unclear meaning of \"%p.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the notation for results is unclear, specifically questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation for results, pointing out that the paper claims an improvement of 3%p for CIFAR10 but does not clarify what \"%p\" stands for. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results section. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered examples of how similar issues have been addressed in other papers. Despite this, the comment is 4 as it highlights a critical area for improvement that can enhance the clarity and transparency of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text, rather than human reading comprehension. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on what needs to be changed, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should be clarified to distinguish between machine comprehension of text and human reading comprehension. The comment provides a clear direction for improvement by suggesting how to clarify the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to distinguish between machine comprehension of text and human reading comprehension. The reviewer provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" typically refer to human reading abilities, not machine comprehension. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it could be clarified to distinguish between machine comprehension of text and human reading comprehension. This is a clear and actionable suggestion that could help the authors improve the clarity and specificity of their title. By making this distinction, the authors can ensure that their work is accurately represented and understood by the audience. However, the comment could be more helpful if it provided additional context or examples of how to make this distinction. Overall, the feedback is 4 as it offers a specific and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should switch to a human metric, but the comment lacks concrete details on which human metric to use or how to implement the change. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"human evaluation\" and \"style control,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using an automatic metric (TSS) instead of a human metric, which weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. The comment provides a logical reasoning by pointing out the potential weakness in using an automatic metric for human evaluation, which is a valid concern. However, it lacks specific examples or references to support the claim that a human metric would be more appropriate or effective. This makes the claim 3, as the authors would need to consider the reasoning and potentially conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. This feedback highlights a specific area where the evaluation methodology could be improved, providing the authors with a clear direction for enhancing the credibility and effectiveness of their human evaluation. However, the comment could be more helpful if it offered specific suggestions on which human metrics to use or how to implement them. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for results and the limited evaluation on only two datasets, which are standard in the RNP community. It provides specific references to external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing, such as confidence intervals and additional datasets. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not provide confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment supports these claims by referencing external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. These references provide a basis for the claim that the evaluation could be more comprehensive. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of confidence intervals affects the interpretation of results. Overall, the claim is 4, as it provides some support but could be further substantiated with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. This feedback is clear and actionable, as it directs the authors to include confidence intervals and expand their evaluation to more datasets, potentially using the referenced works as benchmarks. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or suggestions. Overall, the comment is 4, as it offers valuable insights for improving the paper but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this training process is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the training losses should be included or how they would address the question of stability. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not provide any supporting evidence, reasoning, or references to justify why the stability of the training process is a concern or why training losses are necessary. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While it identifies a potential area of concern, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for improving the stability or provide examples of how training losses could be presented. As a result, the authors are left with a vague understanding of what needs to be improved, making the comment 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, which are claimed to be distinct but are actually the same concept from different viewpoints. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the claims. The action is implicit and vague, as the authors are left to infer that they need to revise their claims but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the paper\"s claims, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis. It supports this claim by explaining that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This logical reasoning provides a clear explanation of why the claim is valid, making the comment 4. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that several aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, are actually the same concept viewed from different perspectives. This feedback is clear and actionable, as it prompts the authors to revisit and clarify their claims to ensure accuracy and avoid overstatement. However, the comment could be more helpful if it provided suggestions on how to rephrase or reorganize the theoretical analysis to better align with the actual contributions. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should investigate the impact of this sampling rate on the comparison with other methods, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as references to specific experiments or data that demonstrate this issue. Without additional context or examples, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. This observation is relevant and could impact the validity of the results presented in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparisons. While it highlights a critical area for consideration, the feedback could be more actionable and helpful by providing concrete steps or recommendations for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The reviewer implies that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative methods they could use. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It suggests that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or where this issue is addressed, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the choice of focal loss but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The reviewer provides a logical explanation of why focal loss might be problematic in this context, noting that it has lower gradients on easy samples, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It points out that focal loss is typically used to address class imbalance problems in classification tasks, but its properties may not be suitable for regression tasks. The comment suggests that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. This feedback is 3 as it identifies a potential issue with the methodology and encourages the authors to consider the appropriateness of their choice. However, it lacks specific suggestions or examples of alternative methods that could be used, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors might investigate this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is a relevant concern for the authors, as understanding how their method performs under varying conditions can impact its applicability and robustness. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the authors are left with a general question that, while important, does not offer a clear path for improvement. Therefore, the comment is 3, as it identifies a potential area of concern but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This is an explicit action that provides a clear direction for the authors to follow. However, the comment lacks specific guidance on which datasets to use or how to integrate them into the study. While the action is explicit, the lack of concrete details makes it 3. The authors know they need to include more datasets but may not be entirely sure of the exact steps to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion should be implemented in, such as the methodology or results section. The authors can infer that it relates to the evaluation or experimental setup, but this inference is not direct. The comment is specific in suggesting additional datasets, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning or evidence to support why these specific datasets are necessary or how they would enhance the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a potential area for improvement by suggesting additional datasets that could enhance the study. However, the comment lacks specific guidance on which datasets to use, how to integrate them, or why these datasets are particularly relevant. While it provides a direction for expansion, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should have been included in Section 4.1. This provides a clear and direct action for the authors to take, which is to add the missing implementation details to the specified section. The comment is explicit and concrete, offering a specific step for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking implementation details of the proposed methods, which should be described in the implementation details section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why these details are crucial. The comment lacks evidence or justification, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods. It suggests that these details should have been included in Section 4.1, providing a clear and actionable piece of feedback. By pointing out this omission, the comment helps the authors to focus on a critical aspect of their work that needs improvement. However, the comment could be more helpful if it offered suggestions on how to present these implementation details or provided examples of what should be included. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant lack of empirical evaluation and comparison with other methods, which makes it difficult to assess the practical value of the contribution. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment identifies a critical issue with the paper, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to conduct empirical evaluations, comparisons with other methods, and provide theoretical arguments for the significance of their contribution. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it 3. The authors know they need to address the lack of empirical evaluation and theoretical justification but may struggle with the specifics of how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to identify the specific parts of the paper that need attention. It also specifies the issues, such as the absence of practical value and the need for theoretical arguments, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment highlights significant gaps in the paper, it does not provide specific examples or references to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It highlights that the absence of such evaluations makes it difficult to assess the practical value of the contribution. The comment also points out the need for theoretical arguments to justify the significance of the contribution. While the feedback is clear about the weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment is 3 as it directs the authors\" attention to important areas for improvement but lacks actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to resolve this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this clarification. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be clarified or corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used inconsistently in the manuscript, sometimes representing a probability and other times a cumulative distribution function. The reviewer provides specific examples by referencing equations (3) and (4) and line 44 in the appendix, which helps to substantiate the claim. This level of detail provides a clear basis for the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by explaining why this inconsistency is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the inconsistent use of the symbol \"P\" to represent both a probability and a cumulative distribution function. It provides examples from the paper, such as Eqs. (3) and (4) and L44 in the appendix, which helps the authors pinpoint the exact locations of the confusion. This feedback is clear and actionable, as it directs the authors to clarify the usage of \"P\" to avoid confusion. However, the comment could be more helpful if it suggested specific ways to resolve the issue, such as recommending a consistent notation or providing examples of how to clarify the distinction between probability and cumulative distribution functions. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and consistency of their manuscript."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the understanding of how neural nets learn natural rare spurious correlations and notes that most analyses and ablation studies use artificial patterns instead. It points out that duplicating artificial patterns is different from natural spurious features, which are complex and varied. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they should focus on natural spurious correlations but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the issue of neural nets learning natural rare spurious correlations, noting that most analyses and ablation studies use artificial patterns instead. It highlights the difference between duplicating artificial patterns and natural spurious features, which are complex and varied. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or experiments, making it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing the issue but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the community lacks understanding of how neural nets learn natural rare spurious correlations and that most analyses use artificial patterns instead. The reviewer provides a logical reasoning by explaining the difference between artificial and natural spurious features, noting that natural ones are complex and varied. However, the comment lacks specific examples or references to support the claim about the community\"s understanding or the prevalence of artificial patterns in analyses. This makes the claim 3, as it provides a logical basis but requires further evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment highlights a gap in the understanding of how neural nets learn natural rare spurious correlations, noting that most analyses and ablation studies use artificial patterns instead. It points out the difference between duplicating artificial patterns and natural spurious features, which are complex and varied. This feedback is 3 as it identifies a potential area for improvement in the analysis and suggests a direction for further exploration. However, it lacks specific guidance or suggestions on how the authors might address this issue or conduct their analysis differently. To be more helpful, the comment could provide examples or recommendations for incorporating natural spurious correlations into the study. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~1 and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this limitation or explore new applications. The action is implicit and vague, as the authors are left to infer that they should consider broader applications but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in applying the method to general MDPs, specifically mentioning navigation problems. It also references PRMRL~1 as a related work that has already discussed combining RL and planning. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the limitation and suggesting a potential area for further exploration, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper is limited to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL~1. The comment provides a reference to an existing work, which supports the claim by indicating that the idea is not novel. However, the comment could be strengthened by providing more detailed reasoning or examples of how the paper\"s method is limited or how it relates to PRMRL~1. This would make the claim more 5. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is primarily focused on navigation problems. It also references a related work, PRMRL~1, which has already discussed combining RL and planning. The comment suggests that it would be interesting to explore the application of such algorithms in more general tasks. This feedback is 3 as it points out a specific limitation and encourages the authors to consider broader applications. However, it lacks detailed guidance or suggestions on how to address this limitation or expand the scope of the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a specific suggestion to avoid this issue by individually standardizing feature dimensions. This feedback is explicit and concrete, as it clearly identifies the potential problem and offers a direct solution. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces being wellsuited for 1NN and provides a suggestion to avoid potential performance issues by individually standardizing feature dimensions. This level of detail guides the authors on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification, suggesting that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a logical reasoning by explaining that individually standardizing feature dimensions could help avoid this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a constructive suggestion to avoid this issue by individually standardizing feature dimensions. This feedback is clear and actionable, offering the authors a specific way to improve their work by addressing a potential limitation. However, the comment could be more helpful if it provided additional context or examples to further illustrate the issue and its implications. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a critical concept in the paper. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap. While the action is implicit, it is concrete in suggesting that the authors need to define the concept more formally. This provides the authors with a clear direction on how to improve their draft, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific concept in the paper. It also provides a clear indication of what is lacking, namely a formal definition for the contrastive gap. The comment suggests that while an intuitive example is given, it is not convincing, and a clear definition is needed. This provides specific guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is unclear and lacks a formal definition. It acknowledges that an intuitive example is provided but questions the setting of this example, suggesting that it is less convincing. The comment implies that a clear definition is necessary but does not provide specific examples or references to support the claim. While the reviewer highlights the issue, the lack of detailed justification or evidence makes the claim 3. The authors would need to infer the specific areas needing clarification or definition, which aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the work. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment highlights the need for a clear, formal definition of the contrastive gap, which is essential for understanding and evaluating the work. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to define the contrastive gap or provided examples of how to clarify the concept. Overall, the comment is 4, as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including other baselines, such as those discussed in the related work section, to enhance the paper. It also mentions that the authors have addressed the reviewer\"s initial concerns and raised their score. However, the comment does not provide explicit instructions on how to incorporate these additional baselines or what specific aspects should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should add more baselines but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the inclusion of other baselines, such as those discussed in the related work section, and references specific works (29, 5, 6). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests including additional baselines and provides a rationale for why this would be beneficial. Additionally, it mentions that the authors have addressed the reviewer\"s initial concerns and that all unclear parts have been answered, indicating a positive development. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including other baselines, such as those discussed in the related work section, to enhance the paper. The reviewer acknowledges that the authors have addressed their initial concerns and raised their score, indicating that the authors have provided sufficient clarification. However, the comment does not provide specific reasoning or evidence to support the claim that including additional baselines would be beneficial. The suggestion is somewhat vague and lacks detailed justification, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in the related work section, would enhance the paper. This is a clear and actionable suggestion that could improve the comprehensiveness and robustness of the study. However, the comment could be more helpful if it provided specific examples of which baselines to include or why they are relevant. Additionally, the mention of the authors addressing the reviewer\"s initial concerns and raising their score indicates a positive development, but this part of the comment does not directly contribute to improving the draft. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more detailed and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text and the notation used in Figure 1, specifically noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This comment explicitly identifies the inconsistency and suggests that the authors should ensure consistency in their notation across the paper. However, it does not provide specific guidance on how to resolve this issue, such as suggesting which notation should be used consistently or how to address the discrepancy. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in notation, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This provides clear guidance on what needs to be addressed, ensuring that the authors know exactly what part of the paper requires revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a discrepancy in notation between the text and Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in notation between the text and Figure 1, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This feedback is clear and actionable, as it directs the authors to ensure consistency in their notation across the paper. However, the comment could be more helpful if it provided guidance on which notation should be used consistently or suggested a way to address the discrepancy. Despite this, the comment is 4 as it highlights a critical issue that needs attention, allowing the authors to make a straightforward correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about other limitations beyond the shallow network in the graph case. While it implies that the authors should consider and address these limitations, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore and discuss additional limitations. However, the comment does suggest a specific area for consideration, which is a step towards actionability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking if the network is shallow in the graph case and if this is also the case here. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations and the network depth, but it lacks grounding as it does not reference a particular section or figure. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of a question asking about other limitations of the method and inquiring about the depth of the network in the graph case. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about other limitations beyond the shallow network in the graph case. While it prompts the authors to consider additional limitations, it lacks specificity and does not provide any guidance or suggestions on how to address these limitations. The comment is 3 as it identifies an area for further exploration, but it does not offer actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the work would be more convincing if it were evaluated in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word compared to \"open domain\" generation tasks like answer generation and summarization. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their evaluation to include machine translation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation tasks or where the authors should include the additional evaluation in machine translation. While the authors can infer that the comment relates to the evaluation section, it lacks full grounding as it does not explicitly mention the section or subsection being addressed. The comment is specific in suggesting an additional evaluation task, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the work would be more convincing if it were evaluated in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word compared to \"open domain\" generation tasks like answer generation and summarization. The reviewer provides a logical reasoning by contrasting the nature of these tasks, suggesting that machine translation would provide a more robust evaluation. However, the comment lacks specific examples or references to support the claim about the differences in uncertainties between these tasks. This makes the claim 3, as it provides a rationale but requires further evidence or detailed explanation to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the proposed method. However, the comment could be more helpful if it offered additional guidance on how to incorporate machine translation into the evaluation or why this would strengthen the paper\"s claims. Overall, the comment is 4 as it directs the authors to a potential area for enhancement, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these questions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the dropping rate and the number of masks generated. This provides clear guidance on what the authors need to address in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout process, specifically regarding the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While it identifies areas that need further explanation, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their understanding of the dropout process. The feedback is 3 as it points out a need for clarification, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the issues. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of information about the type of GPUs used and the inference time during testing. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific metrics to include or methods to report inference times. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information should be included in, such as the methodology or results sections. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this information should be added. The comment is specific in its request for additional information but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks information about the type of GPUs used and inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this omission or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a relevant point that could impact the reproducibility and comprehensiveness of the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific metrics to report or methods to include. Without actionable feedback, the authors are left with a general understanding of what is missing but without a clear path forward for improvement. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or clarify the issue in their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether each node can attend to its own lowerlevel representation, referencing equation 2 and the description of N_l^(s). This provides some grounding as it mentions a specific equation, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed or clarified regarding the ability of nodes to attend to their own lowerlevel representations. The lack of specificity makes it difficult for the authors to understand the exact issue or improvement needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. This question highlights a potential misunderstanding or ambiguity in the paper, prompting the authors to clarify their explanation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the description. While it identifies a point of confusion, it lacks actionable feedback, making it 3. The authors are left with a clear question to address but without specific steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two actions: first, to include the bottomup method 9 in the tables, and second, to evaluate the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. The first suggestion is concrete, as it specifies the inclusion of a particular method in the tables, and the second is also concrete, as it outlines a specific evaluation to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the bottomup method 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests including the bottomup method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset that outperform all methods in Table 4, even when using a ResNet50. It recommends including this method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. The claim is 3 as it provides a specific reference to the bottomup method 9 and suggests a comparison with the paper\"s results. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method 9 in the tables, as it has reported results outperforming all methods in Table 4, even with a ResNet50. This recommendation is clear and could help the authors improve the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This suggestion is also constructive, as it encourages the authors to consider a broader evaluation context. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these suggestions or why they are important. Overall, the feedback is 4, as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides an example from the TACRED slot filling guidelines, highlighting the depth of annotation guidelines in the IE domain. While the comment raises a concern about the paper\"s claim, it does not provide explicit guidance on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claim and potentially expand their annotation guidelines. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim of making use of \u201cannotation guideline\u201d\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing in the paper\"s claim, namely the depth of true guideline understanding, and provides a reference to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s use of \"annotation guidelines\" may be an overstatement, as it only considers label name, label description, and fewshot examples, whereas annotation guidelines in the IE domain are more complex and curated by linguists. The reviewer supports this claim by providing a specific example from the TACRED slot filling guidelines, which demonstrates the depth of annotation guidelines. This example provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by further elaboration or references to other examples or studies that highlight the complexity of annotation guidelines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides a specific example from the TACRED slot filling guidelines, which highlights the depth of annotation guidelines in the IE domain. This feedback is valuable as it prompts the authors to reconsider their claim and potentially expand their annotation guidelines to better align with the complexity of the domain. However, the comment could be more helpful if it offered suggestions on how to enhance the annotation guidelines or provided additional examples to support the claim. Overall, the comment is 4 as it identifies a potential weakness and provides a specific example for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not provide any explicit guidance or concrete suggestions on how to do so. The action is implicit, as the authors need to infer that they should address the lack of discussion on weaknesses, but it lacks specificity on what aspects to focus on or how to present this information. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what specific weaknesses should be addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding the nature of the weaknesses that should be discussed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what weaknesses might exist or how they could be demonstrated, the comment lacks verifiability. Therefore, it is classified as \"1.\"", "helpfulness_rationale": "The review comment points out a significant gap in the paper by noting that the authors have not demonstrated the possible weaknesses of the proposed model. This is a critical observation that could help the authors strengthen their work by addressing potential limitations and vulnerabilities. However, the comment lacks specificity and does not provide guidance on how to identify or discuss these weaknesses. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as its distinction from BGLN. While the comment implies that the authors should expand the related work section, it does not provide specific guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning that it is insufficient and suggests including more work on GLN to highlight the advantages or differences of the proposed method. It also mentions the need to differentiate the proposed method from BGLN. However, the comment does not specify which part of the introduction is insufficient or where the additional information should be included, making it weakly grounded. The authors can infer that it relates to the introduction section, but the lack of explicit references makes it challenging to pinpoint the exact parts needing revision. The comment is specific in suggesting what needs to be addressed, such as highlighting the advantages or differences of the proposed method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current introduction is insufficient. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely that the introduction of related work is insufficient. It suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as its distinction from BGLN. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a concrete way to enhance the paper. However, the comment could be more helpful if it offered examples of GLNrelated work or specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area that needs expansion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the dropout rates used for Moon\"s approach and Variational dropout. It explicitly asks why only one dropout rate is used for Moon\"s approach, while Variational dropout has both an inputoutput and a recurrent dropout parameter. This question prompts the authors to clarify or justify their choice of dropout rates, providing a clear and specific action for them to take. The comment is explicit and concrete, as it directly addresses a specific aspect of the paper and provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a question about the inconsistency in dropout rates used for Moon\"s approach and Variational dropout. It explicitly mentions \"hypers > hyperparameters,\" which suggests that the comment is addressing a specific part of the paper where hyperparameters are discussed. However, it does not specify which section or part of the paper this discussion is in, making it weakly grounded. The comment is specific in its question about the dropout rates, but without explicit references to sections or figures, the authors may have difficulty pinpointing the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inconsistency in dropout rates used for Moon\"s approach and Variational dropout, specifically asking why only one dropout rate is used for Moon\"s approach while Variational dropout has both an inputoutput and a recurrent dropout parameter. This is a factual observation that does not express an opinion or claim requiring verification. It is a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in dropout rates used for Moon\"s approach and Variational dropout. It points out that while Variational dropout has both an inputoutput and a recurrent dropout parameter, Moon\"s approach only uses one dropout rate. This observation prompts the authors to clarify or justify their choice of dropout rates, which could lead to a more comprehensive understanding of their methodology. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the paper. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter, specifically noting that it only offers an empirical conformation estimation. However, the comment does not provide explicit guidance on how to achieve this optimization and validation. The authors are left to infer that they need to conduct additional experiments or analyses to improve the binder design, but without specific instructions on what these experiments should entail or how to validate the results. This lack of concrete guidance makes the action vague and difficult for the authors to implement effectively. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"binder design\" aspect of ProtPainter, suggesting that it only provides an empirical conformation estimation and that further optimization and validation are required. However, it does not specify which part of the paper discusses the binder design or where this issue is presented, making it weakly grounded. The comment is specific in identifying the need for further optimization and validation, but without clear references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion for further optimization and validation. Therefore, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, namely that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work by conducting additional experiments or analyses. However, the comment could be more helpful if it provided suggestions on how to approach this optimization and validation, such as proposing specific methods or experiments. Despite this, the comment still offers valuable guidance for the authors to enhance their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. While the comment implies that the authors should conduct additional evaluations, it does not provide explicit instructions on how to perform these evaluations or what specific metrics or analyses should be included. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more evaluations but may not know exactly what aspects to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be added to, making it weakly grounded. The comment is specific in suggesting the need for additional evaluation, particularly on CIFAR10, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. However, the comment does not provide any reasoning or evidence to support why additional evaluation is necessary or how it would improve the paper. Without specific examples or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. This feedback is clear and actionable, as it provides a specific area for the authors to consider expanding their evaluation. However, the comment could be more helpful if it included suggestions on what specific aspects of the evaluation should be explored or how the evaluation could be improved. Despite this, the comment offers a valuable direction for the authors to enhance their work, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and vague, leaving the authors to infer what needs to be done without clear guidance on how to address these issues. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not explicitly mention which part of the paper it addresses, such as a specific section or figure. However, it is specific in its content, as it raises questions about the placement of a section, the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. The authors can infer that the comment relates to the methodology or results sections, but the lack of explicit references makes it difficult to pinpoint the exact parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. However, the comment does not provide specific reasoning or evidence to support these claims, such as explaining why the placement is counterintuitive or how the lack of reference affects the paper. Without detailed justification or examples, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several points that could be helpful for the authors to address. It questions the placement of a section, which could be counterintuitive, and asks for clarification on the application of Algorithm 1, particularly regarding the number of iterations. Additionally, it points out the lack of reference to Laplacian eigenmaps and suggests that this should be included. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity or relevance of the references. As it stands, the feedback is 3, as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. While the comment identifies a potential issue with the structure of the paper, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the content of Section 2.1 and focus on providing more motivation for the CBN approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the inclusion of this section, questioning the relevance of describing general techniques like Batch Normalization and Conditional Batch Normalization (CBN) in this context. The comment further suggests that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the proposed CBN approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. The reviewer implies that the time spent on describing the ResNet architecture could be better used to provide more motivation and intuition for the CBN approach. However, the comment lacks specific examples or detailed reasoning to support why the inclusion of Section 2.1 is unnecessary or how it could be improved. This makes the claim 3, as the authors would need to infer the potential issues and address them based on the feedback provided.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. This feedback is 3 as it identifies a potential area for improvement in the paper\"s structure and suggests a way to enhance the motivation for the proposed method. However, it lacks specific guidance on how to reorganize the content or provide additional motivation, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the paper regarding the sparsity of the resulting matrix when multiplying by a dense projection matrix. The reviewer questions the expectation of sparsity in this context, suggesting that the multiplication would likely result in a dense matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the expectation of sparsity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the sparsity expectation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the expectation of sparsity when multiplying by a dense projection matrix, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the expectation of sparsity in the resulting matrix when multiplying by a dense projection matrix. The reviewer provides a logical reasoning by pointing out that multiplying by a dense matrix would likely result in a dense matrix, challenging the assumption of sparsity. This reasoning is clear and logical, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the expectation of sparsity in the resulting matrix when multiplying by a dense projection matrix. It points out a potential contradiction in the assumption, suggesting that the multiplication would likely result in a dense matrix rather than a sparse one. This feedback is clear and actionable, as it prompts the authors to clarify their assumptions and expectations regarding sparsity. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested ways to clarify the sparsity expectation. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, implying that the authors should provide a more detailed explanation or clarification regarding the role of initialization in the context of NGD and NGF. While the comment implies that the authors should revise their statement, it does not provide specific guidance on how to do so or what aspects of the statement need clarification. The action is implicit and somewhat vague, as the authors can infer that they need to revise the statement but may not know exactly how to do it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the statement about initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as a pretraining step. The reference to a specific reference, 1 Kunstner et al., adds further specificity by providing a basis for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in the context of NGD being a discretization of NGF, and that solving NGF is an initial value problem (IVP). It suggests that initialization should be considered as pretraining. The comment is supported by a reference to a specific paper by Kunstner et al. (2019), which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional elaboration.", "helpfulness_rationale": "The review comment identifies a specific area where the statement about initialization could be more carefully stated, particularly in the context of NGD being a discretization of NGD. It suggests that initialization should be considered as pretraining, which is a valuable insight for the authors to consider. The reference to a specific paper by Kunstner et al. provides a basis for the claim, offering a potential source for further exploration. However, the comment could be more helpful if it provided more detailed guidance on how to revise the statement or what specific aspects of the initialization process should be clarified. Overall, the comment is 4 as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate comments. The first part raises a concern about the clarity of named entity extraction from the datasets, implying that this aspect needs further explanation or clarification. However, it does not provide specific guidance on how to address this issue. The second part suggests an English proofreading to improve readability, which is a direct and concrete action. While the first part is somewhat vague, the overall comment is 4 because it provides a clear and concrete suggestion for improving the paper\"s readability. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment raises two separate issues: the clarity of named entity extraction from datasets and the need for an English proofreading to improve readability. However, it does not specify which part of the paper discusses named entity extraction, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting improvements, such as clarifying the extraction process and enhancing readability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate claims. The first claim, \"It is not clear how named entities were extracted from the datasets,\" is 3 as it highlights a lack of clarity in the paper. However, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The second claim, \"An English proofreading would significantly improve the readability of the paper,\" is a factual statement and does not require verification. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two separate issues: the lack of clarity regarding the extraction of named entities from datasets and the need for an English proofreading to improve the paper\"s readability. While the comment highlights important areas for improvement, it does not provide specific guidance or suggestions on how to address these issues. For example, it does not explain what aspects of the named entity extraction process are unclear or how the authors might clarify this in the paper. Similarly, the suggestion for an English proofreading is a general recommendation without specific feedback on what aspects of the paper need improvement. As a result, the comment is 3, as it points out areas for improvement but lacks detailed guidance or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define \"L\" and \"E\" in the immediate vicinity of line 296, addressing the inconsistency in their formatting. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The comment also points out the inconsistency in formatting, which is another actionable point. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the formatting of \"L\" and \"E,\" noting that they are sometimes italicized and sometimes not. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting inconsistency of \"L\" and \"E\" in the paper, specifically noting that they are sometimes italicized and sometimes not. This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific formatting issue in the paper, noting that \"L\" and \"E\" are sometimes italicized and sometimes not. This feedback is clear and actionable, as it directs the authors to ensure consistency in the formatting of these variables throughout the paper. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to maintain consistency in formatting across the paper. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct these comparisons, it does not provide specific guidance on which models or techniques to include or how to implement the comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not know exactly how to execute the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. This lack of specificity makes it difficult for the authors to identify where these comparisons should be added. Additionally, the comment does not provide guidance on which specific models or techniques should be included in the comparisons. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the comprehensiveness and robustness of the paper. However, the comment could be more helpful if it provided specific examples of models or techniques that should be included in the comparisons. Despite this, the suggestion is 4 as it guides the authors toward expanding their analysis and improving the paper\"s depth. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of explicit corrections to grammatical errors and inconsistencies in the manuscript. Each correction is clearly stated, providing the authors with direct and concrete actions to take. The comment explicitly identifies the lines where these corrections are needed, ensuring that the authors know exactly where to apply the changes. This level of detail and specificity makes the feedback 5, as the authors can directly implement the suggested corrections to improve the clarity and accuracy of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the grammatical errors and inconsistencies that need to be corrected, providing precise guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of grammatical corrections and suggestions for improvement. Each correction is factual and does not express an opinion or claim that requires verification. The comment is descriptive and provides clear guidance on how to improve the manuscript\"s grammar and clarity. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of explicit corrections to grammatical errors and inconsistencies in the manuscript. It identifies specific lines where these corrections are needed, such as correcting \"Despite of being compact\" to \"Despite being compact\" and \"We refer multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it points out a grammatical error in the phrase \"Effect of the modelling mixed temporalmodality features,\" suggesting that it is not grammatically correct. These corrections are clear and actionable, allowing the authors to directly improve the clarity and accuracy of their draft. However, the comment could be more helpful if it provided additional context or suggestions for improving the content or structure of the paper. Overall, the feedback is 4 as it effectively guides the authors in enhancing the manuscript\"s grammar and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide explicit guidance or suggestions on how to address the issue or clarify the confusion. The authors are left to infer that they need to correct the equation and possibly clarify the context, but the comment lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. This provides full grounding as it explicitly mentions the equation, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the equation, indicating that there is a mistake related to the inversion or division of the number of samples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide any supporting evidence, reasoning, or references to justify the claim of a mistake in the equation. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. While it identifies a potential issue, it lacks specificity and does not provide any guidance or suggestions on how the authors might address the problem or clarify the confusion. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. While it implies that the authors should consider this comparison, the action is not directly stated, and the authors may not know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion for a comparison between sequential and combinational designs, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed comparisons to substantiate the suggestion for a comparison between sequential and combinational designs. Without additional context or justification, the claim remains 1, as it does not provide sufficient information for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. This feedback is 3 as it identifies a potential area for exploration and improvement in the paper. However, it lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it provides a direction for further analysis, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point expresses curiosity about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to include this information, it implies that the authors should consider adding it to their analysis. The action is implicit, as the authors need to infer that they should include this metric, and it is somewhat vague because it does not provide specific guidance on how to calculate or present the metric. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the specific baseline \"LDA+LSTM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the interest in the performance of this baseline in terms of the topic switch percent metric. This provides clear guidance on what the authors need to address or explore further. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or additional information regarding the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking more information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific aspect of the experiment section, namely the LDA+LSTM baseline, and expresses curiosity about its performance in terms of the topic switch percent metric. While it does not provide explicit suggestions for improvement, it highlights an area of interest that the authors might consider exploring further. This feedback is 3 as it prompts the authors to consider additional analysis or metrics that could enhance their study. However, it lacks depth and does not offer actionable guidance on how to address the issue or what specific steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the insufficient backing of the claim regarding the synergies between DQD and PPO. It specifically points out the omission of the TD3GA algorithm in the main paper, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study, implying that the authors should include this comparison to strengthen their claim. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to incorporate the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include the comparison to TD3GA and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim about the synergies between DQD and PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing DQD with TD3 to understand these synergies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up. It specifically points out the omission of the TD3GA algorithm in the main paper, which is crucial for understanding these synergies. The comment suggests that the comparison to TD3GA should be central to the study. This claim is 3 as it provides a specific example of what is missing (the TD3GA algorithm) and suggests a way to strengthen the claim. However, the comment could be more verifiable with additional references or detailed reasoning to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It suggests that the comparison to TD3GA should be central to the study, as it is relevant to the claim that using onpolicy RL better fits the DQD framework. This feedback is clear and actionable, providing the authors with a specific area to address and a direction for improvement. However, it could be more helpful if it offered suggestions on how to incorporate the comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential ambiguity in the phrase \"confident about applying ceterus paribus convexity,\" suggesting that it could be interpreted as either model confidence or human interpretability. The reviewer suggests that some slight rephrasing would be beneficial to clarify the intended meaning. While the comment identifies an issue and implies a need for rephrasing, it does not provide specific guidance on how to rephrase the sentence. The action is explicit but somewhat vague, as the authors know they need to clarify the meaning but may not be entirely sure of the exact wording changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific phrase, \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the ambiguity caused by the word \"confident\" and suggests that some rephrasing would be beneficial to clarify whether it refers to model confidence or human interpretability. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of the word \"confident\" in the context of \"ceterus paribus convexity,\" suggesting that it could be interpreted as either model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the intended meaning and suggests that some rephrasing would be beneficial to clarify the ambiguity. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the ambiguity and how to address it, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the phrase \"We have found it easier to be confident about applying ceterus paribus convexity,\" suggesting that the word \"confident\" could be interpreted as either model confidence or human interpretability. The reviewer provides a logical inference that it might refer to human interpretability but suggests that some rephrasing would be beneficial to clarify the intended meaning. This feedback is 3 as it points out a specific area of ambiguity and offers a constructive suggestion for improvement. However, it could be more helpful if it provided specific guidance on how to rephrase the sentence or offered examples of clearer language. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the work\"s interesting findings but notes that the novelty is limited. It provides a specific observation that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take to address the issue of limited novelty. It lacks guidance on how the authors might enhance the novelty of their work or what specific aspects could be explored further. As a result, the comment is 1, as it does not provide any direction for improvement.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the observation of tighter CIs with finetuning. However, it does not specify which part of the paper discusses these findings or where the authors could improve the novelty. The authors might infer that it relates to the results or discussion sections, but this is not explicitly stated. The comment is specific in its critique of the novelty but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, citing the expectation that taskspecific finetuning would lead to tighter confidence intervals (CIs) while potentially reducing generalizability. This claim is 3 as it is based on a logical reasoning about the effects of finetuning on confidence intervals. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the work\"s interesting findings but notes that the novelty is limited. It provides a specific observation that tighter confidence intervals (CIs) with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any actionable suggestions or guidance on how the authors might enhance the novelty of their work or address this limitation. The feedback is 3 as it points out a potential issue but lacks depth and actionable advice, leaving the authors with a general understanding of the critique but without specific steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on how the authors might address this concern or what specific aspects of their work need to be revised. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide any details on what aspects of the objective or scenarios should be considered. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. While it identifies a potential area for clarification, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation in the paper, including a lack of comprehensiveness and transparency regarding the experiment setup. It specifically mentions the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed information about the experiment setup, explore different scenarios, and consider using multiple datasets. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness and transparency of the evaluation in the paper, specifically mentioning the lack of information about the number of different sets of incontent examples used and the absence of exploration of varying the number of InContext Examples. It also points out the reliance on a single dataset, which may limit generalizability. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the evaluation section, providing some level of grounding. However, the comment is specific in detailing what is missing or lacking in the evaluation, such as the need for more detailed information about the experiment setup and the exploration of different scenarios. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide specific examples or references to support these claims. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, including a lack of comprehensiveness and transparency regarding the experiment setup. It specifically points out the absence of information about the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending the use of multiple datasets or providing guidance on how to present the results. Overall, the comment is 4, as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors need to infer that they should include more references, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, literature review, or discussion sections. Without explicit references to these sections, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in suggesting the inclusion of related work, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. However, it does not provide any reasoning or justification for why these references are relevant or how they relate to the current work. Without specific examples or explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references 1, 2, and 3. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate this related work into the paper. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3, as it points out a weakness but does not offer actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the current focus on the concept of Blackwell winner limits the novelty of the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited by its focus on the concept of Blackwell winner. However, it does not specify which part of the paper should be expanded to include these algorithmic aspects or how the current focus on Blackwell winner limits the novelty. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be explored or how the novelty could be enhanced. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper is limited by its focus on the concept of Blackwell winner. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the current focus on the concept of Blackwell winner limits the novelty of the paper. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might expand their discussion on algorithmic aspects or enhance the novelty of their work. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of actionable feedback. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors could improve their paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method, implying that the authors should provide a more detailed and structured comparison. While the comment is explicit in its suggestion, it lacks concrete guidance on how to implement this improvement, such as suggesting specific metrics or analysis techniques to use. Therefore, the action is 3, as the authors know what needs to be done but may need additional guidance on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Originality\" and references the work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons with the related work more systematic by comparing the best performance of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the closely related work of Zemel et al. (2013) more systematic. It suggests comparing the best performance of each method, which is a logical and reasonable suggestion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact improvements needed based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It recommends comparing the best performance of each method, which is a clear and actionable piece of feedback. This guidance can help the authors enhance the clarity and depth of their analysis, making the comment 4. However, the comment could be more helpful if it included additional suggestions or examples on how to structure these comparisons or what specific metrics to use. Overall, the feedback is constructive and provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels. It suggests that the authors should consider this connection and references a specific chapter in Steinwart and Christmann that discusses universal kernels. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the connection and possibly incorporate the referenced chapter into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific guidance by suggesting a connection to properties of universal kernels and referencing a particular chapter in Steinwart and Christmann. This detailed reference helps the authors understand what needs to be addressed in terms of exploring the connection between the definition and universal kernels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This reference provides a clear and specific external source that supports the claim, making the comment 4. The mention of a particular chapter and the discussion of universal kernels\" ability to separate an arbitrary finite data set with a margin arbitrarily close to one offers a robust basis for the claim. However, the comment could be more 5 if it included a brief explanation of how this connection is relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific question about the connection between the third point of definition one and properties of universal kernels. It references a particular chapter in Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with a margin arbitrarily close to one. This feedback is helpful as it prompts the authors to consider a potential link between their work and existing literature, which could enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided a clearer explanation of how this connection might be relevant or suggested specific ways to incorporate this information into the paper. Overall, the comment is 4, as it offers a valuable direction for the authors to explore, but it could be more comprehensive with additional guidance."}
