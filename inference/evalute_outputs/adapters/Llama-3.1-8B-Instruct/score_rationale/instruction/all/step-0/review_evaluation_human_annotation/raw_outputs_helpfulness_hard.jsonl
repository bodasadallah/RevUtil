{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the description of HIERENC and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment does not provide explicit guidance or suggestions on how the authors could improve the clarity of the description or address the potential issue with noise. The action is implicit and vague, as the authors are left to infer that they need to clarify the description and potentially reconsider their approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the description of HIERENC, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the description, namely that the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary may introduce a lot of noise. The comment provides a detailed critique of the method, suggesting that only one instantiation is likely to be correct, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, as presumably only one of those instantiations is correct. However, the comment lacks specific examples or references to support the claim that this approach is problematic. The reasoning is logical but not fully substantiated, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, questioning the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, as presumably only one of those instantiations is correct. This feedback is clear and highlights a potential weakness in the methodology, providing the authors with a specific area to address and improve. However, the comment could be more helpful if it offered suggestions on how to clarify the description or alternative approaches to consider. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that requires clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" The reviewer suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance. However, the comment does not provide explicit guidance on how to correct this issue or suggest alternative wording. While the action is implicit, it is somewhat actionable as it points out a potential problem that the authors should address, even if the exact steps to take are not fully outlined. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"l.791\") where the issue is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias in the wording used to describe performance, suggesting that \"on par or better\" might be misleading. The comment provides a clear suggestion for improvement by recommending a correction in the wording. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers to label instances where they perform worse as \"on par\" and all other instances as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the context and evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" It suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance, where instances of worse performance are labeled as \"on par\" and all other instances as \"better.\" This feedback is somewhat helpful as it points out a potential problem with the language used in the paper, but it does not provide specific guidance on how to correct this issue or suggest alternative wording. While it highlights an area for improvement, the comment could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOS-V. However, it does not provide any explicit or implicit actions for the authors to take. The questions are more about seeking clarification rather than suggesting changes or improvements to the draft. As a result, the comment lacks actionable guidance for the authors, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the interpretation of results, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOS-V. This provides clear guidance on what aspects of the results need further clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the interpretation of results presented in Table 3. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the interpretation of results presented in Table 3, focusing on the comparison of NVSB to GT Mel A for Chinese MOS-Q and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOS-V. While it highlights areas that need clarification, it does not provide any suggestions or guidance on how the authors might address these questions or improve the clarity of their results. The feedback is limited in its actionable nature, offering only a direction for further investigation without providing concrete steps for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct an ablation study to demonstrate the importance of the post-processing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is required and figure out the details themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of integrated gradients for attribution and the proposed post-processing steps to filter out \"false-positive\" neurons. It suggests that the paper should include an ablation study to demonstrate the importance of these post-processing steps. However, the comment does not specify which part of the paper discusses these methods, making it weakly grounded. The suggestion for an ablation study is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not demonstrate the importance of the post-processing steps proposed for filtering out \"false-positive\" neurons. It suggests that an ablation study may be needed to address this issue. The comment provides a logical reasoning for the claim by pointing out the lack of demonstration of the post-processing steps\\' importance. However, it does not provide specific examples or references to support the claim, which makes it somewhat verifiable. The authors would need to infer the necessity of an ablation study based on the provided reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the importance of the post-processing steps for filtering out \"false-positive\" neurons is not demonstrated. It suggests that an ablation study could be necessary to address this issue, providing a clear and actionable direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs further exploration. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, particularly when the head of the noun phrase is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this challenge. The authors are left to infer that they need to clarify or improve their method for handling pronouns, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. However, it does not specify which part of the paper discusses the method for identifying antecedents or pronouns, making it weakly grounded. The comment is specific in detailing the issue with pronoun predictions, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. The comment highlights a potential issue with the proposed method but does not provide specific examples, references, or detailed reasoning to support the claim. This makes the claim somewhat verifiable, as the authors would need to infer the issue and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. This is a relevant issue that the authors should address to ensure the robustness and accuracy of their method. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this challenge, such as proposing alternative approaches or suggesting additional experiments. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper should include more baselines based on related work. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to include these baselines or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional baselines but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"MST baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison between the proposed models and those that only consider different senses but not sememes. The comment suggests that the emphasis on soft vs. hard word sense disambiguation is not sufficient and recommends including more baselines based on related work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or detailed reasoning to support the claim that the current comparison is unclear or insufficient. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks concrete evidence or references to substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and points out that the emphasis is placed on soft vs. hard word sense disambiguation rather than this comparison. The comment provides a clear and actionable suggestion to include more baselines based on related work, which would strengthen the paper. However, it could be more helpful if it offered specific examples of additional baselines or detailed guidance on how to incorporate them. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect in their draft. The action is implicit, as the authors need to infer that they should provide more detailed information about the selection process. Additionally, the comment lacks concrete details on what specific information should be included or how it should be presented. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of unclear selection processes, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of uncertainty regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide any guidance or suggestions on how the authors might clarify this aspect in their draft. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their work. Therefore, it is rated as barely helpful, as it highlights an issue but lacks depth or actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several weaknesses in the paper, specifically related to the experiments. It mentions that the experiments are limited to an extremely low-resource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method could be applied to more NLP tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen their experiments or demonstrate the potential of their method on other tasks. The feedback is vague and lacks concrete actions for the authors to take, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experiments in the paper, specifically mentioning the limitation to an extremely low-resource regime and the ease of sentence classification. It suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. However, the comment does not specify which part of the paper discusses the experiments or provide detailed guidance on how to address these issues. The authors can infer that the comment relates to the experimental section, but it lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper\\'s experiments are weak, particularly because they are limited to an extremely low-resource regime and focus on sentence classification, which is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which is not demonstrated in the paper. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the experiments are weak or that the method could be applied to more tasks. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific weaknesses in the paper's experiments, noting that they are limited to an extremely low-resource regime and focus on sentence classification, which is an easier task. It suggests that the proposed augmentation method has potential for use in more NLP tasks, which is not demonstrated in the paper. This feedback is somewhat helpful as it points out areas for improvement and provides a direction for further exploration. However, it lacks detailed guidance or suggestions on how the authors might address these limitations or expand their experiments to demonstrate the method's broader applicability. To be more helpful, the comment could include specific recommendations or examples of additional tasks or settings that could be explored. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether treating concept map extraction as a separate task is necessary. It provides a balanced perspective, acknowledging both the potential benefits and challenges of this approach. However, it does not explicitly instruct the authors to take any action or provide specific guidance on how to address this issue. The comment lacks concrete details or suggestions on how to proceed, leaving the authors uncertain about what steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a balanced perspective with both positive and negative points. However, it does not specify which part of the paper this question pertains to, such as a particular section or methodology, making it difficult for the authors to identify the exact area needing attention. The comment is specific in its questioning of the approach but lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of treating concept map extraction as a separate task. It presents a balanced argument, acknowledging both the potential benefits and challenges of this approach. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it provides a logical framework for the discussion, it does not offer enough evidence or justification to make the claim fully verifiable. Therefore, the comment is considered borderline verifiable, as it requires more detailed support to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the necessity of treating concept map extraction as a separate task. It presents a balanced perspective by acknowledging both the potential benefits and challenges of this approach. However, the comment lacks depth and does not provide specific suggestions or examples to help the authors address this question. While it identifies a potential area for consideration, it does not offer actionable guidance or detailed feedback, making it somewhat helpful. The authors are left with a general direction to explore but without clear steps to take, which aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the text, indicating that lines 102-106 are misleading. It points out that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide explicit guidance on how to correct this issue or suggest alternative phrasing. The action is implicit, as the authors need to infer that they should clarify or rephrase the statement to avoid the misleading interpretation. The feedback lacks concrete details on how to implement the suggested change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, indicating that the phrase \"such distribution\" is misleading and cannot refer to the discussion above. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading, specifically regarding the phrase \"such distribution.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this phrase is misleading or how it deviates from the discussion above. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the text, pointing out that lines 102-106 are misleading. It highlights that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it directs the authors to clarify or rephrase the statement to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the statement. Overall, the comment is mostly helpful as it effectively points out a potential issue and guides the authors toward improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of the 4-year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. While it implies that the authors should provide more information or analysis on this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of datasets and the sufficiency of the 4-year period for studying style shifts. However, it does not specify which part of the paper discusses the datasets or style shifts, making it weakly grounded. The comment is specific in its request for clarification on the kind of style shifts that occur within the given timeframe, which provides some guidance on what the authors need to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that a 4-year period is insufficient. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the sufficiency of the 4-year period for studying style shifts. It questions whether this timeframe is adequate for capturing the kind of style shifts that occur, which is a relevant point for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional information could be included to better support their analysis. While it identifies a potential weakness, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a statement that contradicts the claim made in the paper, stating that there is no corresponding set of tools for the reinforcement learning setting. However, it does not provide any actionable advice or suggestions for the authors to address this issue. It does not offer guidance on how to resolve the discrepancy or improve the draft. As a result, the comment lacks any explicit or implicit action for the authors to take, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the claim about the lack of tools for the reinforcement learning setting is being made. It also lacks specificity because it does not provide details on what specific tools are missing or how they could be addressed. Without clear references or context, the authors cannot determine where to make changes or improvements. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a statement that contradicts a claim made in the paper, stating that there is no corresponding set of tools for the reinforcement learning setting. The reviewer claims that this statement is false and provides a reference to support this claim. However, the comment does not elaborate on the specific references or how they contradict the claim, making it somewhat verifiable. The authors would need to access the references to fully understand the basis of the claim, which adds a layer of complexity to the verification process. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review point challenges a claim made in the paper by stating that it is false, specifically regarding the lack of tools for the reinforcement learning setting. However, it does not provide any further explanation, examples, or references to support this claim, nor does it offer suggestions for how the authors might address this issue. Without additional context or guidance, the comment lacks actionable value for the authors, leaving them without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should incorporate this information into their draft. The action is implicit, as the authors need to infer that they should include references to these works, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a link to these similar works that have a similar structure to the CRF and can perform exact inference. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. The claim is somewhat verifiable as it references specific works, providing a basis for the claim. However, the comment could be strengthened by including more detailed reasoning or examples of how these works relate to the current paper, which would make the claim more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the current paper. By mentioning these references, the comment provides the authors with a clear direction for enhancing the context and relevance of their work. However, the comment could be more helpful if it included a suggestion on how to incorporate these references or why they are important for the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written too briefly and could be improved by a slower development for easier readability. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the section. The action is implicit and somewhat vague, as the authors can infer that they need to expand the section but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the section is \"tersely written\" and suggests that a slower development would improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is \"tersely written\" and suggests that a slower development would improve readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a specific issue with the writing style of Section 4, noting that it is \"tersely written\" and suggests that a slower development would improve readability. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks specific guidance or suggestions on how to achieve a slower development or what changes could be made to enhance readability. While it provides some insight, the comment could be more helpful if it included actionable advice or examples. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is highly actionable as it offers concrete steps for improvement, making it easy for the authors to implement the suggested changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a table showing the distribution of video lengths across the dataset and explains how the authors should ensure a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what specific information is missing and what needs to be addressed. The comment is also specific because it details the exact information that should be included and how it should be presented. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how a balanced representation of different video lengths was ensured across the 11 categories. While the claim is logical and based on a reasonable expectation for benchmark evaluation, it lacks specific examples or references to support the importance of this distribution. The suggestion for including a table and explanation is clear, but the claim itself is somewhat verifiable due to the lack of detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the benchmark evaluation that is missing from the paper: the distribution of videos of different lengths. It emphasizes the importance of this information for assessing reasoning ability and robustness. The comment provides specific and actionable feedback by suggesting that the authors include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and constructive, offering the authors a clear path to improve their draft by addressing a significant gap in the evaluation process. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a cautious approach should be taken regarding the contribution of the dataset until it is made publicly available. However, it does not provide explicit guidance on what actions the authors should take to address this issue. The comment implies that the authors should wait for the dataset to be publicly accessible before considering it a significant contribution, but it does not specify how the authors should handle this situation or what steps they should take to ensure the dataset is made available. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the promised dataset not being publicly available, suggesting a cautious approach until it is made accessible. However, it does not specify which part of the paper discusses the dataset or where this issue is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to be cautious, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not been made publicly available, suggesting a cautious approach until it is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a critical issue regarding the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is made publicly accessible. This feedback is important as it points out a potential limitation in the paper\\'s contribution, which could impact its credibility and impact. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they could take to make the dataset available. While it identifies a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it alerts the authors to a critical issue but does not fully support them in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include related work on modular networks for VQA, specifically mentioning a reference \"[A]\" that should be cited. This provides a clear and direct action for the authors to take, ensuring that the introduction accurately reflects the current state of research in modular architectures for VQA. The comment is highly actionable because it specifies exactly what needs to be added and provides a concrete reference to guide the authors. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"When discussing related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the introduction should include related work on modular networks for VQA, such as the reference \"[A],\" to avoid creating a misleading impression. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction should include related work on modular networks for VQA to avoid creating a misleading impression. The reviewer suggests that the current introduction implies no one uses modular architectures for VQA, which is not accurate. However, the comment does not provide specific examples or references to support the claim that such related work exists. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors would need to conduct their own research to verify the existence of such work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction, noting that it does not mention related work on modular networks for VQA. This omission creates a misleading impression that no one uses modular architectures for VQA. The comment provides a clear and actionable suggestion to include this related work, which would enhance the accuracy and completeness of the introduction. By addressing this gap, the authors can improve the paper\\'s credibility and provide a more comprehensive overview of the field. However, the comment could be more helpful if it offered specific examples or references to guide the authors in selecting relevant work. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more detailed to fully support the authors\\' efforts.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem or what specific changes they should make to their tables. The action is implicit and somewhat vague, as the authors can infer that they need to include these missing cases in the tables, but they are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the ablation experiment\" and \"the two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy in the performance without reinforcement learning and highlights the omission of cases where both dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance without reinforcement learning dropped lower than without dependency tree and notes that the tables do not include cases where both dependency tree and RL are not used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. This feedback is clear and actionable, as it highlights a gap in the experimental setup and suggests that the authors should include these missing cases in the tables. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or address the observed performance differences. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out confusion regarding the notation and the explicit split between \"static\" and temporal features into two variables. It suggests that the paper lacks sufficient information, specifically mentioning \"S\" and \"Xt.\" However, the comment does not provide explicit guidance on how to address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation and provide more details, but they are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights confusion regarding the notation and the explicit split between \"static\" and temporal features into two variables. It specifically mentions the variables \"S\" and \"Xt,\" indicating that the authors need to clarify these notations. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the notation and its explanation. The comment is also specific because it clearly specifies what needs to be addressed, namely, providing more information about \"S\" and \"Xt.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a subjective opinion about the notation and the explicit split between \"static\" and temporal features. It suggests that the paper lacks sufficient information, specifically mentioning \"S\" and \"Xt.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this notation is confusing or how it could be improved. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation and the explicit split between \"static\" and temporal features, noting that it was initially confusing. It suggests that the paper lacks sufficient information, specifically mentioning \"S\" and \"Xt.\" This feedback is somewhat helpful as it points out a potential area of confusion in the paper and encourages the authors to provide more clarification. However, the comment could be more helpful if it offered suggestions on how to clarify the notation or provided examples of how to improve the explanation. Overall, the comment provides some guidance but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment identifies areas where more detail is needed, it does not provide explicit instructions on how to incorporate these details or what specific information should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment does not explicitly mention a specific section or part of the paper, it provides clear guidance on what needs to be addressed, such as providing more detailed explanations for certain concepts. This makes the comment weakly grounded, as the authors can infer the parts being addressed, but specific, as it clearly specifies what needs to be improved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1. However, the comment lacks specific examples or references to support the claim that more details are needed, making it somewhat verifiable. The authors would need to infer the exact areas where more detail is required, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. This feedback is somewhat helpful as it identifies areas where more detail is needed to improve the clarity of the paper. However, it lacks specific guidance on how to provide these additional details or what specific information should be included, which limits its usefulness. The authors are given some direction but need to infer the exact steps to take, making the comment somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests introducing specific aspects of the model that are relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and actionable, as it directs the authors to include specific details that would enhance the clarity and understanding of their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, such as introducing specific aspects of the model relevant to the example being discussed. The comment suggests highlighting that the model operates in a setting with finite subdivisions for gamma^1 and gamma^m and that certain parameters are bounded on one side. This level of detail provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify specific aspects of the model relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and actionable, as it offers specific guidance on how to enhance the clarity of the paper. However, it does not contain subjective claims or opinions that require verification. Therefore, the comment is factual and does not fit the criteria for a claim, aligning with the label \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify certain aspects of the model that are specific to the example being discussed. It highlights the need to explicitly mention that the model operates in a setting with finite subdivisions for gamma^1 and gamma^m and that certain parameters are bounded on one side, such as acceleration and scaling parameters. This feedback is clear and constructive, offering the authors a direct way to enhance the clarity and understanding of their work. By addressing these points, the authors can improve the comprehensibility of their draft, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the scalability of the learning rate condition, which is not seen in practice and could lead to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the learning rate condition, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer provides a logical reasoning by stating that in practice, the step size does not grow with the sample size, which supports the claim. However, the comment could be strengthened by providing specific examples or references to datasets where this issue is observed. Overall, the claim is somewhat verifiable as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. This feedback is somewhat helpful as it highlights a potential weakness in the approach and encourages the authors to reconsider their condition. However, the comment could be more helpful if it provided suggestions or alternatives for addressing this issue, such as proposing different scaling methods or discussing potential workarounds. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (EMNLP 2018). This implies an action for the authors to take, which is to modify their approach to better align with real-world applications. The suggestion is explicit and provides a concrete example of how to implement the change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the impracticality of perfectly balanced data in real-world applications and suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in real-world applications. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. (EMNLP 2018). The comment provides a specific reference to support the claim, which is a clear and logical reasoning for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current approach might not align with real-world scenarios. Overall, the claim is mostly verifiable due to the reference provided, but it could be more robust with additional supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a practical issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in real-world applications where label distributions cannot be controlled. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their approach by aligning it with more realistic scenarios. The reference to a similar work in the field adds context and helps the authors understand the potential benefits of the suggested change. Overall, the comment is highly helpful as it offers a constructive and detailed suggestion for enhancing the practicality and relevance of the study.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It also compares this issue to sampling from the leverage score in [3], suggesting that the authors should clarify how sampling from the DPP is easier than from the leverage score. While the comment identifies a potential issue and provides a comparison, it does not explicitly instruct the authors to address this point or offer specific guidance on how to clarify the sampling process. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when eigenfunctions e_n are inaccessible, and it provides a comparison with sampling from the leverage score in [3]. This comparison adds specificity to the comment, as it highlights a potential problem and suggests that the authors should clarify how their method differs from existing approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It also compares this issue to sampling from the leverage score in [3], suggesting that the authors should clarify how their method is easier than existing approaches. The comment provides a logical comparison and highlights a potential problem, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the lack of clarity in sampling from the DPP when eigenfunctions e_n are inaccessible. It also provides a comparison with sampling from the leverage score in [3], suggesting that the authors should clarify how their method is easier than existing approaches. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context for the comparison. Overall, the comment is mostly helpful, as it effectively points out a weakness and guides the authors toward improvement, but it could be more comprehensive with further guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the generalizability of the observations to few-shot learners beyond Prototypical Networks. It suggests that the scope of the submission\\'s contributions might be limited due to this lack of evaluation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and vague, as the authors are left to infer that they need to conduct additional evaluations but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper regarding the generalizability of the observations to few-shot learners beyond Prototypical Networks. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of limited scope but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the extent to which the observations generalize to few-shot learners beyond Prototypical Networks, which may limit the scope of the submission\\'s contributions. This claim is somewhat verifiable as it highlights a potential gap in the evaluation of the paper\\'s findings. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the observations presented do not evaluate their generalizability to few-shot learners beyond Prototypical Networks. This is a valid concern that could impact the scope of the submission\\'s contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or conduct additional evaluations to enhance the generalizability of their findings. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specific guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality (e.g., modality A) while others perform well with another (e.g., modality B). It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how to deal with this issue. The action is implicit and vague, as the authors are left to infer that they need to address the problem but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential difference in contributions of different modalities across instances and questioning how to deal with this problem. The comment provides a clear direction for the authors to address the concern, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this issue, specifically referencing Equation 3. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim or explain why this is a problem. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. This feedback highlights a specific area where the authors may need to clarify or address the implications of their method on different modalities. However, the comment does not provide detailed guidance or suggestions on how to resolve this issue, leaving the authors with a general direction but without actionable steps. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks depth in offering solutions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the impact on the number of parameters and possibly compare it with prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clearer discussion on the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective equation (Eq. 2) requires optimization over both the transformation parameters and the shared model parameters, and that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. The comment provides a specific reference to AlignFlow, which supports the claim by indicating a relevant work for comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed objective equation differs from prior work. Overall, the claim is mostly verifiable, as it provides a clear reference but lacks additional supporting details. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it highlights a gap in the discussion that the authors need to address. By suggesting that the authors should discuss the impact on the number of parameters, the comment provides a specific direction for improvement. However, it could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical aspect of their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the questions or improve the results, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the implications of Eq. 4 and the value of u^l in Eq. 3, which provides some grounding as it refers to specific equations in the paper. However, it does not specify which part of the paper these equations are located in, making it weakly grounded. The comment also critiques the improvement in the designed solutions presented in Table 5, specifically mentioning the marginal improvement on the OfficeHome dataset. This part is specific as it provides a clear example of the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, and it critiques the improvement in the designed solutions presented in Table 5. The claim about the marginal improvement on the OfficeHome dataset is supported by specific numerical values, which provides some level of verification. However, the comment lacks detailed reasoning or references to support the broader claim about the implications of Eq. 4 and the value of u^l. Therefore, the claim is somewhat verifiable, as it provides some evidence but could be strengthened with more detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, which could be an important point for the authors to clarify. Additionally, it critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. This feedback is somewhat helpful as it points out a potential issue with the results, but it lacks depth and does not provide specific suggestions for improvement. The authors are given some insight into areas that may need further exploration or clarification, but the comment could be more helpful with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the idea of utilizing a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1] in the context of real-time dynamic reconstruction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of using a volumetric representation in the deformation field, specifically mentioning VolumeDeform [1] as a reference. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results section, but this inference is not as direct as it could be. The comment is specific in pointing out the lack of novelty in the volumetric representation approach, but it lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1] as a reference. This claim is supported by the mention of a specific external reference, which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed information about how VolumeDeform [1] addresses the issue or by explaining why the authors\\' approach is not novel. Despite this, the reference to VolumeDeform [1] makes the claim mostly verifiable, as it gives the authors a clear direction for further investigation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that the idea of utilizing a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1] in the context of real-time dynamic reconstruction. This feedback is somewhat helpful as it alerts the authors to a potential lack of originality in their approach. However, the comment does not provide specific guidance on how to address this issue or suggest alternative approaches that could enhance the novelty of their work. While it highlights a potential weakness, it lacks depth and actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests that it is common to average over subword representations, referencing a specific work by Hewitt and Manning (2019). This comment implies that the authors should consider averaging over subword representations as an alternative approach, but it does not explicitly instruct them to do so. While the suggestion is concrete, it is not explicitly stated as an action, leaving the authors to infer that they should consider this alternative. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement regarding the use of subword token embeddings and suggests an alternative approach by referencing a specific work by Hewitt and Manning (2019). This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach to handling subword representations, specifically mentioning the practice of averaging over subword representations. It references a specific work by Hewitt and Manning (2019) as an example of this practice. This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how this alternative approach might improve the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests an alternative approach, which is to average over subword representations, and references a specific work by Hewitt and Manning (2019) that demonstrates this practice. This feedback provides the authors with a clear suggestion for improvement and a reference to consider, which can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included a detailed explanation of why averaging over subword representations might be beneficial or how it could impact the results. Overall, the comment offers a useful direction for improvement but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these analyses or what specific aspects of the traditional method should be discussed. The actions are explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as demonstrating the consistency between predicted scores and actual risks, and suggests conducting calibration curves to show agreement. Additionally, it encourages discussing the feasibility of the generated scoring system and the differences between the traditional method and the proposed approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It encourages the use of calibration curves to show agreement and suggests discussing the feasibility of the generated scoring system. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim. The suggestion to discuss the differences between the traditional method and the proposed approach is also not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a rationale but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that while the model AUC can assess discriminant ability, it may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the authors to conduct calibration curves to show this agreement, which is a valuable suggestion for enhancing the paper\\'s credibility and relevance. Additionally, the comment suggests discussing the feasibility of the generated scoring system and the differences between the traditional method and the proposed approach. This feedback is specific, actionable, and constructive, offering the authors a clear path to improve their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their experiments, use default settings for baselines, include missing baselines, and discuss limitations and societal impacts. However, the lack of specific guidance on how to implement these changes makes the comment somewhat actionable. The authors know what needs to be done but may struggle with the details of execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues relate to, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can make an educated guess about the general areas being addressed, the comment lacks full grounding. The feedback is specific in terms of the issues raised, such as the use of position kernels and the absence of certain baselines, but it does not provide detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the experiments, including concerns about their strength and fairness, the use of position kernels, and the absence of certain baselines. The reviewer questions the choice of baselines and suggests that the paper should use default settings from the literature. Additionally, the comment points out the lack of discussion on limitations and societal impacts. While the reviewer provides some reasoning for their concerns, such as questioning the use of position kernels and the absence of certain baselines, the comment lacks specific examples or references to support these claims. This makes the claims somewhat verifiable, as the authors would need to delve deeper into the literature to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including concerns about the strength and fairness of the experiments, the use of position kernels, and the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. These points are actionable and provide clear guidance for the authors to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of relevant baselines to include. Overall, the feedback is mostly helpful as it directs the authors to important areas for improvement, but it could be more detailed to fully support the authors in enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that all sparsity patterns seem to perform equally well, without providing any insight into what is happening. It also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment identifies a potential issue and offers a specific correction, it does not provide guidance on how the authors might address the lack of insight into the sparsity patterns. The action is explicit but somewhat vague, as it lacks detailed instructions on how to improve the analysis or presentation of the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that all sparsity patterns seem to perform equally well and lacks insight into what is happening. Additionally, it suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all sparsity patterns perform equally well and questions whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform equally well without providing any insight into what is happening. This observation raises questions about the uniqueness of this finding to the sparsity detection problem or if it is a general characteristic of Graph Neural Networks (GNNs). The comment also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment highlights an area for further exploration and provides a specific correction, it lacks depth and actionable guidance on how the authors might address the lack of insight or improve their analysis. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a comparison, but they are not provided with specific guidance on how to execute this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should compare the perspective taken in the present manuscript to the contributions of prior efforts, providing clear guidance on what needs to be addressed in Section 6. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that while the related work section is comprehensive, it could benefit from comparing the current manuscript\\'s perspective to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why such a comparison is necessary. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper, specifically suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by contextualizing their contributions within the broader literature. However, the comment could be more helpful if it offered examples or guidance on how to effectively make these comparisons. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not explicitly instruct the authors to conduct this examination or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should explore the impact of varying the number of scenarios, but they are not given specific instructions on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental setup or results section, but this inference is not direct. The comment is specific in suggesting an area for exploration, but it lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance of the model is likely related to the number of scenarios used for training, and it recommends examining the performance with different numbers of scenarios. This feedback is somewhat helpful as it identifies a potential area for exploration and improvement in the paper. However, it lacks specificity and does not provide detailed guidance on how to conduct this examination or what specific insights might be gained from it. The authors are given a general direction but not a clear path forward, making the comment somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between generating a quality label and the model\\'s ability to predict it. It suggests considering whether disturbances in the training data could affect the model\\'s performance in generating correct quality labels. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what experiments to conduct. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between generating quality labels and the model\\'s ability to predict them, suggesting that disturbances in the training data might affect the model\\'s performance. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questioning of the model\\'s ability to predict quality labels under certain conditions, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between generating quality labels and the model\\'s ability to predict them, suggesting that disturbances in the training data might affect the model\\'s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the relationship between generating quality labels and the model\\'s ability to predict them. It suggests considering whether disturbances in the training data could affect the model\\'s performance in generating correct quality labels. This feedback is somewhat helpful as it prompts the authors to think critically about the robustness of their model and its ability to generalize under different conditions. However, the comment lacks specific guidance or suggestions on how to address this issue or what experiments to conduct to test the model\\'s robustness. While it provides a valuable insight, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their draft. The references to other works imply that the authors should consider these extensions, but the comment lacks concrete instructions on how to incorporate this information into their paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"bounded noise assumption\" in the context of stochastic optimization literature, suggesting that it is somewhat restrictive. It references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou, which provide extensions to these noise conditions. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The comment is specific in suggesting that the authors consider these extensions, but it lacks detailed guidance on how to incorporate this information into their work. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they are recent and relevant studies that have explored extensions to the noise conditions. However, the comment could be strengthened by providing more detailed explanations or examples of how these works address the limitations of the bounded noise assumption. Overall, the claim is mostly verifiable, as it is supported by references to relevant literature, but it could benefit from more detailed justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a potential limitation in the paper\\'s use of the bounded noise assumption, noting that it is somewhat restrictive in the context of stochastic optimization literature. It references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou, which have explored extensions to these noise conditions. This feedback is somewhat helpful as it points out a specific area for improvement and provides references to relevant literature. However, it lacks detailed guidance on how the authors might incorporate these extensions into their work or how they might address the limitations of the bounded noise assumption. To be more helpful, the comment could include suggestions or examples of how to apply these extensions or discuss their implications. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what steps to take to rectify the problems. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide examples or details about the specific writing issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper contains \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand and address the issues. Without detailed examples or references, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues, leaving the authors without actionable feedback. Without detailed suggestions or examples, the comment lacks depth and does not offer a clear path for improvement. As a result, it is barely helpful, as it identifies a problem but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. While the comment highlights an area for further exploration and a potential overlap with existing work, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is somewhat actionable as it identifies a potential area for improvement but lacks concrete steps or detailed advice on how to proceed. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation and goals of the model\" and the \"related work review part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the similarity between the model\\'s goals and those of a prior VAE paper, suggesting that the authors should be aware of this overlap. This provides clear guidance on what needs to be addressed in the related work section. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to those of a prior VAE paper. The comment provides a logical reasoning by comparing the novelty of energy models to GANs and VAEs, and by referencing a prior VAE paper for context. However, it lacks specific details or references to support the claim about the similarity in motivation and goals, which would strengthen the verifiability of the comment. Therefore, the claim is mostly verifiable, as it provides a solid foundation but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a more nuanced discussion of the model's goals in relation to existing work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the model's approach or how to address the similarity with the prior VAE paper. Overall, the feedback offers some insight but lacks depth and actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should conduct experiments to explore these challenges, but it lacks concrete steps or suggestions on how to implement these experiments. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of experiments on the difficulties in obtaining labeled data for imitation learning and how performance changes with varying data sizes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for experiments on data acquisition and performance variation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no experiments on the difficulties in obtaining labeled data for imitation learning and how performance changes with varying data sizes. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the importance of such experiments based on general knowledge of the field. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It highlights the importance of conducting experiments to explore these issues, which is a crucial aspect of the methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as proposing specific experiments or analysis techniques. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. However, it does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should clarify or rephrase the term to avoid misinterpretation. The comment lacks concrete details on how to implement this change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"line 267\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the terminology \"certificate\" and explains the concern regarding its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or context to explain why this might be a problem. Without additional information or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. This is a valid observation that could lead to misinterpretation. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative terminology or clarifying the context in which \"certificate\" is used. While it highlights a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the types of experiments and references examples, but it is implicit in the sense that the authors need to infer that they should conduct these experiments. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the types of experiments and providing references, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. It provides references to specific papers ([1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing) that could serve as examples or inspiration for these experiments. This provides a clear rationale for the suggestion, as the references offer concrete examples of experiments that could be conducted. However, the comment could be strengthened by explaining why these specific experiments are necessary or how they would contribute to the paper\\'s strength. Overall, the claim is mostly verifiable due to the provided references, but it could be more robust with additional explanation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from additional experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to further strengthen its findings. It provides specific references to relevant papers, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as examples or inspiration for these experiments. This feedback is clear and actionable, as it directs the authors to specific areas where they can enhance their work. However, the comment could be more helpful if it included a detailed explanation of why these experiments are necessary or how they would contribute to the paper\\'s overall impact. Despite this, the suggestion is mostly helpful as it provides a concrete direction for improvement. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should explore this reformulation to improve the prox-linear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions on how to implement this reformulation or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the steps to take and how to apply the suggested reformulation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the prox-linear subproblem can be reformulated using the conjugate function, which makes the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is somewhat verifiable as it provides a logical reasoning for the equivalence, but it lacks specific examples or references to support the assertion fully. The authors would need to explore the reformulation to understand the claim's validity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation implies that the motivation for Algorithm 1 may be unclear or unnecessary. However, the comment does not provide specific guidance on how to address this issue or improve the clarity of the motivation. While it highlights a potential weakness, it lacks actionable suggestions or detailed feedback, making it somewhat helpful. The authors are given some insight into a potential area for improvement but are left without a clear path forward. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including multiple local prompts may be beneficial, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of varying features and positions across different categories. Without specific suggestions or instructions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that including multiple local prompts may be beneficial, but it does not specify which part of the paper this claim is based on. It also does not provide any details on what features and positions are being referred to, making it difficult for the authors to identify the specific issue or area that needs attention. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including multiple local prompts may be beneficial, but it also notes that the features and their positions are not the same across different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including multiple local prompts may be beneficial, but it points out that the features and their positions are not the same across different categories. However, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue or improve their work. Without detailed feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the alignment of results between Table 6 and Table 1 (MCT-pair), as well as the ablation studies of MCT without adaptive metrics. While it identifies areas of potential concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to investigate and clarify these discrepancies, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the alignment of results and the absence of ablation studies for MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the alignment of results between Table 6 and Table 1 (MCT-pair), as well as the absence of ablation studies for MCT without adaptive metrics. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions, rendering the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two specific questions about the results presented in the paper. It questions the alignment of results between Table 6 and Table 1 (MCT-pair), which could indicate a discrepancy or inconsistency in the data. Additionally, it asks about the absence of ablation studies for MCT without adaptive metrics, suggesting that this could be an important aspect to explore. While the comment identifies potential issues, it does not provide detailed guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it points out areas for further investigation, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. However, the comment does not explicitly instruct the authors to address this issue or suggest how to differentiate their work from existing research. The action is implicit, as the authors can infer that they need to discuss the novelty and originality of their work in relation to prior studies. The feedback is somewhat actionable because it points out a potential weakness but lacks specific guidance on how to address it. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses are already present in prior works, making the results not particularly surprising. This provides clear guidance on what needs to be addressed in terms of novelty and originality. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses are already present in prior works, making the results in the current paper not particularly surprising. It supports this claim by referencing specific prior works, such as RobustBench and [Croce et al. (2021)], which have studied the robustness of CIFAR-10 models on distribution shifts. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from or builds upon these prior studies. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. This feedback is somewhat helpful as it highlights a potential weakness in the paper, namely the lack of novelty in the analyses presented. However, it does not offer specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing research. While it provides some insight into the need for originality, it lacks depth and actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the 10 sub-tasks are too simplistic for bAbi and that the authors could solve all of them with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not explicitly instruct the authors to add these discussions or specify how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add more discussion but are not given clear guidance on what to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the 10 sub-tasks in the context of bAbi, suggesting that they are too simplistic and that the authors could solve all of them with their final model. However, it does not specify which part of the paper these sub-tasks are discussed in, making it weakly grounded. The comment is specific in its suggestion that more discussions are required, but it lacks detailed guidance on what aspects should be discussed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are too simplistic for bAbi and that the authors could solve all of them with their final model. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of this assertion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the simplicity of the 10 sub-tasks in the context of bAbi, suggesting that the authors could solve all of them with their final model. It implies that the paper lacks sufficient discussion on this aspect, which could be a critical area for improvement. However, the comment does not provide specific guidance on how the authors might address this issue or what additional discussions could be included. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This implies that the authors should clarify the meaning of this term. Second, it points out the absence of related work, suggesting that the paper seems to be related but does not negate its novelty. While the comment identifies areas for clarification and suggests the inclusion of related work, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the term \"sqeuence of episodes\" and suggesting that practice and evaluation might be the types of sequences being referred to. Additionally, it points out the absence of related work, which is a specific area for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two distinct claims. The first claim questions the term \"sqeuence of episodes\" and suggests that practice and evaluation might be the types of sequences being referred to. This is a subjective opinion that requires clarification, but it is not entirely unverifiable as it points out a potential ambiguity in the text. The second claim points out the absence of related work, suggesting that the paper seems related but does not negate its novelty. This claim is somewhat verifiable as it provides a logical reasoning for the absence of related work, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this term. Second, the comment points out the absence of related work, noting that the paper seems related but does not negate its novelty. This is a valuable observation that could help the authors contextualize their work within the existing literature. However, the comment could be more helpful if it provided specific examples of related work or suggested how to address the issue of novelty. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes might be necessary to clarify the nature of the study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the study\\'s classification, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This claim is based on a logical reasoning that ablation studies typically involve removing or varying a specific component to assess its impact. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the context of their study and the typical definitions of ablation studies to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the classification of the study on different subdomain sizes as an 'ablation' study, suggesting that it does not involve removing a component of the method. This feedback is somewhat helpful as it points out a potential misunderstanding or mislabeling in the study's methodology. However, it lacks depth and does not provide specific guidance on how the authors might clarify or correct this classification. The comment identifies a potential issue but does not offer actionable steps for improvement, leaving the authors with a general direction but not a clear path forward. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without architectural competitors like AutoDial and AdaBN. This implies that the authors should include these competitors in their evaluation to provide a more comprehensive comparison. However, the comment does not specify how to implement this suggestion or which specific aspects of the evaluation should be adjusted. The action is implicit and somewhat vague, as the authors need to infer that they should include additional competitors and figure out how to integrate them into the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without architectural competitors like AutoDial and AdaBN. This provides clear guidance on what needs to be addressed to enhance the evaluation. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation would be stronger if the base DA methods were compared with and without architectural competitors like AutoDial and AdaBN. The comment provides a logical reasoning by stating that including these competitors would provide a more comprehensive comparison, making the evaluation stronger. However, it lacks specific examples or references to support the claim that AutoDial and AdaBN are direct competitors to the proposed TransferNorm architecture. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for enhancing the evaluation section of the paper. It acknowledges the current evaluation as a good start but suggests that it would be stronger if the base DA methods were compared with and without architectural competitors like AutoDial and AdaBN. This feedback is actionable as it offers a specific direction for improvement, encouraging the authors to include these competitors in their evaluation to provide a more comprehensive comparison. However, the comment could be more helpful if it provided additional guidance on how to incorporate these competitors or why they are relevant. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for enhancing the evaluation, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on how the attention module is attached to the ResNet-20 architecture during the search process. It specifically requests information on the number of attention modules used and their placement, such as after each block or stage. This provides clear and direct guidance for the authors to address the issue by providing detailed explanations or visualizations. The comment is highly actionable as it specifies exactly what needs to be clarified and how the authors can improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module\" and \"backbone ResNet-20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the exact placement and number of attention modules used during the search process. The comment provides detailed guidance on what information should be included to improve the clarity of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the attachment of the attention module to the ResNet-20 architecture during the search process. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of the attention module into the ResNet-20 architecture during the search process. It asks for clarification on the number of attention modules used and their placement, such as after each block or stage. This feedback is clear and actionable, as it provides the authors with a precise direction for improving the clarity and comprehensiveness of their draft. By addressing these questions, the authors can enhance the understanding of their methodology and provide a more detailed explanation of their approach. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the clarity of Theorem 8, which is crucial for understanding the linear convergence rates. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the proof of Theorem 8, but it does not specify how to do so or what changes are needed. This makes the action vague and inferred, aligning with a score of 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the clarity of the proof of Theorem 8, particularly its location at the end of the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific details or examples to support this claim, nor does it offer suggestions for improving the clarity of the proof. This lack of supporting evidence or detailed reasoning makes the claim difficult for the authors to address effectively, rendering it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential obstacle for readers who may struggle to understand the theoretical foundation of the paper. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the proof or where it could be moved to a more accessible location in the main text. Despite this, the comment is somewhat helpful as it directs the authors\\' attention to a critical area that needs improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should expand their analysis to include a broader range of NAS approaches, but the comment lacks concrete details on which specific approaches to consider or how to incorporate them. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the analysis of BRP-NAS, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This provides full grounding as it explicitly mentions the specific part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what is missing in the analysis, namely a comparison with other NAS approaches. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of BRP-NAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This claim is somewhat verifiable as it provides a specific critique of the analysis, noting the limited scope of comparisons. However, the comment lacks detailed reasoning or examples of how these other approaches could enhance the analysis, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claim but could be more fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This feedback is clear and actionable, as it highlights an area where the authors could expand their analysis to provide a more comprehensive evaluation. By suggesting the inclusion of additional NAS approaches, the comment offers a concrete direction for improvement, which can help the authors enhance the depth and breadth of their analysis. However, the comment could be more helpful if it provided specific examples or references to these alternative approaches, which would further guide the authors in making these additions. Overall, the comment is mostly helpful, as it provides valuable feedback that can lead to a more robust evaluation of BRP-NAS.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader real-world applications compared to digit or text images. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further testing, modification, or discussion regarding the method\\'s applicability to natural images. Without any guidance or direction, the authors are left without a clear understanding of how to address this concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader real-world applications compared to digit or text images. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questioning of the method\\'s applicability but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader real-world applications compared to digit or text images. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader real-world applications compared to digit or text images. This is a relevant concern that could impact the practicality and relevance of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or explore the method\\'s applicability to natural images. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is existing work that offers a way to approximate the contribution of FFNs, given that a linear decomposition cannot be obtained. It suggests that if no such work exists, the authors should add a statement indicating that it is an open problem. This feedback is explicit in its request for additional information and provides a clear direction for the authors to follow. The suggestion to add a line or two to address the issue is concrete, as it specifies what the authors should do to improve the readability and clarity of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider existing work that might offer a way around the issue of not being able to obtain a linear decomposition. The comment further recommends adding a statement indicating that there is no solution for this problem and that it is an open issue. This provides clear guidance on what needs to be addressed to improve the readability and overall picture of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, and suggests that the authors consider existing work that might offer an approximation. The comment implies that the current state of knowledge does not provide a solution, and suggests adding a statement to acknowledge this as an open problem. However, the comment does not provide specific references or detailed reasoning to support the claim that no existing work offers an approximation. This lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand the issue and its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid point about the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider whether there is existing work that offers a way around this limitation, such as an approximation. If no such work exists, the comment recommends adding a statement to acknowledge this as an open problem, which would improve the readability and clarity of the paper. This feedback is clear and actionable, providing the authors with a specific direction to enhance their draft. However, it could be more helpful if it included examples of existing work or more detailed guidance on how to address the issue. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about questionable design choices, specifically the use of perplexity as a measure of the model retaining semantic information after fine-tuning. It highlights the need to consider domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not provide explicit guidance on how to address these concerns or control these factors. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore methods to mitigate domain drift and catastrophic forgetting but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about \"questionable design choices\" related to the use of perplexity as a measure of the model retaining semantic information after fine-tuning. It mentions the need to consider aspects of domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the design choices and the need to control domain drift and catastrophic forgetting, but without explicit references to specific sections, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of perplexity as a measure of the model retaining semantic information after fine-tuning, suggesting that it may not fully account for domain drift and catastrophic forgetting. The comment questions how these factors are controlled, implying that the authors should provide a more comprehensive explanation or justification for their design choices. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues and how to address them, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the design choices in the paper, specifically the use of perplexity as a measure of the model retaining semantic information after fine-tuning. It highlights the need to consider aspects of domain drift and catastrophic forgetting, which are separate from the original task. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or control these factors. While it points out a potential weakness, it lacks actionable feedback, leaving the authors with a general idea of what might need improvement but without detailed steps to take. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or expand their method to include other types of features. The comment implies that the authors should consider the broader applicability of their method, but it lacks concrete steps or recommendations for how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the limitation of the work and suggests that the method should be tested with a mix of feature types. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. This is a subjective opinion that suggests a limitation in the current approach. However, the comment does not provide specific examples, references, or detailed reasoning to support why the method should be applicable to other types of features. The lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as it requires the authors to infer the potential applicability based on the reviewer\\'s suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the work by noting that it only uses binary features, whereas real-world data often includes a mix of binary, real, and categorical features. This observation highlights a potential gap in the applicability of the method, suggesting that the authors should consider whether their approach can be extended to handle other types of features. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore the applicability to real and categorical features. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the algorithm for constructing coreset is not novel, as it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of novelty or suggestions for improving the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the algorithm for constructing coreset, specifically mentioning that it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper discusses this algorithm, making it weakly grounded. The comment is specific in detailing the lack of novelty, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coreset is not novel, as it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This claim is somewhat verifiable, as it provides a logical reasoning by referencing existing frameworks. However, the comment lacks specific references or examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment points out a lack of novelty in the algorithm for constructing coreset, noting that it extends existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. While this feedback identifies a potential weakness in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the originality of their work. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their approach, but it lacks concrete details on what changes should be made or how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its questioning of the methodology, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the decision to only consider ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, the comment does not provide any supporting evidence, reasoning, or references to justify why including all reports would be easier or more beneficial. Without additional context or explanation, the claim remains vague and unverifiable, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the methodology used in the paper, specifically why only ECG segments with one label are considered. It suggests that including all reports might be more beneficial, implying that the current approach might be limiting. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or why including all reports would be beneficial. Without actionable advice or further explanation, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This implies that the authors should increase the complexity of their instances to better test the capabilities of LLMs. However, the comment does not provide specific guidance on how to achieve this or what specific constraints or variables should be added. While the action is implicit, it is somewhat concrete in suggesting a direction for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in suggesting the need for more complex instances, but without clear grounding, the authors may struggle to identify the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This raises a concern about the ability of LLMs to model problems with large instance sizes. The comment provides a logical reasoning for the suggestion, as it implies that the current instances may not adequately test the capabilities of LLMs. However, the comment lacks specific examples or references to support the claim about the limitations of the current instances. Therefore, the claim is somewhat verifiable, as it provides a rationale but requires further evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This feedback is somewhat helpful as it identifies a potential limitation in the experimental setup and suggests a way to improve it. However, the comment could be more helpful if it provided specific guidance on how to increase the complexity of the instances or what types of constraints or variables should be added. Additionally, it could benefit from a clearer explanation of why this is important for testing the capabilities of LLMs. Overall, the comment offers a direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It asks whether this means the base node affects the ordering, key nodes for attention, and ultimately the model performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what specific aspects of the paper need clarification or improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NodeSort\" and \"base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node, asking whether this affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It does not contain a claim or opinion that requires verification. It is a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It seeks clarification on whether this affects the ordering, key nodes for attention, and ultimately the model performance. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the implications in their paper. The feedback is somewhat helpful as it points out a potential area of ambiguity, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i), implying that the current direction might not align with this purpose. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative directions for the arrow. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the direction of the arrow based on the reviewer\\'s suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in Figure 2 and suggests that it should be from the latent space to n^(i) instead of from a Gaussian space. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of an arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space. The comment provides a logical reasoning for the suggested change, implying that the current direction might not align with the main purpose of influencing n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is sound, the lack of additional evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the direction of an arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is somewhat helpful as it prompts the authors to reconsider the representation of their model and potentially clarify the purpose of the arrow. However, the comment lacks depth and does not provide suggestions or guidance on how to address this issue or improve the clarity of the figure. While it identifies a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the paper, namely that many abbreviations lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to avoid confusion. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of undefined abbreviations, particularly mentioning \"AR\" and its meaning in the context of domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning \"AR\" in Table 5. This claim is verifiable as it provides a clear example of an undefined abbreviation and its context, allowing the authors to understand and address the issue. The comment is specific and provides a concrete example, making it mostly verifiable. However, it could be further strengthened by suggesting how the authors might define these abbreviations or provide a list of undefined abbreviations for clarity. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that many abbreviations are undefined and cause confusion. It provides a concrete example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to improve clarity and avoid confusion. By addressing this issue, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it suggested specific ways to define the abbreviations or provided a list of undefined abbreviations. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the performance comparison in Table 1, specifically that VINS sets different sample weights, while most compared baselines set all sample weights as 1. This implies that the comparison may not be fair due to the different sample weights. However, the comment does not provide explicit guidance on how to address this issue or suggest a way to make the comparison fair. The action is implicit and somewhat vague, as the authors need to infer that they should either adjust the sample weights for the compared baselines or find another way to make the comparison fair. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance comparison, noting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed to ensure a fair comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights, while most compared baselines set all sample weights as 1. This claim is somewhat verifiable as it highlights a potential issue with the comparison, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The comment does not provide a clear explanation of how the different sample weights might affect the fairness of the comparison, nor does it offer suggestions for how to address this issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This observation highlights a potential unfairness in the comparison, which could impact the validity of the results. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative methods for ensuring a fair comparison. While it points out a critical flaw, it lacks actionable advice, making it somewhat helpful. The authors are informed of a potential problem but are left to figure out how to resolve it on their own. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the reply buffer being too large, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize the buffer size or proposing alternative methods to reduce complexity. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"reply buffer\" and references a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning,\" which provides some grounding by indicating the context of the issue. However, it does not specify which part of the paper discusses the reply buffer or how the time complexity issue is addressed. The authors can infer that it relates to the methodology or results section, but the comment lacks full grounding. The comment is specific in identifying the potential issue with the time complexity of a large reply buffer, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.\" However, the comment does not provide detailed reasoning or examples to support why the time complexity would be a concern or how it relates to the referenced paper. The reference to the paper is not fully utilized to substantiate the claim, making the comment somewhat verifiable. The authors would need to delve into the referenced work to fully understand the claim, which adds to the complexity of verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could lead to high computational costs. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or optimize the buffer size. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a brief conclusion and a summary of the paper\\'s contributions. This is a clear and direct action that the authors can take to improve their draft. The comment specifies exactly what needs to be added, providing concrete guidance on how to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a brief conclusion and a summary of the paper\\'s contributions are needed. However, it does not specify which part of the paper this should be included in, such as the abstract, introduction, or conclusion sections. Without explicit references to these sections, the authors may find it challenging to determine where to make these additions. The comment is specific in its request for a conclusion and summary but lacks grounding due to the absence of specific references. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a brief conclusion and a summary of the paper\\'s contributions are necessary. However, it does not provide any reasoning, examples, or references to support why these elements are missing or why they are important. Without additional context or justification, the authors may find it challenging to understand the significance of this feedback or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a clear gap in the paper by pointing out the need for a brief conclusion and a summary of the paper\\'s contributions. This feedback is actionable as it provides a specific direction for the authors to enhance their draft by ensuring that the paper is concluded effectively and that the reader is aware of the key contributions. However, the comment could be more helpful if it offered suggestions on how to structure the conclusion or what aspects to highlight in the summary. Despite this, the feedback is mostly helpful as it directs the authors toward a critical aspect of the paper that needs improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APE-GAN may not fully demonstrate the framework\\'s capabilities. While the comment implies that this additional comparison would enhance the paper\\'s results, it does not explicitly instruct the authors to make this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison and figure out how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the current comparison with APE-GAN may not fully demonstrate the framework\\'s capabilities. However, it does not specify which part of the paper this suggestion should be addressed in, such as the results section or the discussion. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting a potential enhancement to the comparison, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that comparing the proposed framework with a method designed to defend against multiple attacks would provide more meaningful results. However, the comment does not provide specific examples or references to support the claim that such a comparison would be beneficial or that the current comparison with APE-GAN is insufficient. The suggestion is based on logical reasoning, but it lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an additional comparison for the proposed framework, which could enhance the paper\\'s results by demonstrating its effectiveness against multiple attacks. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their draft. However, the comment could be more helpful if it included examples of methods that defend against multiple attacks or provided guidance on how to conduct such a comparison. Despite this, the suggestion is valuable and offers a concrete way for the authors to strengthen their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the plan-based method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, as indicated by Table 2. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the plan-based method and its requirement for manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also mentions the comparison with learned plan methods and the difficulty in generalizing to new datasets without ground truth summaries, as indicated by Table 2. However, the comment does not specify which part of the paper discusses these issues or where Table 2 is located, making it weakly grounded. The comment is specific in detailing the concerns about the plan-based method and its limitations, but without clear grounding, it is challenging for the authors to pinpoint the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also suggests that the learned plan methods are not comparable to those with pre-defined plans, as indicated by Table 2. The comment provides a logical reasoning by highlighting the impracticality of manual plan design and the lack of comparability with pre-defined plans. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to consider this critique and potentially provide additional evidence or comparisons to strengthen their argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the plan-based method, specifically that it requires manual design of a plan based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with pre-defined plans, as indicated by Table 2. This feedback highlights a critical issue with the generalizability of the proposed method, suggesting that it may struggle to adapt to new datasets without access to ground truth summaries. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. While it raises an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding a first sentence to introduce Section 3.2, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be done, making it highly actionable. The authors know exactly how to apply this feedback to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2, but it does not provide any reasoning or justification for why this is necessary or how it would improve the clarity of the section. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a first sentence to introduce Section 3.2, which is a clear and actionable piece of feedback. This recommendation can help improve the clarity and organization of the paper by providing a clear overview of what the section covers. However, the comment could be more helpful if it explained why this introduction is necessary or how it would enhance the reader\\'s understanding. Despite this, the feedback is still somewhat helpful as it provides a specific suggestion for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial rationale selector being \"perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what aspect of the paper needs clarification or further explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the initial rationale selector is \"perfect,\" suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"perfect\" in the context of the initial rationale selector, suggesting that if it were perfect, no additional work would be needed. This feedback identifies a potential ambiguity or misunderstanding in the paper and prompts the authors to clarify their rationale. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it highlights a point that needs attention, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a clarification to improve the clarity of the paper. It explicitly recommends updating the definition of uncertainty to include the representation of epistemic model uncertainty in the prior distribution and its update to a posterior distribution upon observing data. This provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to enhance the clarity of their draft. The comment is explicit and provides detailed guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the definition of \"uncertainty\" and suggests a clarification regarding the representation of epistemic model uncertainty in the prior distribution and its update to a posterior distribution. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear suggestion for improving the clarity of the definition, specifying what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a clarification regarding the definition of uncertainty, proposing a more detailed explanation of how epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This suggestion is based on logical reasoning and provides a clear path for the authors to enhance the clarity of their work. However, the comment does not include specific references or examples to fully substantiate the claim, which limits its verifiability. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the authors to improve their draft but lacks detailed evidence or references to fully support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the clarity of the paper. It identifies a specific area where the definition of uncertainty could be clarified by explaining how epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This feedback is valuable as it guides the authors on how to enhance the comprehensibility of their work, particularly in the context of uncertainty representation. However, the comment could be more helpful if it included additional suggestions or examples to further clarify the concept. Overall, the comment is mostly helpful as it offers a constructive way to improve the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct questions. The first question is about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. This is an implicit action, as the authors are being asked to clarify their experimental approach. However, it is not explicitly stated, and the authors may need to infer that they should provide additional information on this aspect. The second question is about the number of questions created for the zero-shot intent classifier and its accuracy. This is also an implicit action, as the authors are being asked to provide specific details about their experimental setup. Both questions are somewhat vague, as they do not provide explicit instructions on how to address them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the experimentation with domain ontologies to avoid placeholder generation and the details about the zero-shot intent classifier, such as the number of questions created and its accuracy. This provides clear guidance on what the authors need to clarify or expand upon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification about the experimental setup and results. The first question asks if the authors experimented with domain ontologies to avoid placeholder generation, and the second question inquires about the number of questions created for the zero-shot intent classifier and its accuracy. These are factual questions that require clarification and do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two distinct questions that could help the authors improve their draft. The first question seeks clarification on whether the authors experimented with the use of domain ontologies to avoid the generation of placeholders in the evaluated responses. This is a relevant inquiry that could provide insight into the robustness of the experimental setup. The second question asks for specific details about the zero-shot intent classifier, including the number of questions created and its accuracy. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the comprehensiveness and clarity of their results. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar experiments have been conducted in the field. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines despite mentioning various model criticism techniques. The reviewer suggests that the authors could compare with a chain-of-thought prompting approach. This feedback is explicit and provides a concrete suggestion for improvement, indicating that the authors should consider adding more robust baselines to their comparisons. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of meaningful baselines and suggests a particular approach, such as comparing with a chain-of-thought prompting method, to enhance the comparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests that the authors could compare with a chain-of-thought prompting approach, providing a specific example of a more meaningful baseline. This suggestion is supported by logical reasoning and a concrete example, making the claim mostly verifiable. However, the comment could be strengthened by explaining why the current baselines are insufficient or how the suggested baseline would improve the analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that despite mentioning various model criticism techniques in Section 2, the authors only compare with simple naive baselines. The reviewer suggests a specific alternative, such as comparing with a chain-of-thought prompting approach, which could provide a more robust and meaningful comparison. This feedback is clear and actionable, offering the authors a concrete suggestion for improving the depth and relevance of their comparisons. By addressing this issue, the authors can enhance the validity and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that important experimental details are missing or relegated to the appendix, and the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback provides a clear and explicit action for the authors to take: they should include detailed explanations and interpretations of the experimental results, particularly for the PCA experiments mentioned. The comment is highly actionable as it specifies exactly what needs to be addressed and provides concrete guidance on how to improve the draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of missing explanations and interpretations for the PCA experiments in these figures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the appendix, and that the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This claim is somewhat verifiable as it highlights a specific issue with the presentation of experimental results, but it lacks detailed examples or references to support the claim fully. The authors would need to review their paper to understand the extent of the issue, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the presentation of experimental details, noting that many important details are missing or relegated to the appendix. It specifically points out that the PCA experiments in Figures 3, 7, and 8 are not explained, which is a critical oversight. This feedback is clear and actionable, as it directs the authors to include detailed explanations and interpretations of their experimental results, particularly for the mentioned figures. By addressing this feedback, the authors can significantly enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as highly helpful, as it provides specific guidance that can lead to substantial improvements in the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the notation \"K\" being used for both a known kernel function and the number of layers. However, it does not provide explicit guidance on how to resolve this issue or suggest a specific action for the authors to take. The comment implies that the authors should clarify or differentiate the use of \"K\" in their notation, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L166 and L176) where the notation \"K\" is used for different purposes, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that \"K\" is used for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is abused by being used for both a known kernel function and the number of layers. This claim is supported by specific line references (L166 and L176), which provide evidence of the notation\\'s misuse. The mention of specific lines allows the authors to verify the claim and understand the context of the notation\\'s use. Therefore, the comment is fully verifiable, as it provides clear and direct evidence to support the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K\" being used for both a known kernel function and the number of layers. This feedback is clear and actionable, as it directs the authors to clarify or differentiate the use of \"K\" in their notation to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to resolve this issue, such as recommending alternative notations or explaining the context in which \"K\" is used. Despite this, the comment still offers valuable guidance that can help the authors improve the clarity and consistency of their notation, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\\' statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison. However, it does not explicitly instruct the authors to make these clarifications or provide specific guidance on how to incorporate additional citations. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' statement about the problem being fairly reductionist and the reference to \"Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition and suggests that the authors need to clarify their claim and provide more citations for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of connections to human cognition in the context of the paper, specifically the statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR. The reviewer challenges the authors\\' claim by pointing out that the problem is described as fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that it would be surprising for a behavioral economist to ignore these aspects and requests more citation for comparison. While the comment provides some reasoning, it lacks specific examples or detailed references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the critique but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\\' statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The reviewer points out that it would be surprising for a behavioral economist to ignore these aspects and suggests that the authors need to clarify their claim and provide more citations for comparison. This feedback is somewhat helpful as it identifies a potential weakness in the paper and prompts the authors to address it. However, it could be more helpful if it provided specific suggestions on how to incorporate these aspects or offered examples of relevant literature. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an issue with the wording in the conclusion, specifically mentioning that it is \"overly exaggerated\" and \"flamboyant.\" The reviewer suggests that the word choice is too elaborate, providing a clear action for the authors to take: to revise the language in the conclusion to make it more modest and less flamboyant. This feedback is direct and provides a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the wording being \"overly exaggerated\" and suggests that the word choice is \"flamboyant\" in multiple places. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide any supporting evidence or examples to substantiate this claim. Without specific examples or references to similar work, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the conclusion, noting that it is overly exaggerated and flamboyant. This feedback is clear and actionable, as it directs the authors to revise the language to make it more modest and less elaborate. By pointing out this issue, the comment provides a concrete suggestion for improvement, which can help the authors refine their writing and present their contributions more effectively. However, the comment could be more helpful if it provided examples of specific phrases or sentences that need revision. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment implies that the authors should conduct such comparisons to prove the effectiveness of their proposed approach, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification for why such comparisons are necessary or how they would impact the paper\\'s effectiveness. Without this information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. This is a critical observation that highlights an important gap in the paper\\'s evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular baselines to include or suggesting ways to integrate them into the evaluation framework. While the comment points out a key area for improvement, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the approach by stating that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their work. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the approach by mentioning the introduction of multi-granularity and multi-scale to enhance model performance, which is a common approach in convolutional networks. It also discusses the use of algorithms from object detection and their limitations in MLMs. However, the comment does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. While the comment is specific in its critique, the absence of clear grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the novelty of the approach by pointing out that the introduction of multi-granularity and multi-scale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. This feedback highlights a potential weakness in the paper\\'s contribution and provides some insight into the limitations of the approach. However, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the novelty of their work. While it identifies an area for improvement, the comment could be more helpful with additional details or constructive feedback. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the lack of perturbation noise in selecting positive samples, which could impact generalization performance. The reviewer suggests conducting more experiments on different downstream tasks and across various domains to address these concerns. While the comment identifies specific areas for further experimentation, it does not provide explicit instructions on how to conduct these experiments or what specific metrics or analyses should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing and generalization performance. It suggests conducting more experiments on different downstream tasks and across various domains. However, the comment does not specify which part of the paper these concerns or suggestions relate to, making it difficult for the authors to pinpoint the exact sections that need revision. The authors can make an educated guess that it might relate to the experimental section, but the comment lacks full grounding. It is specific in detailing the concerns and suggestions for additional experiments, but the lack of explicit references to specific sections or parts of the paper limits its grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the lack of perturbation noise in selecting positive samples. The reviewer suggests that this could lead to lower generalization performance and recommends conducting more experiments on different downstream tasks and across various domains. However, the comment does not provide specific evidence, examples, or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The reasoning is somewhat logical but lacks detailed justification or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the lack of perturbation noise in selecting positive samples. It suggests that this could lead to lower generalization performance and recommends conducting more experiments on different downstream tasks and across various domains. While the comment identifies a potential issue and provides a direction for further experimentation, it lacks specific guidance on how to address the concerns or what specific experiments should be conducted. The feedback is somewhat helpful as it points out a potential weakness and encourages additional research, but it could be more actionable with detailed suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether fast SMP is less expressive than SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the discussion should be expanded upon or how the authors could address the question. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or justify the need for additional discussion. Without any context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment does not offer suggestions for what aspects of the discussion should be expanded upon or how the authors might explore the power of different architectures. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not provide enough detail for the authors to effectively address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that evaluating methods across different splits of train-val-test would be more robust than using different initialisation seeds. This is an explicit suggestion for improvement, as it clearly indicates what the authors should do to enhance the robustness of their results. However, the comment does not provide specific guidance on how to implement this suggestion, such as which specific splits to use or how to ensure that the evaluation is robust. While the action is explicit, the lack of concrete details makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that evaluating methods across different splits of train-val-test would be more robust than using different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion for improvement but lacks grounding, as it does not clearly indicate where in the paper this evaluation should be conducted. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating methods across different splits of train-val-test would be more robust than using different initialisation seeds. This claim is based on a logical reasoning that different splits can provide a more comprehensive evaluation of the methods\\' robustness. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this suggestion and potentially conduct additional experiments to verify its validity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that evaluating methods across different splits of train-val-test would be more robust than using different initialisation seeds. This is a clear and actionable suggestion for improving the robustness of the results. By providing a specific recommendation, the comment offers the authors a concrete way to enhance the validity and reliability of their findings. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion, such as which specific splits to use or how to ensure robustness. Overall, the comment is mostly helpful as it provides a valuable direction for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights ambiguity in Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multi-sphere icosahedral discretization process. While the comment identifies areas of concern, it does not provide explicit guidance on how to address these issues or clarify the symbols. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the symbols and address the concerns about redundancy and interference. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that some symbols are not explained clearly. Additionally, it raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the ambiguity of Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multi-sphere icosahedral discretization process. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of supporting evidence or detailed justification renders the claim somewhat verifiable, as the authors would need to infer the specific problems and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out specific weaknesses, but it lacks actionable advice or examples to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, specifically the assumption that the spectrum of a kernel is sub-gaussian, which is acceptable for Gaussian kernels but not for other popular kernels like Matern kernels. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this limitation or whether it should be explored further. The comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitation of the obtained results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular kernels like Matern kernels, whose spectrum decays polynomially. However, the comment does not specify which part of the paper discusses these assumptions or limitations, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the implications for the results, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is sub-gaussian, which is acceptable for Gaussian kernels but not for other popular kernels like Matern kernels. The reviewer provides a logical explanation by contrasting the behavior of Gaussian and Matern kernels, which supports the claim. However, the comment could be strengthened by providing specific examples or references to studies that have explored the implications of this assumption. Overall, the claim is mostly verifiable, as it offers a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the assumption of a sub-gaussian spectrum for kernels is restrictive, as it excludes other popular kernels like Matern kernels that have a polynomial decay. This feedback is valuable as it highlights a potential limitation in the scope of the results, prompting the authors to consider the broader applicability of their findings. However, the comment could be more helpful if it suggested ways to address this limitation, such as exploring the implications of different kernel types or providing examples of how the results might be extended to include other kernel classes. Despite this, the comment provides a clear direction for the authors to consider, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should focus more on the pretraining method in the main paper, as it is a key factor in the performance gain. While the comment implies that the authors should provide a more detailed discussion on the unsupervised pretraining, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more discussion on the pretraining method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining and its importance compared to other modules. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. It also suggests that the main paper lacks a detailed discussion on this aspect, which is a problem. The reviewer further supports this claim by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This comparison provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened with more specific examples or references to support the claim fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. However, it points out that there is no detailed discussion on this aspect in the main paper, which could be a problem. The reviewer further supports this by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This feedback is clear and actionable, as it suggests that the authors should focus more on the pretraining method in the main paper. By highlighting this critical aspect, the comment provides valuable guidance for the authors to improve their draft. Therefore, it is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited scope of the method\\'s testing, noting that it is only evaluated on two datasets. The comment suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. However, it does not provide specific guidance on which additional datasets to use or how to conduct the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to expand their dataset testing but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the limited scope of the method\\'s testing, noting that it is only evaluated on two datasets. However, it does not specify which part of the paper this issue is addressed in, such as the results section or the discussion of experimental methodology. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment pertains to. The comment is specific in its suggestion to test the method on more datasets, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is only tested on two datasets, suggesting that the authors should test it on more datasets to gain a better understanding of its performance. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how it could improve their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the method is only tested on two datasets. It suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. This feedback is somewhat helpful as it points out a potential area for improvement, encouraging the authors to expand their experimental evaluation. However, the comment lacks specific guidance on which additional datasets to use or how to conduct the evaluation, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify the domain of the inputs, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include information about the domain of the inputs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the domain of the inputs, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. This is a factual observation that does not contain a subjective claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It suggests that taking Z\\\\\\' as the empty set should imply that x and y are independent given W, but Eq. (7) contradicts this. This feedback is explicit in pointing out the conflict and provides a specific example to consider, making it clear what the authors need to address. However, it does not offer a direct solution or guidance on how to resolve the conflict, leaving the authors to infer the necessary steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a conflict between the second rule and the definition of minimal conditional dependence, particularly when Z\\\\\\' is taken as the empty set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It provides a logical reasoning by suggesting that if Z\\\\\\' is taken as the empty set, x and y should be independent given W, but Eq. (7) contradicts this. This reasoning is clear and provides a specific example, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example by suggesting that taking Z\\\\\\' as the empty set should imply independence between x and y given W, but Eq. (7) contradicts this. This feedback is clear and actionable, as it directs the authors to examine and potentially resolve this inconsistency. However, the comment could be more helpful if it offered suggestions on how to reconcile the conflict or provided additional context. Overall, the comment is mostly helpful as it highlights a critical issue that needs attention, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the differences between the two normalization methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper discusses Batch Normalization and Online Normalization, making it difficult for the authors to identify the exact section being addressed. It also lacks specificity because it does not detail what is unclear or what needs to be clarified about the bias in Batch Normalization and the claimed unbiased nature of Online Normalization. Without clear references or detailed explanations, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the confusion or the alleged bias. Without additional context or justification, the claim remains unverifiable, as it does not provide a clear path for the authors to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. It highlights a potential confusion in the paper regarding the estimation of the real gradient distribution. However, the comment does not provide any specific suggestions or guidance on how the authors might clarify this point or address the confusion. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this concept in their draft. The action is implicit, as the authors need to infer that they should provide further explanation or clarification. However, the comment lacks concrete details on how to address the issue, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the concept of \"local interactions,\" specifically whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the concept, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the concept of \"local interactions,\" specifically whether it refers to interactions within a time window or within the same modality. However, the comment does not make a claim or provide an opinion that requires verification. It is a factual question seeking clarification, which aligns with the label \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential area of confusion regarding the concept of \"local interactions,\" specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is somewhat helpful as it highlights a specific point that needs clarification, prompting the authors to provide more detailed explanation or examples to ensure the concept is clear to readers. However, the comment lacks depth and does not offer suggestions on how to address the issue or improve the clarity of the concept. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The comment implies that the authors should reconsider their claims or explore alternative methods, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not provide a clear path for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in Table 3, questioning the claim of better results and suggesting that the proposed constrained method may actually yield lower validity and diversity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion of better results in the Molecule generation experiment is incorrect, as the proposed constrained method actually yields lower validity and diversity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. This feedback is somewhat helpful as it points out a potential issue with the paper\\'s claims, prompting the authors to reconsider their results and possibly revise their conclusions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. To be more helpful, the comment could include recommendations for alternative approaches or further analysis to validate the claims. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not specify what aspects of the environment should be described or how detailed the description should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting where the additional information could be included, but without explicit references to sections or figures, the authors may still find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks a detailed description of the Starcraft environment, implying that this is a necessary addition. However, the comment does not provide specific examples or reasoning to support why this description is crucial or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the paper could benefit from a more detailed description of the Starcraft environment. While it implies that this information could be included in an appendix, it does not provide specific guidance on what aspects of the environment should be described or how this would enhance the paper. The comment lacks actionable details, leaving the authors with a general idea of what might be missing but without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to address it effectively.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for combining existing techniques without innovation, specifically mentioning that the domain adaptation method used is old and simple. The reviewer suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. While the comment implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which methods to consider or how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors for combining existing techniques without innovation, specifically mentioning the use of an old and simple domain adaptation method. It suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. However, the comment does not specify which part of the paper discusses the combination of techniques or the specific domain adaptation method used, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part. The comment is specific in suggesting alternative methods, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have combined existing techniques without innovation, specifically mentioning the use of an old and simple domain adaptation method. The reviewer suggests that more effective domain adaptation methods should be considered to improve performance. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to recent effective domain adaptation methods. This makes the claim somewhat verifiable, as the authors would need to conduct further research to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the authors have combined existing techniques without introducing any innovation. It specifically critiques the use of an old and simple domain adaptation method, suggesting that more effective methods proposed in recent years could be used to improve performance. This feedback is clear and actionable, as it directs the authors to consider alternative methods that could enhance their work. However, the comment could be more helpful if it provided specific examples or references to these recent methods, which would give the authors a clearer path forward. Overall, the comment is mostly helpful, as it highlights an area for improvement and offers a direction for enhancement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be conducted on more than one game environment, implying that the authors should expand their experimental scope. However, the comment does not provide specific guidance on which additional game environments should be considered or how to conduct these experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be conducted on more than one game environment, implying that the current scope is limited. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or results. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for more experiments, but without grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment lacks specific reasoning or evidence to support why additional game environments are needed or how this would improve the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental scope, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a clear and actionable piece of feedback. However, the comment lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but requires further elaboration to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no suggestion for improvement, such as optimizing the implementation or discussing potential reasons for the slow performance and low accuracy. Without any guidance or direction, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the implementation, mentioning the time it takes to test an ImageNet picture and the accuracy achieved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the implementation of ImageNet is slow and has low accuracy, citing specific times (\"1 day and 2.5 days\") and accuracy (\"around 70%\") for testing an ImageNet picture using AlexNet and ResNet-18. This provides concrete evidence to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or references to similar implementations for better context. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time it takes to test an ImageNet picture using AlexNet and ResNet-18, as well as the accuracy achieved. This feedback is valuable as it highlights a specific area where the authors may need to improve their implementation or provide further justification for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided context for why these results are unexpected. Overall, the comment is somewhat helpful as it identifies a potential problem but lacks depth in terms of actionable advice or further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed new network compared to the standard softmax network. It suggests that the authors should report the classification accuracy of the proposed classifier on ImageNet data to address this concern. Additionally, the comment recommends providing theoretical justifications for the issue. While the comment implies that the authors should conduct additional experiments and provide theoretical support, it does not explicitly instruct them to do so. The action is mostly inferred and somewhat vague, as the authors know they need to address the concern but are not given specific guidance on how to do so. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the classification network proposed by the authors, expressing doubt about its classification error compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a recommendation for theoretical justifications. However, the comment does not specify which part of the paper discusses the proposed network, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its request for additional data and theoretical justifications, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed new network compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a recommendation for theoretical justifications. However, the comment does not provide specific evidence or references to support the claim that the proposed network\\'s classification error is universally as good as the standard softmax network. The suggestion to report classification accuracy on ImageNet data is a logical step, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the classification error of the proposed new network compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data to address this concern. Additionally, the comment recommends providing theoretical justifications for the issue. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered additional guidance on how to interpret the results or potential theoretical frameworks to consider. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs further exploration and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar scale pre-trained model as the proposed method. It highlights a potential issue with the experimental setup, suggesting that the proposed method without SSL performs inferior to most compared methods. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pre-training stage and ensure fairness in the comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness of the comparison due to the pre-training stage and the potential lack of similar initialization for the compared methods. The comment provides a clear critique of the experimental setup and suggests that the proposed method without SSL performs inferior to most compared methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair due to the proposed method being pre-trained before the fine-tuning stage, while it is unclear if the compared methods were initialized with the same or similar scale pre-trained model. The comment provides a logical reasoning by pointing out the potential bias in the comparison and highlights a specific issue with the experimental setup. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to investigate and address this concern to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the pre-training stage of the proposed method. It highlights a concern that the compared methods may not have been initialized with the same or similar scale pre-trained model, which could impact the results. This feedback is clear and actionable, as it prompts the authors to clarify the experimental setup and ensure fairness in the comparison. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure fairness in the comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information CD captures beyond Predictive Uncertainty. It also questions why entropy is not a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides specific areas for improvement, such as explaining the additional information CD captures and justifying the choice of measure. While the action is explicit, the comment could be more actionable by providing concrete examples or suggestions for alternative formulations. Overall, the comment is mostly actionable as it clearly identifies areas for improvement and provides some guidance on how to address them.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 115\" and \"line 113,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for alternate formulations for Confidence Diversity (CD) and the explanation of why entropy is not a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should describe alternate formulations for Confidence Diversity (CD) and questions the choice of entropy as a measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current formulation and suggesting that additional information is needed to understand the contribution of CD beyond Predictive Uncertainty. However, it lacks specific examples or references to support the claim that entropy is not a good measure, making the claim somewhat verifiable. The authors would need to provide more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the current formulation, specifically asking why entropy is not a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment highlights a potential gap in the paper's explanation and offers a clear direction for improvement by asking for clarification on the additional information CD captures beyond Predictive Uncertainty. This feedback is detailed and constructive, empowering the authors to enhance their draft by addressing these specific points. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\\'s weakness. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the human baseline. The action is implicit and vague, as the authors are left to infer that they need to clarify or address the discrepancy in the human baseline\\'s performance. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the human baseline and the discrepancy in the duration of speech recordings it follows, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline is weaker due to this limitation, and it references Section 4.1 for additional factors contributing to this weakness. Additionally, the comment critiques the abstract for being misleading regarding the human baseline\\'s performance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the human baseline is weaker than the model baseline due to the human only closely following a little more than 1 hour of speech recordings, rather than the full 15 hours. The comment provides a specific comparison and references Section 4.1, which mentions additional factors contributing to the human baseline\\'s weakness. However, the claim could be strengthened by providing more detailed reasoning or examples of how the 1-hour limitation affects the baseline\\'s performance. Overall, the comment is mostly verifiable, as it provides a clear basis for the claim but lacks comprehensive evidence or references to fully substantiate it. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. This observation is critical, as it highlights a potential flaw in the comparison between the human and model baselines. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\\'s weakness, providing some context for the issue. However, the comment could be more helpful if it offered suggestions on how to address this discrepancy or improve the human baseline. Despite this, the feedback is mostly helpful as it directs the authors\\' attention to a critical area that needs clarification or improvement. Therefore, it aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as Reinforcement Learning (RL) methods, but none of these methods are used as a baseline. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, how to incorporate them, or what specific aspects to focus on. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to address this observation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This provides clear guidance on what needs to be addressed in the related work section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s methodology. However, the comment lacks specific examples or references to the RL methods mentioned, which would strengthen the justification. Providing more detailed information or examples would make the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a gap in the related work section by noting that it discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This feedback is somewhat helpful as it identifies an area where the authors could enhance their work by incorporating additional baselines or methods for comparison. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending which RL methods to include or how to integrate them into the baseline comparison. While it provides some insight, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of different projection matrices on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an investigation into the resilience of the metric, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. The reviewer acknowledges that pathological projection matrices could skew the MFTMA capacity and width scores, but notes that this is unlikely with random projections. The comment provides a logical reasoning for the concern and suggests a potential area for further investigation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this suggestion to fully address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the variability in results due to the choice of random projection matrix. It suggests that the authors should investigate the resilience of the metric to different projection matrices, which is a reasonable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Additionally, the mention of \"pathological projection matrices\" adds a layer of complexity that could be clarified further. Overall, the comment identifies a potential issue and offers a direction for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This implies that the authors should expand the evaluation of FGT to include its use in comparing the proposed method with other methods. However, the comment does not provide specific guidance on how to implement this change or which aspects of FGT should be evaluated. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and the details of the evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This claim is somewhat verifiable as it provides a logical reasoning for the evaluation process, suggesting that FGT should be used for a broader evaluation. However, the comment lacks specific examples or references to support why this change is necessary or how it would improve the evaluation. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of FGT, noting that it is only used in the ablation study and suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation process. However, the comment could be more helpful if it offered additional guidance on how to implement this change or why it is important for the evaluation. Despite this, the comment is mostly helpful as it directs the authors to a significant improvement in their evaluation methodology. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work\\'s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might expand their work to increase its impact or suggestions for broader applications. As a result, the comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the work\\'s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the work are limited or how the authors might address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might broaden the impact of their work. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work\\'s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. While this observation highlights a potential limitation of the work, it does not provide any actionable suggestions or guidance for the authors to address this issue. The comment lacks depth and does not offer any specific advice on how the authors might broaden the scope of their work or enhance its applicability. As a result, the comment is barely helpful, as it identifies a potential weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on whether the distinction is necessary or how it could be simplified, leaving the authors uncertain about the action to take. As a result, the comment is vague and does not offer a clear path for improvement, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper this observation pertains to, such as a specific section or equation where these distances are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what implications this observation might have for the paper or how it could be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or justification, the authors may find it challenging to understand the basis of the suggestion or how it could impact their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. This observation could prompt the authors to reconsider their approach and potentially simplify their methodology. However, the comment lacks specificity and does not provide any guidance on how to address this issue or what implications it might have for the paper. Without actionable suggestions or further explanation, the feedback is somewhat helpful as it identifies a potential area for simplification but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on their selection criteria and potentially explore other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details and consider alternative datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses the evaluation on MTEB, making it weakly grounded. The comment is specific in its request for clarification on the selection criteria and the potential for different insights from other tasks or datasets. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. The comment provides a logical reasoning for the concern about generalizability, but it lacks specific examples or references to support the claim. While the authors are directed to consider alternative datasets, the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the claim is somewhat verifiable, as it provides a basis for the concern but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and potentially expand their evaluation to other datasets, which could enhance the robustness and applicability of their findings. However, the comment could be more helpful if it offered specific suggestions on which additional datasets or tasks to consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not provide specific guidance on what aspects of the experiment description need more detail or how the authors might improve the clarity. The comment refers to \"Questions\" for further details, but without elaboration, the authors are left without concrete steps to take. This makes the comment somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for more clarity in the experiment description, but without explicit references to specific sections or elements, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment description lacks detail, making it difficult for readers to judge the results. However, it does not provide specific examples or evidence to support this claim, such as which aspects of the experiment are unclear or how the lack of detail impacts the reader\\\\\\'s understanding. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experiment description, noting that it lacks detail, which makes it difficult for readers to understand the results. This is a critical observation that could impact the clarity and reproducibility of the paper. However, the comment does not provide specific suggestions or guidance on how to improve the experiment description, such as what details should be included or how to present them in a clearer manner. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a key issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper is not self-contained and that the supplementary material is necessary for understanding large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the source code, it does not provide specific guidance on how to improve the self-containment of the paper or how to make the source code accessible. The action is explicit but somewhat vague, as the authors know they need to address these issues but may not be entirely clear on the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper not being self-contained, noting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. It also requests the authors to release the source code of their experiments. However, the comment does not specify which parts of the paper are not self-contained or how the supplementary material could be improved to address this issue. While it provides a clear request for the source code, the lack of specific guidance on the paper\\'s content makes it weakly grounded. The comment is specific in requesting the source code, but the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not self-contained, which is a subjective opinion. It provides a logical explanation by noting that the supplementary material is necessary for understanding large parts of the main paper and for reproducibility. The request for the authors to release the source code is also a logical suggestion to enhance reproducibility. However, the comment lacks specific examples or references to support the claim about the paper\\'s lack of self-containment. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s self-containment, noting that the supplementary material is necessary for understanding large parts of the main paper. It also highlights the importance of reproducibility by requesting the authors to release the source code of their experiments. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve the paper by making it more self-contained and reproducible. However, the comment could be more helpful if it offered suggestions on how to integrate the supplementary material more effectively or provided examples of how to make the source code accessible. Overall, the comment is mostly helpful, as it directs the authors toward important improvements that can enhance the quality and usability of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training instead of PPO. It implies that the choice might be related to the attention model paper being iterated upon, but it does not explicitly state this connection. While the action is implicit, it is concrete in suggesting that the authors should provide clarification on the choice of algorithm. The authors can infer that they need to explain the reasoning behind their choice, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training versus PPO. It implies that this choice might be related to the attention model paper being iterated upon, but it does not specify which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training versus PPO. The comment implies that this choice might be related to the attention model paper being iterated upon, but it does not provide specific evidence or references to support this claim. The suggestion is logical and reasonable, but the lack of detailed reasoning or examples makes it somewhat verifiable. The authors would need to infer the connection to the attention model paper and provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm for training versus PPO. This feedback is clear and actionable, as it directs the authors to clarify their methodology and provide reasoning for their choices. By addressing this point, the authors can enhance the transparency and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific examples or references to support the suggestion, such as discussing the advantages of REINFORCE over PPO in the context of the attention model paper. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and justification of their methodology.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing discussion about the Set Transformer and other related works that use summary tokens. It provides a specific reference to the Set Transformer paper, which gives the authors a clear action to take: they should include a discussion about this work and other related works in their paper. The comment is explicit and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a reference to the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. By mentioning a specific reference (https://arxiv.org/abs/1810/00825), the comment provides a clear and actionable suggestion for the authors to include a discussion about these works. This feedback is valuable as it directs the authors to a relevant area that could enhance the comprehensiveness and depth of their paper. However, the comment could be more helpful if it offered additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details about this process, but it lacks concrete instructions or examples on how to improve the draft. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of details on how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of fitting the residual, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the network\\'s architecture, specifically the lack of details on how it fits the residual instead of directly learning the input-output mapping. This is a relevant observation that could help the authors clarify their methodology and improve the clarity of their paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional details could be included. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the experiment setup in Section 3.3, specifically requesting information about data augmentation methods and learning rates. This provides a clear and direct action for the authors to take, which is to provide detailed information about the experiment setup. The reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is likely intended to provide context or a relevant example, but it does not directly instruct the authors on how to address the request. Overall, the comment is explicit in its request for information but lacks detailed guidance on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the experiment setup, including data augmentation methods and learning rates. The reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides additional context, but it is not directly related to the request for experiment setup details. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual question about the experiment setup in Section 3.3, along with a reference to a specific paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks.\" The inclusion of the reference provides context and supports the request for more information about the experiment setup. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that lacks clarity, namely the experiment setup in Section 3.3. By asking for details about data augmentation methods and learning rates, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important for the reader to understand. Additionally, the reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" could be more relevant if it were directly connected to the experiment setup being questioned. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not explicitly instruct the authors to perform such a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider statistical significance but are not given specific instructions on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what specific numbers are being referred to. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider a statistical significance test, but it lacks grounding and specificity regarding the specific part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, the comment does not provide any specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to justify the need for a statistical significance test. This lack of supporting information makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. This is a relevant point that could impact the interpretation of the results, and the suggestion to consider a statistical significance test is clear and actionable. However, the comment could be more helpful if it provided specific guidance on how to conduct such a test or what statistical methods might be appropriate. Despite this, the feedback is mostly helpful as it directs the authors to a potential area for improvement in their analysis. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors have reported significance testing but questions the choice of test. It implies that a paired test setting, such as the Wilcoxon signed-rank test, might be more appropriate for comparing two samples generated from the same input. While the comment identifies a potential issue with the choice of test, it does not explicitly instruct the authors to use a paired test setting. The action is implicit and somewhat vague, as the authors need to infer that they should consider using a paired test. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the significance testing reported in the paper, questioning the choice of test. It suggests using a paired test setting, such as the Wilcoxon signed-rank test, for comparing two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing, making it weakly grounded. The suggestion to use a paired test setting is specific, as it provides a clear alternative approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signed-rank test, might be more appropriate for comparing two samples generated from the same input. The comment provides a logical reasoning for the suggestion, as it explains the context in which a paired test would be more suitable. However, it lacks specific examples or references to support the claim that the current test choice is incorrect. This makes the claim somewhat verifiable, as the authors would need to consider the reasoning and potentially conduct further research to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signed-rank test, might be more appropriate for comparing two samples generated from the same input. This feedback is somewhat helpful as it points out a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it explained why the current test choice is inappropriate or offered additional guidance on how to implement the suggested paired test setting. Overall, the comment provides valuable insight but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. While the comment implies that these changes should be made, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement these changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, it does not specify which part of the paper is lacking in this regard, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding, as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, the comment does not provide specific examples or reasoning to support why these changes are necessary or how they would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the organization of the paper, suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific area for improvement, it lacks detailed guidance or examples on how to implement these changes. The feedback is somewhat helpful as it points out a direction for improvement but does not provide actionable steps or specific suggestions, leaving the authors with a general idea of what to focus on but without detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. While it identifies a gap in the comparison, it does not provide explicit guidance on which models should be included or how to incorporate them into the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to add these models to their comparison but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of comparisons with other representative panoptic segmentation models, specifically mentioning PanopticFPN and Mask2Former. However, it does not specify which part of the paper this comparison should be included in, such as the experimental section or the discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the models that should be included in the comparison, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models are not compared, specifically mentioning PanopticFPN and Mask2Former. However, the comment does not provide any reasoning or evidence to support why these models should be included in the comparison. Without specific examples or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. This feedback is somewhat helpful as it highlights an area where the paper could be improved by expanding the scope of comparisons. However, the comment lacks specific guidance on how to incorporate these models or why they are relevant, which limits its usefulness. To be more helpful, the comment could provide suggestions on how to integrate these models into the evaluation or explain their significance. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is also true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not provide explicit guidance on how to address these issues or improve the bounds. The authors are left to infer that they need to investigate and potentially revise the bounds, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is also true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not specify which part of the paper these observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issue with the bounds but lacks grounding as it does not reference specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is also true for the results on the adaptive adversary and the counterfactual feedback. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires more detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds, specifically noting the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is true for the results on the adaptive adversary and the counterfactual feedback. This feedback is somewhat helpful as it points out a potential issue with the bounds and suggests an alternative approach. However, it lacks specific guidance on how to address these issues or improve the bounds, which would make it more actionable. The authors are left to infer the necessary steps to take, making the comment somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results in other modalities, specifically mentioning language-related tasks. It also provides a nuanced comment about the relevance of expected test loss for language-related tasks, noting that OOD performance is also important. While the comment implies that the authors should expand their results to include other modalities, it does not provide explicit instructions on how to do so or which specific modalities to consider. The suggestion is concrete in terms of the modalities to explore but lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, specifically mentioning language-related tasks. It also provides a nuanced comment about the relevance of expected test loss for language-related tasks, noting that OOD performance is also important. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where results are presented. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the inclusion of results in other modalities and the consideration of OOD performance, but it is not fully grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including results in other modalities, such as language-related tasks, would be beneficial. It also provides a nuanced comment about the relevance of expected test loss for language-related tasks, noting that OOD performance is also important. However, the comment lacks specific examples or references to support the claim that results in other modalities would be valuable or that expected test loss is not meaningful in this context. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include results in other modalities, such as language-related tasks, which could enhance the comprehensiveness of their study. It also provides a nuanced observation about the relevance of expected test loss for language-related tasks, noting that OOD performance is also important. This feedback is clear and actionable, as it directs the authors to expand their results and consider additional aspects of performance. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these additional modalities or performance metrics. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should compare their work with CoCoOp in the experiments, as it is a relevant and officially published work. The comment provides a clear and direct action for the authors to take, which is to include CoCoOp in the experimental comparisons. This feedback is concrete and actionable, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CoCoOp,\" allowing the authors to accurately identify the part of the paper being addressed, which is the experimental section. It is also specific because it clearly specifies the need to compare the work with CoCoOp, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work CoCoOp should be compared in the experiments, despite being published after the NeurIPS deadline. The comment provides a logical reasoning by explaining that CoCoOp is an extended version of CoOp, implying its relevance to the work. However, the claim could be strengthened by providing more context or examples of how CoCoOp relates to the current work. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific omission in the experimental comparisons, namely the lack of comparison with CoCoOp, a recent related work that is an extended version of CoOp. It provides a clear and actionable suggestion for the authors to include CoCoOp in the experiments, which is a relevant and necessary comparison given the work\\'s publication status. This feedback is valuable as it directs the authors to a specific area for improvement, enhancing the comprehensiveness and validity of their experimental section. However, the comment could be more helpful if it offered additional context or suggestions on how to incorporate CoCoOp into the experiments. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that the author only tested the ReBeL performance on two typical games and suggesting that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment does not provide explicit guidance on how to address this issue or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experimental scope but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental scope by mentioning that the author only conducted experiments on two typical games and suggests exploring the performance on more complex problems, especially those with larger depth. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental scope and the need to explore more complex problems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the author only conducted experiments on two typical games and suggests that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment lacks specific examples or references to support the claim about the complexity of the games or the impact of depth on the value and policy functions. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental scope of the paper, noting that the author only conducted experiments on two typical games and suggesting that the performance on more complex problems, especially those with larger depth, should be explored. This feedback is somewhat helpful as it points out an area where the authors could expand their analysis to provide a more comprehensive understanding of the ReBeL\\'s performance. However, the comment lacks specific suggestions or guidance on how to conduct these additional experiments or what specific complexities should be explored. While it highlights a potential area for improvement, it does not provide detailed actionable steps, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it lacks concrete details on what specific aspects should be covered or how to present the discussion. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the missing discussion on theoretical guarantees, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it directs the authors to include a discussion on this theoretical aspect, which could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measures to evaluate the generated VCEs, with evaluation primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is mainly performed through visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of generated VCEs lacks quantitative measures, relying mainly on visual inspection. This is a subjective opinion that requires justification, as it implies that the current evaluation method is insufficient. However, the comment does not provide specific examples or references to support why quantitative measures are necessary or how they could be implemented. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors would need to infer the importance of quantitative measures based on general knowledge of evaluation practices. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it relies heavily on visual inspection without quantitative measures. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should incorporate more robust evaluation methods to assess the quality and effectiveness of the generated VCEs. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used for evaluation. Despite this, the feedback is clear and actionable, making it mostly helpful for guiding the authors in enhancing their evaluation process. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights significant artifacts in the generated videos, noting that only some beach videos are convincing. It also mentions that the action recognition performance is below the current state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their results. The questions posed do not offer actionable steps for the authors to take. As a result, the comment lacks concrete actions or detailed instructions, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"significant artifacts\" in the generated videos and notes that only some beach videos are convincing. It also compares the action recognition performance to the current state-of-the-art on the UCF dataset, highlighting the use of more complex architectures. However, the comment does not specify which part of the paper discusses the generated videos or the action recognition performance, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides some specific information about the artifacts and performance, it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current state-of-the-art on the UCF dataset. However, it does not provide specific examples or detailed comparisons to support these claims, nor does it offer any references or logical reasoning to substantiate the assertions. The lack of supporting evidence or detailed justification makes the claims difficult for the authors to address, rendering the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the presence of significant artifacts in the generated videos and the subpar action recognition performance compared to the current state-of-the-art on the UCF dataset. It highlights that only some beach videos are convincing, suggesting that the artifacts are a significant concern. Additionally, it points out the gap in action recognition performance, noting that the used architectures are less complex than those employed in the current state-of-the-art. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their results. While it provides some insight into the weaknesses of the paper, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it implies that the authors should clarify the connection between their work and the referenced paper, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017), providing a clear direction for the authors to clarify this connection. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it references a specific paper, it does not provide any further explanation or reasoning to support why this question is relevant or how it impacts the paper. The lack of detailed justification or context makes it difficult for the authors to understand the basis of the question, rendering the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it points out a potential connection that could be explored, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify the relevance of the term in their work. The comment identifies a potential area for improvement but does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on what additional datasets or experiments could be considered, the authors are left without a clear path for improvement. As a result, the comment lacks actionable advice, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide details on what specific aspects of the experiments are limited. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on how to address the limitation. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments are limited to MNIST and a single real-world dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the validity of the results. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single real-world dataset. While this feedback identifies a potential weakness in the study, it lacks specificity and does not provide actionable suggestions for how the authors might address this limitation. Without guidance on which additional datasets could be considered or how to expand the experimental scope, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights an issue but does not offer constructive feedback for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should quantify and clarify the claim that \"ReLU does not work very well in very deep or in convolutional networks.\" The reviewer provides a specific example from the AlexNet paper, which used ReLUs in a deep and convolutional network, challenging the claim. However, the comment does not explicitly instruct the authors to revise their claim or provide guidance on how to quantify or clarify it. The action is implicit and somewhat vague, as the authors need to infer that they should address the claim and provide more detailed evidence or reasoning. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the performance of ReLU in deep or convolutional networks. It provides a counterexample from the AlexNet paper, which used ReLUs in a deep and convolutional network, challenging the claim. This allows the authors to identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies what needs to be addressed, namely the quantification and clarification of the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that \"ReLU does not work very well in very deep or in convolutional networks\" by referencing the AlexNet paper, which used ReLUs in a deep and convolutional network. This provides a specific example that challenges the claim, making the comment somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim that ReLUs were effective in the context of AlexNet. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions a claim made in the paper regarding the performance of ReLU in deep or convolutional networks. It provides a specific example from the AlexNet paper, which used ReLUs in a deep and convolutional network, challenging the initial claim. This feedback is helpful as it prompts the authors to reconsider their assertion and potentially provide more nuanced or detailed evidence to support their claim. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided additional context for the authors to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more explanations regarding the consistency between training and inference, which can be easily satisfied due to the smoothness of neural models. While the comment implies that the authors should expand on this aspect, it does not specify what additional information or explanations are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given explicit guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (95-97 and 308-310) where the paper discusses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that the authors provide more explanations on this topic, which is a clear and actionable request. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanations regarding the consistency between training and inference, which is attributed to the smoothness of neural models. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the exact areas where more explanation is needed, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference, which is attributed to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work. However, the comment could be more helpful if it offered specific suggestions on what additional information or examples should be included to enhance the explanation. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should provide evidence or experiments to support their claim by testing their model with larger word embedding and LSTM parameters. While the comment suggests an action\u2014testing the model with larger parameters\u2014it does not provide explicit instructions on how to conduct these tests or what specific parameters to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the authors\\' claim about achieving superior performance with fewer parameters compared to the baseline. It mentions specific aspects of the model, such as the word embedding size and LSTM size, which are directly related to the claim. The comment also specifies what needs to be addressed by asking for improvements when the proposed model uses larger word embedding and LSTM parameters. This provides clear guidance on what the authors need to consider to support their claim. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. The reviewer asks for evidence or experiments to support the claim by testing the proposed model with larger word embedding and LSTM parameters. This request for additional evidence or experiments provides a clear direction for the authors to substantiate their claim, making the comment mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the authors\\' claim of achieving superior performance with fewer parameters compared to the baseline. It suggests that the baseline model might have been tested with standard parameter settings, implying that the authors should provide evidence or experiments to support their claim. The comment asks for improvements when the proposed model uses larger word embedding and LSTM parameters, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what parameters to test. Overall, the feedback is mostly helpful as it identifies a potential weakness in the authors\\' claim and offers a direction for further investigation, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the introduction of two new hyperparameters, k and \u03b7, which require fine-tuning. It notes that this fine-tuning depends on the availability of the environment or a good OPE (Online Planning Evaluation) method. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific methods for fine-tuning or discussing potential alternatives. As a result, the authors are left without a clear understanding of how to proceed with the fine-tuning process. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the introduction of two new hyperparameters, k and \u03b7, and their requirement for fine-tuning. However, it does not specify which part of the paper discusses these hyperparameters, making it weakly grounded. The comment is specific in detailing the issue with the fine-tuning process, noting its dependence on environmental availability or a good OPE method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two new hyperparameters, k and \u03b7, requires fine-tuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two new hyperparameters, k and \u03b7, which require fine-tuning. It highlights the dependency on the environment or a good OPE (Online Planning Evaluation) method, which could be a limitation. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or mitigate its impact. Without specific recommendations or examples, the feedback is somewhat helpful as it points out a potential problem but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, such as correcting a typo (\"f\" to \"g\") in line 108 and removing an extra period in line 115. Additionally, it poses a question about the convergence of the baseline MCL with deep learning, which implies that the authors should address this concern in their draft. The feedback is clear and provides specific instructions on what needs to be corrected and what needs further explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (\"line 108\" and \"line 115\") where corrections need to be made, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as a typo and an extra period, which provides clear guidance on what needs to be addressed. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, which further specifies the area needing clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions, without any subjective claims or opinions that require verification. It points out specific errors in the text, such as a typo and an extra period, and raises a question about the convergence of the baseline MCL with deep learning. Since it does not contain any claims or suggestions that need justification, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by pointing out two errors in the text: a typo in \"f\" to \"g\" in line 108 and an extra period in line 115. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, which is a critical aspect of the methodology. This feedback is clear and directs the authors to correct the errors and address the question, making it highly helpful for improving the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the performance of FedPCL is heavily reliant on the selection of pre-trained models, which limits its applications. It notes that the model accuracy is sensitive to these pre-trained models, as shown in Table 4. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to address this limitation, such as experimenting with different pre-trained models or developing strategies to reduce reliance on them. Without actionable guidance, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the performance of FedPCL being heavily reliant on the selection of pre-trained models and notes the sensitivity of model accuracy to these models. The comment further acknowledges the efforts of the authors in addressing these limitations by developing a lightweight federated learning framework and integrating pre-trained models for federated aggregation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedPCL heavily relies on the selection of different pre-trained models, limiting its applications. It supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pre-trained models. The comment also acknowledges the authors\\' efforts to address this limitation by developing a lightweight federated learning framework and integrating pre-trained models for federated aggregation. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the limitations of FedPCL. Therefore, the claim is mostly verifiable, as it provides some evidence but could be strengthened with more detailed analysis or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the limitations of the performance of FedPCL, specifically its reliance on the selection of different pre-trained models, which limits its applications. It references Table 4 to support the claim that the model accuracy is sensitive to these pre-trained models. The comment also recognizes the authors\\' efforts to address this limitation by developing a lightweight federated learning framework and integrating pre-trained models for federated aggregation. This feedback is somewhat helpful as it identifies a key limitation of the work and acknowledges the authors\\' attempts to mitigate it. However, it could be more helpful if it provided specific suggestions or guidance on how to further improve the framework or address the limitations. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should add these elements, it does not provide explicit guidance on how to do so or which figures should be updated. The action is implicit and somewhat vague, as the authors can infer that they need to include additional attention maps but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding \"tentative attention maps\" to the qualitative figures, which implies that it is addressing the figures where attentions are discussed. However, it does not explicitly mention which figures or sections this pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of tentative attention maps, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to include \"tentative attention maps\" in the qualitative figures, alongside the retrieved and final attentions. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the understanding of the results. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including \"tentative attention maps\" in the qualitative figures would be beneficial. This feedback is somewhat helpful as it identifies a potential enhancement to the visual presentation of the results, which could provide additional insights into the attention mechanisms. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these maps or why they would be valuable. While it points out an area for improvement, it does not offer actionable steps or detailed suggestions, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about Figure 5, either suggesting that the reviewer does not understand the figure or questioning the accuracy of the labels. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the figure, correct the labels, or improve the figure's clarity. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is either the reviewer\\'s misunderstanding of the figure or the incorrect labels. This provides clear guidance on what needs to be clarified or corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about Figure 5, either questioning the reviewer\\'s understanding of the figure or the accuracy of the labels. However, it does not provide any supporting evidence, reasoning, or examples to clarify the issue. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about Figure 5, either questioning the reviewer\\'s understanding of the figure or the accuracy of the labels. While it identifies a potential issue, it lacks specificity and does not provide any actionable guidance or suggestions for improvement. The authors are left without a clear understanding of what needs to be clarified or corrected, making it difficult for them to address the issue effectively. Therefore, the comment is barely helpful, as it highlights a potential problem but does not offer any actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their derivation. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper the derivation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning the need for Bayesian considerations, but without explicit references to sections or specific elements of the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example, \"Bayesian-PAC based bounds,\" which supports the claim. However, the comment lacks detailed reasoning or references to substantiate why these bounds are not realistic without Bayesian considerations. While the example provides some context, the claim could be strengthened with more comprehensive evidence or references. Therefore, the comment is mostly verifiable, as it provides some support but could be further substantiated.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' derivation, noting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback is somewhat helpful as it points out a potential limitation in the authors\\' approach and suggests a possible direction for improvement by considering Bayesian-PAC based bounds. However, the comment lacks depth and does not provide detailed guidance on how the authors might incorporate these considerations or address the issue. While it highlights an area for improvement, it does not offer actionable steps or specific suggestions, limiting its usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The comment implies that the authors should consider reporting cosine similarities for larger weight decay strengths, but it does not specify how to do so or what specific changes are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the application of weight decay to all layers, the expected impact on training loss, and the absence of reported cosine similarities for large weight decay parameters. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that applying weight decay to all layers would lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. It suggests that the absence of reported cosine similarities for such large weight decay strengths is convenient, implying that the authors might be avoiding reporting suboptimal results. However, the comment lacks specific examples or references to support the claim about the expected impact of weight decay on training loss and cosine similarities. The reasoning is somewhat logical but requires more detailed evidence or examples to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that the authors might be avoiding reporting suboptimal results. This feedback is somewhat helpful as it highlights a specific area for improvement and encourages the authors to consider reporting cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional insights into the potential impact of weight decay on the results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant omission in the title, abstract, introduction, and discussion regarding the results being for unsupervised random forests. The reviewer emphasizes that this is a serious issue that needs to be addressed for publication, as casual readers might draw incorrect conclusions. The comment explicitly states that this issue must be fixed, providing a clear and direct action for the authors to take. Additionally, the reviewer suggests that it would be straightforward to make these changes. The feedback is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title, abstract, introduction, and discussion do not adequately explain that the results are for unsupervised random forests, which could lead to incorrect conclusions. The reviewer emphasizes the importance of this clarification, suggesting that it is a \"fairly serious omission.\" However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the exact issues and how to address them based on the reviewer\\'s general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically that the title, abstract, introduction, and discussion do not clearly indicate that the results are for unsupervised random forests. This omission could lead to incorrect conclusions by casual readers. The reviewer emphasizes the importance of addressing this issue for publication, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful by offering specific guidance on how to incorporate this clarification into the paper. Despite this, the feedback is mostly helpful as it highlights a significant weakness and directs the authors to a necessary correction. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what kind of evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more evidence but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment specifies what is missing in terms of evidence and analysis, it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper lacks evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific areas that require more evidence or analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the need for more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be most beneficial or how to present it effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential impact of regularization effects on the improvements observed in the paper, rather than the distillation process itself. It suggests that the fine-tuning on GLUE without early-stopping could lead to high variances, and proposes that proper ablation studies are needed to verify the claims. While the comment identifies a potential issue and suggests a course of action (conducting ablation studies), it does not provide specific guidance on how to conduct these studies or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific aspect of the paper being addressed, namely the case where the student distills knowledge to the teacher and the potential impact of regularization effects. It also specifies the issue by pointing out the lack of early-stopping during fine-tuning on GLUE, which could lead to high variances. The comment suggests that proper ablation studies are needed to verify the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern that the improvements observed in the paper could be due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that fine-tuning on GLUE without early-stopping can lead to high variances, which could mask the true effects of distillation. The comment suggests that proper ablation studies are needed to verify the claims. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the impact of regularization effects. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical point about the potential impact of regularization effects on the observed improvements in the paper, rather than the distillation process itself. It suggests that the fine-tuning on GLUE without early-stopping could lead to high variances, which might mask the true effects of distillation. The comment provides a clear and actionable suggestion for the authors to conduct proper ablation studies to verify their claims. This feedback is valuable as it highlights a potential flaw in the paper\\'s methodology and offers a specific direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to design and conduct these ablation studies. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement and offers a constructive suggestion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the applicability of node importance in a 1-shot scenario and another about the absence of a 1-shot setting in the experiment section, despite related works like RALE having it. While the comment identifies areas of confusion and potential gaps in the paper, it does not provide explicit or implicit actions for the authors to take. The questions are more exploratory in nature, seeking clarification rather than suggesting specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address these issues. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two distinct questions: one about the applicability of node importance in a 1-shot scenario and another about the absence of a 1-shot setting in the experiment section, despite related works like RALE having it. The first question is not grounded as it does not specify which part of the paper discusses node importance, making it difficult for the authors to identify the exact section being addressed. The second question is more specific, as it points out the absence of a 1-shot setting in the experiment section, but it still lacks full grounding since it does not specify which part of the paper discusses related works like RALE. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: one about the applicability of node importance in a 1-shot scenario and another about the absence of a 1-shot setting in the experiment section, despite related works like RALE having it. The first question is a request for clarification and does not contain a claim that requires verification. The second question is a factual observation about the absence of a 1-shot setting in the paper, which is not a claim but rather a statement of fact. Therefore, the comment is factual and does not contain any claims that need verification, aligning with a score of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two distinct questions that could help the authors improve their draft. First, it questions the applicability of node importance in a 1-shot scenario, which could prompt the authors to clarify or expand their discussion on this aspect. Second, it points out the absence of a 1-shot setting in the experiment section, despite related works like RALE having it, which could encourage the authors to include this setting or explain why it was not included. While the comment identifies areas for clarification and potential gaps in the paper, it does not provide specific suggestions or detailed guidance on how to address these issues. Therefore, the feedback is somewhat helpful, as it highlights important areas for improvement but lacks depth and actionable advice. The authors would need to infer the specific actions to take, making the comment somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula, specifically mentioning the need for specific details about the BCE formula, even if it is simple. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. The comment provides a specific example of what needs to be addressed, making it highly actionable. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear request for more details about the formula, even if it is simple, and suggests giving specific details about the BCE formula. This level of detail guides the authors on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula, specifically mentioning the BCE formula. However, the comment does not provide any reasoning or justification for why these details are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of these details or how to address the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by requesting more details about the formula, specifically mentioning the BCE formula. While the comment is straightforward, it lacks depth and does not offer specific guidance on what aspects of the formula should be detailed or how this would enhance the paper. The feedback is somewhat helpful as it identifies an area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to conduct these discussions or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but may not know exactly how to approach it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion for additional discussion but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussion about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these problems. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional insights and analysis. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach these discussions. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of insight into why self-supervised learning is necessary for 360 video data with spatial audio. It implies that the authors should provide more justification or explanation for this choice. However, the comment does not explicitly instruct the authors to add this information or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add an explanation but are not given specific instructions on how to do it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results section, specifically questioning the need for self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more insight into why this approach is valuable. However, the comment does not explicitly mention which part of the paper discusses the experimental results or the need for self-supervised learning, making it weakly grounded. The comment is specific in its request for additional insight, but without explicit references, the authors may find it challenging to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of self-supervised learning on 360 video data with spatial audio, suggesting that the paper lacks insight into why this approach is valuable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, it lacks insight into why self-supervised learning is necessary for this type of data. This feedback highlights an area where the authors could provide more context and justification for their approach, which could enhance the clarity and impact of their work. However, the comment does not offer specific suggestions or guidance on how to address this issue, leaving the authors with a general direction for improvement. Therefore, the comment is somewhat helpful, as it points out a weakness but lacks detailed actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the analysis, specifically noting that only the SimCLR case is covered and that the projection head, an important part of the approach, is not analyzed. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include an analysis of the projection head, but it does not specify how this should be done or what aspects of the projection head should be analyzed. This lack of explicit action and detailed guidance makes the comment somewhat actionable, as the authors can infer the need for additional analysis but may not know exactly how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SimCLR\" and \"projection head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis on an important aspect of the SimCLR approach, namely the projection head, and references recent papers like SimCLR-v2 that highlight its significance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis is incomplete because it only covers the SimCLR case and neglects the projection head, an important aspect of the approach. The reviewer supports this claim by referencing SimCLR-v2 and other recent papers that highlight the significance of the projection head. This provides a logical reasoning and external references to substantiate the claim, making it mostly verifiable. However, the comment could be strengthened by providing more specific examples or detailed references to these recent papers. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the analysis by noting that only the SimCLR case is covered, while the projection head, an important aspect of the approach, is not analyzed. It references SimCLR-v2 and other recent papers that highlight the importance of the projection head, providing a clear direction for the authors to expand their analysis. This feedback is actionable and constructive, as it guides the authors to include a critical component of the SimCLR approach, thereby enhancing the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it suggested specific aspects of the projection head that should be analyzed or provided examples of how other papers have addressed this aspect. Overall, the comment is mostly helpful, as it effectively directs the authors to a significant area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the approximations introduced in the paper, specifically mentioning lines 107-110 where the assumption of attacks being in the feasible set is made. The reviewer suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to expand on the vulnerability. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (107-110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability related to the approximations introduced and suggests that this issue needs to be expanded upon to reassure readers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approximations introduced in the paper leave \"loose ends\" and suggests that the vulnerability related to the assumption of attacks being in the feasible set needs to be expanded upon. The comment provides a specific reference to lines 107-110, which helps to ground the claim. However, it lacks detailed reasoning or examples to fully substantiate the claim about the vulnerability. While the reviewer identifies a potential issue, the comment could be strengthened by providing more explicit evidence or reasoning to support the claim. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks comprehensive evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximations introduced in the paper, noting that they leave \"loose ends\" and highlight a potential vulnerability related to the assumption of attacks being in the feasible set. The reviewer acknowledges that approximations are necessary for deriving clean results but emphasizes the need to address the vulnerability to reassure readers. This feedback is clear and actionable, as it directs the authors to expand on the vulnerability to provide reassurance. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provide additional context. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the experimental results, noting that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models learned based on each dataset, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the experimental setup or provide additional context to justify the use of prior knowledge. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method has no advantage over the state-of-the-art without prior information and that the comparison is unfair due to the added complexity and cost of using two representation models. The comment provides a clear critique of the experimental setup and suggests that the authors should consider these factors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information, but it shows an advantage when using prior knowledge. The reviewer argues that this comparison is unfair because the proposed method requires two representation models, adding complexity and cost. While the comment provides a logical reasoning for the unfairness of the comparison, it lacks specific examples or references to support the claim about the proposed method\\'s performance without prior information. This makes the claim somewhat verifiable, as it requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information. It highlights that the advantage only appears when using prior knowledge, which could be considered unfair due to the added complexity and cost of using two representation models (VAE/GAN + CL). This feedback is somewhat helpful as it points out a critical aspect of the experimental setup that needs to be addressed. However, it lacks specific suggestions or guidance on how the authors might improve the comparison or mitigate the added complexity. To be more helpful, the comment could provide recommendations on how to address this issue, such as suggesting alternative experimental designs or analyses. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the model. There is no guidance on potential modifications, alternative approaches, or further research directions that could help mitigate the issue. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed model, namely that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the issue with the model, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the proposed model, namely that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a valuable observation that highlights a potential constraint of the model, which could impact its applicability and effectiveness. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the model to handle higher dimensions. While it points out a critical issue, it lacks actionable feedback, making it somewhat helpful. The authors are informed of a potential problem but are not given a clear path to resolve it, which limits the comment\\'s usefulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the supervised pretraining method based on the prediction of the homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to the homo, lumo, and gap. The comment also questions the claim of the paper being a \"general-purpose neural network model.\" While the comment identifies a potential issue and provides an example, it does not explicitly instruct the authors to address this concern or suggest specific changes to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the potential negative transfer issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and references the \"QM9\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue of negative transfer and provides an example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to the homo, lumo, and gap. This provides clear guidance on what needs to be addressed in the paper, specifically the claim of being a \"general-purpose neural network model.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of the homo-lumo gap may lead to negative transfer, citing an example from the QM9 dataset where Transformer-M performs poorly on most tasks except those related to the homo, lumo, and gap. This claim is supported by the specific example from the QM9 dataset, which provides a concrete instance of the potential negative transfer. However, the comment could be strengthened by providing more detailed analysis or references to similar cases in the literature. Overall, the claim is mostly verifiable, as it offers a clear example but lacks comprehensive evidence or references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the supervised pretraining method based on the prediction of the homo-lumo gap, suggesting that it may lead to negative transfer. It provides a specific example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to the homo, lumo, and gap. This example challenges the claim of the paper being a \"general-purpose neural network model,\" as it highlights a limitation in the model\\'s performance. The comment is mostly helpful as it points out a specific area for improvement and provides a concrete example to support the claim. However, it could be more helpful if it offered suggestions on how to address this issue or improve the model\\'s generalizability. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a subjective opinion about the theoretical contribution being \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to strengthen the theoretical contribution, improve the bound, or enhance the mathematical novelty of the proof. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on how to improve the theoretical contribution. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the theoretical contribution need improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the theoretical contribution being \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\\'s assessment. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a subjective assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not offer any specific suggestions or guidance on how the authors might improve their theoretical contribution or address the issues raised. Without actionable feedback or constructive advice, the authors are left without a clear path for enhancing their work. Therefore, the comment is not helpful at all, as it does not provide any meaningful insights or directions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the exact change needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 240 and 428, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the phrase \"is sufficient\" and provides a possible interpretation of what the authors might mean, suggesting that they should clarify the context. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment does not provide any evidence or references to support the claim that this interpretation is necessary or accurate. The lack of supporting information makes the claim somewhat verifiable, as the authors would need to infer the necessity of clarification based on the reviewer\\'s suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific phrase, \"is sufficient,\" at lines 240 and 428, and questions its meaning. It provides a possible interpretation, suggesting that the authors might want to clarify that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is somewhat helpful as it points out a potential ambiguity in the text and offers a possible way to address it. However, it could be more helpful if it provided additional guidance on how to clarify the meaning or suggested alternative phrasing. Overall, the comment is somewhat helpful, as it directs the authors to a specific area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a trade-off in the proposed method, noting that while it reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space, such as DAGs. The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, implying that the authors should consider this aspect in their analysis. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this trade-off further and potentially discuss it in their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and its comparison to [10], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the trade-off between computation time and the richness of the search space, noting that the output of ACI has less information compared to the output of [10]. The comment raises a question about the information encoded in ancestral graphs compared to DAGs, which provides a clear direction for the authors to consider in their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the trade-off between computation time and the richness of the search space in the proposed method. It suggests that the method reduces computation time by limiting the search space to ancestral graphs, which results in less information compared to the output of a method with a richer search space, such as DAGs. The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, implying that this is a critical aspect to consider. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it provides a logical framework for understanding the trade-off, it requires more detailed evidence or examples to be considered fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a trade-off in the proposed method, noting that while it significantly reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space, such as DAGs. This observation is valuable as it prompts the authors to consider the implications of this trade-off and how it might impact their results. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or explore the trade-off further. By raising a question about the information encoded in ancestral graphs compared to DAGs, the comment encourages the authors to delve deeper into this aspect, but it lacks actionable guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the description of the VAD (Voice Activity Detection) in the paper, suggesting that it is misleadingly referred to as a VAD. The reviewer argues that the method described is not a true VAD, as it discards TF bins with a magnitude less than epsilon, which is equivalent to discarding TF bins with zero magnitude to avoid division by zero. The reviewer provides a clear explanation of what a VAD should do and how the described method deviates from this. However, the comment does not explicitly instruct the authors to revise their description or provide specific guidance on how to improve it. While the authors can infer that they need to clarify or correct their VAD description, the action is not explicitly stated, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the \"VAD description\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly explains what is puzzling about the VAD description, namely that it discards TF bins with a magnitude less than epsilon, which is not a typical approach for VAD. The comment further clarifies that a VAD should look for the presence of speech, not just energy, and is usually defined over time, not frequency. This provides clear guidance on what needs to be addressed in the VAD description. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD description in the paper is puzzling and suggests that it is not accurately described as a VAD. The reviewer provides a logical explanation by contrasting the described method with the typical characteristics of a VAD, which should look for the presence of speech and not just energy, and is usually defined over time, not frequency. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or literature that support the typical characteristics of VADs, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the description of Voice Activity Detection (VAD) in the paper. It points out that the method described, which discards TF bins with a magnitude less than epsilon, is not accurately represented as a VAD. The reviewer clarifies that a true VAD should look for the presence of speech, not just energy, and is typically defined over time, not frequency. This feedback is clear and provides a specific critique that the authors can address by revising their description to accurately reflect the method being described. However, the comment could be more helpful if it offered suggestions on how to improve the description or provided examples of how to better align the method with the typical characteristics of VADs. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should address the fairness of the comparison and provide additional metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed comparisons and metrics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously, and requests the inclusion of KID/FID metrics for the teacher network. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional metrics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the comparison might not be fair or why the requested metrics are necessary. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It questions whether this simultaneous training affects the performance of the teacher network and suggests that the authors provide KID/FID metrics for the teacher network. This feedback is clear and actionable, as it prompts the authors to consider the implications of their training approach and to provide additional metrics that could help assess the fairness of the comparison. However, the comment could be more helpful if it provided specific guidance on how to address the fairness issue or suggested alternative methods for comparison. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It explicitly recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback provides a clear and concrete action for the authors to take, as it specifies what additional analysis or presentation could be included to enhance the paper. The suggestion is explicit and provides detailed guidance on how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, it implies that this analysis could be integrated into the results or discussion sections. The authors can infer that this suggestion pertains to the sections where model performance is evaluated. The comment is specific in suggesting a particular analysis to enhance the paper, but it lacks full grounding as it does not explicitly mention the sections where this analysis should be included. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a logical suggestion for enhancing the paper, it lacks specific examples or references to support the claim that such an investigation would add nuance to the conclusions. The suggestion is based on a reasonable assumption but requires more detailed justification or evidence to be fully verifiable. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is actionable and provides a clear direction for the authors to enhance their analysis and conclusions. By suggesting a specific area for further investigation and offering a concrete example of what could be presented, the comment offers valuable guidance for improving the paper. However, it could be more helpful if it included additional suggestions or examples of how to conduct this analysis. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It questions the need for additional evaluation of these aspects and requests clarification on the motivation for considering them. While the comment implies that the authors should clarify their approach, it does not provide explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification without detailed instructions on how to achieve it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the evaluation of disentanglement (D) and the potential entanglement between DCI and ES, which helps the authors understand what needs to be clarified. The comment requests clarification on the motivation for considering explicitness (E) and size (S) as extra evaluation, further specifying what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. The reviewer provides examples to support the claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the entanglement between DCI and ES. While the examples provide some support, the lack of comprehensive evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It provides examples to support this claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). The comment also points out the potential entanglement between DCI and ES, which could impact the evaluation. However, it lacks specific suggestions or guidance on how the authors might address these concerns or clarify the motivation for considering explicitness and size as extra evaluations. While the comment identifies important issues, it does not provide actionable feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider the practicality and safety of the interventions included in the paper for real-world querying. However, it does not provide explicit guidance on how to assess or address these concerns. The action is implicit, as the authors need to infer that they should evaluate the practicality and safety of their interventions. Additionally, the comment lacks concrete details on how to conduct this evaluation or what specific aspects to consider. As a result, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for real-world querying. However, it does not specify which part of the paper discusses these interventions, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider practicality and safety but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while the interventions included in the paper are reasonable computationally, they may not be practical or safe for real-world querying. However, the comment does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important consideration about the practicality and safety of the interventions discussed in the paper. It encourages the authors to think beyond the computational feasibility and consider the real-world implications of their work. However, the comment lacks specificity and does not provide detailed guidance on how to assess or address these concerns. While it highlights a relevant area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific alternatives. The action is implicit and somewhat vague, as the authors are left to infer that they should explore automated disentangling methods but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically. However, the comment does not specify which part of the paper discusses the disentangling process or the choice of the semantic segmentation network, making it weakly grounded. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. The reviewer suggests that it would be more interesting if everything were learned automatically. However, the comment lacks specific examples, references, or detailed reasoning to support why manual disentangling is a problem or how an automated approach would be beneficial. This makes the claim somewhat verifiable, as the authors would need to infer the potential issues and explore alternative methods on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the manual disentangling process, and questions the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to explore automated disentangling methods. However, the comment lacks depth and does not provide specific guidance on how to implement this change or what benefits it might bring. Therefore, it aligns with a score of 3, as it offers some insight but is incomplete in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the connection between the theoretical analysis and the proposed method. It suggests that the method appears to simply adopt the self-attention mechanism from transformers without explaining how it enhances generalization for distant nodes. However, the comment does not provide explicit guidance or suggestions on how the authors could improve this aspect of their paper. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or clarifications are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not explicitly mention which part of the paper discusses the theoretical analysis or the proposed method, making it weakly grounded. The comment is specific in detailing the issue with the connection between the theoretical analysis and the proposed method, but without explicit references, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not clearly enhance generalization for distant nodes, questioning the connection between the theoretical analysis and the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to similar works or theoretical frameworks that could help establish the connection. Without additional evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a gap in the paper regarding the connection between the theoretical analysis and the proposed method. It questions how the proposed method enhances generalization for distant nodes, suggesting that the method may simply adopt the self-attention mechanism without providing a clear explanation of its benefits. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. The feedback is somewhat helpful as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the work as being incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of \"tricks\" to improve defense evaluation. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as revising the pipeline, providing more context, or explaining the novelty of their approach. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the work as being incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of \"tricks\" to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity in terms of what aspects of the pipeline are considered \"tricks\" or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not novel, suggesting it is merely a collection of \"tricks\" to improve defense evaluation. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to other works that have achieved similar results, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the work by stating that its contribution is incremental and that the proposed pipeline is not novel, suggesting it is merely a collection of \"tricks\" to improve defense evaluation. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance the novelty or impact of their work, nor does it suggest specific areas for revision. As a result, the comment is not helpful at all, as it does not provide any actionable insights for the authors to improve their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the distribution of the eta_ri term, specifically asking why it is a non-central chi-squared distribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify the distribution. The comment lacks actionable details, such as suggesting ways to explain or justify the choice of distribution, or recommending additional information to include in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the distribution of the eta_ri term, specifically asking why it is a non-central chi-squared distribution. However, it does not specify which part of the paper this question pertains to, such as a specific section or equation where this distribution is discussed. Without explicit references or context, the authors cannot confidently determine where in the paper this issue is addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the distribution. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of a non-central chi-squared distribution for the eta_ri term, but it does not provide any reasoning, evidence, or references to support why this choice might be problematic or unclear. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the distribution of the eta_ri term, specifically asking why it is a non-central chi-squared distribution. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue in their paper. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path to improve their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct comments. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks, and references a literature example and a leaderboard. This feedback is explicit and provides a concrete suggestion for improvement by referencing specific literature and resources. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the first part is highly actionable, the second part is somewhat actionable as it provides a clear critique but lacks detailed guidance on how to improve the analogy. Overall, the comment is mostly actionable due to the explicit and concrete suggestions in the first part, but the second part adds some vagueness. Therefore, it aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 15 and 16-18, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the vagueness of the statement at line 15 and suggests that the reinforcement learning/agent analogy is out of place, recommending that generalization capabilities be better illustrated by examples given later in the paper. The reference to specific lines and the detailed critique make this comment fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, providing some support for the claim. However, the reference to the leaderboard is not fully elaborated, and the comment could benefit from more detailed examples or references to substantiate the claim. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This part lacks specific examples or references to support the claim, making it somewhat verifiable. Overall, the comment is mostly verifiable, as it provides some justification but could be strengthened with more detailed evidence or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. The first part critiques the vagueness of a statement at line 15, suggesting that it lacks specificity regarding the performance of certain RNNs in natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, offering a concrete example to support the critique. This feedback is clear and actionable, as it directs the authors to provide more specific examples or references to substantiate their claims. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated by examples provided later in the paper. While this feedback identifies a potential issue, it lacks specific guidance on how to improve the analogy or what alternative approaches might be more effective. Overall, the comment is mostly helpful as it provides clear and actionable feedback on the first point, but the second part could be more detailed to fully support the authors in improving their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of speed analysis in the experiments, noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. This feedback is explicit in its request for additional analysis and comparison, but it lacks specific guidance on how to conduct this analysis or what metrics to use. While the authors know they need to include speed analysis, the comment does not provide detailed instructions on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of speed analysis in the experiments, specifically noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. This suggests that the authors should include an analysis of inference speed, which would be more interesting than just reducing FLOPs. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in detailing what is missing, namely the comparison of inference speed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of speed analysis in the experiments is a significant omission, as it only compares GFLOPs among different segmentation networks without evaluating inference speed. The reviewer suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. While the comment highlights a potential gap in the analysis, it does not provide specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is logical but lacks detailed evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the analysis of the paper, specifically the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. This feedback is clear and actionable, as it directs the authors to include a critical aspect of their work that could significantly enhance its impact. However, the comment could be more helpful if it provided specific guidance on how to conduct the speed analysis or what metrics to use. Overall, the comment is mostly helpful, as it highlights a key area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method is not well-positioned in the literature and recommends a thorough literature review to better understand its novelty. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to improve the positioning of their method in the literature. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific concept of representing the marginal score as the expectation of scores of distributions conditioned on inputs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that this concept is not novel and has been used in other works, such as denoising score matching and score-interpolation. The reviewer provides specific references to support this claim, which further enhances the specificity of the comment. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. The reviewer supports this claim by referencing specific works, such as denoising score matching and score-interpolation, which use similar concepts. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, suggesting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. It references specific works, such as denoising score matching and score-interpolation, which use similar concepts, and recommends a thorough literature review to better understand the method\\'s positioning. This feedback is clear and actionable, as it directs the authors to conduct a more comprehensive literature review to contextualize their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this literature review or what aspects to focus on. Overall, the comment is mostly helpful, as it offers a valuable direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, if resources are available. However, it does not provide explicit instructions or concrete steps on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this comparison and figure out how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this suggestion is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting a comparison, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any reasoning, evidence, or references to support why this comparison would be beneficial or how it might impact the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While it highlights an interesting area for exploration, it lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea but limited direction for enhancement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions why the distribution cannot have changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to clarify the matter. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or experiments to address the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and asking about the disentanglement of changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide specific examples or references to support the claim that the debate was previously left open or that the distribution might have changed. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to delve deeper into the paper to understand the context and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s argument and encourages the authors to consider alternative explanations. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of experiments that could be conducted to clarify the matter. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how to address this curiosity or whether it is relevant to the current draft. As a result, the authors are left without any actionable steps to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this question pertains to, nor does it provide any guidance on what specific aspects of performance or the adaptive metric are being questioned. Without explicit references or detailed suggestions, the authors cannot confidently determine which part of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide clear guidance on what needs to be addressed or improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question expressing curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any specific suggestions or guidance on how the authors might address this curiosity or whether it is relevant to the current draft. The comment lacks actionable feedback or insights that could help the authors improve their work. As a result, it is not helpful at all, as it does not offer any meaningful direction for enhancing the draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the plots are \"terrible\" due to several issues, including their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are crucial for presenting experimental results and should be clearer. This feedback provides a direct and concrete action for the authors to improve their draft by revising the plots to make them more readable and informative. The comment specifies the issues and suggests that the authors should address these problems to enhance the clarity of their presentation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" due to several issues, including their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of the problems, such as the difficulty in distinguishing between \"pink vs red\" and the lack of clarity in axis labels. This detailed critique supports the claim, making it mostly verifiable. However, the comment could be strengthened by suggesting specific improvements or alternatives for enhancing the plots. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, including the small size of the plots, difficulty in distinguishing between colors, poorly labeled axes, and visually similar labels. By highlighting these problems, the comment helps the authors understand what needs to be improved to enhance the clarity and effectiveness of their presentation. The feedback is clear and direct, offering a clear path for the authors to improve their draft. However, it could be more helpful if it suggested specific solutions or alternatives for addressing these issues. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the presentation of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to improve the performance or what specific changes could be made to enhance the results. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what aspects of the performance gains are being referred to or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. This claim is based on a factual observation, as it describes a specific numerical comparison. However, it does not provide any reasoning or justification for why this level of performance gain is considered low or insufficient. Without additional context or comparison to expected or typical performance gains, the claim remains somewhat verifiable, as it lacks detailed evidence or references to support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment points out that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. While this observation highlights a potential issue with the paper's results, it does not provide any actionable feedback or suggestions on how the authors might improve the performance or address this concern. Without specific guidance or recommendations, the comment lacks depth and does not offer a clear path for the authors to enhance their work. Therefore, it is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and suggests comparing the performance of LinearTop and NLTop to a better Unary baseline. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. The comment references an external work ([14]) to support the claim that a different and probably better neural network was used, which could impact the comparison. However, the comment lacks detailed reasoning or specific examples from the referenced work to fully substantiate the claim. While it provides some basis for the question, it requires more detailed justification to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance boost observed in the paper, specifically whether it is due to the addition of more parameters. It provides a detailed analysis by comparing the performance of LinearTop and NLTop to Unary, suggesting that the performance boost might be attributed to the use of a different and possibly better neural network. This feedback is clear and actionable, as it prompts the authors to consider using a better Unary baseline to verify the performance boost. By doing so, the authors can gain a deeper understanding of their results and potentially improve their draft. Therefore, the comment is mostly helpful, as it provides a specific direction for further investigation and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only descriptions of the related works but also discussions of the differences to the presented work. This feedback is explicit, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to implement this suggestion, such as which specific related works should be discussed or how to effectively highlight the differences. While the action is clear, the lack of concrete guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, suggesting that the authors should include a more detailed discussion of related work, not only describing the works but also discussing the differences with the presented work. This level of detail gives the authors a clear understanding of what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, including descriptions and discussions of differences with the presented work. However, the comment does not provide specific examples or references to support this claim, making it somewhat vague. While the suggestion is logical and reasonable, the lack of detailed justification or examples limits its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending a more detailed discussion of related work. It not only suggests describing the related works but also encourages the authors to discuss the differences between these works and the presented work. This feedback is valuable as it can help the authors enhance the context and relevance of their work by highlighting its unique contributions. However, the comment could be more helpful if it included specific examples or references to guide the authors in their discussion. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper this suggestion pertains to, such as the experimental section or the results. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in suggesting the need for additional experiments, but it lacks grounding, as it does not clearly identify the sections or elements being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a subjective opinion or suggestion, as it implies that the current scope of experiments is limited and that exploring other architectures and tasks could provide valuable insights. However, the comment does not provide specific reasoning or examples to support why these additional experiments would be beneficial or how they might impact the paper\\'s findings. Without detailed justification or references, the claim remains somewhat verifiable, as the authors would need to infer the potential value of these additional experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it identifies a potential limitation in the scope of the experiments and encourages the authors to consider broader applicability. However, the comment lacks specific guidance on which architectures or tasks to explore, which could be beneficial for the authors in planning their next steps. While it provides a direction for improvement, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the output from the algorithm depends on the order in which the data are processed and recommends that this should be clarified. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to clarify this dependency or what steps to take to resolve it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the output from the algorithm depends on the order in which the data are processed and recommends clarification. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the dependency on data processing order. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or clarify the dependency. Without actionable suggestions or examples, the feedback is somewhat helpful as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum. It notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. The comment implies that the authors should conduct more comprehensive experiments to evaluate the impact of sampling on convergence. However, it does not provide specific guidance on how to conduct these experiments or what metrics to use, leaving the authors to infer the necessary actions. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum and notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks. The comment specifies the need for more comprehensive evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum, but it is not experimentally evaluated thoroughly on the proposed benchmarks. The comment provides some support by mentioning that this aspect is only compared to sampling from a uniform distribution in Table 1 of the supplementary material. However, the claim lacks detailed reasoning or specific examples of how the sampling affects convergence, making it somewhat verifiable. The authors would need to delve deeper into the experimental evaluation to fully understand the impact of sampling on convergence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights an important aspect of the paper that has not been thoroughly evaluated: the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is only briefly mentioned in the supplementary material, specifically in Table 1, where it is compared to sampling from a uniform distribution. This feedback is valuable as it identifies a potential gap in the experimental evaluation and suggests that the authors should conduct more comprehensive experiments to assess the impact of sampling on convergence. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. While the comment highlights areas of confusion and potential inconsistencies, it does not provide explicit instructions or suggestions for how the authors should address these issues. The authors are left to infer that they need to clarify the logic and methodology, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed steps for the authors to follow.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons and the focus on computational cost, suggesting that this aspect is unclear and lacks further discussion. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in detailing the issues with the comparison and the focus on computational cost, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\\'s concerns. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. The comment highlights a potential confusion in the paper and suggests that the authors should clarify these points. However, it does not provide specific suggestions or guidance on how to address these issues, leaving the authors with a general understanding of what needs to be improved but without detailed steps to take. Therefore, the comment is somewhat helpful, as it identifies areas for clarification but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to see how the model works for tabular data, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include a specific analysis or experiment with tabular data, nor are there any details on how to implement this suggestion. As a result, the comment lacks actionability, leaving the authors without a clear understanding of what steps to take to address the suggestion. Therefore, this comment is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests exploring the model\\'s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multi-modal data, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to see how the model works for tabular data, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations of why exploring tabular data would be beneficial or how it relates to the current work. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring the model\\'s performance on tabular data, which is a specific area of interest. While it acknowledges that this is not necessary, it still provides a direction for potential expansion or analysis. However, the comment lacks depth and does not offer specific guidance on how to approach this exploration or what aspects of the model should be evaluated. The suggestion is somewhat helpful as it identifies a potential area for improvement, but it could be more beneficial with additional details or actionable steps. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more details on using attention, potentially as an additional appendix. This is an explicit action that the authors can take to enhance their draft. The suggestion is clear and concrete, as it specifies a particular aspect of the paper that needs more detail and provides a potential location for this additional information. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the additional information should be included. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion to include more details is specific, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not provide any reasoning or evidence to support why this additional information is necessary or how it would enhance the paper. Without specific examples or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide more details on the use of attention, which could be beneficial for readers who are interested in understanding this aspect of the paper. The suggestion to include this information as an extra appendix is clear and actionable, offering a specific way for the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or examples of how the attention mechanism is used, which would give the authors a clearer understanding of what details to include. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. While the comment implies that the authors should provide a justification or explanation for this limitation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This implies that the comment is addressing the section where the authors discuss the performance of their model on different types of noise. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in its request for a justification or explanation for the limited scope of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This is a logical observation that prompts the authors to provide a justification or explanation for the limited scope of their results. However, the comment does not provide any specific evidence, examples, or references to support the claim that the model should perform well on other types of noise. The lack of detailed reasoning or supporting information makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why the authors only show results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This feedback prompts the authors to consider expanding their evaluation to include other types of noise, which could enhance the comprehensiveness and robustness of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional noise types to test or suggesting ways to incorporate them into the analysis. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical version of the objective (3) should be placed in the supplementary materials. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify why this change is necessary or how it might impact the main text, which could make it slightly less actionable. Despite this, the authors know exactly what action to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests moving the empirical version of the objective (3) to the supplementary materials. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the empirical section where the objective is discussed. However, the comment lacks specificity regarding why this change is necessary or what benefits it would bring. Therefore, the comment is weakly grounded because it does not explicitly identify the part of the paper being addressed, but it is specific in suggesting a potential change. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests moving the empirical version of the objective to the supplementary materials. However, it does not provide any reasoning or justification for this suggestion, such as why this information is better suited for the supplementary materials or how it might impact the main text. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests moving the empirical version of the objective to the supplementary materials. While this feedback provides a clear and actionable suggestion for improving the organization and presentation of the paper, it lacks further explanation or justification for why this change might be beneficial. The authors are given a specific direction to consider, but without additional context or reasoning, the comment could be more helpful if it provided more depth or rationale for the suggestion. Therefore, the comment is somewhat helpful, as it offers a clear action but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques a specific line in the paper, pointing out that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their draft. Without actionable suggestions or a clear direction for revision, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 180-182, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Corollar 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the claim made in Corollar 10, suggesting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out the limitation of the corollar, which is a clear and specific critique. However, it does not provide additional evidence or references to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the critique but could benefit from more detailed justification or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific critique of the paper by questioning the interpretation of Corollar 10. It points out that the corollar only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily mean it is not minimizing the expected convex surrogate. This feedback is somewhat helpful as it prompts the authors to reconsider their interpretation and potentially clarify or expand on the implications of Corollar 10. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for a clearer understanding. Overall, the comment identifies a potential weakness but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. It suggests that these details should be added. The comment provides a clear and direct action for the authors to take, which is to include these details in their draft. The action is concrete, as it specifies exactly what needs to be added, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the numbers and the method used for division, such as whether it was done randomly or with other considerations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division of the dataset into training and test sets, specifically regarding the numbers and the method used for division. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the specific issues or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the division of the dataset into training and test sets. It highlights the importance of including numbers and the method used for division, such as whether it was done randomly or with other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is crucial for the paper. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their methodology that needs clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. While the comment implies that the authors should expand their testing to include other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should test the model on other tasks but are not provided with specific guidance on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, it does not specify which part of the paper this question pertains to, such as a specific section or results section where the testing results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment raises a valid point about the scope of testing, it does not provide specific guidance on what needs to be addressed or improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. This is a factual inquiry that seeks clarification rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid question about the scope of the model\\'s testing, specifically noting that it was only tested on the single supporting fact dataset (Task 1 of bAbI) and asking if other tasks were considered. This feedback is somewhat helpful as it prompts the authors to consider expanding their testing to include other tasks, which could enhance the comprehensiveness and robustness of their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending which additional tasks to include or how to integrate them into the testing framework. Therefore, while it provides a useful direction for improvement, it could be more helpful with additional details or actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be conducted on medium or large datasets, such as ImageNet, to make the results more convincing. However, it labels this as a \"minor issue\" and notes that it will not affect the overall quality of the paper. While the comment implies that the authors should consider using larger datasets, it does not provide explicit guidance on how to implement this suggestion or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the importance and method of addressing this issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset size used in the experiments, suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting the use of larger datasets, but it lacks detailed guidance on how to implement this suggestion or why it would improve the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of small datasets in the experiments makes the results less convincing and recommends using medium or large datasets like ImageNet. However, the comment does not provide specific examples or references to support why larger datasets would be more convincing or how they would impact the results. The suggestion is based on a logical assumption that larger datasets can provide more robust results, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, specifically the use of small datasets in the experiments. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. However, the comment labels this as a \"minor issue\" and notes that it will not affect the overall quality of the paper. While the feedback provides a direction for improvement, it lacks depth and does not offer specific guidance on how to address the issue or why it would be beneficial to include larger datasets. The comment is somewhat helpful as it points out a potential area for enhancement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from empirical justification to support the claimed contribution regarding the proposed algorithm not requiring as many points or apriori knowledge about dimensions of subspaces. While the comment implies that the authors should provide empirical evidence to substantiate this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include empirical justification without specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the first claimed contribution of the paper, which is about the proposed algorithm not requiring as many points or apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this claim is made in, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for empirical justification, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s first contribution is not adequately justified, specifically regarding the claim that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the empirical justification for the claimed contribution of the proposed algorithm. It suggests that the paper would benefit from empirical evidence to support the claim that the algorithm does not require as many points or apriori knowledge about dimensions of subspaces. This feedback is somewhat helpful as it points out an area where the paper could be strengthened, but it lacks specific guidance on how to provide this empirical justification. The authors are left to infer that they need to include empirical evidence, but without detailed instructions, the comment could be more helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), implying that the novelty of the proposed method is limited. It explicitly states that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, providing the authors with a specific action to take\u2014namely, to include a detailed comparison with RMED in the discussion. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed S1DB-ED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the similarity to RMED (Komiyama et al. 2015) and the need for a sufficient discussion on the comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of the proposed method is limited. The reviewer supports this claim by referencing RMED, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed comparisons or specific examples of similarities between the two algorithms. This would enhance the verifiability of the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could benefit from additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed S1DB-ED algorithm, suggesting that it is too similar to RMED (Komiyama et al. 2015). This is a valuable observation that could help the authors improve their draft by highlighting the need for a more detailed comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the proposed algorithm from RMED or offered guidance on what aspects of the comparison should be emphasized. Despite this, the feedback is mostly helpful as it directs the authors to address a critical aspect of their work, namely the novelty and originality of their contribution. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a comparison of their approach, GCG, with other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action, as it clearly instructs the authors on what additional content should be included in the paper. The comment also mentions a minor point about the jailbreaking percentage being low for certain LLMs, which could be a separate action for the authors to address. However, the suggestion to include the comparison is the primary actionable point. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included, namely a comparison of the approach with other LLMs, and mentions a minor point about the jailbreaking percentage. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors showed their approach, GCG, could be transferred to other LLMs and that it could craft adversarial prompts and transfer them to other LLMs. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The mention of a \"minor point\" about the jailbreaking percentage being low for certain LLMs is also not substantiated with evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable, as it lacks detailed justification and specific examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors include a comparison of their approach, GCG, with other LLMs. This is a clear and actionable piece of feedback that could enhance the paper by demonstrating the versatility and applicability of GCG. Additionally, the comment points out a minor issue regarding the jailbreaking percentage being low for certain LLMs, which could be an area for further exploration or clarification. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects of the jailbreaking percentage should be addressed. Overall, the comment is mostly helpful as it offers constructive feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not explicitly instruct them to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these limitations further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any evidence, reasoning, or references to support the claim that there are limitations. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment is somewhat helpful as it prompts the authors to consider the broader applicability of their framework, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It suggests that the authors could consider using the Kialo dataset instead, which is cleaner and more established. However, the comment does not explicitly instruct the authors to use the Kialo dataset or provide specific guidance on how to integrate it into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using the Kialo dataset but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the creation of the dataset and the use of the Kialo dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the dataset creation, noting that the Kialo dataset is well-studied and cleaner, and suggests that the dataset created in the paper could be used as additional data. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the creation of the dataset is optional and suggests using the Kialo dataset instead, which is well-studied and cleaner. The reviewer provides a logical reasoning by comparing the two datasets, highlighting the advantages of using the Kialo dataset. However, the comment lacks specific examples or references to support the claim about the Kialo dataset being \"cleaner\" or the absence of automatic processes for its construction. This makes the claim somewhat verifiable, as it provides a general rationale but requires further evidence or details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential improvement in the paper by suggesting the use of the Kialo dataset, which is well-studied and provides pairs of short claims and their counters. It highlights that the dataset created in the paper could be considered as additional data to learn from. This feedback is clear and actionable, as it provides a specific alternative to the dataset creation and suggests a way to enhance the paper. However, the comment could be more helpful if it offered further guidance on how to integrate the Kialo dataset into the paper or discussed potential benefits of using it. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the number of tasks in the experiments is considered limited and suggests that the authors should include several tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. The comment also includes a question for the authors to address their comments on weaknesses. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft, which is to expand the number of tasks and present results in a different format. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically mentioning the limited number of tasks and the desire to see several tasks and sequential results. However, it does not specify which part of the experiments section this feedback pertains to, such as a particular figure or table. The authors can infer that it relates to the experimental setup or results section, but this inference is not as direct as it could be. The comment is specific in detailing what the authors should address, namely the number of tasks and the presentation of results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of tasks in the experiments is limited and suggests that the authors should include several tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why 10 tasks are considered sufficient or why the current approach is inadequate. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the number of tasks considered in the experiments, suggesting that the authors should include more tasks (at least 10) and present results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup and presentation. However, the comment could be more helpful if it offered additional guidance on how to select or design these additional tasks or how to present the results effectively. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with further suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. While it highlights a potential issue with the analysis, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the motivation for their choice of analysis. However, the comment lacks concrete details on how to improve the draft, making it somewhat actionable. The authors know they need to address the issue but may not be entirely sure how to do so without further guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the analysis choice but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity would not appear in earlier layers. This is a logical question that prompts the authors to clarify their methodology and reasoning. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim that the motivation is unclear. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it highlights a potential issue but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This prompts the authors to clarify their methodology and provide a clear rationale for their choice of analysis. However, the comment does not offer specific suggestions or guidance on how to address this issue or improve the draft. While it identifies a potential weakness, it lacks depth and actionable feedback, making it somewhat helpful. The authors are left with a clear question to address but without detailed guidance on how to enhance their work. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not provide any explicit guidance or suggestions on how to address this issue. The comment lacks concrete details or actionable steps for the authors to follow, leaving them without a clear understanding of what needs to be done to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not specify which part of the paper discusses this parameter or where the issue arises. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of setting the parameter S are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the parameter S, stating that its setting remains a problem. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the parameter S, noting that its setting remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the draft. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to resolve the problem. This lack of specificity and guidance makes the comment barely helpful, as it highlights a concern but does not offer any actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer argues that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback implies that the authors should clarify or address this point in their introduction, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the introduction but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" where the claim is made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" by pointing out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that while the introduction states that \"these shape constraints do not require tuning a free parameter,\" the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. The reviewer provides a logical reasoning by pointing out that the choice of these constraints can indeed be considered a hyperparameter, which supports the claim. However, the comment could be strengthened by providing specific examples or references to similar cases where such choices are considered hyperparameters. Overall, the claim is mostly verifiable, as it provides a clear logical basis but lacks detailed examples or references to fully substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential inconsistency in the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer points out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is somewhat helpful as it highlights a specific area where the introduction may be misleading or incomplete. It prompts the authors to clarify or address this point, which could improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to rephrase or expand the introduction to address this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the datasets and models used, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or what specific datasets or models should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include more diverse datasets and models, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper in terms of datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also points out the absence of assessments on state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what is missing, such as assessments of other biases and datasets, and the inclusion of state-of-the-art generative models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has limited datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also points out the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights a limitation, it does not provide specific examples or references to support the claim about the absence of other biases or datasets. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to conduct further research to fully understand the scope of the limitation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation in the paper, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also points out the absence of assessments on state-of-the-art generative models like GPT. This feedback is clear and actionable, as it highlights areas where the authors can expand their analysis to provide a more comprehensive evaluation of biases and models. However, the comment could be more helpful if it suggested specific datasets or models that should be included or provided guidance on how to incorporate these assessments. Despite this, the comment provides valuable insights that can guide the authors in improving their draft, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with Figure 3, stating that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback provides a clear and direct action for the authors to take: improve the clarity of Figure 3 by enhancing the workflow and captions and clarifying the representation of communication modes. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, including the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be improved in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, and confusion regarding the representation of communication modes. However, the comment does not provide any specific examples or detailed reasoning to support these claims. Without additional context or explanation, the authors may find it difficult to understand and address the issues. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes. This feedback is clear and actionable, as it provides a direct suggestion for improvement by highlighting areas where the figure needs clarification. However, the comment could be more helpful if it offered specific suggestions on how to enhance the clarity of the figure, such as proposing alternative visualizations or reorganizing the content. Despite this, the comment is mostly helpful as it directs the authors to a critical area that needs attention, allowing them to make significant improvements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to conduct error analysis in the paper and provide detailed explanations of the model\\'s performance under different scenarios. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The comment also provides a rationale for why this is important, stating that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting error analysis and providing detailed explanations of the model\\'s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where error analysis could be included. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its request for error analysis, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not provide specific examples or references to support why error analysis is necessary or how it would aid in guiding subsequent improvements. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of error analysis based on general knowledge. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would provide more detailed guidance for the authors. Overall, the comment is mostly helpful as it directs the authors toward a significant improvement in their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not identify any NLP-specific elements in their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their draft. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim about their work being one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in questioning the NLP-specific elements in the approach, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not identify any NLP-specific elements in their approach. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of supporting evidence or detailed justification renders the claim borderline verifiable, as it requires more information to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not identify any NLP-specific elements in their approach. This feedback is somewhat helpful as it points out a potential inconsistency in the authors' claim, prompting them to reconsider and clarify their work's relevance to NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential weakness, it does not provide actionable steps for improvement, limiting its helpfulness. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This comment provides a clear and explicit action for the authors to take, which is to include an NCE-based method in their comparison. It also offers a specific reference to support the suggestion, providing concrete guidance on how to implement the action. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a study that shows the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion should be made in, nor does it provide detailed guidance on how to incorporate this comparison. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This claim is somewhat verifiable as it provides a reference to support the suggestion, indicating that NCE-based methods are viable for learning EBM on natural images. However, the comment lacks specific details or examples of how this comparison would enhance the paper, which could make it more challenging for the authors to understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include at least one NCE-based method for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing a specific suggestion for enhancing the paper by broadening the scope of comparisons. However, the comment could be more helpful if it offered additional guidance on how to incorporate this comparison or why it is important for the paper. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two improvements for the experiment section: conducting a significance test on the human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment explicitly states these actions, it does not provide detailed guidance on how to conduct the significance test or which specific LLMs should be compared. The authors are given a clear direction but lack specific instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements for the \"experiment section,\" which provides some grounding as it indicates a specific part of the paper. However, it does not specify which part of the experiment section needs improvement, such as the methodology, results, or discussion. The comment is specific in suggesting the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). However, the lack of explicit references to sections or specific elements of the experiment section makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests improvements for the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment provides a logical suggestion for enhancing the experiment, it lacks specific examples or references to support why these changes are necessary or beneficial. The claim is somewhat verifiable as it offers a direction for improvement but requires more detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experiment section, suggesting that a significance test should be conducted on the human evaluation results and that the proposed method should be compared with recent Large Language Models (LLMs). These suggestions are clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experiment. However, the comment could be more helpful if it included specific examples of LLMs to compare with or detailed guidance on conducting the significance test. Overall, the feedback is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the use of a newly collected large dataset (209M) compared to the smaller datasets used by existing methods. The reviewer implies that the superior performance of the proposed method could be due to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should consider the impact of dataset size on the results and potentially adjust their analysis or comparisons accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset versus smaller datasets used by existing methods like GEM, which employs only 20M unlabeled data. This provides a clear context for the issue, allowing the authors to identify the part of the paper being discussed, such as the results or discussion sections where comparisons are made. However, the comment does not specify what needs to be addressed or how the authors should adjust their comparisons to make them more fair. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a larger dataset. The reviewer provides a specific example, mentioning that GEM uses only 20M unlabeled data, while the proposed method uses a 209M dataset. This comparison highlights the potential impact of dataset size on accuracy, suggesting that the superior performance of the proposed method could be attributed to the larger dataset rather than the method itself. The claim is supported by logical reasoning and specific examples, making it mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison with state-of-the-art (SOTA) methods. It points out that the proposed method\\'s performance is based on a newly collected 209M dataset, while existing methods use smaller datasets, such as GEM with only 20M unlabeled data. This observation suggests that the superior performance of the proposed method may be due to the larger dataset rather than the method itself. The comment provides a clear and actionable suggestion for the authors to consider the impact of dataset size on their results and potentially adjust their analysis or comparisons to make them more fair. However, it could be more helpful if it offered specific guidance on how to address this issue, such as suggesting alternative comparisons or adjustments to the experimental setup. Overall, the comment is mostly helpful as it highlights an important consideration for the authors to address in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their examples. The comment implies that the authors should consider providing more context or analysis to establish the generalizability of these examples, but it does not specify how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding the generalizability of specific examples presented in the paper. The comment highlights the need for more context or analysis to establish the generalizability of these examples. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents specific examples of biases in target statistics and prediction shift of gradient values, but it does not provide a clear explanation of why these examples are unclear or how they could be improved. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. It points out that while the paper provides examples, it does not establish the generalizability of these situations. This feedback is somewhat helpful as it highlights a potential weakness in the paper and prompts the authors to consider providing more context or analysis to address this issue. However, the comment could be more helpful if it offered specific suggestions or guidance on how to improve the clarity and generalizability of the examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify whether their work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the concern. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the work in this section includes any novel efforts beyond following the previous work, \"Luciddreamer.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the work is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality of the work presented in Section 3.1, specifically regarding the generation of 3D Gaussians. It questions whether the work merely follows the previous work, \"Luciddreamer,\" without any additional novel efforts. This feedback prompts the authors to clarify the novelty of their approach, which is an important aspect of academic integrity and originality. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate or highlight any novel contributions. Overall, the comment is somewhat helpful as it directs the authors to address a critical aspect of their work, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the first paragraph of the Introduction for being too general and not relevant to the paper\\'s focus on detecting drift types and magnitude. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion to revise or remove the paragraph, nor is there guidance on how to improve the introduction to better align with the paper\\'s focus. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, namely that it focuses too much on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The comment provides a clear critique of the relevance of the content, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is not relevant to the paper because it focuses on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. However, the comment does not provide specific examples or detailed reasoning to support why this introduction is not valuable or how it deviates from the paper\\'s focus. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of the paper, noting that the first paragraph focuses too much on a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This feedback is somewhat helpful as it points out a potential misalignment between the introduction and the paper\\'s main topic. However, the comment could be more helpful if it provided suggestions on how to better integrate the introduction with the paper\\'s focus or offered guidance on what specific aspects of drift should be highlighted. By providing more detailed feedback, the comment could be more actionable and beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors present a simplified version of Theorem 2 for a general audience, similar to Theorem 1. This implies that the authors should work on making Theorem 2 more accessible by simplifying it. However, the comment does not provide specific guidance on how to simplify the theorem or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take and may not know exactly how to simplify the theorem. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, and mentions that Definition 2 and Theorem 2 are hard to digest on their own. This provides specific guidance on what needs to be addressed, which is the clarity and accessibility of Theorem 2. However, it does not explicitly mention which part of the paper these theorems and definition are located in, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Theorem 2 is difficult for a general audience to understand and proposes simplifying it, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is hard to digest or how it could be simplified. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis for the suggestion and develop their own reasoning to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors present a simplified version of Theorem 2, similar to Theorem 1, to make it more accessible to a general audience. This feedback is clear and actionable, as it identifies a specific area where the authors can improve the clarity and readability of their work. By simplifying Theorem 2, the authors can enhance the understanding of their results for a broader audience. However, the comment could be more helpful if it provided specific guidance on how to simplify the theorem or what aspects to focus on. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting experiments with a larger image resolution to see how it affects performance. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions or guidance on how to proceed. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct experiments with larger resolutions without specific details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"1, All the experiments are conducted using images under 224*224 resolution,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting experiments with a larger image resolution to see how it affects performance. This provides clear guidance on what the authors could do to enhance their work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be interesting to see how performance changes with a larger image resolution. However, it does not provide any reasoning, evidence, or references to support why this would be beneficial or how it might impact the results. The comment lacks specific examples or logical reasoning to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting direction for further experimentation by proposing the use of larger image resolutions in the experiments. This feedback is somewhat helpful as it provides a potential area for improvement and expansion of the study. However, it lacks specific guidance on how to conduct these experiments or what aspects to focus on, which limits its usefulness. The authors are given a general idea of where to explore further, but the comment does not offer detailed actionable steps or insights to fully address the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is an explicit action that provides clear guidance on what the authors should add to their draft. The comment is specific and concrete, as it directly instructs the authors to include this information, making it easy for them to implement the suggested change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is a specific and actionable piece of feedback that could enhance the clarity and completeness of the paper. By addressing this suggestion, the authors can provide additional context and depth to their explanation, which is beneficial for the reader\\'s understanding. However, the comment could be more helpful if it explained why this information is important or how it relates to the broader context of the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on larger data sets, acknowledging that compute resources might be a limiting factor. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of batch size on probability maintenance without specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Additional experiments on larger data sets,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the concern about maintaining probabilities, particularly at large batch sizes, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests conducting additional experiments on larger data sets, acknowledging potential compute resource issues. However, it does not provide specific reasoning or evidence to support why these experiments are necessary or how they would improve the paper. The comment also mentions maintaining probabilities at large batch sizes but does not elaborate on why this is an issue or how it affects the results. Without detailed justification or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the author\\'s response to the initial concern about additional experiments on larger data sets. It also addresses the issue of maintaining probabilities at large batch sizes, noting that while it might become an issue, it is not critical. The comment provides a nuanced perspective on the concerns raised, acknowledging the potential challenges but not prioritizing them as critical. However, it does not offer specific suggestions or guidance on how to address these issues, leaving the authors with a general understanding of the concerns but without actionable steps for improvement. Therefore, the comment is somewhat helpful, as it provides insight into the reviewer\\'s perspective but lacks depth and specificity in terms of actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more detailed explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what aspects of the bounds need further explanation. Therefore, the comment is somewhat actionable, as the authors can infer the need for additional explanation but may not be entirely sure of the specifics.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more detailed explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper currently lacks this explanation, making it weakly grounded. The comment is specific in suggesting that the explanation of the bounds could be improved, but it does not provide detailed guidance on what aspects of the bounds need clarification. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more detailed explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning or evidence to support why this additional explanation is necessary or how it would enhance the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the space limitations in the paper but suggests that the authors could benefit from providing more explanation of the meaning of the bounds, possibly in the appendix. This feedback is somewhat helpful as it identifies an area where the paper could be improved by offering more clarity. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the bounds need further explanation or how to present this information effectively. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should consider adding more datasets or ensuring that all algorithms can be used on the existing ones, but it does not specify which datasets are problematic or how to resolve the issue. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not specify which datasets are problematic or how they impact the evaluation. The comment also mentions an addendum that provides additional context, but it does not explicitly mention which part of the paper this issue pertains to. The authors can make an educated guess that it relates to the sections discussing datasets and experiments, but the comment lacks full grounding. It is specific in identifying the issue with the datasets but not specific in terms of which datasets or how to address the problem. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The addition of an addendum that acknowledges the authors\\' response and provides context does not address the initial claim. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for certain tasks might not be enough for a thorough evaluation. However, the comment does not provide specific guidance on how the authors might address this issue or suggest alternative datasets that could be used. Additionally, the addendum acknowledges the authors\\' response and clarifies that the datasets are novel and that a repository and online platform for reproducing experiments have been provided. While the comment highlights a potential weakness, it lacks actionable advice or detailed suggestions for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This comment implies that the authors should include results for these larger models to provide a more comprehensive evaluation of their approach. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The suggestion is concrete in that it specifies which models should be included, but the authors need to infer the action themselves. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the performance results on imageNet classification, specifically mentioning the use of ResNet50/34/18 models. However, it does not specify which part of the paper these results are presented in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in pointing out the absence of results for larger models like ResNet101/152, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is good performance on imageNet classification with ResNet50/34/18 but lacks results for larger models like ResNet101/152. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment is based on an observation rather than a detailed analysis or comparison, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This feedback is somewhat helpful as it identifies an area where the authors could expand their evaluation to provide a more comprehensive assessment of their approach. However, the comment lacks specific suggestions or guidance on how to address this gap or what benefits might be expected from including results for larger models. To be more helpful, the comment could include recommendations or insights on why larger models are important or how they might impact the results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit and vague, as the authors are left to infer what needs to be done without clear instructions on how to improve the draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment does not specify which part of the paper discusses the sparse reward problems or the experiments, making it weakly grounded. The comment is specific in its critique of the method\\'s approach to sparse rewards, but without explicit references to sections or experiments, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim that the method does not address sparse reward problems effectively. The lack of supporting evidence or detailed analysis makes the claim difficult for the authors to address, rendering it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the method\\'s ability to address sparse reward problems, suggesting that the experiments do not provide sufficient support for this claim. It also implies that the proposed method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s claims and prompts the authors to reconsider their approach. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the paper. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to improve the paper. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"confusing mistakes in the proof of the main results,\" which suggests that it is addressing the section where the proof is presented. However, it does not specify which part of the proof is confusing or provide details on the mistakes. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but it does not specify which previous work or how it should be compared. The comment is weakly grounded as it does not explicitly mention the section, but it is specific in identifying the issues with the proof and the lack of comparison with previous work. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence and detailed justification renders the claims unverifiable, as the authors are left without a clear path to improve their work based on the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to take. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not provide detailed feedback for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the clarity and fairness of the paper. It questions the motivation for using an adversarial network in the model and points out that the comparison of experimental results is unfair due to the inclusion of a pre-trained model. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should clarify the motivation and ensure a fair comparison, but it lacks concrete steps or examples to guide the authors in making these improvements. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the motivation and fairness of the experimental results, specifically questioning the need for an adversarial network and the comparison methodology. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issues with the motivation and experimental comparison but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental results. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks concrete evidence or references to substantiate the assertions, making it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues: the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It points out that the proposed model is larger than others due to the inclusion of CAT and GAN, and that even the pre-trained model is compared with other models. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity and fairness of their comparisons. While it highlights important areas for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of an adversarial loss to ensure that the perturbed data is similar to the authentic data. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details on what specific adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of the action needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the absence of an adversarial loss to ensure the perturbed data is similar to the authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there is no adversarial loss to guarantee the perturbed data is similar to the authentic data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure that the perturbed data is similar to the authentic data. This is a clear and actionable feedback that highlights a potential weakness in the methodology or results. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific adversarial loss could be used. While it points out a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific actions the authors should take to improve the optimization process or how to handle the variability in hyperparameters. As a result, the authors are left without a clear understanding of how to implement the suggested improvements. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the number of hyperparameters that need to be tuned (step size, N, and \\\\(\\\\delta t\\\\)) and the variability in optimal hyperparameters due to sample-by-sample optimization. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the issue with hyperparameter tuning but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variability in optimal hyperparameters due to sample-by-sample optimization. However, it does not provide specific examples, references, or detailed reasoning to support the claim. The comment lacks concrete evidence or examples to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and the potential variability in optimal hyperparameters due to sample-by-sample optimization. This is a critical concern that could impact the robustness and reliability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending techniques for hyperparameter tuning or discussing potential strategies for mitigating variability. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not offer detailed guidance for resolution.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited comparison of performance with few methods and notes that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance comparison and the consistency of the proposed method with other methods. It suggests that the authors should provide analysis for inferior results that contradict the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for analysis of inferior results, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistent performance. Without detailed evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the limited comparison of performance with only a few methods. It points out that the proposed method is not consistently better than others, which contradicts the motivation. The reviewer suggests that the authors should provide analysis for inferior results, which is a constructive and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which aspects to focus on. Despite this, the feedback provides a clear direction for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for the comparison but may not be entirely sure of the exact methodology or metrics to use. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this suggestion should be implemented in, such as the results section or the discussion. This makes it weakly grounded, as the authors cannot confidently determine where to address the comment. The comment is specific in suggesting a particular comparison method, which is an improvement over the lack of specificity in the grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any reasoning or evidence to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between the proposed scheme and baseline methods, specifically recommending the use of a Jaccard index. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not offer detailed guidance on how to implement this comparison or what specific insights it might provide. While it points out a potential area for improvement, it does not fully address the authors\\' needs for comprehensive feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should consider whether their work is an extension or introduces novel contributions, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable feedback, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the originality of the article, suggesting similarities with another study, \"How Do Nonlinear Transformers Learn and Generalize in In-Context Learning.\" However, it does not specify which parts of the article are similar or how they relate to the previous study. The authors may infer that the comment pertains to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity regarding what aspects need to be addressed or how the authors should differentiate their work. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the concern. The comment lacks concrete evidence or references to the other study, which would be necessary to fully substantiate the claim. As a result, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. This is a valid point that could prompt the authors to reflect on whether their work introduces novel contributions or is merely an extension of existing research. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this concern or differentiate their work. Without actionable suggestions or examples, the feedback is somewhat helpful, as it identifies an area for consideration but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the very-long-term forecasting task has limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments and provide a more appropriate context for their results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct these experiments or what constitutes the \"correct\" forecast horizon. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the very-long-term forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. However, the comment does not explicitly mention which part of the discussion is being addressed, making it weakly grounded. The suggestion to conduct additional experiments and improve the context is specific, as it provides clear guidance on how to enhance the discussion. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task has limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about the limited practical significance of the task. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practical significance of the very-long-term forecasting task and suggests ways to improve the discussion. It recommends conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a more appropriate context for the results. This feedback is clear and actionable, as it offers specific suggestions for enhancing the discussion and providing a more robust evaluation of the task. However, the comment could be more helpful if it provided additional guidance on what constitutes the \"correct\" forecast horizon or how to select datasets for the experiments. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft, but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors. While the comment implies that the authors should conduct these analyses, it does not provide specific guidance on how to approach these analyses or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include theoretical analyses or extensive experiments to understand why certain methods outperform others. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what aspects need further analysis, such as the comparison between simple greedy selection and more principled acquisition functions, and the performance of deterministic MLP predictors versus probabilistic predictors. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical results of the proposed method are strong, but it lacks specific evidence or reasoning to support the claim that the simple greedy selection approach outperforms more principled acquisition functions or that deterministic MLP predictors outperform probabilistic predictors. The comment implies that rigorous analyses are missing in the paper, but it does not provide detailed justification or references to substantiate these claims. As a result, the comment is considered unverifiable, as it lacks sufficient evidence or reasoning to support the claims made.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for further exploration and improvement in the paper. It suggests that the authors conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by addressing these gaps. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or experiments. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. This is a clear and direct action for the authors to take, as it identifies a specific area that needs to be addressed in the draft. However, the comment does not provide guidance on how to conduct this analysis or what aspects of security should be considered. While the action is explicit, the lack of concrete details on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. However, it does not specify which part of the paper this issue is related to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this analysis is lacking. The comment is specific in its critique of the security analysis but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security and privacy protection of the proposed framework. This is a critical area that authors should address to ensure the robustness and trustworthiness of their work. However, the comment does not provide specific guidance or suggestions on how the authors might conduct this analysis or what aspects of security and privacy should be considered. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a critical area but lacks depth in terms of actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the multi-scale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. It implies that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the statement. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the multi-scale statement and its benefits. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"multi-scale statement\" in the paper, which implies that it is referring to a specific part of the paper where this statement is made. However, it does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in detailing the issue with the statement, explaining that the slow and fast RNNs operate on a logical time scale rather than a physical one, and suggesting that the only benefit is the reduction of the gradient path. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical explanation for this claim, suggesting that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider the reviewer\\'s reasoning and potentially provide additional context or evidence to fully address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the multi-scale statement in the paper, suggesting that it might be misleading. It provides a specific critique by explaining that the slow and fast RNNs operate on a logical time scale rather than a physical one, which could lead to a misunderstanding of the benefits. The comment also points out that the only benefit might be the reduction of the gradient path by the slow RNN. This feedback is clear and actionable, as it prompts the authors to clarify the nature of the multi-scale statement and its implications. However, the comment could be more helpful if it offered suggestions on how to rephrase or expand the statement to address the issue. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential area for improvement in the proposed invariant learning module, specifically suggesting that the feature selection could be enhanced by considering representation learning. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The authors are left to infer that they should explore incorporating representation learning into the feature selection process, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the feature selection in Section 4.2 could be improved by considering representation learning, as discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the feature selection in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions the discussion about representation learning in the appendix but does not elaborate on how this could enhance the feature selection process. Without additional evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the proposed invariant learning module, specifically focusing on the feature selection process in Section 4.2. It points out that the current framework seems not limited to raw-level selection and suggests that representation learning could be considered to enhance the feature selection. This feedback is clear and actionable, as it directs the authors to explore a specific aspect of their work that could be improved. However, the comment could be more helpful if it provided additional guidance or examples on how to incorporate representation learning into the feature selection process. Overall, the comment is mostly helpful as it offers a constructive suggestion for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the quality of paraphrases generated for the training data, specifically questioning how different these paraphrases are from the original sentences. It emphasizes the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment suggests that if the paraphrases are not significantly different from the originals, the quality of the final training data will be low, leading to a limited number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting methods to evaluate or improve the paraphrasing process. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess and potentially improve the paraphrasing quality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of paraphrasing for the training data, specifically questioning how different the paraphrases are from the original sentences. It highlights the importance of this aspect for the subsequent steps in the process. However, it does not specify which part of the paper discusses the paraphrasing process, making it weakly grounded. The comment is specific in detailing the concern about the quality of paraphrases and their impact on the final training data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases generated for the training data, suggesting that if the paraphrases are not significantly different from the original sentences, the quality of the final training data will be compromised. The comment logically connects the quality of paraphrases to the impact on the training data, providing a clear rationale for the claim. However, it lacks specific examples or references to support the assertion about the impact of paraphrase quality on the training data. This makes the claim somewhat verifiable, as it requires further evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paraphrasing process for the training data, specifically questioning the difference between the paraphrases and the original sentences. It highlights the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment logically explains that if the paraphrases are not significantly different, the quality of the final training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is clear and actionable, as it prompts the authors to evaluate and potentially improve the paraphrasing process to ensure the quality of their training data. However, it could be more helpful if it provided specific suggestions or examples on how to assess or enhance the paraphrasing quality. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or evaluations, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and determine the specific models to test. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting additional models to test, but it lacks grounding, as it does not clearly reference a particular part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Flipped-QA framework should be tested on non-LLM-based models like HiTeA and InternVideo to verify its universality. The claim is somewhat verifiable as it provides a logical reasoning for the suggestion, implying that the current application to LLM-based models may not fully demonstrate the framework\\'s capabilities. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. This feedback is clear and actionable, as it identifies a potential limitation in the current application of the framework and provides specific models for further testing. By addressing this suggestion, the authors can enhance the robustness and generalizability of their work, making the comment highly helpful. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the proposed method\\'s lack of theoretical novelty, as it primarily builds upon existing methods such as Clopper-Pearson intervals and Gaussian elimination. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific aspects of the method need to be improved to demonstrate novelty. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical novelty in the proposed method, which is primarily based on existing methods like Clopper-Pearson intervals and Gaussian elimination. However, it does not specify which part of the paper discusses these methods or where the authors could improve the novelty. The authors can infer that it relates to the methodology section, but the comment lacks full grounding as it does not explicitly mention the section. The comment is specific in identifying the issue of lacking novelty, but without explicit grounding, it aligns with a weakly grounded and specific label.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks theoretical novelty, as it primarily builds upon existing methods such as Clopper-Pearson intervals and Gaussian elimination. The reviewer supports this claim by referencing specific sources, including the original work by Clopper and Pearson and a textbook on matrix computations by Golub and Van Loan. This provides a clear and logical basis for the claim, making it fully verifiable. The inclusion of references allows the authors to understand the context and evaluate the novelty of their method effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of theoretical novelty in the proposed method, which primarily builds upon existing methods like Clopper-Pearson intervals and Gaussian elimination. This feedback is valuable as it highlights an area where the authors could improve their work by providing more original contributions. However, the comment could be more helpful if it offered specific suggestions on how the authors might enhance the theoretical novelty or provide examples of potential new contributions. While it provides a clear direction for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their draft. As a result, the comment is unactionable, as it does not offer any direction for improvement or clarification.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspect of the text input or object elements is being questioned. Without clear grounding or specificity, the authors are left without a clear direction for improvement. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the concatenation of text inputs by the four text elements of an object. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point raises a question about whether the text input can be concatenated by the four text elements of an object. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or clarify their methodology. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer justification for why the subject matter is important or relevant. However, the comment does not specify how to achieve this motivation or what aspects of the paper need to be revised to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section or clarify the importance of the topic. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer justification for why the subject matter is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors can make an educated guess that it relates to the introduction or background sections, but the comment lacks full grounding. It is specific in suggesting the need for motivation but does not provide detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks motivation for why the topic is important or relevant. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting that it lacks motivation for why the topic is important or relevant. This is a valid point, as understanding the significance or relevance of the research can enhance its impact and interest. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending additional background information, highlighting specific applications, or discussing the broader implications of the research. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the comment implies that such experiments would be beneficial, it does not explicitly instruct the authors to perform them. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments to strengthen their work. However, the suggestion is concrete in terms of the specific datasets to use, which provides some guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to incorporate these additional experiments. The comment is specific in suggesting a particular type of dataset for further experimentation, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any reasoning or evidence to support why these specific datasets would be beneficial or how they would enhance the support for C2D. Without such justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific type of dataset that could enhance the validation of the C2D method. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D method would benefit from them. While it offers a direction for further exploration, it does not fully support the authors in making significant improvements to their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of essential visualization of intermediate processes and comparisons, but it does not provide specific guidance on how the authors should address this issue. It does not suggest what kind of visualizations are needed or how they should be integrated into the paper. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it refers to the introduction, methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding what kind of visualizations are needed or how they should be integrated. Without explicit references or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance their draft by including visualizations that could help readers better understand the intermediate steps and comparisons. However, the comment could be more helpful if it provided suggestions on what types of visualizations would be most beneficial or how they could be effectively integrated into the paper. Despite this, the comment still offers valuable guidance, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the importance of the result and provides a comparison with existing work, specifically [15], which claims that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer suggests that the decentralized algorithm's ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the reviewer notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer what changes might be necessary without clear direction. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the importance of the result, provides a comparison with existing work ([15]), and notes the change in iteration complexity in Theorem 3. This level of detail helps the authors understand what needs to be addressed in their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of the result presented in the paper, comparing it to existing work ([15]) that claims perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer suggests that the decentralized algorithm\\'s ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the comment notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. While the comment provides a logical comparison and references existing work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the literature and the specific results to fully understand the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the result presented in the paper, suggesting that it is not surprising given existing work on perturbed gradient descent. The reviewer provides a specific reference to [15] and notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. While the comment identifies a potential issue with the novelty of the result, it does not offer actionable suggestions or guidance on how the authors might address this concern or improve their work. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and does not provide specific advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing that incorrect choices could negate any potential improvements from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a sensitivity analysis or provide more information on hyperparameter choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sensitivity of empirical results to hyperparameter choices, which is an important issue for the paper. However, it does not specify which part of the paper this concern relates to, such as specific sections or results that need to be addressed. The authors can infer that it might relate to the experimental setup or results sections, but this is not explicitly stated. The comment is specific in its request for information on sensitivity to hyperparameter choices, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\\'s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The suggestion to investigate this issue is logical, but without further elaboration, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical concern about the sensitivity of empirical results to hyperparameter choices, which is a crucial aspect of evaluating the robustness and reliability of the method. It highlights the potential impact of incorrect hyperparameter choices on the results, emphasizing the need for the authors to address this issue. The comment also expresses a willingness to reconsider the rating if this issue is resolved, providing a clear incentive for the authors to address the concern. However, the comment could be more helpful if it offered specific suggestions or guidance on how to conduct the sensitivity analysis or address the issue. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, as it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. While the comment implies that the authors should address the lack of novelty, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer justification of their method\\'s originality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty and contribution of the proposed method, suggesting that it is similar to using the transferability of adversarial examples directly and that the authors need to further claim the novelty of their approach. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for the authors to clarify the novelty and contribution of their method, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that it is similar to using the transferability of adversarial examples directly. The reviewer implies that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim of similarity or the need for additional novelty claims. This makes the claim somewhat verifiable, as the authors would need to provide more detailed justification or evidence to address the critique effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. This feedback is somewhat helpful as it points out a gap in the paper\\'s claims of originality and contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Providing more detailed advice or examples would make the feedback more actionable and helpful for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a concern with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large enough perturbation value, which makes it challenging to trust the results. The reviewer suggests that the experiment could be strengthened in two ways, but does not specify what these ways are. While the comment implies that the authors should address the issues related to the use of pseudo feature importance and the perturbation value, it lacks explicit guidance on how to do so. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"One experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of pseudo feature importance and the reliance on Proposition 3.2, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment using pseudo feature importance is problematic due to its reliance on Proposition 3.2 and the choice of perturbation value. However, the comment does not provide specific details or examples to support this claim, such as how the pseudo feature importance affects the results or how the perturbation value impacts the experiment. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the potential issues and address them on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment that estimates the quality of uncertainty estimates, noting that it uses pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the need for a large enough perturbation value, which makes it challenging to trust the results. The comment suggests that the experiment could be strengthened in two ways, but it does not specify what these ways are. While the comment points out a critical issue, it lacks detailed guidance or suggestions on how to address it, leaving the authors with a general idea of what needs improvement but without actionable steps. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential non-convexity issue or what properties of function Z should be considered. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 182-184, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of non-convexity and suggests that it may not be a problem for the SGD to converge if the function Z has good properties. This provides clear guidance on what needs to be addressed in the specified part of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of what \"good properties\" might entail or how they would affect convergence. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific line in the paper (ln. 182-184) and suggests that non-convexity may not be an issue for the SGD to converge if the function Z has good properties. While this observation is relevant and could be a valuable insight for the authors, the comment lacks depth and does not provide any actionable suggestions or further guidance on how to address this issue. It does not offer specific advice on what properties of function Z should be considered or how to ensure convergence. As a result, the comment provides some insight but is incomplete, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental settings are not properly mentioned, which is crucial for result reproducibility. It also mentions that the code is not provided. This feedback is clear and direct, providing the authors with specific actions to take: they need to properly document the experimental settings and provide the code. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experimental settings and the lack of code, which are critical for result reproducibility. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not properly mentioned, which affects result reproducibility. It also mentions the lack of code, which is a critical aspect for reproducibility. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings, noting that they are not properly mentioned, which affects result reproducibility. It also points out the lack of code, which is essential for reproducibility. This feedback is clear and actionable, as it highlights specific areas that need improvement. By addressing these issues, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the documentation of experimental settings or offered guidance on making the code available. Overall, the comment is mostly helpful, as it directs the authors toward important improvements but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes should be made to support the claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of effectiveness, questioning whether the slight improvement supports the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why the slight improvement is insufficient to support the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the validity of the claim regarding the effectiveness of the proposed prompts, citing the slight improvement observed in Table 6 and Table 7. While it identifies a potential issue with the claim, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"Cycle FC align features\" and suggests that the analysis is insufficient. It implies that the authors should consider different designs, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC align features, making it weakly grounded. The suggestion for additional analysis is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes additional experiments or analysis with different sampling intervals and sample sizes. However, the comment lacks specific examples or references to support the claim that the analysis is insufficient or to justify the need for these additional experiments. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the analysis of the Cycle FC align features, suggesting that the current analysis is insufficient. It proposes that the authors consider different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is somewhat helpful as it points out an area for improvement and provides a specific suggestion for enhancing the analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of how different sampling intervals and sample sizes could impact the analysis. Overall, the comment provides a clear direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the dimensionality of each region and the feature extractor used, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on how to address the question or what information should be added to the draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the dimensionality of each region and the feature extractor used, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is a clear and actionable point for the authors to address. By asking for clarification on this aspect, the reviewer provides a direct way for the authors to improve their draft by ensuring that the information is accurate and complete. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context. Overall, the comment is mostly helpful as it identifies a specific area for improvement and guides the authors toward enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more details about the motivation. However, the suggestion is concrete in terms of what needs to be done, which aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation behind applying CMD in federated learning, suggesting that it could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to provide a clearer explanation of the motivation, but without explicit grounding, it is challenging for the authors to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that a more explicit demonstration or explanation would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the motivation behind applying CMD in federated learning is unclear. It provides a clear and actionable suggestion by recommending a more explicit demonstration or explanation of this motivation. This feedback is valuable as it directs the authors to clarify an important aspect of their work, which could enhance the paper\\'s clarity and impact. However, the comment could be more helpful if it offered specific examples or guidance on how to present this explanation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment further supports its claim with references to relevant works by Raonic et al. and Gupta et al., providing additional context and justification for the suggestion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the complexity of the proposed CoNO model, questioning whether the performance boost is due to the fractional transform or the UNet operation. The reviewer suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This claim is supported by logical reasoning and references to external works, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical point about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This feedback is clear and actionable, as it directs the authors to include comparisons to UNets to clarify the source of the performance boost. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a subjective opinion that the contribution is marginal, suggesting that the methods used are well-designed and demonstrated. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or address the perceived lack of novelty. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, suggesting that it is marginal because the methods used are well-designed and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as a particular section or methodology. The authors may infer that it relates to the experimental or results sections, but this is not explicitly stated. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered marginal or how they could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contribution is marginal, suggesting that the methods used are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the reviewer\\'s opinion. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion that the contribution of the paper is marginal, as the methods used are well-designed and demonstrated. However, it does not provide any specific feedback or suggestions on how the authors could enhance their contribution or address the perceived lack of novelty. Without actionable guidance or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment highlights a potential area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the additional experiments should be emphasized or clarified. As a result, the comment lacks actionability, leaving the authors without a clear path for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. This provides some specificity about the part of the paper that the reviewer did not fully engage with, but it does not specify what aspects of the additional experiments need attention or improvement. The comment is weakly grounded because it does not explicitly mention which section of the paper the additional experiments are located in, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a factual statement expressing appreciation for the comprehensive Appendix and acknowledging the reviewer\\'s inability to thoroughly read the additional experiments due to time constraints. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive Appendix as a valuable addition to the paper, providing additional detail about certain aspects. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment appreciates the effort to provide more detail, it does not offer any suggestions or guidance on how the authors might improve the clarity or presentation of these additional experiments. The feedback is somewhat helpful as it highlights an area where the authors might consider clarifying or expanding their work, but it lacks actionable advice or specific suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not provide explicit guidance on how to address this issue or clarify the distinction between the two methods. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and potentially provide more information about the active learning pipeline. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the authors\\' claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in its questioning of the method\\'s description, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. The comment raises a concern about potential misdescription and suggests that clarification is needed. However, it does not provide specific examples or references to support the claim that the methods are different or how this might impact the readers\\' understanding. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to provide additional context or clarification to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of the authors\\' claim regarding the use of active learning in step 2. It questions whether the \"active learning pipeline\" method is the same as traditional active learning, which selects informative samples to label. This feedback is somewhat helpful as it points out a potential source of confusion in the paper and prompts the authors to clarify their description. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to differentiate between the two methods. Overall, the comment identifies a specific area for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment implies that the authors should clarify whether 300W-LP is used in all experiments and, if so, why it might be considered an unfair advantage. While the comment identifies an issue, it does not explicitly instruct the authors to address it or provide specific guidance on how to clarify the methodology. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset in training the model. It points out that the paper initially states that 300W-LP is used for training but later claims the same procedure is used as for the baselines. The comment asks if 300W-LP is used in all experiments and whether this would provide an unfair advantage to the proposed method. This issue is related to the experimental setup, which is discussed in the methodology section. However, the comment does not explicitly mention the section, making it weakly grounded. It is specific in detailing the issue with the experimental methodology and the potential unfair advantage. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset in training the model. It points out that the paper initially states that 300W-LP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment suggests that if 300W-LP is used in all experiments, it could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that using 300W-LP would be unfair. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires further evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental methodology, specifically questioning the use of the 300W-LP dataset in training the model. It points out that the paper initially states that 300W-LP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment raises a concern about whether 300W-LP is used in all experiments and whether this would provide an unfair advantage to the proposed method. This feedback is somewhat helpful as it highlights a potential flaw in the experimental setup and prompts the authors to clarify their methodology. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to ensure fairness in the experimental design. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their techniques. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on why these techniques are not novel or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of certain techniques used in the algorithm, such as computation offloading and gradient augmentation. However, it does not provide specific examples or detailed explanations of why these techniques are not novel or how they could be improved. Without actionable guidance or suggestions, the authors are left with a general indication of a potential problem but without a clear path to address it. This makes the comment somewhat helpful, as it highlights an area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the formulation introduced by the authors, suggesting that the observations might be aggregated by methods other than averaging, such as summation or population-weighted average. It also provides specific examples, like disease incident data being available in counts or rates per number of residents. While the comment identifies a potential limitation and provides examples, it does not explicitly instruct the authors to address this issue or suggest how to modify their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, pointing out that the observations might be aggregated by methods other than averaging, such as summation or population-weighted average, and provides specific examples like disease incident data. This level of detail helps the authors understand what needs to be addressed in their formulation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the formulation introduced by the authors assumes observations are obtained by averaging over the corresponding support, but suggests that other aggregation methods, such as summation or population-weighted average, might be more appropriate. The comment provides specific examples, like disease incident data being available in counts or rates per number of residents, to support the claim. This level of detail and reference to specific examples makes the claim mostly verifiable, as it provides a clear rationale for the suggestion. However, the comment could be strengthened by referencing the specific sections of the paper where these assumptions are made, which would further enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that other aggregation methods, such as summation or population-weighted average, might be more appropriate, particularly in the context of disease incident data. The comment provides specific examples, like disease incident data being available in counts or rates per number of residents, which helps the authors understand the potential limitations of their formulation. However, the comment could be more helpful if it offered suggestions on how to address these limitations or provided examples of how other aggregation methods might be applied. Overall, the feedback is somewhat helpful as it highlights a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the comprehensiveness of the analyses of the method and experimental outcomes, noting that the experiments primarily focus on presenting results. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their analysis. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comprehensiveness of the analyses of the method and experimental outcomes, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not specify which sections or experiments are lacking in analysis, making it weakly grounded. The authors can infer that the issue relates to the experimental sections, but the comment lacks specificity regarding what aspects of the analysis are insufficient. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the analyses of the method and experimental outcomes are not comprehensive enough, particularly given that the authors\\' method underperforms the baseline in some instances. The comment questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are insufficient or that the performance improvement is questionable. This makes the claim somewhat verifiable, as it provides a general critique but lacks concrete evidence or references to substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the comprehensiveness of the analyses in the paper, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis of the method and experimental outcomes. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to provide more detailed and comprehensive analyses to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to enhance the analysis or provide additional data to substantiate the claims. Overall, the comment is somewhat helpful, as it directs the authors to a key area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical results' lack of immediate practical implications but suggests that the authors could provide more take-away points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but notes that it is unclear if this is a novel finding in the paper. While the comment provides a concrete suggestion, it lacks guidance on how to present these take-away points or whether this suggestion is indeed novel. The action is mostly actionable because it offers a specific idea but lacks detailed instructions on how to implement it. Therefore, the comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, suggesting that the authors provide more take-away points for practitioners. It mentions a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. However, the comment does not specify which part of the paper discusses these theoretical results or the suggested take-away points, making it weakly grounded. The comment is specific in suggesting a particular approach for practitioners but lacks detailed guidance on how to implement it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. However, the reviewer suggests that the main take-away point is to query a cluster proportionally to the square root of its size, questioning whether this is a novel finding. The comment provides some reasoning by acknowledging the novelty of the work and suggesting a specific take-away point, but it lacks detailed evidence or references to support the claim that this suggestion is novel or significant. The reasoning is somewhat verifiable, as it provides a logical basis for the claim but requires more substantiation to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the theoretical nature of the results and their limited practical implications, which is understandable given the novelty of the work. It suggests that the authors could provide more take-away points for practitioners, which is a valuable insight. The comment also highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment provides some direction for improvement, it lacks detailed guidance on how to present these take-away points or whether the suggested approach is indeed novel. The feedback is somewhat helpful as it identifies an area for improvement but could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the introduction of separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the introduction of separators and asking for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. It is factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the introduction of separators in section 4. It questions the rationale behind their inclusion and asks for clarification on what additional information they provide beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to provide a justification for the introduction of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to effectively explain the role of separators. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the synthesized results for UCF-101, noting inconsistent motion, changing color, or objects disappearing over time. It suggests that it would be interesting to see videos with a longer duration by running the LSTM over many time steps. However, the comment does not provide explicit guidance on how to address these issues or improve the results. The suggestion to explore longer video sequences is implicit and lacks concrete details on how to implement it. As a result, the authors may infer that they need to conduct additional experiments, but they are not provided with specific steps or methods to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"UCF-101,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. The comment suggests exploring videos with longer durations by running the LSTM over many time steps. This provides clear guidance on what needs to be addressed and how to improve the results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the results of the paper, specifically mentioning inconsistent motion, changing color, or objects disappearing over time in the synthesized results for UCF-101. It suggests that exploring videos with longer durations could improve the results. However, the comment lacks specific examples or detailed reasoning to support the claim about the current results being inconsistent. While it provides a general direction for improvement, the lack of concrete evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the synthesized results for UCF-101, noting inconsistencies in motion, color changes, or objects disappearing over time. It suggests that exploring videos with longer durations by running the LSTM over many time steps could be beneficial. This feedback is clear and actionable, as it points out a particular area for improvement and provides a direction for further experimentation. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how longer video sequences might improve the results. Overall, the comment is mostly helpful as it guides the authors toward a potential enhancement of their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the cost implications for men and women after the proposed method is applied. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific information should be included in the paper. The lack of actionable advice or suggestions leaves the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the cost implications for men and women after the proposed method is applied, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether this is related to the methodology, results, or discussion sections, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or context about what specific aspects of the cost implications are being questioned. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the cost implications for men and women after the proposed method is applied. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the cost implications for men and women after the proposed method is applied. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their paper. The comment does not offer actionable feedback or insights that could help the authors improve their draft. As a result, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper\\'s categorization of papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the availability of papers on arXiv when categorizing them, but they are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of how the paper categorizes papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the issue with the categorization, but without clear grounding, the authors may find it challenging to identify the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s categorization of papers based on their publication years on the ACL anthology is incorrect, as many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This example supports the claim by providing a concrete instance of the issue, making the comment mostly verifiable. However, the comment could be strengthened by further elaboration or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the paper\\'s categorization of papers based on their publication years on the ACL anthology. It highlights that many papers are available on arXiv earlier than their publication in the ACL anthology, using the BERT paper as an example. This feedback is somewhat helpful as it identifies a specific area where the paper\\'s categorization might be inaccurate. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their categorization method. To be more helpful, the comment could provide recommendations or examples of how to handle papers that are available on arXiv before their publication in the ACL anthology. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part questions the authors\\' decision to use a relaxation of rejection sampling with an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q. It does not provide any explicit or implicit actions for the authors to take. The second part suggests that the authors should clarify the difference between QRS and RS by providing a specific value of u for which they will behave differently. While this part implies an action, it is somewhat vague as it does not specify how the authors should present this information. Overall, the comment lacks explicit guidance and is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"QRS and RS,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between QRS and RS and the need to provide a value of u for which they will behave differently. This provides clear guidance on what the authors need to revise. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the authors\\' decision to use a relaxation of rejection sampling with an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q. However, it does not provide any supporting evidence or reasoning to justify why the authors should have used importance sampling instead. The second part raises a question about the difference between QRS and RS, suggesting that the authors should provide a specific value of u for which they will behave differently. This part lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two distinct points. The first part questions the authors\\' decision to use a relaxation of rejection sampling with an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. This feedback is somewhat helpful as it prompts the authors to reconsider their approach and potentially improve it. However, it lacks specific guidance on how to implement importance sampling or why it might be more appropriate. The second part of the comment questions the difference between QRS and RS, suggesting that the authors should provide a specific value of u for which they will behave differently. This is a clear and actionable suggestion that could help the authors clarify their methodology and improve the clarity of their paper. Overall, the comment provides some helpful insights but could be more comprehensive and detailed in its suggestions. Therefore, it aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. While the comment identifies a potential confusion, it does not provide explicit guidance on how to address this issue or clarify the terminology. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"non-sequential information\" and \"chunks\" in their draft. However, the comment does not offer specific suggestions on how to resolve the confusion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"non-sequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the terminology used in the paper, specifically the phrase \"non-sequential information such as chunks.\" It raises a logical concern about whether \"chunk\" is considered sequential information, which is a reasonable inquiry. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim or clarify the confusion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the term \"non-sequential information such as chunks.\" It questions whether \"chunk\" is still considered sequential information, which is a valid point that could clarify the terminology used in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this confusion or clarify the terminology. While it highlights an area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of technical novelty in the paper, suggesting a comparison with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be improved. The comment implies that the authors should consider the similarities between their work and the previous papers, but it lacks concrete steps or suggestions on how to enhance the novelty or differentiate their work. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of limited technical novelty by comparing the paper with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper this comparison should be made in, such as the introduction, related work section, or methodology. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in identifying the issue of limited novelty and the similarity in ideas, co-attention mechanisms, and architecture with the previous papers. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The reviewer highlights similarities in the idea, co-attention mechanism, and architecture between the current paper and the previous works. However, the comment does not provide detailed comparisons or specific examples of how the current paper's contributions differ from the mentioned works. This lack of detailed analysis or references makes the claim somewhat verifiable, as the authors would need to conduct their own analysis to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s technical novelty, suggesting that the idea, co-attention mechanism, and architecture are similar to those in previous papers. It provides a specific reference to two papers (Xing and Tsang, 2022a, b) for comparison, which could help the authors understand the context of their work. However, the comment lacks actionable guidance on how the authors might differentiate their work or enhance its novelty. While it highlights an important area for consideration, the feedback could be more helpful if it included suggestions for addressing the similarity or improving the originality of the paper. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction, and if so, why. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the paper need to be revised. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the problem or its applicability are unclear. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the applicability of the problem discussed in the paper. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the problem discussed in the paper, specifically whether it is specific to binding affinity prediction or if it applies to other downstream tasks. While the comment identifies a potential area for clarification, it lacks depth and does not provide any specific guidance or suggestions on how the authors might address this question or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider the broader implications of their work, but it does not offer actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of computation cost and running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of computation cost or running time should be compared or how this comparison should be presented. Without any actionable steps or suggestions, the authors are left without a clear understanding of what changes or additions are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of computation cost and running time but does not specify which part of the paper this comparison should be made in. It lacks grounding as it does not identify a specific section, table, or figure where this comparison is discussed. Additionally, it is not specific about what aspects of computation cost or running time should be compared. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for a comparison in terms of computation cost and running time, which does not contain any claims or opinions that require verification. It is a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of computation cost and running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address the question or what changes might be necessary. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggests that one type (the column header) should suffice. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the division of tables into three types in Section 3, specifically wondering if one type (the column header) should suffice. However, the comment does not provide any reasoning, evidence, or examples to support why the current division is unnecessary or how it could be simplified. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). While it identifies a potential area for clarification, the comment lacks depth and does not provide any actionable suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to reconsider their categorization of tables, but it does not offer specific advice or examples to improve the draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the task is closer to Argument Mining than Summarization and recommends that the paper clarify the differences against Argument Mining/Discussion Summarization. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so or offer specific guidance on how to make these clarifications. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task is closer to Argument Mining than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in suggesting that the paper should clarify the differences, but it does not provide detailed guidance on how to do so. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task is closer to Argument Mining than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the task being closer to Argument Mining than Summarization and suggests that the paper should clarify the differences against Argument Mining/Discussion Summarization. This feedback is somewhat helpful as it identifies a potential confusion in the task's categorization and prompts the authors to provide clarification. However, the comment lacks specific guidance on how to clarify these differences or what aspects of the paper need to be addressed. While it points out an area for improvement, it does not provide detailed actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The comment also suggests showing the advantages of the proposed method's assumptions compared to existing methods. While the comment identifies areas that need clarification and evidence, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the definition and provide evidence to support the sparsity assumption. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The comment also suggests comparing the advantages of the proposed method\\'s assumptions with existing methods. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the sparsity of the residual term is discussed. The comment is specific in detailing what needs to be clarified and improved, such as providing evidence for the sparsity assumption and comparing with existing methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The comment also suggests comparing the advantages of the proposed method\\'s assumptions with existing methods. While the comment identifies areas that need clarification and evidence, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the sparsity definition of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the comment suggests that the authors should demonstrate the advantages of their method\\'s assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology and provide evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to present this evidence or compare with existing methods. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the models and datasets used are too toy-like and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small, to enhance the experiment. The reviewer also asks about the feasibility of experimenting on language tasks. While the comment provides explicit suggestions for improvement, it lacks concrete guidance on how to implement these changes or address the questions raised. The authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the models and datasets used in the paper, suggesting that they are too toy-like and proposing specific alternatives like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. However, it does not explicitly mention which part of the paper discusses these models and datasets, making it weakly grounded. The comment is specific in suggesting alternative models and datasets, but it lacks grounding as it does not direct the authors to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the models and datasets used are \"too toy-like\" and suggests using more challenging datasets like CIFAR100 or models like ResNet 34 or 50, and ViT-tiny or small. The reviewer provides specific examples of alternative models and datasets, which supports the claim. However, the comment lacks detailed reasoning or references to justify why these alternatives are more suitable or challenging. While the suggestion is clear, the lack of detailed explanation or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the models and datasets used in the paper, suggesting that they are too toy-like. It provides specific and actionable suggestions for improvement, such as using CIFAR100, ResNet 34 or 50, and ViT-tiny or small, which would enhance the experiment. Additionally, the reviewer raises a question about the feasibility of experimenting on language tasks, which could prompt the authors to consider this aspect. The comment is clear and provides concrete guidance, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a comparison against baselines in the paper, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment suggests that this is a common practice in binary analysis applications and that many papers have developed architecture-agnostic similarity comparisons or reported similar tasks. While the comment implies that the authors should include baselines for comparison, it does not explicitly instruct them to do so or provide specific guidance on which baselines to use. The action is implicit and somewhat vague, as the authors can infer the need for baselines but may not know exactly which ones to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the lack of baselines in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not comparing against baselines and references a common practice in binary analysis applications. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment supports this claim by referencing a \"widely-understood binary analysis application\" and mentioning that many papers have developed architecture-agnostic similarity comparisons or reported similar tasks. This provides a logical reasoning and common knowledge basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison against baselines. It highlights that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines, which is a common practice in binary analysis applications. The comment also references other papers that have developed architecture-agnostic similarity comparisons or reported similar tasks, providing context and suggesting that the authors should include baselines for comparison. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers a reference point for enhancing the paper. However, it could be more helpful if it provided specific suggestions on which baselines to use or how to incorporate them into the study. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific guidance or suggestions on how to enhance the contribution or address the perceived limitations. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically mentioning the overfitting problem of training GANs with limited data and the proposal of differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in identifying the issue with the contribution, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper is not sufficient, specifically addressing the overfitting problem of training GANs with limited data and proposing differentiable augmentation. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a concern about the sufficiency of the paper's contribution, specifically mentioning the overfitting problem of training GANs with limited data and the proposal of differentiable augmentation. However, it does not provide any specific suggestions or guidance on how the authors might enhance their contribution or address the perceived limitations. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is barely helpful, as it highlights an issue but lacks depth and actionable advice.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their proof technique. The action is implicit and vague, as the authors are left to infer that they need to clarify or address the contradiction in their proof. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity, and references Section 3 for further context. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that this is mentioned in Section 3, where the authors discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide further explanation or evidence to support why this is a concern or how it affects the validity of the proof. The lack of detailed reasoning or references makes the claim somewhat verifiable, as the authors would need to delve deeper into the paper to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that this is mentioned in Section 3, where the authors discuss the inapplicability of Theorem 1 due to normalization. This feedback is somewhat helpful as it points out a potential weakness in the proof technique, but it lacks depth and does not provide suggestions on how the authors might address this issue or improve their proof. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment also explains the reasoning behind the suggestion, which is that allowing \"t\" to be arbitrary does not add value. This level of detail makes the action concrete and easy for the authors to implement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a replacement of \"t\" with the size of \"T\" for clarity, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity, implying that allowing \"t\" to be arbitrary does not add value. However, the comment does not provide any reasoning or evidence to support why this change would improve clarity or why \"t\" being arbitrary is problematic. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of \"T\". This feedback is actionable and offers a clear direction for the authors to enhance the readability and precision of their work. However, the comment could be more helpful if it explained why this change is necessary or how it would impact the understanding of the kernel. Despite this, the suggestion is clear and provides a concrete step for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two. While the comment implies that the authors should consider this alternative, it does not provide explicit guidance on how to address the question or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and provide a response. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this assumption is discussed. Without explicit references, the authors may find it challenging to determine where to address this question. The comment is specific in its inquiry about the difference between the two distributions, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification on the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on whether it is possible to assume a general Gaussian distribution and what the difference is between the two. While the comment identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or its implications for their work. The feedback is somewhat helpful as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, implying that the authors should clarify or justify the purpose of this section. However, it does not provide any explicit guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation about the section\\'s intent. Without specific instructions or examples, the authors may find it challenging to determine the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the intent of this section, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the intent of Section 5.2, rather than a claim or opinion that requires verification. It does not contain any subjective opinions, judgments, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, indicating a lack of clarity or understanding regarding the purpose of this section. While it identifies a potential area for improvement by questioning the section\\'s intent, it does not provide any specific suggestions or guidance on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors with a vague direction for improvement. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers. However, the comment does not provide explicit guidance or suggestions for the authors to improve their approach or address these limitations. The feedback is implicit and lacks concrete details on how the authors might enhance their work. As a result, the authors are left without a clear understanding of what actions to take to address the concerns raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The authors can make an educated guess about the sections related to the proposed approach and the comparison with operator learning methods, but the comment lacks full grounding. It is specific in detailing the critique of the approach, but the lack of explicit references to specific sections or parts of the paper limits its grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed approach by suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. The comment provides a logical reasoning by highlighting the differences between the proposed approach and existing methods, but it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to delve deeper into the literature to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critical evaluation of the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers, noting that they are more universal but less accurate. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is somewhat helpful as it points out a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the target of the paper or where to make the necessary changes. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not specify which part of the paper should be revised to address this issue, nor does it provide detailed guidance on how to clarify the target. The authors can infer that the issue is related to the introduction or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any specific examples, reasoning, or references to support the claim of confusion. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the paper\\'s focus on single-token or multi-token cloze queries. It highlights that the clarification is not clear until the conclusion, indicating a potential issue with the paper\\'s organization or clarity. However, the comment does not provide specific suggestions or guidance on how the authors might address this confusion or improve the clarity of their paper. While it points out a weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. While the comment implies that the authors should make their code public to facilitate reproducibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for code sharing but are not given specific guidance on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the code or results are problematic. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are hard to reproduce or why code availability is necessary. The comment lacks specific details or references that would help the authors understand the issue or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical issue regarding the reproducibility of the results, which is a significant concern in scientific research. By asking if the code will be made publicly available, the reviewer highlights a potential barrier to verifying the findings. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or improve the reproducibility of their work. Without actionable suggestions or detailed feedback, the authors are left with a general awareness of the problem but no clear path forward for improvement. Therefore, the comment is barely helpful, as it identifies an important issue but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies that the technical contribution of the paper is limited. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their contribution. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies a limitation in the technical contribution of the paper. However, it does not specify which part of the paper this similarity is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the similarity are problematic or how this similarity affects the paper\\'s contribution. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies a limitation in the technical contribution of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the similarity or how it affects the paper\\'s contribution. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the paper, suggesting that $kNN-ECD$ is very similar to $kNN-MT$, which could limit the technical contribution of the paper. However, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this similarity or enhance their contribution. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the author was unclear about the numbers of parameters used in each approach, specifically in Section B.3. This provides a direct action for the authors to take, which is to clarify and provide the specific numbers of parameters used in each approach. The comment is explicit and concrete, as it clearly instructs the authors on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the numbers of parameters used in each approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement requesting clarification on the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the numbers of parameters used in each approach, as mentioned in Section B.3. This feedback is clear and actionable, as it directs the authors to clarify and provide the specific numbers of parameters used in each approach. By addressing this point, the authors can improve the clarity and transparency of their paper, making it more understandable for readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the evaluation results reported in Table 1, specifically noting that they are based on only three trials for each case. The reviewer suggests that this is statistically insignificant and questions the relevance of reporting deviations. The comment also critiques statements claiming performance superiority over baselines due to the lack of statistical significance. While the comment identifies a potential issue with the evaluation methodology and the interpretation of results, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should either increase the number of trials or rephrase their claims to reflect the limitations of the current evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that they are based on only three trials for each case, which is statistically insignificant. The comment further explains why this affects the interpretation of deviations and the validity of claims about performance superiority over baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically insignificant. The reviewer argues that this lack of statistical significance makes it nonsensical to report deviations and supports the claim that statements about performance superiority over baselines are not valid. The comment provides a logical reasoning for the claim, explaining why the limited number of trials affects the reliability of the results. However, it could be strengthened by providing specific examples or references to support the assertion about the statistical significance. Overall, the claim is mostly verifiable, as it offers a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that they are based on only three trials for each case. This is a critical observation because it highlights a potential flaw in the statistical significance of the results, which could impact the validity of claims about performance superiority over baselines. The comment provides a clear and actionable suggestion by pointing out that the lack of statistical significance makes it nonsensical to report deviations or make claims about performance superiority. This feedback is valuable as it prompts the authors to reconsider their evaluation methodology and potentially revise their claims to reflect the limitations of their data. However, the comment could be more helpful if it offered specific guidance on how to address this issue, such as suggesting additional trials or statistical analyses. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size, as recent work by Ni et al. shows that the scaling law applies to dense retrieval models. This implies that the authors should conduct or present additional experiments to support their claims about model size and performance. While the action is implicit, it is concrete in its suggestion to provide detailed experimental results. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that it is unreasonable for increasing model size to hurt performance, referencing recent work by Ni et al. that shows the scaling law applies to dense retrieval models. It implies that the authors should provide preliminary experimental results on Wikipedia regarding model size. However, the comment does not specify which part of the paper discusses model size or performance, making it weakly grounded. It is specific in suggesting the need for detailed experimental results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unreasonable for increasing model size to hurt performance, referencing recent work by Ni et al. that shows the scaling law applies to dense retrieval models. This claim is somewhat verifiable as it provides a reference to external work that supports the idea that model size can impact performance. However, the comment lacks specific details or examples from the paper being reviewed, making it difficult for the authors to fully understand the context and implications of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the claim that increasing model size can hurt performance, which seems counterintuitive given recent findings in the field. It references a recent paper by Ni et al. that shows the scaling law applies to dense retrieval models, suggesting that the authors should provide preliminary experimental results on Wikipedia regarding model size. This feedback is clear and actionable, as it identifies a potential inconsistency in the paper and provides a specific direction for the authors to address it by conducting or presenting additional experiments. However, the comment could be more helpful if it offered guidance on how to interpret the results or what specific aspects of the model size should be explored. Overall, the comment is mostly helpful, as it directs the authors to a critical area that needs further investigation and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might address this question or incorporate it into their draft. As a result, the comment lacks actionability and does not offer any direction for the authors to improve their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups struggle with Greek, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address this question or what aspects of the paper might be relevant. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking additional information about the paper\\'s findings or experiments. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. While it highlights a potential area of interest, it does not provide any specific suggestions or guidance on how the authors might address this question or incorporate it into their draft. The comment lacks actionable feedback or detailed insights that could help the authors improve their work. As a result, it is barely helpful, as it identifies a potential area of interest but does not offer any actionable steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the study, specifically whether it is limited to only one truck and one drone, and suggests that considering multiple trucks and drones could be more interesting and practical. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address the issue or what specific steps should be taken to extend the study to multiple trucks and drones. As a result, the authors are left without a clear understanding of what changes are needed or how to implement them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the study, specifically whether it only considers one truck and one drone, and suggests that extending it to multiple trucks and drones could be more interesting and practical. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion to consider multiple trucks and drones but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scope of the study by noting that it only considers one truck and one drone, and suggests that extending it to multiple trucks and drones could be more interesting and practical. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension would be beneficial or how it would impact the study. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid point about the scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical, which is a relevant observation. However, the comment lacks specific guidance or suggestions on how the authors might address this limitation or what additional considerations would be necessary to extend the study. While it identifies a potential area for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\\'s ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or suggest specific modifications to Equation 8. The action is implicit, as the authors need to infer that they should reconsider the subtraction of \"s\" from the dynamic information. The feedback lacks concrete details on how to implement the suggested change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue with subtracting \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\\'s ability to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential loss of dynamic information when subtracting \"s\" from the dynamic information in Equation 8. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks concrete evidence or detailed explanation, making it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and hinder the LSTM module\\'s ability to capture complete dynamic changes. This feedback is somewhat helpful as it points out a specific area of concern that the authors should address. However, it lacks depth and does not provide detailed guidance on how to resolve the issue or suggest alternative approaches. While it highlights a potential problem, it does not offer actionable steps for improvement, limiting its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors are left to infer that they should investigate or discuss these aspects in their paper, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not specify which part of the paper these questions relate to, such as specific sections or experiments. Without explicit references or context, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in its inquiry but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. By asking these questions, the reviewer prompts the authors to consider and potentially investigate these aspects further, which could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or what specific aspects of the network structure or MC samples are most relevant. While it identifies areas for exploration, the feedback is somewhat helpful as it provides a direction for further investigation but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the notation usage in Section 2, noting that the notations of \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way. However, it does not provide any explicit guidance or suggestions on how to resolve this issue or clarify the notation usage. The comment lacks actionable details, leaving the authors uncertain about how to address the problem. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of mixed notation usage for \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\), providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way in Section 2. However, it does not provide any supporting evidence, examples, or reasoning to justify why this mixed usage is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation usage in Section 2, noting that \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way. This feedback is clear and actionable, as it directs the authors to clarify and standardize the notation usage in the section. However, the comment could be more helpful if it provided suggestions on how to resolve the issue or offered examples of consistent notation usage. Despite this, the comment still offers valuable guidance for improving the clarity and consistency of the paper, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not provide explicit guidance or suggestions on how the authors might improve this aspect of their work. The action is implicit and vague, as the authors are left without clear instructions on what changes to make or how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the metric learning theory in the paper, suggesting it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this is not explicitly stated. The comment is specific in its critique of the metric learning theory, but without clear grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It suggests that the metric perspective analysis proposed in the paper does not work, implying a lack of effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the issue or enhance the metric learning theory. Without detailed feedback or constructive suggestions, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential source of confusion in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit guidance or suggestions on how to resolve this issue. The comment lacks concrete details on how to address the confusion, such as recommending alternative notation or suggesting a clearer distinction between the two types of risks. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation used in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in detailing the issue with the notation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the notation. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it affects the clarity of the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, where \"r\" is used to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable feedback that can help the authors clarify their notation and avoid potential confusion for readers. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending alternative notation or explaining the context in which each use of \"r\" is appropriate. Despite this, the comment is still somewhat helpful as it directs the authors to a specific area needing attention and improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits need to be demonstrated. It implies that the authors should provide evidence or examples to support their claims, particularly regarding the impact of sparsity on training speed and cost savings. However, the comment does not explicitly instruct the authors to conduct specific experiments or analyses to address these concerns. While the action is implicit, it is somewhat concrete in suggesting that the authors need to provide evidence to support their claims. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the necessity of claims about the desirability of sparsity in training and suggests that any potential benefits need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by mentioning the need to demonstrate benefits and the importance of practical implementation, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of claims about the desirability of sparsity in training, suggesting that any potential benefits need to be demonstrated. The reviewer provides a logical reasoning by pointing out that a larger network that cannot fit into memory without sparsity may perform better, and that any hypothetical training speed increases due to reduced FLOPs are meaningless without evidence of practical cost savings. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the necessity of claims about the desirability of sparsity in training, suggesting that these claims are not obvious and need to be substantiated. It provides a logical reasoning by pointing out that a larger network that cannot fit into memory without sparsity may perform better, and that any hypothetical training speed increases due to reduced FLOPs are meaningless without evidence of practical cost savings. This feedback is somewhat helpful as it prompts the authors to provide evidence or examples to support their claims, which could lead to a more robust argument in the paper. However, the comment could be more helpful if it offered specific suggestions on how to demonstrate these benefits or provided examples of how to address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. While the comment implies that the authors should conduct an analysis to support the claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform an analysis to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the morphfitting results in a more meaningful space. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the current geometry is not meaningful. This lack of evidence makes the claim somewhat verifiable, as the authors would need to infer the need for additional analysis or evidence to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry of the space is meaningful, such as demonstrating that specific operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. This feedback is clear and actionable, as it prompts the authors to conduct an analysis that could significantly enhance the understanding and interpretation of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and offers a direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is explicit and provides a concrete direction for the authors to explore, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks detailed reasoning or evidence to support why the authors should focus on these aspects or how they relate to the improvements. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and offers a clear direction for the authors to explore, which could lead to a more comprehensive understanding of their results. However, the comment could be more helpful if it included additional suggestions or examples of how to analyze these aspects. Overall, the comment is mostly helpful as it provides a valuable insight into potential areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the components of the \"scoring function\" and the threshold values/ranges used. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify these aspects, but it does not specify what information should be included or how it should be presented. As a result, the action is implicit and somewhat vague, leaving the authors to infer the necessary steps without clear direction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"scoring function\" and the threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is unclear: the components of the \"scoring function\" and the threshold values/ranges. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the \"scoring function\" and the threshold values/ranges used. However, it does not provide any specific examples, reasoning, or references to support why this clarity is important or how it affects the paper. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the \"scoring function\" and the threshold values/ranges used. It points out that the authors have not provided sufficient information on how these components were determined, which could be crucial for understanding the methodology and results. However, the comment does not offer any suggestions or guidance on how the authors might clarify this aspect or provide additional details. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a potential weakness but lacks depth in terms of actionable feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the model comparison section of the paper. It points out that the selection of datasets is inadequate because only one dataset has categorical features, while the others have exclusively numerical features. This is considered a limitation because categorical features are generally more challenging for deep learning models. Additionally, the authors are criticized for not using one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should consider a more diverse set of datasets and potentially adjust their methodology for handling categorical features. However, the lack of explicit instructions on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"model comparison\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, while others have exclusively numerical features. This is a critical point because categorical features are generally considered more challenging for deep learning models. The comment further specifies the issue by mentioning the lack of one-hot encoding for the dataset with categorical features, which could negatively affect performance for some models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model comparison is inadequate due to the selection of datasets, specifically noting that only one dataset has categorical features, while others have numerical features. It suggests that this omission may affect conclusions because categorical features are generally more challenging for deep learning models. The comment also points out that the authors do not use one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. This reasoning is logical and based on common knowledge about the challenges of deep learning with categorical features. However, the comment could be strengthened by providing specific examples or references to support the claim about the impact of categorical features on model performance. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the model comparison section of the paper, specifically noting that the selection of datasets is inadequate. It points out that only one dataset has categorical features, while others have exclusively numerical features, which could affect the conclusions drawn from the comparison. Additionally, the comment highlights that the authors do not employ one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific areas for improvement, such as considering a more diverse set of datasets and adjusting the methodology for handling categorical features. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of datasets that could be included. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the robustness and validity of their model comparison.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the choice of IoT datasets (FlatCam Face and Head-pose detection) is unusual and may make the benchmarking results difficult to evaluate. It suggests that better options for IoT benchmarking could include wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback provides a clear and concrete action for the authors to consider alternative datasets that might improve the comprehensibility and relevance of their benchmarking results. The comment is explicit and provides specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of IoT datasets, specifically mentioning \"FlatCam Face\" and \"Head-pose detection,\" and suggests alternative datasets that could be used for benchmarking. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of IoT datasets is unusual and may make the benchmarking results difficult to evaluate. The reviewer provides specific examples of the datasets used, \"FlatCam Face\" and \"Head-pose detection,\" and explains why they are considered uncommon choices. The reviewer also suggests alternative datasets that could be used for benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that these datasets are not commonly used. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of IoT datasets used in the paper, namely \"FlatCam Face\" and \"Head-pose detection.\" It questions the relevance and popularity of these datasets, suggesting that they may not be the best choices for benchmarking. The reviewer provides a rationale for this critique by noting that \"FlatCam Face\" is relatively recent but not widely followed, and \"Head-pose detection\" is outdated, having been published in 2004. The comment also offers suggestions for alternative datasets that could be used for IoT benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the relevance and comprehensibility of their benchmarking results. By addressing this issue, the authors can enhance the credibility and impact of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim about the regret bound for the proposed mini-batch method, as it could not be found in the supplementary material. While the comment highlights a potential issue with the paper, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to verify the claim and potentially revise the paper to include the missing information. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the regret bound for the mini-batch estimator was not found in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have stated the regret bound for the proposed mini-batch method is in the appendix, but it could not be found in the supplementary material. The reviewer supports this claim by referencing a specific external work, \"Online Variance Reduction for Stochastic Optimization,\" which suggests that the claim is based on a comparison with existing literature. However, the comment could be strengthened by providing more detailed reasoning or examples of how the absence of the regret bound affects the paper. Overall, the claim is mostly verifiable, as it provides a logical basis for the critique but lacks specific references or detailed analysis within the paper. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a discrepancy between the authors\\' claim and the actual content of the paper. It specifically mentions that the regret bound for the proposed mini-batch method is claimed to be in the appendix but could not be found in the supplementary material. This feedback is clear and actionable, as it directs the authors to verify and correct their claim. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested potential reasons for the discrepancy. Overall, the comment is mostly helpful as it identifies a critical error that needs to be corrected, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this weakness or improve their method. Without guidance on potential solutions or areas for further investigation, the authors are left without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where this issue needs to be addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the authors might address this weakness. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as a main weakness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a clear and actionable piece of feedback that highlights a critical area for improvement. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this weakness or improve their method. While it points out a significant issue, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative approach for evaluating the quality of \\\\overline{\\\\Pi} by using the performance in the worst MDP instead of the summation over all MDPs in S_{test}. The reviewer provides a clear rationale for this suggestion, explaining that the summation might mask the poor performance of policies in certain MDPs. This feedback is explicit and provides a concrete action for the authors to consider, making it highly actionable. The authors know exactly what they need to do to address the issue, which is to evaluate the quality of \\\\overline{\\\\Pi} using the performance in the worst MDP. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"intuitive goal\" and the evaluation of \\\\overline{\\\\Pi} with the performance in the worst MDP, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, suggesting an alternative method using the \\\\min over S_{test} instead of the summation. This provides clear guidance on how to improve the evaluation of \\\\overline{\\\\Pi}. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach for evaluating the quality of \\\\overline{\\\\Pi} by using the performance in the worst MDP instead of the summation over all MDPs in S_{test}. The reviewer provides a logical explanation for this suggestion, arguing that the summation might mask poor performance in certain MDPs. This reasoning is clear and provides a rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for evaluating the quality of \\\\overline{\\\\Pi}. It suggests using the performance in the worst MDP instead of the summation over all MDPs in S_{test}, which could help identify potential issues with the current approach. The comment explains the reasoning behind this suggestion, highlighting how the summation might mask poor performance in certain MDPs. This feedback is clear and provides a concrete direction for the authors to improve their evaluation methodology. However, it could be more helpful if it included additional context or examples to further illustrate the potential benefits of the suggested approach. Overall, the comment is mostly helpful, as it offers a valuable insight that can guide the authors in enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extraction of parts of sentences and documents, as well as the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis, which provides a clear action for the authors to take. However, the comment does not specify how the authors should conduct this analysis or what specific details should be included. While the action is explicit, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. The comment requests a more detailed analysis, providing clear guidance on what the authors should focus on. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the extraction process and its impact on the experiment. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the extraction process, specifically asking how parts of sentences and documents are extracted and whether the rules of extraction have any effect on the experiment. It also requests a more detailed analysis, which is a clear and actionable suggestion for the authors to improve their draft. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs further exploration and explanation. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to rephrase a section of the paper (L107-114) that is deemed speculative or overly opinionated. It suggests that this content should be presented as a remark or aside in the Discussion section or removed altogether. This feedback provides clear and direct guidance on what action to take, making it highly actionable. The authors know exactly what needs to be done to address the issue, and the comment offers concrete steps to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it seems speculative or overly opinionated and suggesting that it should be rephrased as a remark or aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific section of the paper (L107-114) is \"speculative or overly opinionated.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (L107-114) as being speculative or overly opinionated. It provides clear guidance by suggesting that this content should be rephrased as a remark or aside in the Discussion section or removed altogether. This feedback is actionable and offers a concrete way for the authors to improve the clarity and focus of their draft. By addressing this issue, the authors can enhance the credibility and effectiveness of their argument. Therefore, the comment is rated as highly helpful, as it provides specific and constructive feedback that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it raises a concern about the lack of clarity in the motivation, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the reasoning behind their choice of distributions, but it does not specify what information should be added or how to present it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper discusses these distributions, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the motivation but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. This is a relevant concern that could help the authors clarify their methodology and provide a clearer rationale for their choices. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. While it identifies an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete details on what specific information should be included or how the authors should present their data. As a result, the authors are left with an implicit action to clarify the data usage, but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its request for clarification on the data usage but lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual inquiry that seeks clarification rather than an opinion or suggestion. It does not contain any subjective claims or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. This is an important point that the authors need to address to ensure transparency and reproducibility of their findings. However, the comment lacks specific suggestions or guidance on how the authors might clarify this information, such as recommending the inclusion of detailed data descriptions or examples. While it highlights a significant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a clear explanation of how their SE framework improves and why it is beneficial. It also emphasizes the need to demonstrate the reasoning behind their achievements, going beyond just showing results. The comment provides a specific action for the authors to take, which is to include a detailed explanation of the framework\\'s benefits and how it is implemented. Additionally, it suggests referencing a specific paper to support their claims, offering a concrete example of how to enhance the paper. This feedback is explicit and provides clear guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for a clearer explanation of how the SE framework improves and why it is beneficial, and it suggests showing the reasoning behind the achievements. Additionally, it references a specific paper, \"Neural architecture search with gbdt,\" which provides a concrete example of how to enhance the paper. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide a clearer explanation of how their SE framework improves and why it is beneficial. The reviewer suggests that the authors should demonstrate the reasoning behind their achievements, rather than just showing results. The comment references a specific paper, \"Neural architecture search with gbdt,\" which provides a relevant example of how to enhance the paper. However, the claim is mostly verifiable as it lacks detailed reasoning or examples specific to the authors\\' work. The reference to the external work provides some support, but the authors may need to elaborate on how their framework aligns with or improves upon the referenced work. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by emphasizing the need for the authors to explain how their SE framework improves and why it is beneficial. It instructs them to go beyond just showing results and to provide a detailed explanation of the reasoning behind their achievements. This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their paper. Additionally, the comment suggests referencing a specific paper, \"Neural architecture search with gbdt,\" which could serve as a useful example for the authors to follow. By addressing these points, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without significant difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific changes should be made to the approach. The comment lacks concrete details or suggestions, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without too much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the approach\\'s limitations but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without difficulty. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of the approach being restricted to only two views, suggesting that the system should be able to generalize to more views without significant difficulty. This is a valid point that could prompt the authors to consider expanding their approach to multiple views. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this limitation or what specific changes could be made to improve the generalizability of their system. Without detailed suggestions or examples, the feedback is somewhat helpful as it identifies an area for potential improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the applicability of the metrics used for evaluating continual learning in certain scenarios, such as when task boundaries are unknown or not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for alternative metrics or approaches that could be more suitable. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue with the applicability of these metrics in certain scenarios. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in scenarios where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the \"loss after switch\" and \"recovery time after switch.\" It points out that these metrics might not be applicable in scenarios where task boundaries are unknown or not clearly defined. This feedback is somewhat helpful as it highlights a potential weakness in the evaluation approach, prompting the authors to consider alternative metrics or methods that could be more suitable for their dataset. However, the comment lacks specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the setup need attention. The comment implies that the authors should address these concerns, but it lacks concrete details or actionable steps. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific issues arise from the current setup. The authors may infer that it relates to the experimental section, but without explicit references, it is weakly grounded. The comment is specific in identifying the need for a better experiment setup but lacks detailed guidance on how to achieve this. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup due to the questions that arise. However, the comment does not provide specific examples of these questions or elaborate on why the current setup is inadequate. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. It raises questions about the current setup, indicating that the authors should address these concerns. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to improve the experiment setup. Without actionable advice or examples, the authors are left with a general idea of what might need attention but without a clear path forward. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the error analysis on the movie dataset is missing, which is a clear action for the authors to take. It also provides a concrete suggestion by specifying that the authors need to identify the cases where the model fails, which would help other researchers continue working on this task. This feedback is direct and provides a clear path for the authors to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the cases where the model fails, which is crucial for other researchers to continue working on this task. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the missing analysis or how it impacts the work. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of error analysis on the movie dataset. It highlights the importance of understanding the cases where the model fails, which is crucial for other researchers to build upon this work. This feedback is clear and actionable, as it provides a specific area for the authors to focus on and improve their draft. By addressing this gap, the authors can enhance the comprehensiveness and utility of their paper. Therefore, the comment is rated as highly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing part in the paper, specifically the lack of a separate section or subsection to introduce the inference strategy for using multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to add a separate part or subsection to address this gap. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by indicating where the authors should add more detail. However, the comment could be more helpful if it offered additional guidance on what aspects of the inference strategy should be included or how to effectively present this information. Despite this, the comment is mostly helpful as it directs the authors to a critical area that needs expansion, allowing them to enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations for the observed results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations without specific guidance on what aspects to focus on. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to identify the exact section being addressed. The comment suggests that more explanations are needed, but it does not provide specific guidance on what aspects of the results or explanations are lacking. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods like f-CLSWGAN and f-VAEGAN-D2. However, the comment lacks specific reasoning or evidence to support why these results are unexpected or how they compare to the mentioned methods. Without detailed analysis or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue with the results, it lacks specific guidance or suggestions on how the authors might address this concern or provide additional explanations. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it is somewhat vague because it does not specify what aspects of the plan should be detailed or how the authors should present this information. The authors know they need to provide a more detailed plan but may not be entirely sure of the exact steps or level of detail required. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. However, it does not specify which limitations are being referred to or where in the paper these limitations are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in its request for a detailed plan but lacks grounding, as it does not identify the specific sections or aspects of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This claim is somewhat verifiable as it acknowledges the authors\\' mention of limitations but highlights the need for a more detailed plan. However, the comment lacks specific examples or references to support the claim that the current plan is insufficient. Providing more detailed guidance or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the authors have mentioned limitations in the paper but suggests that they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is somewhat helpful as it identifies a potential area for improvement by encouraging the authors to be more specific about their plans for addressing the limitations. However, the comment could be more helpful if it provided specific guidance on what aspects of the plan should be detailed or how the authors might structure their future work discussion. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that similar methods have already been proposed for multi-task learning and notes that this has not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper should be revised. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that similar methods have already been proposed for multi-task learning and notes that this has not been discussed in the paper. However, it does not specify which part of the paper should include this discussion or which specific methods are being referred to. The authors can make an educated guess that it relates to the methodology or literature review sections, but the comment lacks full grounding. It is specific in pointing out the omission of discussing similar methods, but without explicit references or detailed guidance, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar methods have already been proposed for multi-task learning and have not been discussed in the paper. However, it does not provide any specific examples or references to these existing methods, making it difficult for the authors to understand the basis of the claim or how to address it. Without supporting evidence or detailed information, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that similar methods for multi-task learning have already been proposed and are not discussed in the paper. This is a relevant observation that could help the authors improve their draft by ensuring they are aware of existing work in the field and potentially incorporating it into their discussion or methodology. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or integrate the existing methods into their work. While it highlights an important area for consideration, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an expectation about the computational complexity of FedMITR compared to other methods and asks if a comparison has been made. While it implies that the authors should consider comparing the computational complexity, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors may infer that it relates to the experimental or results sections, but this is not explicitly stated. The comment lacks specificity as it does not provide details on what aspects of computational complexity should be compared or why this comparison is important. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the expectation or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. While it identifies a potential area for comparison, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of computational complexity should be considered. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide guidance on how to clarify it. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to \"1) and 2)\" and \"figure 3,\" which provides some grounding as it implies specific parts of the paper being discussed. However, it does not explicitly mention which sections or figures these numbers correspond to, making it weakly grounded. The comment suggests using a generic external knowledge base to address issues 1 and 2, but it does not specify what these issues are or how the knowledge base would resolve them. This lack of specificity makes it difficult for the authors to understand what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion. The mention of \"the writing is too confusing\" adds to the lack of clarity, as it does not specify what aspects of the writing are confusing or how they could be improved. Without detailed reasoning or examples, the claim is not verifiable, making it a 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague and lacks specificity, as it does not clearly explain what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide any guidance on how to clarify it. Without detailed feedback or actionable suggestions, the authors are left without a clear understanding of what needs to be improved or how to make those improvements. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived weakness in the analysis, specifically regarding the theoretical work on sampling and particle-based optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of the discretization in time and space. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more theoretical justification but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical work on sampling and particle-based optimization methods,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issues with the analysis, such as the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and guarantees of discretization. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the provided analysis is \"somewhat weak\" in light of theoretical work on sampling and particle-based optimization methods. It specifically points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of discretization. However, the comment does not provide detailed reasoning or references to support this claim, making it somewhat verifiable. The authors would need to infer the specific issues and potential solutions based on the general critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the analysis, specifically noting that the provided analysis seems weak in light of theoretical work on sampling and particle-based optimization methods. It highlights the lack of evidence for the existence and smoothness of the solution of SDE (2a)-(2d) and any guarantees of discretization. This feedback is clear and actionable, as it points out specific areas where the authors need to strengthen their analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how to improve the theoretical foundation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that the authors may need to trace them in the source code. While the comment implies that the authors should provide more detailed information about these hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more details about the hyperparameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of missing hyperparameters for many components, suggesting that the authors should provide these details. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model has many components with hyperparameters not fully provided, suggesting that the authors should include these details. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand which components are missing information. The lack of detailed evidence or examples renders the claim somewhat verifiable, as the authors would need to investigate further to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This is a critical piece of information for the authors, as it highlights a potential gap in the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific hyperparameters to include or methods for documenting them. Despite this, the comment is still somewhat helpful as it directs the authors\\' attention to an important area for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these suggestions, such as which specific cases to focus on or how to analyze the limitations. The action is explicit but somewhat vague, as the authors know they need to include qualitative results and failure cases but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these suggestions should be applied to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but without explicit references, it is challenging to pinpoint the exact parts. The comment is specific in detailing what needs to be addressed, such as showing qualitative results and failure cases, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that qualitative results, particularly with a zoomed-in view, should be included for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not provide specific examples, reasoning, or references to support why these qualitative results are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors include qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. This feedback is clear and actionable, as it provides specific guidance on how to enhance the paper by adding qualitative results and failure cases. By following this advice, the authors can better demonstrate the effectiveness and robustness of their proposed method, which is valuable for improving the draft. However, the comment could be more helpful if it offered examples of how to present these results or suggested specific aspects to focus on when analyzing limitations. Overall, the comment is mostly helpful, as it offers constructive feedback that can significantly improve the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, namely that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what aspects of the interpretability tax should be evaluated or how to conduct such an evaluation. Without concrete instructions or examples, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or analysis. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is not grounded as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on how to evaluate the interpretability tax. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. This is a relevant observation that could be addressed by the authors to enhance the comprehensiveness of their work. However, the comment does not provide any guidance or suggestions on how the authors might evaluate this aspect or what specific metrics or approaches could be used. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses to address the reviewer\\'s concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the training process is discussed. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the training losses are of interest or how they should be presented. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not provide any supporting evidence, reasoning, or references to justify why the stability is a concern or why training losses are necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable advice or insights that could help the authors improve their draft. Therefore, it is barely helpful, as it highlights a potential issue but does not provide enough detail or direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability, which are claimed to be distinct but are actually the same concept from different viewpoints. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the claims. The action is implicit and vague, as the authors are left to infer that they need to revise their claims but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the paper\\'s claims, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis. It supports this claim by explaining that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are actually the same concept from different viewpoints. This logical reasoning provides a clear explanation of why the claim is valid, making the comment mostly verifiable. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that several aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability, are actually the same concept viewed from different perspectives. This feedback is clear and actionable, as it prompts the authors to revisit and clarify their claims to ensure accuracy and avoid overstatement. However, the comment could be more helpful if it provided suggestions on how to rephrase or reorganize the theoretical analysis to better reflect the actual contributions. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the relevance of the proposed method to the authors\\' motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract section\" and the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the proposed method to the authors\\' motivations and suggesting that it may not be effective for evaluating a single dialogue system. The comment provides a clear critique of the proposed framework and its limitations, making it specific. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the relevance of the proposed method to the authors\\' motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer provides a logical reasoning by pointing out that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are used for comparing dialogue systems, not for evaluating a single system. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is mostly verifiable, as it provides a logical argument but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of the proposed method to the authors\\' motivations, specifically questioning its effectiveness in evaluating a single dialogue system. It suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. This feedback is somewhat helpful as it identifies a potential limitation in the proposed method and encourages the authors to consider this aspect in their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the evaluation framework. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The comment implies that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternatives they could consider. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It suggests that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or where this issue is addressed. The authors can make an educated guess that it relates to the methodology or experimental setup sections, but the comment lacks full grounding. It is specific in detailing the potential issue with using focal loss for regression tasks, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The reviewer provides a logical explanation of why focal loss might be problematic in this context, noting that it has lower gradients on easy samples, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It points out that focal loss is typically used to address class imbalance problems in classification tasks, but its properties may not be suitable for regression tasks. The comment suggests that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. This feedback is somewhat helpful as it identifies a potential issue with the methodology and encourages the authors to consider the appropriateness of their choice. However, it lacks specific suggestions or examples on how to address this issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors might investigate this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is a relevant concern for the authors, as understanding how their method performs under varying conditions can significantly impact its applicability and robustness. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable advice or examples, the authors are left with a general question that, while important, does not offer a clear path for improvement. Therefore, the comment is somewhat helpful, as it identifies a critical area for consideration but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. This is an explicit suggestion, as it clearly indicates a potential improvement and provides a specific example of what could be used. However, the comment does not provide detailed guidance on how to implement this change or why RoBERTa-base might be a better choice. While the action is explicit, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an improvement by proposing the use of a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting a potential improvement but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using a better encoder, such as RoBERTa-base, could lead to improvement. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTa-base would be a better choice or how it would impact the results. The claim lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that using a better encoder, such as RoBERTa-base, could lead to improvements in the paper. This is a specific and actionable suggestion that could help the authors enhance their work. However, the comment lacks depth and does not provide detailed guidance on how to implement this change or why RoBERTa-base might be a better choice. While it identifies a potential area for improvement, it does not fully address the authors\\' needs for comprehensive feedback. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of information about the type of GPUs used and the inference time during testing. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific metrics to include or methods to report inference times. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information should be included in, such as the methodology or results sections. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this information should be added. The comment is specific in its request for additional information but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks information about the type of GPUs used and inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand the significance of this omission or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a relevant point that could impact the reproducibility and comprehensiveness of the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific metrics to report or methods to include. Without actionable feedback, the authors are left with a general understanding of what is missing but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback provides a clear and direct action for the authors to take, ensuring that the Perceptual Metric is accurately represented. The comment is explicit and concrete, leaving no ambiguity about what needs to be corrected. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the Perceptual Metric in Figure 2, suggesting a correction in how the images are connected. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for improving their draft. By addressing this issue, the authors can enhance the accuracy and clarity of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically wondering if it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to investigate or address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this possibility but are not provided with specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically wondering if it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the potential effect of adaptive gradient methods, but it lacks grounding as it does not clearly reference a specific section or context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically wondering if it might amplify updates for weights associated with hard features. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations that would help the authors understand the potential effects of using adaptive gradient methods. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a relevant question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically wondering if it might amplify updates for weights associated with hard features. This is a thoughtful consideration that could influence the interpretation of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or explore its implications further. While it highlights a potential area of concern, it lacks actionable advice or depth, making it somewhat helpful. The authors are left to infer that they should consider this aspect, but without detailed guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in the comparison, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide specific instructions on how to execute them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sufficiency of the experiments, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. It references a table (Tab.) for the latter point, providing some grounding by indicating where the authors can find the information. However, the comment does not specify which section of the paper discusses the experiments, making it weakly grounded. It is specific in detailing the issues with the experiments, such as the limited types of teacher architectures and the outdated methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. The comment references a table (Tab.) for the latter point, which provides some evidence to support the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the limited types of teacher architectures. While the reference to the table adds some verifiability, the overall claim remains somewhat verifiable due to the lack of comprehensive evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. By pointing out these limitations, the comment provides the authors with clear areas for improvement. However, it lacks detailed guidance or suggestions on how to address these issues, such as recommending specific architectures to include or suggesting ways to incorporate more recent methods. While the comment highlights important weaknesses, it does not offer actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without state-related registers and proposes a comparison between sequential and combinational designs. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. While it implies that the authors should consider this comparison, the action is not directly stated, and the authors may not know exactly how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without state-related registers. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion for a comparison between sequential and combinational designs, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without state-related registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed comparisons to substantiate the suggestion for a comparison between sequential and combinational designs. Without additional context or justification, the claim remains unverifiable, as it does not provide sufficient information for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without state-related registers and proposes a comparison between sequential and combinational designs. This feedback is somewhat helpful as it identifies a potential area for exploration and improvement in the paper. However, it lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it provides a direction for further analysis, it does not offer detailed actionable steps, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the paper\\'s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this concern. It lacks guidance on how the authors might address the issue or improve the practicality of their work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of the paper\\'s approach, which relies on known causal relationships between features. However, it does not specify which part of the paper discusses this approach, making it weakly grounded. The comment is specific in highlighting the concern about the availability and accuracy of prior knowledge for specific subpopulations and the focus on mining causal relationships from data automatically. This provides clear guidance on what needs to be addressed, but the lack of explicit reference to a specific section or part of the paper limits its grounding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the paper\\'s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning by explaining the potential limitations of relying on prior knowledge and the common practice in the field. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this perspective and potentially address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the paper\\'s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. This feedback is somewhat helpful as it points out a potential limitation of the proposed method and encourages the authors to consider the practical implications of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the practicality of their work. While it provides some insight, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides specific examples of non-linear blocks that could be included in the comparative experiments. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks comparative experiments with other non-linear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, noting that such experiments could showcase the unique advantages or potential shortcomings of the proposed method. However, the comment lacks specific examples or references to existing works that have conducted similar experiments, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests a concrete way for the authors to enhance their draft by including these comparative experiments. By doing so, the authors can better demonstrate the unique advantages or potential shortcomings of their proposed method in a broader context. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
