{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part critiques the adopted baseline models as weak and suggests that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is an explicit suggestion for improvement, as it clearly identifies a missing comparison that the authors should make. The second part points out a grammatical error in the text, suggesting a correction. Both parts provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 277,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a grammatical error and suggests a correction, providing clear guidance on what needs to be addressed. Additionally, the comment critiques the adopted baseline models, suggesting comparisons with Campos et al. (2020) and other domain adaptation methods, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasons or evidence to support why the baseline models are weak or why these comparisons are necessary. The mention of Campos et al. (2020) and other domain adaptation methods is a suggestion for improvement, but it lacks detailed justification or examples to substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment identifies two main issues with the paper. First, it critiques the adopted baseline models as weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is a valuable suggestion for improving the paper by providing a more comprehensive comparison. Second, the comment points out a grammatical error in the text, suggesting a correction. Additionally, it highlights the absence of comparisons with other domain adaptation methods, which is an important aspect to address for a robust evaluation. However, the comment could be more helpful if it provided specific examples or references for the domain adaptation methods to be compared. Overall, the feedback is 4 as it identifies areas for improvement and offers actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding information about the input being word embeddings, similar to the Lample et al. model, which is a clear and concrete instruction. Second, it questions whether the KNs in Figure 3 are in the source language or English, indicating a need for clarification. The authors are explicitly told to correct the figure, providing a direct action. These actions are specific and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need to add information about word embeddings and the clarification regarding the KNs in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. model. This is a logical suggestion based on the context of the paper, but it does not provide specific examples or references to support the claim. The comment also questions the language of the KNs in Figure 3, which is a factual observation rather than a claim. Overall, the comment provides some logical reasoning but lacks detailed evidence or references, making it 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct issues in the paper. First, it suggests adding information about the input being word embeddings, similar to the Lample et al. model, which could enhance clarity and consistency. Second, it questions the language of the KNs in Figure 3, noting that the mentions have been translated to English, and requests clarification. The comment is clear and direct, offering concrete suggestions for improvement that can help the authors enhance the quality and accuracy of their draft. However, it could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is 4, as it provides valuable guidance for improving the paper."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are in need of further analysis or provide guidance on how the authors might conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims require more depth and how to achieve it. Without explicit instructions or examples, the authors may struggle to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any details on what aspects of the analysis are lacking. This makes it difficult for the authors to identify the exact parts of the paper that need improvement. The comment lacks both grounding and specificity, as it does not provide any clear guidance on what needs to be addressed or how to address it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any supporting evidence or reasoning to justify this claim. Without specific examples or detailed explanation, the authors may find it challenging to understand which claims need further analysis and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that several claims in the paper would benefit from more indepth analysis. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which claims are in need of further analysis or how the authors might conduct this analysis. Without detailed suggestions or examples, the authors are left with a general idea of what might need more attention but without actionable steps to take. Therefore, the comment is 2, as it provides minimal guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397) and requests a clearer definition of the variables in Equation (7), specifically whether E_i represents the type or identity of AC i. Additionally, it suggests that the lefthand side of the equation should be a conditional probability. These explicit requests provide clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 397 and 472) and equations (Equation 7), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and defining the variables in Equation 7. The comment also provides a suggestion for improving the presentation of the equation by indicating that the lefthand side should be a conditional probability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions and concerns about the presentation of the model, including the pooling method used for embedding features and the clarity of Equation (7). It provides detailed requests for clarification, such as defining whether E_i represents the type or identity of AC i, and suggests that the lefthand side of the equation should be a conditional probability. These requests are logical and provide a clear basis for the reviewer\"s concerns, making the claim 5. The comment is supported by specific references to the paper, which helps the authors understand the issues and address them effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is a clear and concrete request for additional information. Additionally, it raises a question about the clarity of Equation (7), specifically whether E_i represents the type or identity of AC i, and suggests that the lefthand side of the equation should be a conditional probability. These suggestions are detailed and provide the authors with a clear path to improve the clarity and comprehensibility of their work. By addressing these points, the authors can enhance the readability and understanding of their model, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This is an explicit action that the authors need to take, as it clearly instructs them to include empirical evidence to substantiate their claim. The comment provides a specific direction for improvement, making it 5. The authors know exactly what is expected of them, which is to conduct empirical tests and present the results to validate their claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of empirical evidence is needed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate why this evidence is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to conduct empirical tests to validate their claim. However, the comment could be more helpful if it provided specific guidance on what kind of empirical evidence is needed or how to present it. Despite this, the suggestion is 4 as it points out a critical area for improvement that could strengthen the paper. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, providing specific examples and data to support the disagreement. The comment suggests that the authors should address the discrepancy in performance between DeiT models and CNNs as capacity increases. While the action is explicit, the comment could be more actionable by providing specific guidance on how to conduct the additional analysis or what aspects to focus on. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance trending of increasing the number of parameters for ViT (DeiT) and challenges the authors\" viewpoint on the benefit of increased model capacity. The comment provides specific examples and data to support the disagreement, such as the performance of DeiTB models compared to DeiTT and DeiTS on various datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint on the benefit of increased model capacity for both CNNs and ViTs is incorrect. It provides specific examples and data from Figure 3 to support this claim, such as the performance of DeiTB models compared to DeiTT and DeiTS on various datasets. This detailed analysis and evidence make the claim 4, as it provides a clear rationale for the disagreement. However, the comment could be strengthened by including more detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, offering detailed examples and data to support the disagreement. This feedback is valuable as it prompts the authors to revisit their analysis and potentially revise their conclusions based on the provided evidence. However, the comment could be more helpful if it included suggestions on how to conduct the additional analysis or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that requires further exploration and clarification."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It mentions that the group attention design is related to ResNeSt but not discussed in the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their method from existing ones. The action is implicit and vague, as the authors are left to infer that they need to discuss the differences or provide a more detailed comparison with existing works. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relation to ResNeSt. However, it does not explicitly mention which part of the paper discusses these similarities or the proposed method, making it weakly grounded. The comment is specific in detailing the issue of limited novelty and the similarity to existing works, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works 1, 2, 3 and noting the similarity to ResNeSt 4. However, the comment lacks detailed comparisons or specific examples of how the proposed method is similar to or different from these works. This makes the claim 3, as the authors would need to conduct their own analysis to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that the proposed method lacks novelty due to its similarity to other attentional modules in previous works. It highlights the similarity to ResNeSt and notes that while the previous works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. This feedback is valuable as it points out a critical weakness in the paper, prompting the authors to address the lack of novelty and differentiate their work from existing ones. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or offered examples of how to discuss the differences with existing works. Overall, the comment is 3 as it directs the authors to a key area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a specific issue with the \"required implicit call to the Witness oracle,\" indicating that it is confusing. However, it does not provide any guidance or suggestions on how to clarify or address this confusion. The comment lacks explicit instructions or concrete details on what changes should be made to improve the clarity of the implicit call. As a result, the authors are left without a clear understanding of how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"required implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is located in, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address the confusion. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this is confusing or how it could be clarified. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation or suggestions on how to clarify this confusion or improve the clarity of the paper. Without actionable guidance or detailed feedback, the authors are left without a clear understanding of how to address the issue, making the comment 2. It highlights a potential problem but lacks the depth needed to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature using a \"coarse\" methodology. It questions the necessity of this observation, given that it has been made at each step of the evolution of language models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or address the critique, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used by the authors to reproduce a wellknown result in the literature, specifically the left political bias in ChatGPT and LLMs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the methodology, questioning the need for this observation given its repetition across the evolution of language models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result in the literature regarding the left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the historical context of similar observations in word2vec, BERT, and ChatGPT, suggesting that the claim is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to consider this historical context to fully understand the critique, but the comment could be strengthened with more detailed references or examples.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding the left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models, from word2vec to BERT to ChatGPT. The comment highlights a lack of novelty in the observation, which could be seen as a critique of the paper\"s contribution. However, it does not provide specific suggestions or guidance on how the authors might address this critique or improve their work. The feedback is 3 as it points out a potential weakness in the paper, but it lacks actionable advice or depth, making it less comprehensive than it could be. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it offers a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"proposed framework row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training, and suggests renaming a column in Table 1. Additionally, it provides a detailed suggestion for improving the clarity of the table by using two columns to specify the data used for training each model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training in their proposed method. It provides a specific example from Table 1, where the authors are advised to rename a column to better reflect the semisupervised version of the method. The suggestion to use two columns to specify the data used for training each model is also offered. While the comment provides a clear and logical reasoning for the suggested changes, it lacks specific references or examples from the literature to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the suggestion but could benefit from additional references or detailed explanations.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area where the authors can improve the clarity and organization of their paper. It suggests that the authors should distinguish between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The comment offers a concrete suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it proposes a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is detailed and provides the authors with specific guidance on how to enhance the clarity and presentation of their work, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback provides a clear direction for the authors to expand their experimental evaluation by considering additional datasets and models, which would enhance the comprehensiveness of their work. However, the comment could be more actionable by specifying which datasets or models the authors should consider. Overall, the comment is 4 as it gives a concrete direction for improvement, even if it lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The comment further suggests consulting specific works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experimental evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 3 as it provides a logical reasoning for the limitation in the experimental scope and suggests a specific direction for improvement by referencing relevant literature. However, the comment could be strengthened by providing more detailed examples or specific references to datasets and models that should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. It suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types, providing a clear direction for improvement. This feedback is actionable and constructive, as it highlights a critical area for expansion and offers specific references to enhance the comprehensiveness of the experimental evaluation. By addressing this feedback, the authors can significantly improve the depth and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). This implies an action for the authors to take, which is to modify their approach to better align with realworld applications. However, the comment does not provide specific guidance on how to implement this change or what specific aspects of the current approach need to be adjusted. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the data being perfectly balanced, which is impractical in realworld applications, and suggests using a more realistic setting as done in a referenced paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in realworld applications. The reviewer suggests using a more realistic setting, as done in a referenced paper, to sample unlabeled data from millions of reviews. The claim is supported by a specific reference to a related work, \"Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018,\" which provides a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current approach is impractical. Overall, the claim is 4 due to the reference to a relevant work, but it could be more robust with additional supporting evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a practical issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications where label distributions cannot be controlled. It suggests that the authors should adopt a more realistic setting, as done in a referenced paper, by sampling unlabeled data from millions of reviews. This feedback is clear and actionable, providing the authors with a specific direction to improve their approach by aligning it with more realistic and applicable scenarios. However, the comment could be more helpful if it included additional details or examples of how to implement this suggestion. Overall, the comment is 4, as it offers a constructive critique that can guide the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out inconsistencies in the notation and questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. While the comment identifies specific areas of confusion and references the original paper for context, it does not provide explicit instructions on how to clarify or address these issues. The authors are left to infer that they need to clarify the notation and the use of unlabeled data in source domains. The action is implicit and somewhat vague, as it lacks detailed guidance on how to resolve the confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the description of the MFDA setting, including the confusion caused by the notation for the target domain and the use of labeled and unlabeled data. The comment provides specific examples and references to the original MFDA paper, which helps the authors understand what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing, specifically mentioning the notation for the target domain and the use of labeled and unlabeled data. The reviewer references the original MFDA paper (Yue et al., 2021a) to support their claim, noting that the target data is unlabeled. This provides a logical basis for the claim, as it highlights a potential inconsistency in the paper\"s description. However, the comment could be strengthened by providing more detailed examples or explanations of how the confusion arises. Overall, the claim is 4, as it is supported by a reference to the original paper but could benefit from additional clarification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, pointing out confusion in the notation and the use of labeled and unlabeled data. It references the original MFDA paper (Yue et al., 2021a) to highlight the inconsistency and questions whether the unlabeled data in source domains are used during training, as in the original paper. This feedback is clear and actionable, as it directs the authors to clarify the notation and the use of data in their setting, which could significantly improve the clarity and accuracy of their description. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to clarify the notation. Overall, the comment is 4, as it effectively points out a critical area for improvement and guides the authors toward a solution."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code and the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, essentially a combination of GraphRAG and GraphCare, and that key baselines were not cited. It also suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. The claim is 3 as it provides a logical reasoning for the incremental nature of the contribution and highlights specific missing references. However, the comment lacks detailed examples or references to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides several specific points for improvement, including the observation that the contribution is incremental and primarily a combination of existing works like GraphRAG and GraphCare. It also highlights the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is actionable and provides clear guidance on what the authors need to address to strengthen their paper. However, the comment could be more helpful if it offered suggestions on how to integrate these missing elements or provided examples of how to effectively cite the baselines. Overall, the comment is 4 as it identifies key areas for improvement and offers direction for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of certain stateoftheart references in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer also compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. While the comment identifies a gap in the references and provides a specific example, it does not explicitly instruct the authors to include these references or to address the comparison with the mentioned work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" along with a link to the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the missing stateoftheart references and provides a comparison with the results in Table 3, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a specific reference to the Baidu work and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the missing references impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the references used in the experiment on face recognition, pointing out the omission of a stateoftheart work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a detailed reference to the work, including a link to the results, and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This feedback is clear and actionable, as it directs the authors to include these references and consider the comparison with the mentioned work. By addressing this gap, the authors can enhance the credibility and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a specific and actionable step, ensuring that the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not citing the source of the example, which is inspired by previous work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and requests that the authors cite the source. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the claim or understand the basis of the suggestion. Without additional context or evidence, the authors may struggle to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and requests that the authors properly cite the source. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide proper attribution. By addressing this issue, the authors can ensure the integrity and transparency of their work. However, the comment could be more helpful if it provided additional context or examples of similar work, which would further assist the authors in understanding the relevance and importance of proper citation. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests that it is common to average over subword representations, referencing a specific work by Hewitt and Manning (2019). This comment implies that the authors should consider averaging over subword representations as an alternative approach, but it does not explicitly instruct them to do so. While the suggestion is concrete, it is not explicitly stated as an action, leaving the authors to infer that they should consider this alternative. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement regarding the use of subword token embeddings and suggests an alternative approach by referencing a specific work by Hewitt and Manning (2019). This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an alternative approach to handling subword representations, specifically mentioning the practice of averaging over subword representations. It references a specific work by Hewitt and Manning (2019) as an example of this practice. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this alternative approach might impact the paper\"s results or methodology. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests an alternative approach, which is to average over subword representations, and references a specific work by Hewitt and Manning (2019) that demonstrates this practice. This feedback provides the authors with a clear suggestion for improvement and a reference to consider, which can enhance the robustness of their methodology. However, the comment could be more helpful if it provided additional context or explanation of why averaging over subword representations might be beneficial. Overall, the comment offers actionable feedback but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, additional experiments, or clarification needed. As a result, the comment lacks any actionable guidance for the authors, making it 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and crossdomain imitation. However, it does not specify which part of the paper these experiments are described in, nor does it provide any specific feedback or suggestions for improvement. The authors can infer that the comment is related to the experimental section, but it lacks grounding and specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a factual statement describing the experiments conducted by the authors to validate the efficacy of CATER. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any specific feedback, suggestions, or critiques that could help the authors improve their work. The comment lacks depth and does not offer any actionable advice for enhancing the draft. As a result, it is 2, as it does not provide the authors with any meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their draft. The references to other works imply that the authors should consider these extensions, but the comment lacks concrete instructions on how to incorporate this information into their paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"bounded noise assumption\" in the context of stochastic optimization literature, suggesting that it is somewhat restrictive. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which provide extensions to these noise conditions. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The comment is specific in suggesting that the authors consider these extensions, but it lacks detailed guidance on how to incorporate this information into their work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they are recent and relevant studies that have explored extensions to the noise conditions. However, the comment could be strengthened by providing more detailed explanations or examples of how these works address the limitations of the bounded noise assumption. Overall, the claim is 4, as it is supported by references to relevant literature, but it could benefit from more detailed justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper\"s use of the bounded noise assumption, noting that it is somewhat restrictive in the context of stochastic optimization literature. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which have explored extensions to these noise conditions. This feedback is 3 as it points out a potential area for improvement and provides references to relevant literature. However, it lacks detailed guidance or suggestions on how the authors might address this issue in their draft, such as how to incorporate these extensions or what specific aspects to focus on. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment identifies a potential ambiguity, it does not provide explicit guidance on how to clarify or address this issue in the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"100 steps\" in their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps,\" which is a clear and direct question that requires a specific response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1, specifically asking if it refers to 100 sampled strategies. While the comment identifies a potential ambiguity, it does not provide any suggestions or guidance on how the authors might clarify this point or address the issue. The feedback is limited in its actionable nature, as it does not offer any specific advice or direction for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions whether it might lead to scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the modulator\"s design. The comment lacks actionable details, such as recommending alternative approaches or methods for addressing scalability issues. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the heuristic design of the modulator and questions its scalability, particularly in relation to hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the modulator\"s design and potential scalability issues but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions its scalability, particularly in relation to hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the modulator is heuristically designed or that it might lead to scalability issues. Without additional evidence or explanation, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the heuristic design of the modulator, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the modulator\"s design. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it highlights an area for improvement but does not provide sufficient detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images, as shown in recent papers. It also recommends comparing the current method with these types of methods. While the comment implies that the authors should include this information and comparison, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss and compare their method with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention the use of untrained neural networks (like deep image prior) for solving inverse problems and to place the current method in context by comparing it with those methods. This level of detail guides the authors on what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s claim of strong OOD generalization by the trained network is interesting but notes that recent papers have shown that untrained neural networks can solve inverse problems across a wide class of images. The reviewer recommends mentioning this in the paper and comparing the current method with those approaches. While the comment provides a logical reasoning for the suggestion, it lacks specific references to the papers that demonstrate the effectiveness of untrained neural networks. This makes the claim 3, as the authors would need to conduct further research to fully understand the context and make the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interest in the OOD experiments, noting the strong OOD generalization of the trained network. However, it suggests that the authors should place their method in context by mentioning recent papers that have shown the effectiveness of untrained neural networks (like deep image prior) in solving inverse problems across a wide class of images. The comment provides a constructive suggestion to enhance the paper by comparing the current method with these existing approaches. While the feedback is clear and actionable, it could be more helpful if it included specific references to the papers mentioned or detailed guidance on how to incorporate this comparison. Overall, the comment is 4 as it offers a valuable direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model with a proofofconcept test, it should be clearer and justified with a future useful application. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue, such as suggesting specific comparisons or justifications to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and justification for their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper\" and references a specific existing work, \"PhaseNetDas, Zhu et al. 2023,\" which helps the authors identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison with existing DAS earthquake detectors and the need for a clearer justification of the benefit of the proposed method. Additionally, it suggests that if the paper claims to be a foundation model, it should provide a clearer explanation and justification for its future applications. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model, it should be clearer and justified with a future useful application. The comment provides a specific reference to PhaseNetDas, which supports the claim that such detectors exist. However, it lacks detailed reasoning or examples to fully substantiate the claim that the paper\"s goal is unclear or that comparisons are necessary. The reference to PhaseNetDas is a good starting point, but more elaboration is needed to fully verify the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a critical concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It points out that no comparison was made, nor was there a justification for the benefit of the proposed method over existing ones. The comment suggests that if the paper claims to be a foundation model, it should be clearer and provide a justification for its future applications. This feedback is clear and actionable, as it identifies a significant gap in the paper and provides guidance on how to address it. However, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that needs improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to Croce et al. (2021) and A, B, which evaluate the robustness of models to unseen attacks. However, the comment does not explicitly instruct the authors to address this issue or suggest how to differentiate their work from existing research. The action is implicit, as the authors can infer that they need to discuss the novelty and originality of their work in relation to prior studies. The feedback is 3 because it points out a potential weakness but lacks specific guidance on how to address it. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works, such as RobustBench and references to Croce et al. (2021) and A, B, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses are already present in prior works, making the results not particularly surprising. This provides clear guidance on what needs to be addressed in terms of novelty and originality. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses are already present in prior works, making the results in the current paper not particularly surprising. It supports this claim by referencing specific prior works, such as RobustBench and Croce et al. (2021), which have studied the robustness of CIFAR10 models on distribution shifts. Additionally, it mentions that A, B have evaluated the robustness of adversarially trained models to unseen attacks. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from or builds upon these prior studies. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to Croce et al. (2021) and A, B, which evaluate the robustness of models to unseen attacks. This feedback is 3 as it highlights a potential weakness in the paper, specifically the lack of novelty in the analyses presented. However, it does not offer specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing research. While it provides some insight into the paper\"s limitations, it could be more helpful with additional constructive feedback or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two separate issues. The first part addresses a potential inaccuracy in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to state that all works are based on simple SGD for decentralized optimization. This is an explicit action for the authors to correct the statement. The second part points out a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. Both parts provide explicit actions with clear guidance on how to address the issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inaccuracies in the statements regarding the Walkman algorithm and the lack of clarity in the reference to \"it.\" The comment provides clear guidance on what needs to be corrected or clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim challenges the statement that all works are based on simple SGD for decentralized optimization, pointing out that the Walkman algorithm (Mao et al., 2020) uses ADMM with two versions. This claim is 4 as it provides specific details about the algorithm and its variations, allowing the authors to understand the basis of the critique. The second claim points out a lack of clarity in the reference to \"it\" in Section 3, which is a factual observation requiring no justification or evidence. Therefore, the overall comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by addressing two distinct issues in the paper. First, it corrects an inaccuracy in the Related Work section regarding the Walkman algorithm, pointing out that it uses ADMM with two versions, not just simple SGD. This feedback is clear and helps the authors improve the accuracy of their work. Second, it identifies a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. This feedback is also specific and actionable, guiding the authors to improve the clarity of their writing. By addressing these specific issues, the comment is 5 as it provides detailed and constructive suggestions for improving the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It implies that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., 1, 2, 3), are necessary. However, the comment does not specify which additional works should be included or how the experiments should be conducted. While the action is clear, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, referencing specific works (1, 2, 3) that focus on the same questions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It suggests that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., 1, 2, 3), are necessary. However, the comment does not provide specific examples or detailed reasoning to support why these additional works are relevant or how they would enhance the experimental section. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of these additional comparisons based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that additional experimental comparisons with other works that focus on the same questions would be beneficial to demonstrate the effectiveness of the proposed method. The comment provides a clear direction for improvement by referencing specific works (1, 2, 3) that could be included in the comparison. This feedback is actionable and provides the authors with a specific suggestion to enhance the robustness of their experimental results. However, it could be more helpful if it included a detailed explanation of why these additional comparisons are necessary or how they would impact the overall evaluation of the proposed method. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors need to provide more information about the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. By following this suggestion, the authors will be able to provide a more comprehensive understanding of their dataset, which is essential for assessing its quality. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary for assessing the dataset\"s quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, and more information is needed to assess the dataset\"s quality. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing information. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specific aspects that need clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset\"s quality. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for evaluating the dataset. However, the comment could be more helpful if it suggested specific aspects of the methodology that need clarification or provided examples of what information should be included. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning several types of methods that should be discussed. It also suggests positioning SSMs appropriately within this context. The comment provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the section, specifically suggesting the inclusion of a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for the authors on how to improve the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details, specifically regarding longcontext language models. It suggests that the authors should provide a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment provides a clear and detailed list of methods that should be discussed, which supports the claim and provides a basis for the authors to improve their work. However, the comment could be strengthened by explaining why these specific methods are relevant or how they relate to the authors\" work. Overall, the claim is 4 due to the detailed suggestions provided, but it could be more robust with additional reasoning or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the Related Work section, which is deemed lacking in details. It provides a clear and actionable suggestion by specifying the types of methods that should be discussed, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and depth of their Related Work section, particularly in the context of longcontext language models. However, the comment could be more helpful if it offered additional guidance on how to integrate these methods into the narrative or provided examples of how to effectively position SSMs within the existing literature. Overall, the comment is 4 as it provides clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing need improvement or which points are unclear. The comment lacks explicit or implicit actions that the authors can take to address the issue. Without concrete suggestions or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not mention a specific section or part of the paper and does not provide detailed feedback on what needs to be clarified or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"The writing should be improved\" and mentions that \"some points in the paper are unclear.\" However, it does not provide any specific examples or details about what aspects of the writing are unclear or how they could be improved. Without supporting evidence or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it lacks specificity and does not provide any detailed guidance or examples on what aspects of the writing need improvement or which points are unclear. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issues identified. This makes the comment 2, as it identifies a general area for improvement but does not provide enough detail to be actionable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is explained in relation to the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or explain the relationship between the data distribution and the network model, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how the data distribution illustrated in Figure 1 is explained in relation to the network model, particularly in a nonseparable case. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is explained in relation to the network model. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed explanations that would help the authors understand the issue or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is explained in relation to the network model. This feedback highlights a potential weakness in the paper and prompts the authors to clarify or address this aspect. However, the comment lacks detailed guidance or suggestions on how to improve the explanation or address the issue, which limits its helpfulness. While it points out a critical area for improvement, it does not provide actionable steps or examples to enhance the draft. Therefore, the comment is 3, as it identifies a problem but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the efficiency of the pairwise matching or suggestions for alternative approaches. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, suggesting that it is very low and difficult to use in practical applications. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without explicit references to sections or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or data to demonstrate the inefficiency, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of pairwise matching, suggesting that it may be too low for practical application. However, it does not provide any specific suggestions or guidance on how the authors might improve the efficiency or address this concern. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that adding a method to improve transferability is a good approach but notes that it cannot be considered a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or what specific aspects need to be addressed to make the addition more significant. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the addition of a method to improve transferability, suggesting it is a good approach but not a significant contribution. However, it does not specify which part of the paper this method is added to or how it relates to other methods. The authors can infer that it might be related to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in suggesting that the addition is not considered a significant contribution, but it does not provide detailed guidance on how to enhance the contribution. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that adding a method to improve transferability is good but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition is not considered significant. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the addition of a method to improve transferability as a good approach but questions its significance as a contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance the contribution or address the reviewer\"s concerns. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests toning down a specific statement regarding the neural network memorizing \"critical points.\" Second, it advises compressing the method section to focus on essential definitions, indicating that this could improve clarity. Lastly, it instructs the authors to doublecheck for grammatical errors, particularly with respect to plurals and articles. These actions are clear and concrete, providing the authors with specific steps to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"to force the neural network to memorize them\" and the reference to TopoNet 24, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests toning down a particular statement and provides feedback on the method section, suggesting it could be compressed to focus on essential definitions. Additionally, it points out grammatical errors, offering a specific example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about the neural network memorizing \"critical points\" is not supported by any evidence or references, making it 1. The suggestion to tone down the statement is vague and lacks justification. The second claim about the method section being wordy is not substantiated with specific examples or reasoning. The comment also mentions grammatical errors without providing examples, which further reduces its verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides several points of feedback that could be helpful for the authors. It suggests toning down a statement regarding the neural network memorizing \"critical points,\" which could help clarify the language and avoid potential misinterpretations. Additionally, it advises compressing the method section to focus on essential definitions, which could improve the clarity and concision of the paper. The comment also points out grammatical errors, specifically mentioning plurals and articles, and provides an example, which is a practical suggestion for improving the paper\"s readability. However, the comment could be more helpful if it provided specific examples of the grammatical errors or offered more detailed guidance on how to compress the method section. Overall, the feedback is 4, as it identifies areas for improvement and offers actionable suggestions, but it could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment raises valid points and questions, it does not provide explicit instructions or concrete actions for the authors to take. The questions are implicit and require the authors to infer the need for clarification or further explanation. Therefore, the comment is 3, as it provides guidance but lacks detailed instructions on how to address the issues.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the claim of parameter efficiency for COCOLM. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This provides specific feedback on the comparison and the claim of parameter efficiency. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is \"a little overrated\" and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This claim is 3 as it provides a logical reasoning based on the similarity in performance and model sizes. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider this feedback and potentially provide more detailed comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This critique questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment identifies a potential issue with the comparison and raises questions for further clarification, it lacks detailed guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement but could be more comprehensive with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer questions the reasoning behind the observation that this indicates GSP50 learns better representations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this critique or improve their analysis. The action is implicit and vague, as the authors are left to infer what changes might be needed without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (128149) and references a figure (Fig 3), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, questioning the reasoning behind the observation that GSP50 learns better representations. The comment provides a clear critique of the analysis and suggests that the authors should explain why this observation indicates GSP50 learns better representations. Additionally, it references external works, which can help the authors understand the context and improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, questioning the conclusion that GSP50 learns better representations. It provides a specific observation about the histogram in Fig 3, noting that GSP50 has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer suggests that additional context may allow the network to reduce its dependency, but does not fully explain why this observation supports the claim that GSP50 learns better representations. The comment references two external works, which could provide additional context, but the reasoning is not fully developed. Therefore, the claim is 3, as it provides some support but lacks detailed explanation or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment critiques the analysis from line 128 to 149, questioning its convincingness. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, which suggests it shares more features, while ResNet50 learns more classspecific features. The reviewer hypothesizes that additional context may allow the network to reduce its dependency, but questions why this observation indicates GSP50 learns better representations. This feedback is 3 as it identifies a specific area of concern and provides a basis for further analysis. However, it lacks depth and does not offer actionable suggestions for improvement, such as how the authors might address the critique or enhance their analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some conclusions in the paper are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It implies that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should explore more combination methods or consider the referenced works, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, allowing the authors to identify the parts of the paper being addressed. It also provides specific examples and references to recent works that have shown potential in featurereplay methods for continual learning, such as R1, R2, and R3. This level of detail helps the authors understand what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically questioning the assertion that continuous learning with unlabeled data accumulates noise. The reviewer provides a rationale by suggesting that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. This provides a logical reasoning and some supporting evidence, making the claim 4. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions drawn in the paper, questioning their convincingness. It provides a detailed critique by suggesting that the results might be due to the limited exploration of combination methods, particularly in the context of rehearsalfree continual learning. The comment references recent works that have shown great potential in featurereplay methods, such as R1, R2, and R3, which could be valuable for the authors to consider. This feedback is clear and actionable, as it directs the authors to explore more combination methods and consider the referenced works to strengthen their conclusions. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these references or methods into the paper. Overall, the comment is 4, as it offers valuable insights and references that can guide the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential dependency or what specific aspects of the design might be affected. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects are hardware or software dependent. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of this assertion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, noting that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, context, or suggestions on how to address this dependency. Without detailed guidance or actionable feedback, the authors are left without a clear understanding of how to improve their draft. The comment highlights a potential area for consideration but lacks depth and specificity, making it 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature. It notes that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. The feedback is implicit and vague, leaving the authors without a clear understanding of what specific changes are needed to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not specify which part of the paper discusses these issues or where the authors should provide additional insights. While the authors can infer that the discussion of novelty and contribution is relevant, the comment lacks full grounding as it does not explicitly mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. The reviewer provides some justification by mentioning the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim of limited novelty. While it highlights the modifications proposed, such as different penalty coefficients, it does not provide enough evidence or references to support the assertion that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. Therefore, the claim is 3, as it provides some basis for the critique but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also notes the proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment points out a potential weakness in the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the uniqueness of their contribution, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in Section 4.2 regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests clarifying these points and raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback provides explicit actions for the authors to take, such as clarifying the description and addressing the potential numerical instability issue. The guidance is clear and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in this section, including the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description in Sec. 4.2 does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests that the equation might be illconditioned and numerically unstable due to the multiplication of two sigmoid activations. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to delve deeper into the equation and its components to understand the critique fully. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for complete verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, where the use of the question to learn an attention on the image feature is not clearly explained. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer also raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides specific guidance on what needs to be clarified and addressed in the paper. By highlighting these issues, the comment helps the authors improve the clarity and accuracy of their work, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or how they could enhance their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which section of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the perceived lack of novelty, particularly regarding the ENCODE part and the decomposition contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part. However, the comment does not provide any specific examples or detailed reasoning to support this claim, such as how the decomposition part differs from existing work or why it is not considered novel. Without these details, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or explanation to fully substantiate it.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in reference 10 and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential weakness in the paper\"s originality, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance their contribution. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the formatting to meet the page limit. The comment lacks concrete details on what specific changes should be made to rectify the problem, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, including crammed equations and captions too close to figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the formatting issues. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples of where the whitespace has been reduced or how it affects the page count. Without such details, the claim remains 1, as the authors may not be able to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in crammed equations and captions that are too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the 9page paper limit. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to improve the layout or suggesting alternative formatting options. Despite this, the comment effectively points out a critical area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the technical details and formulations are limited and that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations are limited and that the main novelty is reflected in the scheme or procedure. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or clear indicators, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are limited or how the novelty could be better highlighted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"technical details and formulations are limited\" and suggests that the main novelty is reflected in the scheme or procedure. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references to illustrate the limitations or the novelty, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance the technical details or formulations to better highlight the novelty. Without actionable feedback or examples, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it points out a potential issue but lacks depth and specificity to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It suggests that crossdataset experiments could be a good way to test the generalization of such work, as the paper currently lacks. While the comment implies that the authors should conduct crossdataset experiments to address this issue, it does not provide specific guidance on how to implement these experiments or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units and the need for crossdataset experiments to test generalization. The comment provides a clear example of how the relationships can differ across datasets, such as the cooccurrence of AU1 and AU12 in Figure 1. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may not generalize well across datasets due to differences in cooccurrence patterns. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and notes that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment also references Figure 1, which illustrates the different cooccurrences of AU1 and AU12. This detailed explanation and reference to specific data points provide a solid basis for the claim, making it 4. However, the comment could be strengthened by including more examples or references to support the generalization issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the potential for these relationships to vary across different datasets. It provides a specific example by noting that AU6 can occur in both pain and happiness expressions, and that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment suggests that crossdataset experiments could be a good way to test the generalization of such work, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered guidance on how to conduct these crossdataset experiments or which datasets to use. Overall, the comment is 4 as it points out a critical area for improvement and provides a direction for further research, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a contradiction between the statement that overparametrization leads to overfitting and worse performance, and the observation that it is beneficial for supervised learning of deep neural networks in practice. The reviewer also mentions theoretical works that support the benefits of overparametrization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this contradiction or incorporate the theoretical works into their paper. The action is implicit and vague, as the authors are left to infer that they should clarify or reconcile the apparent contradiction, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 4748, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a contradiction between the statement about overparametrization leading to overfitting and the observation that it is beneficial for supervised learning of deep neural networks in practice. The comment further supports this observation by referencing theoretical works that show the benefits of overparametrization. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparametrization is beneficial for supervised learning of deep neural networks in practice, contradicting the statement that it leads to overfitting and worse performance. The reviewer supports this claim by referencing theoretical works that show the benefits of overparametrization. However, the comment lacks specific references to these theoretical works, which would strengthen the claim. Additionally, the reviewer does not provide detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of overparametrization on deep neural networks. It points out that the statement \"overparametrization invariably overfits the data and results in worse performance\" seems to contradict the observation that overparametrization is beneficial for supervised learning in practice. The reviewer supports this observation by referencing theoretical works that demonstrate the benefits of overparametrization. This feedback is 4 as it highlights a critical inconsistency in the paper and provides a reference to theoretical works that could help the authors address this issue. However, the comment could be more helpful if it offered specific suggestions on how to reconcile the contradiction or integrate the theoretical works into the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar scale pretrained model as the proposed method. It highlights a potential issue with the experimental setup, suggesting that the proposed method without SSL performs inferior to most compared methods. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pretraining conditions for the compared methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness due to the pretraining stage and the potential difference in pretrained models used by the compared methods. The comment specifies the concern about the performance of the proposed method without SSL compared to other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to the pretraining stage of the proposed method. It questions whether the compared methods were initialized with the same or similar scale pretrained model, which could impact the fairness of the comparison. The comment provides a logical reasoning by pointing out the potential discrepancy in pretraining conditions, which could affect the results. However, it does not provide specific examples or references to support the claim fully. Therefore, the comment is 4, as it offers a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, questioning the fairness of the comparison due to the pretraining stage of the proposed method. It highlights a concern that the compared methods may not have been initialized with the same or similar scale pretrained model, which could impact the results. This feedback is clear and actionable, as it prompts the authors to clarify the pretraining conditions for the compared methods. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a control experiment or a detailed explanation of the pretraining process. Overall, the comment is 4 as it directs the authors to a critical area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests exploring these options for better performance. The comment explicitly instructs the authors to update the paper with the performance of their method using better metadata embeddings. This feedback is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metadata used for zeroshot learning on the CUB dataset and suggests exploring better metadata embeddings options, referencing a specific paper for further guidance. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these better metadata embeddings options could improve performance. The reference to the external work is a good starting point, but the claim could be more fully verified with additional supporting evidence or examples. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the use of \"attribute\" metadata is good for fair comparison but suggests that better metadata embeddings options are available. It references a relevant paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which could offer insights into improving performance. The comment is actionable as it suggests exploring these better metadata embeddings options and provides a specific reference for further investigation. This feedback is clear and constructive, offering the authors a concrete direction for enhancing their work. Therefore, it is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), and implies that this should be discussed in the context of various approaches to DRL. The comment explicitly suggests that the authors should include this discussion, even though the paper currently uses quantile regression. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph range (lines 2230) and refers to a particular topic, \"distributional RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking relevant literature on using moment matching instead of quantile regression in DRL, referencing a specific paper (NguyenTang et al AAAI\u201921) and suggesting that this should be discussed in the context of various approaches to DRL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be applied or compared to quantile regression in the context of the paper. Despite this, the reference to a specific paper provides a solid foundation for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature, namely the discussion of moment matching in distributional reinforcement learning (DRL) compared to quantile regression. It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which provides a relevant example of an alternative approach. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the current paper uses quantile regression. This feedback is clear and actionable, as it directs the authors to include a discussion on moment matching, potentially enhancing the comprehensiveness and depth of their work. However, it could be more helpful if it provided specific guidance on how to integrate this discussion into the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived lack of novelty or suggestions for improving the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the interpretation of deep neural networks using a linear model. However, it does not specify which part of the paper discusses this novelty or where the authors could improve it. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the novelty, but without clear references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the work, specifically pointing out that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach. The reviewer questions the assumptions underlying the use of PCA and references a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit, as the authors need to infer that they should clarify the assumptions and significance of their approach. The feedback lacks concrete details on how to improve the draft, making it 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, questioning the assumptions underlying this approach. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the assumptions and suggests referencing a specific paper for further context. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach. The reviewer questions the assumptions underlying this method and references a specific paper for further context. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The reference to the external work provides some basis for the claim, but more specific evidence or analysis would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it may be an intuitive approach rather than a novel contribution. The reviewer questions the assumptions underlying this method and references a specific paper for further context. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific guidance or suggestions on how the authors might address these concerns or enhance the novelty of their approach. The feedback is 3 as it prompts the authors to consider the assumptions and significance of their method, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the limited scope of the evaluative framework, specifically mentioning its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or expand the scope of their framework. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability and potential generalization, but without concrete steps or examples, it remains unclear how to implement these suggestions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning its limited scope due to the focus on only three QuestionAnswering tasks and two language models. However, it does not explicitly mention which part of the paper discusses this framework, making it weakly grounded. The comment is specific in detailing the limitations and suggesting potential areas for broader applicability, such as considering other reasoning or generation tasks or more advanced models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope due to its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment lacks specific examples or references to support the claim about the limitations of the framework or the potential for broader applicability. The reasoning is somewhat vague and does not provide detailed justification or evidence, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models is uncertain. This feedback is 3 as it points out a potential weakness in the framework, prompting the authors to consider expanding their evaluation to include a broader range of tasks and models. However, the comment could be more helpful if it provided specific suggestions or examples of additional tasks or models that could be included. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an action: \"I would suggest using a second yaxis or another visualization which is more physically accurate.\" This provides a clear and concrete direction for the authors to improve their draft by addressing the issue with Figure 6C. The suggestion is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when it should not, and suggests using a second yaxis or another visualization to address this issue. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization to address this issue. However, the comment does not provide any evidence or reasoning to support the claim that the figure implies negative rates. Without specific examples or references, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should not. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is specific and offers a concrete way for the authors to improve the clarity and accuracy of their figure, making it 4. However, the comment could be more helpful if it included additional context or examples of how to implement the suggested changes effectively. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any explicit guidance or suggestions on how to achieve this improvement. The action is implicit and vague, as the authors are left to infer what specific changes could be made to enhance the complexity of the algorithm. Without concrete details or examples, the authors may struggle to determine how to address this feedback effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not specify what aspects of the algorithm\"s complexity need improvement or how it could be enhanced. The authors can infer that the comment is related to the algorithmic section of the paper, but without specific guidance, it is difficult to pinpoint the exact part that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the complexity of Algorithm 2, suggesting that there is still room for enhancement. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. This makes the comment 3, as it points out a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized. The comment raises a specific issue with the statement and questions whether dropout is applied to the hidden states, implying that this could be a potential reason for the observed behavior. While the comment identifies a potential issue and raises a question, it does not explicitly instruct the authors to investigate or address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the regularization methods used in their models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement regarding the necessity of smaller architectures for language models compared to GAN models, and it provides a counterexample from Zaremba et al. (2014) to support the claim. Additionally, the comment raises a question about the application of dropout to hidden states, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. The comment raises a specific question about whether dropout is applied to the hidden states, which could be a potential reason for the observed behavior. While the counterexample provides some evidence, the comment could be strengthened by further elaboration or references to support the claim. Therefore, the claim is 4, as it provides a logical reasoning and some supporting evidence but lacks additional details for full verification.", "helpfulness_rationale": "The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. This feedback is 3 as it points out a potential issue with the statement and raises a question about the application of dropout to hidden states. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or suggested alternative approaches to regularization. Overall, the feedback identifies a specific area for improvement but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While the comment implies that the authors should make these changes, it does not provide specific guidance on how to achieve conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors can infer that they need to make these changes but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the paper is being referred to, such as a specific section or chapter, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and that empirical results should be included, but it lacks detailed guidance on how to achieve these improvements. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, the comment lacks specific examples or detailed reasoning to support why the current content is not concise or why empirical results are necessary. Without these details, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies areas for improvement, the comment lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. This makes it 3, as the authors gain some insight into potential improvements but are left without actionable steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or improve the analysis. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is unclear or which analyses are considered standard. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not refer to any specific section or element of the paper, and it is not specific in detailing what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. This feedback is important as it highlights a critical area that needs clarification and improvement. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might enhance the clarity of their technical contribution or differentiate their analysis from standard approaches. Without detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a key area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the application of regularization between the LN model and the GLM presented by pillow et al. It suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. However, the comment does not provide explicit instructions on how to achieve this, such as which specific features to focus on or how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to align their approach with the previous model, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of regularization to both LN models and GLMs, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the GLM presented by pillow et al., suggesting that the authors should try to reproduce the main features of this model to make the comparison fair. This level of specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization differently to the LN model and the GLM, suggesting that the GLM by pillow et al. used L1 regularization and a lowrank approximation. However, the comment does not provide specific references or detailed comparisons to support this claim, making it 3. The authors would need to consult the original work by pillow et al. to fully understand the differences and verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of regularization in the LN model and the GLM, suggesting that the authors should align their approach with the previous model by pillow et al. to ensure a fair comparison. This feedback is 3 as it points out a specific area for improvement, but it lacks detailed guidance on how to implement this change or what specific features of the previous model should be replicated. While it provides a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include some failure cases and related discussion. While the comment implies that the authors should add this information, it does not provide specific guidance on what constitutes a \"failure case\" or how to structure the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to include additional content but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including \"some failure cases and related discussion,\" but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit guidance, it is difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the inclusion of failure cases and discussion, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including \"some failure cases and related discussion\" would be beneficial. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including failure cases and related discussion would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what constitutes a \"failure case\" or how to structure the discussion. The feedback is 3 as it points out a potential gap in the paper, but it does not offer actionable advice on how to address it. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is an explicit suggestion for improvement, as it provides a specific action for the authors to take. The comment is also concrete, as it clearly instructs the authors on how to enhance the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and equations (10) and (11), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests introducing epsilon when discussing equation (11), providing clear guidance on how to improve the clarity of the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is a logical suggestion based on the structure of the equations, but it does not provide specific reasoning or examples to support why this change would improve clarity. The comment lacks detailed justification or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending that the introduction of epsilon in equation (11) be discussed when that equation is introduced. This feedback is clear and actionable, as it directs the authors to a particular section where they can enhance the readability of their work. However, the comment could be more helpful if it explained why this change would improve the paper or provided additional context. Overall, the comment is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the limitations of the claim about evolutionary dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some lowvariance units. It also mentions that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be explicitly discussed. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or where to incorporate this discussion in the paper. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim about evolutionary dropout addressing the internal covariate shift,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, noting that it can only increase the variance of some lowvariance units and suggesting that Batch Normalization standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This comparison provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it can only increase the variance of some lowvariance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This feedback is clear and actionable, as it prompts the authors to discuss these limitations explicitly in their paper. By addressing this point, the authors can provide a more comprehensive understanding of the strengths and weaknesses of their approach, enhancing the clarity and depth of their work. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or provided additional context. Overall, the comment is 4, as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. While it explicitly states an action, it lacks specific guidance on what aspects of the contribution should be elaborated or how to present them. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description, making it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide specific guidance on what aspects of the contribution should be elaborated. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated or how to present them. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it provides a general direction but lacks actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific change to the terminology used in section 4, recommending that \"X\" should be a multiset instead of a set. This is an explicit action with clear guidance on how to implement the change, as it specifies the need to include multiplicities of labels in the graph to accurately represent it. The authors know exactly what needs to be done to address the comment, making this feedback 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. The comment provides a clear rationale for the change, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of a set in section 4 is inappropriate because it does not account for the multiplicities of labels in a graph. The reviewer provides a logical explanation for why a multiset would be more appropriate, as it can include repeated elements. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a potential issue with the terminology used in section 4, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and provides a concrete way for the authors to enhance the clarity and accuracy of their work. By addressing this suggestion, the authors can improve the precision and effectiveness of their representation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds that are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their derivation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds that are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper the derivation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning the need for Bayesian considerations, but without explicit references to sections or specific elements of the paper, it remains weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example, \"BayesianPAC based bounds,\" which supports the claim. However, the comment lacks detailed reasoning or references to substantiate why these bounds are not realistic without Bayesian considerations. While the example provides some context, the claim could be strengthened with more comprehensive evidence or references. Therefore, the comment is 4, as it provides a basis for the claim but requires additional support for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it falls into classical learning theorybased bounds that are not realistic unless Bayesian considerations are taken into account. This feedback is 3 as it points out a potential limitation in the current approach and suggests a possible direction for improvement by considering BayesianPAC based bounds. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this issue or integrate Bayesian considerations into their work. While it highlights an area for improvement, it does not offer actionable steps or suggestions, limiting its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer suggests that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of these claims. This feedback is explicit and provides a clear action for the authors to take, which is to conduct significance testing to support their claims. The comment is 5 as it gives a direct and concrete instruction on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking significance testing to support claims about the differences between certain methods. The reviewer provides a specific example from the paper, highlighting the need for proper testing, including checking the distribution and accounting for multiple comparisons. This level of detail helps the authors understand what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between certain methods without providing sufficient evidence or testing to support these claims. The reviewer specifically points out an example from line 486, where the authors discuss the conversational ability of ChatGPT and GPT4, and highlights the need for significance testing to determine the significance of these differences. The comment provides a clear rationale for the claim by explaining the importance of statistical testing and referencing specific metrics. However, it could be strengthened by including references to relevant literature or studies that support the need for significance testing. Overall, the claim is 4, as it provides a logical argument but lacks specific references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer points out that the differences between the methods are minimal and that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is 5 as it clearly highlights a critical gap in the paper and provides specific guidance on how to address it, empowering the authors to improve the rigor and validity of their claims. The comment is actionable and provides a clear path for the authors to enhance their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects on the improvements observed in the paper, rather than the distillation process itself. It suggests that the finetuning on GLUE without earlystopping could lead to high variances, and proposes that proper ablation studies are needed to verify the claims. While the comment implies that the authors should conduct additional studies to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform ablation studies to clarify the impact of regularization effects. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim that distillation improves the teacher\"s performance, suggesting that the improvements could be due to regularization effects rather than distillation. It specifically mentions the finetuning process on GLUE without earlystopping, which is known to have high variances. The comment implies that proper ablation studies are needed to verify the claims. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental setup and results sections. The comment is specific in detailing the potential issue with regularization effects and the need for ablation studies, but it lacks full grounding as it does not explicitly reference a specific section. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that finetuning on GLUE without earlystopping can lead to high variances, which could mask the true effects of distillation. The comment suggests that proper ablation studies are needed to verify the claims. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the impact of regularization effects. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical point about the potential impact of regularization effects on the observed improvements in the teacher\"s performance, rather than attributing them to distillation as claimed. It suggests that the finetuning process on GLUE without earlystopping could lead to high variances, which might mask the true effects of distillation. The comment provides a clear and actionable suggestion for the authors to conduct proper ablation studies to verify their claims. This feedback is valuable as it highlights a potential flaw in the experimental design and offers a specific direction for improvement. However, it could be more helpful if it provided additional guidance on how to design these ablation studies or what specific aspects to focus on. Overall, the comment is 4, as it effectively identifies a critical area for improvement and offers a constructive suggestion for further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as revising the contribution section or explaining the novelty of the model. Without any actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution and incremental nature of the proposed model but does not specify which part of the paper this assessment is based on. It lacks grounding as it does not identify a specific section, figure, or aspect of the paper being addressed. Additionally, it is not specific about what aspects of the contribution or model are considered limited or incremental. Without clear references or detailed feedback, the authors cannot effectively address the concerns raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper appears limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived limitations or enhance their work. As a result, the comment is 1, as it does not provide any value in terms of improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of the homolumo gap, citing an example from the QM9 dataset where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. The comment suggests that this finding may contradict the paper\"s claim of a \"generalpurpose neural network model.\" While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their model. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the generalizability of their model or clarify their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and references the \"QM9\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of the issue, namely the poor performance of TransformerM on most tasks except those related to homo, lumo, and gap, and suggests that this may contradict the paper\"s claim of a \"generalpurpose neural network model.\" This level of detail provides the authors with clear guidance on what needs to be addressed in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of the homolumo gap may lead to negative transfer, citing an example from the QM9 dataset where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This claim is supported by the specific example from the QM9 dataset, which provides a concrete instance of the potential issue. However, the comment could be strengthened by providing more detailed analysis or references to similar findings in the literature. Overall, the claim is 4, as it offers a clear example but lacks comprehensive evidence or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of the homolumo gap. It provides a specific example from the QM9 dataset, where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This observation is relevant to the paper\"s claim of a \"generalpurpose neural network model,\" as it suggests that the model may not be as versatile as claimed. The comment highlights a potential issue that the authors should address, offering a clear direction for further investigation or clarification. However, it could be more helpful if it provided suggestions on how to address this issue or offered additional insights into the implications of negative transfer. Overall, the comment is 4 as it identifies a critical area for improvement and provides a specific example, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two main issues with the experimental evaluation section. First, it notes that the \"picking\" step is not ablated, which is a claim made in the paper but not supported by experimental evidence. Second, it criticizes the comparison on CIFAR, suggesting that the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper, which could make the comparison unfair or incorrect. The comment provides specific suggestions for improvement, such as abating the \"picking\" step and ensuring that the comparison to DEN is fair by using the same setup. These suggestions are explicit and concrete, providing the authors with clear actions to take to enhance the validity and fairness of their experimental evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the ablation study, specifically the lack of ablation for the \"picking\" step, and the comparison on CIFAR, which is not convincing due to the limited comparison to only one approach (DEN). The comment further specifies that the comparison would be more convincing if the authors used the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experimental evaluation is flawed in two areas: the lack of ablation for the \"picking\" step and the limited comparison on CIFAR. The reviewer provides specific details about the issues, such as the need for ablation studies and the lack of a fair comparison to other approaches. However, the comment does not provide references or examples to support these claims, making it 3. The authors would need to conduct additional research or provide more detailed explanations to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out two main issues: the lack of ablation for the \"picking\" step, which is claimed as a distinct aspect of the approach, and the limited comparison on CIFAR, where the paper only compares to one approach (DEN) without using the same setup as in the DEN paper. The comment suggests that using the same setup as in the DEN paper would make the comparison more convincing and fair. This feedback is clear and provides concrete guidance for the authors to improve the validity and fairness of their experimental evaluation. By addressing these issues, the authors can enhance the robustness and credibility of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a tradeoff in the proposed method, noting that while it reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, implying that the authors should consider this aspect in their analysis. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this tradeoff further and potentially discuss it in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison to 10, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the tradeoff between computation time and the richness of the search space, noting that the output of ACI has less information compared to the output of 10. The comment raises a question about the information encoded in ancestral graphs compared to DAGs, which provides a clear direction for the authors to consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time and the richness of the search space in the proposed method. It suggests that the reduction in computation time comes at the cost of less information in the output compared to a method with a richer search space (DAGs). The comment provides a logical reasoning by explaining the tradeoff and questioning the extent of information loss. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to delve deeper into the literature or provide additional analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a tradeoff in the proposed method, noting that while it significantly reduces computation time compared to a previous method, it does so by limiting the search space to ancestral graphs. This results in less information in the output compared to the richer search space of DAGs. The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which could be an important consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might explore or discuss this tradeoff in their paper. While it highlights an important aspect of the method, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. The comment concludes by asking the authors to clarify this issue, implying that without clarification, the motivations in the paper may not be solid. While the comment identifies a specific area of concern and suggests a need for clarification, it does not provide explicit instructions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and their differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically regarding the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This explanation is based on common knowledge and logical reasoning, as it references established literature and methodologies. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consult the referenced literature to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and their differences, which could significantly improve the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context. Overall, the comment is 4, as it identifies a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment is specific and concrete, as it directly instructs the authors to address a particular aspect of their explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed in, such as a particular section or figure. The authors can infer that it relates to the discussion of Fourier modes, but without explicit references, it remains weakly grounded. The comment is specific in its request for clarification, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a logical suggestion to improve clarity in the paper, but it does not contain a claim that requires verification. It is a request for clarification rather than an opinion or judgment that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their explanation. By addressing this point, the authors can enhance the understanding of their work for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the overall understanding of the paper. Overall, the comment is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss case studies and error studies to demonstrate the effectiveness of each proposed component. It provides an example of how this could be done by mentioning a specific case study related to graph pretraining for AMR parsing and generation. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of what could be included, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to demonstrate the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of a case study related to graph pretraining for AMR parsing and generation. This feedback is specific as it identifies a particular aspect of the paper that could be improved and provides a concrete example of how to address it. However, it is not fully grounded because it does not explicitly mention the section where this discussion should be included, leaving the authors to infer the relevant part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of a case study related to graph pretraining for AMR parsing and generation, which supports the claim. However, the comment could be strengthened by explaining why case studies are necessary or how they would improve the paper\"s impact. The suggestion is 4 as it provides a concrete example, but it lacks detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper could be strengthened by including case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of how this could be done, referencing a case study related to graph pretraining for AMR parsing and generation. This feedback is actionable and provides a clear direction for the authors to enhance their draft by adding concrete examples. However, the comment could be more helpful if it offered additional guidance on how to conduct these case studies or what specific aspects to focus on. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions regarding the experimental setup and the design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While the questions are clear and imply that the authors should provide explanations for these design choices, they do not explicitly instruct the authors to make any changes or additions to their draft. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the main rationales behind two specific design choices: (a) having a separate timbre encoder module and (b) why SADTW takes outputs from the content encoder instead of the timbre encoder. This provides clear guidance on what needs to be addressed in the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the experimental setup and design choices in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of a series of questions regarding the experimental setup and design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While these questions are clear and indicate areas where the authors might need to provide more explanation or justification, they do not offer specific suggestions or guidance on how to address these issues. The feedback is 3 as it prompts the authors to clarify their experimental design, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, such as revising certain sections or clarifying specific points. Without actionable advice or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not specify which part of the paper this issue occurs in. The authors cannot confidently determine which sections or parts of the paper are affected by this jumbled presentation, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the writing or presentation are jumbled or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to particular sections or issues, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges a perceived issue with the writing or presentation of the paper, noting that it can be \"a bit jumbled at times.\" However, it does not provide specific examples or details about where these issues occur or how they could be improved. Without actionable guidance or suggestions, the authors are left without a clear understanding of what changes are needed to address the problem. This lack of specificity and actionable feedback makes the comment 2, as it does not offer much value in terms of improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. While the comment implies that the authors should consider and report on the computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this aspect but are not provided with specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and potential power demand, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support these claims. The lack of detailed reasoning or supporting information makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the computational complexity of the proposed method, particularly in the context of mobile devices. It questions the total computational complexity compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand. This feedback is 3 as it prompts the authors to consider and address the computational efficiency of their method, which is an important aspect for practical applications. However, the comment lacks specific suggestions or guidance on how to evaluate or improve the computational complexity, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have made an incorrect statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It specifies that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback provides clear and explicit guidance on what needs to be corrected in the draft, ensuring that the authors know exactly what action to take to improve the accuracy of their statement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement in the paper (\"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\") and references Section 3 of Wang et al., 2023, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the statement, indicating that the heads are active at the S2 token but do not primarily attend to it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Induction, Duplicate Token, and Previous Token heads primarily attending to the S2 token is incorrect, as per Section 3 of Wang et al., 2023. The comment provides a specific reference to external work, which supports the claim by indicating that the heads are active at the S2 token but do not primarily attend to it. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including a direct quote or more detailed explanation from Wang et al., 2023, to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and reliability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides two distinct comments. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks, and references a specific example from the literature on natural language inference. This feedback is explicit and provides a concrete example to support the claim, making it 5. The second part of the comment questions the relevance of the reinforcement learning/agent analogy in the context of the paper, suggesting that generalization capabilities are better illustrated by examples provided later in the paper. While the action is explicit, the comment could be more actionable by providing specific guidance on how to address the issue. Overall, the comment is 4 due to its explicit nature and the concrete example provided, but it could be more detailed in its suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L15 and L1618), allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on the vagueness of the statement at line 15 and the relevance of the reinforcement learning/agent analogy. The comment is specific in detailing what is wrong with the statement and suggesting alternative ways to illustrate generalization capabilities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references the literature on natural language inference and a leaderboard at https://nlp.stanford.edu/projects/snli/, providing a specific example to support the claim. This makes the first part of the comment 4. The second part questions the relevance of the reinforcement learning/agent analogy, suggesting that generalization capabilities are better illustrated by examples later in the paper. However, this part lacks specific references or detailed reasoning to fully substantiate the claim. Overall, the comment is 4, as it provides some support but could be strengthened with more detailed examples or references.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, offering a concrete example to support the claim. This feedback is clear and actionable, helping the authors to clarify their statement and provide more specific examples. The second part questions the relevance of the reinforcement learning/agent analogy, suggesting that generalization capabilities are better illustrated by examples provided later in the paper. While this feedback identifies a potential issue, it could be more helpful if it offered specific suggestions on how to integrate the analogy more effectively. Overall, the comment is 4 as it provides clear and actionable feedback on specific areas of the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the representation of kernel functions by neural networks (NNs). It points out that while it is claimed that every kernel can be described by a feature space parameterized by a NN, this is not true for infinitedimensional RKHSs, such as the RBF kernel. The reviewer suggests that this limitation should be made more clear. While the comment identifies a specific issue that needs clarification, it does not provide explicit guidance on how to address it or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors know they need to clarify the limitation but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, providing a counterexample with RBF kernels and their infinitedimensional RKHS. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, particularly for RBF kernels. The reviewer provides a logical explanation by pointing out that the RKHS for RBF kernels is infinitedimensional, requiring an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that demonstrate this limitation, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear and logical explanation by referencing the infinitedimensional RKHS of RBF kernels, which cannot be represented by a neural network with finite width. This feedback is valuable as it highlights a critical limitation in the paper and suggests that this should be clarified. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provide examples of kernels that can be represented by neural networks. Despite this, the comment provides a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method is not wellpositioned in the literature and recommends a thorough literature review to better understand its novelty. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to improve the positioning of their method in the literature. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific concept of representing the marginal score as the expectation of scores of distributions conditioned on inputs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that this concept is not novel and has been used in other works, such as denoising score matching and scoreinterpolation. The reviewer provides specific references to support this claim, which further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, which use similar concepts. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, suggesting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. It references specific works, such as denoising score matching and scoreinterpolation, to support this claim. The reviewer recommends a thorough literature review to better understand the method\"s positioning in the literature. While the comment highlights an important area for improvement, it could be more helpful by providing specific guidance on how to conduct the literature review or what aspects to focus on. Additionally, it does not offer suggestions for how the authors might differentiate their work from existing literature. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address the feedback. Additionally, the comment lacks specificity regarding what aspects of the technical contribution are limited or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific suggestions or guidance on how the authors might enhance their technical contribution or what aspects could be improved. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to address the identified issue. Therefore, the comment is 1, as it lacks depth and does not offer any constructive advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the novelty of the approach\"s components, specifically mentioning that the weak predictor used (MLP, Regression Tree, or Random Forest) has been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their work. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy (similar to epsilongreedy and identical to BRPNAS). It also references Table 2 in Appendix C, allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what is not novel about the approach and how it compares to existing work, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, citing the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. The claim is supported by references to specific works 2, 3, 7 and 5, which provide evidence for the lack of novelty in the approach. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional supporting details.", "helpfulness_rationale": "The review comment provides a detailed critique of the novelty of the approach, specifically addressing the components used in the weak predictor and the sampling strategy. It points out that the weak predictor is not novel, as it consists of MLP, Regression Tree, or Random Forest, which have been used before for NAS performance prediction. Additionally, it notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. This feedback is clear and actionable, as it highlights areas where the approach lacks originality and suggests that the authors should consider these points in their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or improve the novelty of the approach. Overall, the comment is 4, as it provides valuable insights for the authors to consider in their revisions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should clarify their calculation methods and consider reporting AUC results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about their calculations and consider reporting AUC results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the calculation of precision, recall, and F1score and suggests providing AUC results for comparisons. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, and suggests providing AUC results for breast cancer detection. The comment is based on common practices in the field of breast cancer detection and classification, which typically involve reporting AUC with sensitivity and specificity at different operating points. This reasoning is logical and aligns with standard practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the suggestion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises important questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, which is a specific and relevant aspect of the paper. It also suggests providing AUC results for breast cancer detection, which is a common practice in the field. This feedback is clear and actionable, as it directs the authors to clarify their methodology and consider a more informative way to present their results. By addressing these points, the authors can enhance the clarity and comprehensiveness of their draft. Therefore, the comment is 4, as it provides specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It suggests that the authors could consider using the Kialo dataset instead, which is cleaner and more established. However, the comment does not explicitly instruct the authors to use the Kialo dataset or provide specific guidance on how to integrate it into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using the Kialo dataset but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset and the use of the Kialo dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the dataset creation, noting that the Kialo dataset is wellstudied and cleaner, and suggests that the dataset created in the paper could be used as additional data. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional and suggests using the Kialo dataset instead, which is wellstudied and cleaner. The reviewer provides a logical reasoning by comparing the two datasets, highlighting the advantages of using the Kialo dataset. However, the comment lacks specific examples or references to support the claim about the Kialo dataset being \"cleaner\" or the absence of automatic processes for its construction. This makes the claim 3, as it provides a general rationale but requires further evidence or details to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting the use of the Kialo dataset, which is wellstudied and provides pairs of short claims and their counters. It highlights that the dataset created in the paper could be considered as additional data to learn from. This feedback is clear and actionable, as it provides a specific alternative to the dataset creation and suggests a way to enhance the paper. However, the comment could be more helpful if it included a detailed explanation of why the Kialo dataset is preferable or how it could be integrated into the paper. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the transformer modification and its impact on machine learning insights. It also questions the significance of the improvement brought by the selfcross attention in the ablation study. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concerns about novelty, the impact of the modification, or the interpretation of the ablation study results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the novelty of the transformer modification and the limited improvement brought by the selfcross attention in the ablation study. The comment provides a clear critique of the significance of the proposed modification and suggests that the main improvements come from using a na\u00efve transformer rather than the proposed modification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the transformer modification is no longer novel and does not bring significant insights in machine learning. It also questions the significance of the improvement brought by the selfcross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer. The comment provides some reasoning by mentioning the limited improvement (<1%) and the lack of novelty in the transformer modification. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the paper to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the paper, questioning the novelty of the transformer modification and its impact on machine learning insights. It points out that the selfcross attention brings limited improvement (<1%) in the ablation study, suggesting that the main improvements may come from using a na\u00efve transformer rather than the proposed modification. This feedback is 3 as it highlights a potential weakness in the paper\"s claims of innovation and suggests that the authors should reconsider their approach to demonstrating the significance of their modifications. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or improve the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to discuss a specific previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019, and to illustrate the relationship between this work and their proposed method. The comment also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of research on joint error for UDA and references a specific previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: discussing the relationship between the referenced work and the proposed method, and explaining why the proposed method is better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" in ICML2019. The reviewer provides a specific reference to support the claim, which is a clear and robust form of evidence. This level of detail allows the authors to understand the basis of the critique and address it effectively. Therefore, the claim is 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that there is no research focusing on the joint error for Unsupervised Domain Adaptation (UDA). It points out that this problem has already been studied in a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. The comment provides a specific reference and suggests that the authors should discuss this work and its relationship to their proposed method, as well as explain why their method is better. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by addressing the gap in their claim and providing a more comprehensive discussion of related work. Therefore, the comment is 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the use of a newly collected large dataset (209M) compared to the smaller datasets used by existing methods. The reviewer implies that the superior performance of the proposed method could be due to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should consider the impact of dataset size on the results and potentially adjust their analysis or comparisons accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset versus smaller datasets used by existing methods like GEM, which employs only 20M unlabeled data. This provides a clear context for the issue, allowing the authors to identify the part of the paper being discussed as the section comparing the proposed method with SOTA methods. However, the comment does not specify what needs to be addressed or how the authors should adjust their comparison to make it more fair. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a larger dataset. The reviewer provides specific examples, such as GEM using only 20M unlabeled data, and highlights the significant impact of dataset scale on accuracy. This reasoning is logical and wellsupported by the examples provided, making the claim 4. However, the comment could be strengthened by including more detailed comparisons or references to specific studies that demonstrate the effect of dataset size on performance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods, pointing out that the proposed method\"s performance is based on a newly collected large dataset (209M), while existing methods use smaller datasets. This observation is important as it highlights a potential bias in the comparison that could impact the perceived superiority of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it identifies a critical point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider the impact of dataset size but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs, noting that the research gap and limitations of existing methods are not discussed. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to discuss the limitations of existing methods and justify the need for a new approach, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a gap but does not fully direct the authors on how to fill it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on the limitations of existing methods. The comment provides a clear direction for the authors to address the gap in their justification, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified and that the research gap is not discussed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence leaves the authors without a clear path to address the issue, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods are discussed in Section 1, the need for a new curriculum learning method for text graphs is not justified. It points out the lack of discussion on the limitations of existing methods and the research gap that justifies the development of a new method. This feedback is clear and actionable, as it directs the authors to address the gap in their justification and provide a rationale for the need of a new approach. However, the comment could be more helpful if it offered suggestions on how to structure this discussion or what specific aspects of existing methods should be highlighted. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that powerful pretrained language models, such as BERT and XLNet, should be used as the base encoder for all methods to overcome the domainshift problem. It implies that the authors should compare the efficacy of the transfer parts rather than using the simplest ngram features. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specific guidance on integrating these models or how to compare the efficacy of the transfer parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods to address the domainshift problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the use of these models, but it is 1, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that powerful pretrained language models, such as BERT and XLNet, can overcome the domainshift problem to some extent. It implies that these models should be used as the base encoder for all methods and that the efficacy of the transfer parts should be compared instead of using the simplest ngram features. However, the comment lacks specific examples, references, or detailed reasoning to support why these models are more effective or how they should be integrated. This makes the claim 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for improving the approach to domain adaptation in the NLP field. It recommends using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, which could potentially overcome the domainshift problem. This is a clear and actionable piece of feedback that could significantly enhance the draft by offering a more robust approach to addressing the domainshift issue. However, the comment could be more helpful if it included specific guidance on how to integrate these models or detailed examples of their application. Overall, the comment is 4 as it provides a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment explicitly asks if it is possible to perform a quantitative comparison on the final outputs. This provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. The feedback is explicit and concrete, offering a specific step for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs, and suggests that a quantitative comparison on the final outputs would be more convincing. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, rather than the final outputs, and that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing. While the comment highlights a potential issue with the evaluation methodology, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a quantitative comparison on the final outputs is logical but lacks detailed justification or references to support the need for this change. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results presented in the paper, noting that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs. It suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. The comment also questions whether it is possible to perform a quantitative comparison on the final outputs, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the evaluation methodology and offers a specific direction for enhancing the paper. However, it could be more helpful if it provided additional context or examples of how such a comparison could be conducted. Overall, the comment is 4, as it effectively guides the authors toward improving the robustness of their evaluation results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. The reviewer also questions the number of landmarks used, the type of image features, and the fixed radius with different scales. Additionally, they ask about achieving shape invariance. While the comment identifies several areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, specifically the sparsification process, extraction of landmark features, and generation of landmarks on the edge. It also raises questions about the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This provides clear guidance on what aspects of the paper need more detail and explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It raises several specific questions about the sparsification process, landmark feature extraction, and other aspects of the methodology. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. The lack of detailed reasoning or specific examples makes it challenging for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of detail about the techniques used, which makes it difficult to reproduce the results. It raises several specific questions about the sparsification process, landmark feature extraction, and other aspects of the methodology. This feedback is clear and actionable, as it provides the authors with a list of areas where they need to provide more detailed explanations to improve the reproducibility and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what kind of detail is needed. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or mitigate the potential biases. The action is implicit, as the authors need to infer that they should consider alternative approaches or additional criteria to reduce bias. The feedback is 3 because it identifies a potential problem but lacks concrete steps for resolution.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach to determining chunk significance in FIITED, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The comment is specific in detailing the potential issue of biases introduced by basing eviction decisions solely on utility scores and provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for recent chunks to gain a temporary high utility, leading to premature evictions of other valuable chunks. This claim is 3 as it provides a logical reasoning about the potential bias in the utilitybased approach. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This feedback is 3 as it highlights a potential weakness in the approach and offers a specific example of the problem. However, it does not provide suggestions or guidance on how the authors might address this issue or mitigate the potential biases. To be more helpful, the comment could include recommendations or alternative methods to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the first paragraph of the Introduction for being too general and not relevant to the paper\"s focus on detecting drift types and magnitude. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion to revise or remove the paragraph, nor is there guidance on how to improve the introduction to better align with the paper\"s focus. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, namely that it is too general and does not mention drift, which is the core focus of the paper. The comment provides a clear direction for improvement by suggesting that the introduction should be more relevant to the paper\"s focus. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is too general and does not mention drift, which is the core focus of the paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate why the introduction is not relevant. This lack of supporting information makes the claim difficult for the authors to address effectively, as they may not fully understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of the paper, noting that the first paragraph is too general and does not mention drift, which is the core focus of the paper. This feedback is valuable as it highlights a potential misalignment between the introduction and the paper\"s main contributions. However, the comment could be more helpful if it provided suggestions on how to improve the introduction to better align with the paper\"s focus or offered examples of how to integrate driftrelated information more effectively. While it points out a weakness, it lacks actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms to provide a clearer understanding of the framework\"s performance. The comment also implies the need for more detailed explanations of the presented results. While the action is implicit, it is concrete in suggesting specific improvements, such as conducting quantitative experiments and comparisons. The authors can infer that they need to enhance the experimental section to address the reviewer\"s concerns. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"result section\" and the need for \"quantitative experiments and comparison between selection of algorithms\" or \"a more detailed explanation\" of the presented results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the result section, namely quantitative experiments and comparisons, and the need for detailed explanations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contributions to the final result are unclear. It suggests that the lack of quantitative experiments and comparisons between algorithms makes it difficult to understand the framework\"s performance. The comment is 3 as it provides a logical reasoning for the claim, noting the absence of quantitative experiments and comparisons. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding how different parts of the framework contribute to the final result. It highlights the need for quantitative experiments and comparisons between algorithms to provide a clearer understanding of the framework\"s performance. The comment also suggests that the result section lacks detailed explanations of the presented results. This feedback is actionable and provides clear guidance on how the authors can improve their draft by enhancing the experimental section and providing more detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their final results on the official COOC leaderboard on the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. This provides clear and concrete guidance on what action the authors should take to improve their draft. The comment also suggests comparing to specific approaches that have won the challenge, which adds a level of detail to the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leaderboard on the blind test set, providing a specific link for reference. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely comparing results on the official test set and referencing specific approaches that have been evaluated on the blind challenge set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leaderboard on the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. The comment provides a logical reasoning by pointing out the importance of comparing results on the official test set and referencing specific examples of approaches that have been evaluated on the blind challenge set. This provides a clear justification for the claim, making it 4. However, the comment could be strengthened by including more detailed references or examples of these approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback regarding the comparison of results in the captioning experiment. It highlights the importance of comparing results on the official COOC leaderboard on the blind test set, rather than on a nonofficial test or dev set. The comment also references specific approaches that have won the challenge and been evaluated on the blind test set, suggesting that the authors should compare their results to these. This feedback is clear and detailed, offering the authors a concrete path to improve the validity and relevance of their results. By addressing this feedback, the authors can enhance the credibility and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a need for clarification regarding the terms \"good,\" \"bad,\" and \"wrong\" explanation at line 248. It suggests that the authors should clarify these concepts before using them, which provides a direct and concrete action for the authors to take. The comment is explicit and specific, offering clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of needing clarification on the terms \"good,\" \"bad,\" and \"wrong\" explanation. The comment provides a clear direction for improvement by suggesting that the authors should clarify these concepts before using them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests that the paper should clarify the concepts of \"good,\" \"bad,\" and \"wrong\" explanations before using them. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by clarifying the meaning of \"wrong\" at line 248. It suggests that the authors should provide a clear explanation of what is meant by \"good,\" \"bad,\" and \"wrong\" explanations before using these terms. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and coherence of their draft. However, the comment could be more helpful if it offered additional suggestions on how to present this clarification or provided examples of how similar concepts have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison between the author\"s method and Mid Vision Feedback (MVF) in terms of image classification results. The comment implies that the authors should include this comparison to demonstrate the superiority of their method. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the author\"s method and Mid Vision Feedback (MVF) in terms of image classification results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental comparison, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison between the author\"s method and Mid Vision Feedback (MVF) in terms of image classification results. The reviewer argues that this omission prevents the demonstration of the superiority of the schema searched by the author\"s method over Mid Vision Feedback (MVF). While the comment highlights a potential gap in the experimental evaluation, it does not provide specific examples or references to support the claim. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It specifically points out the lack of comparison between the author\"s method and Mid Vision Feedback (MVF) in terms of image classification results, which is crucial for proving the superiority of the schema searched by the author\"s method. This feedback is clear and actionable, as it directs the authors to include this comparison to strengthen their experimental evaluation. However, the comment could be more helpful if it provided suggestions on how to conduct this comparison or what specific metrics to use. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should consider whether their work is an extension or introduces novel contributions, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable feedback, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, suggesting similarities with another study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" However, it does not specify which parts of the article are similar or how they relate to the previous study. The authors may infer that the comment pertains to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity regarding what aspects need to be addressed or how the authors should differentiate their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the concern. The comment lacks concrete evidence or references to the other study, which would be necessary to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. This is a valid point that could prompt the authors to reflect on whether their work is an extension of existing research or introduces novel contributions. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work. Without actionable advice or examples, the feedback is 3, as it identifies an area for consideration but does not provide a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the results, specifically regarding the sublinearity of regret. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. The comment is purely a query seeking clarification, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding the sublinearity of regret, prompting the authors to clarify their discussion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the interpretation of the results regarding sublinearity of regret. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of the results regarding sublinearity of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. While it identifies a potential confusion in the paper, it does not provide any suggestions or guidance on how to address this issue or clarify the interpretation. The comment is 3 as it points out a potential misunderstanding, but it lacks actionable feedback or detailed guidance for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the balance between longrange dependencies and locality, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a discussion about the importance of learning longrange dependencies versus the role of locality in the graph structure, particularly in relation to image size. The comment provides a clear direction for the authors to consider the balance between these factors and how it affects prediction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, the claim is not fully supported by specific examples, references, or detailed reasoning, making it 3. The authors would need to provide additional evidence or clarification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion on the importance of learning longrange dependencies for powerful predictors. It acknowledges that the paper demonstrates this importance in the context of semantic segmentation but suggests that the discussion could be more nuanced. The reviewer points out a specific concern about the role of locality in the graph structure and its impact on prediction, particularly in relation to image size. This feedback is 3 as it prompts the authors to consider a more balanced discussion of the tradeoffs between longrange dependencies and locality. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the definition of $e_l$ in Eq. (3) and points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also mentions that the performance is getting worse than standard random features, as shown in Figure 1, which may indicate a weakness in the proposed approaches. While the comment identifies areas that need clarification or further investigation, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of $e_l$ and investigate the implications of the exponential dependence on $M$, but the comment lacks concrete guidance on how to implement these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3),\" \"Corollaries 1, 2, and 3,\" and \"Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the exponential dependence on the diameter $M$ of the domain of data and its impact on the required feature size. Additionally, it references Figure 1 to support the claim that the performance is getting worse than standard random features. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for clarification of $e_l$ in Eq. (3) and the observation that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also suggests that this dependence affects the constant factor of the required feature size and references Figure 1 to support the claim that the performance is worse than standard random features. While the comment provides some logical reasoning and references specific parts of the paper, it lacks detailed examples or references to support the claim about the exponential dependence and its impact. Therefore, the comment is 4, as it provides a solid foundation for the claims but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment raises several points that are helpful for the authors to consider. It questions the definition of $e_l$ in Eq. (3), which prompts the authors to clarify this aspect of their work. Additionally, it points out the exponential dependence on the diameter $M$ of the domain of data in Corollaries 1, 2, and 3, and Theorem 4, which could impact the required feature size. The comment also references Figure 1 to illustrate that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. While the comment identifies important areas for clarification and improvement, it could be more helpful by providing specific suggestions on how to address these issues or by offering alternative approaches to mitigate the identified weaknesses. Overall, the feedback is 4 as it directs the authors to key areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues in their draft. While it points out areas for consideration, it lacks actionable steps or concrete recommendations for improvement. As a result, the authors are left with a general understanding of the potential problems but without clear direction on how to address them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential issues. It also suggests that oversmoothing could be another factor, referencing a specific paper for further context. However, the comment does not specify which part of the paper discusses DGNs or their modeling abilities, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issues with DGNs, such as oversquashing and oversmoothing, and provides a reference for further exploration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the poor longrange modeling ability of DGNs could be due to oversquashing and vanishing/exploding gradients, and also mentions oversmoothing as another potential factor. The claim is supported by a reference to a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a basis for the suggestion. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples within the paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. This feedback is 3 as it points out a specific area for improvement and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on how to incorporate the referenced paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not provide specific guidance or suggestions on how to clarify the formulation. The authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. Without explicit instructions or concrete examples, the authors cannot effectively address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not specify which specific examples or sections of the paper are causing the confusion. This makes it difficult for the authors to pinpoint the exact parts that need clarification. The comment lacks grounding as it does not identify a specific part of the paper, and it is also not specific about what aspects of the formulation are unclear. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in both the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 2, as it points out a problem but does not offer any direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about considering finer grouping for quantization instead of pertensor and perchannel approaches. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what specific actions they should take. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about considering finer grouping for quantization instead of pertensor and perchannel approaches. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine where in the paper this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of finer grouping should be considered or how it might improve the quantization approach. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for justification or explanation regarding the choice of quantization approach. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization approach, specifically asking why a finer grouping for quantization is not considered instead of pertensor and perchannel methods. While it identifies a potential area for improvement, the comment lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue. Without actionable advice or detailed reasoning, the feedback is 3 as it prompts the authors to consider an alternative approach, but it does not fully support them in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, it does not provide explicit guidance or suggestions on how the authors should clarify or address this point in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the use of epsilongreedy exploration. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, indicating that the authors should clarify whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, the comment does not provide any supporting evidence, reasoning, or references to clarify the issue or explain why this might be a concern. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be addressed. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether the authors should consider alternative approaches or modifications. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the applicability of the proposed methodology, specifically mentioning dynamic precision control during training and its potential limitations on bitserial accelerators. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment provides some insight into the potential implications of the methodology but lacks specificity in terms of what needs to be addressed or how the authors might improve their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. The comment provides a logical reasoning by contrasting the proposed methodology with the more commonly used bitparallel fixedpoint numbers in existing accelerators. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this point and potentially conduct further analysis or provide additional context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the proposed methodology, specifically questioning whether dynamic precision control during training would only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. This observation highlights a potential limitation of the proposed approach and encourages the authors to consider the broader implications of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. While it identifies a relevant area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. The reviewer also recommends explaining the network model in Section 4.2 with equations to improve clarity. While the comment implies that the authors should clarify the reward source and provide equations for the network model, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Equation 12, questioning the origin of the reward and suggesting that it might be related to one of the r_i terms from Equation 11. Additionally, it provides a recommendation to explain the network model in Section 4.2 with equations to improve clarity. The inclusion of specific references to equations and sections provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of Equation 12, specifically asking where the reward comes from at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. The reviewer also recommends explaining the network model in Section 4.2 with equations to improve clarity. While the comment raises valid points about the need for clarification, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The inclusion of references to external works is an attempt to support the suggestion for improvement, but it does not directly address the confusion in Equation 12. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. This feedback is clear and actionable, as it directs the authors to clarify the source of the reward, which could significantly improve the understanding of the model. Additionally, the comment recommends explaining the network model in Section 4.2 with equations, which would enhance the paper\"s clarity. The inclusion of references to external works provides additional context and potential resources for the authors to consider. However, the comment could be more helpful if it provided specific examples or more detailed guidance on how to address the issues. Overall, the feedback is 4, as it effectively guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the idea, improve the metric, or make the method more complex. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the idea and the straightforwardness of both the new metric and method. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the novelty or method are considered straightforward, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the novelty of the idea, suggesting that both the new metric and method are relatively straightforward. However, it does not provide any specific guidance or suggestions on how the authors might enhance the novelty or complexity of their approach. Without actionable feedback or examples, the comment lacks depth and does not offer a clear path for the authors to improve their work. As a result, it is 2, as it highlights a potential issue but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to break down the generative process into more detailed steps and simplify the notation, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. The comment is specific in suggesting improvements to the model description, but it is 1 as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, the comment does not provide specific examples or detailed reasoning to support why this would enhance understanding. It lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. This feedback is 3 as it identifies a potential area for improvement in the clarity and presentation of the model description. However, the comment lacks specificity and does not provide detailed guidance on how to achieve these improvements. It does not offer concrete suggestions or examples of how to break down the generative process or simplify the notation, leaving the authors with a general idea of what needs to be addressed but without actionable steps. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer explanation of why the subject matter is important or relevant. However, the comment does not specify how to achieve this motivation or what aspects of the paper need to be revised to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section or enhance the introduction to explain the significance of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer explanation of why the subject matter is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors can make an educated guess that it relates to the introduction or background section, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting the need for motivation, but without clear guidance on where to address it, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks motivation for why the topic is important or relevant. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that it lacks motivation for why the topic is important or relevant. This is a valid observation, as the paper could benefit from a clearer explanation of its significance and relevance. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending additional background information, highlighting specific aspects of the topic, or suggesting ways to frame the motivation. While the comment points out a potential weakness, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or specific suggestions for further investigation. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the tradeoff for baselines and potentially explore hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the performance comparison with Decouple Kang et al. and the tradeoff between head and tail categories. The comment provides a clear suggestion for further investigation by encouraging the authors to explore the tradeoff for the baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance, and it highlights a tradeoff between head and tail categories. The reviewer suggests that similar tradeoffs could be explored for the baselines by adjusting hyperparameters. While the comment provides some reasoning, it lacks specific examples or detailed comparisons to fully substantiate the claim. The reference to Decouple Kang et al. is mentioned, but without further elaboration or data, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple Kang et al. for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that adjusting hyperparameters in Decouple Kang et al. could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a significant weakness in the paper and provides a specific direction for further investigation. However, the comment could be more helpful by offering suggestions on how to address these issues or by providing examples of how to explore the tradeoff for the baselines. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It highlights two issues: the requirement for \"all of the structured elements for perspectives to be present in the generated tweets,\" which may not be realistic, and the use of \"author embeddings initialized by averaging the corresponding artificial tweets,\" which is also not realistic. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific changes. The authors can infer that they need to evaluate the realism of their tweets and consider more realistic approaches, but the feedback lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the realism of the tweets, particularly the requirement for \"all of the structured elements for perspectives to be present\" and the use of \"author embeddings initialized by averaging the corresponding artificial tweets.\" This provides clear guidance on what needs to be addressed in terms of improving the realism of the evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the use of \"author embeddings initialized by averaging the corresponding artificial tweets.\" These examples offer a clear rationale for why the evaluation might not be realistic, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, questioning the realism of the evaluated tweets. It provides two specific points: the requirement for \"all of the structured elements for perspectives to be present in the generated tweets,\" which may not be realistic, and the use of \"author embeddings initialized by averaging the corresponding artificial tweets,\" which is also not realistic. This feedback is clear and actionable, as it highlights areas where the evaluation could be improved to better reflect realworld scenarios. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of more realistic approaches. Overall, the comment is 4, as it directs the authors to focus on enhancing the realism of their evaluation, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It explicitly requests a comparison with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This provides clear and concrete guidance on what action the authors should take to enhance their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not explicitly mention which part of the paper this comparison should be made in, leaving the authors to infer that it should be integrated into the discussion or results section. The suggestion is specific in terms of the comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between the proposed model and existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This suggestion is based on the observation that ternary potential seems to be the main factor in the performance improvement of the proposed model. However, the comment does not provide detailed reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The reference to Jabri et al. is a good starting point, but more context or explanation would be needed to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It recommends comparing the model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by exploring the impact of ternary potential in the context of existing models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should reconsider their design choice. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and does not incur significant computational costs for longer sequences. This provides clear guidance on what aspect of the paper needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This claim is 3 as it provides a logical reasoning for questioning the design choice, but it lacks specific examples or references to support the assertion that trimming questions is unnecessary. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This feedback identifies a potential issue with the experimental design and provides a rationale for why the trimming might not be necessary. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or whether they should reconsider their design choice. While it highlights a potential area for improvement, the feedback could be more actionable and helpful if it included specific recommendations or alternatives. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change two lines in red to green in the Supplemental Material. It provides specific line numbers and references to the changes needed, such as \"SuppMat, L502: \u03f5 \u03b8 > z \u03b8\" and \"SuppMat, L507: (4) > Table 4.\" This level of detail provides clear and concrete guidance on what actions to take, ensuring the authors know exactly how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the Supplemental Material (SuppMat, L502, L507, and L509) and provides clear instructions for changes, such as changing \"\u03f5 \u03b8\" to \"z \u03b8\" and \"(4)\" to \"Table 4.\" This allows the authors to accurately identify the parts of the paper that need revision. The comment is also specific because it details exactly what changes are needed, providing clear guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding specific lines in the Supplemental Material that should be changed from red to green. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. It identifies two lines in the Supplemental Material that should be changed from red to green, along with the exact line numbers and references to the changes needed. This level of detail empowers the authors to make precise corrections, ensuring that their draft is accurate and consistent. The comment is clear and direct, offering a straightforward path for improvement, which aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that important references are missing and encourages the authors to conduct a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" It also provides specific references to these works, which are \"Gated Fully Fusion for Semantic Segmentation, AAAI\"20\" and \"EfficientFCN: Holisticallyguided Decoding for Semantic Segmentation, ECCV\"20.\" This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The suggestion to include a comprehensive comparison with these works is explicit and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, \"GFF\" and \"EfficientFCN,\" and provides their respective references. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it suggests a comprehensive comparison with these works, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing and suggests a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" The reviewer provides specific references to these works, which supports the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the current work. Despite this, the inclusion of references provides a solid foundation for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically mentioning \"GFF\" and \"EfficientFCN,\" which are relevant to the topic of fast semantic segmentation in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, providing specific references to facilitate this process. This feedback is clear and actionable, offering a concrete suggestion for enhancing the paper by addressing a critical omission. However, the comment could be more helpful if it provided additional context or examples of how these references could be integrated into the paper. Overall, the comment is 4, as it directs the authors to a specific area for improvement with actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without a solution to this issue. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability problem but are not given specific steps or methods to consider. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, specifically mentioning its applicability to largescale datasets like ImageNet. However, it does not specify which part of the paper discusses the NC measure or its scalability issues, making it weakly grounded. The comment is specific in identifying the problem of scalability and suggesting that the practical contribution of the paper could be reduced without a solution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, questioning how it can be applied to largescale datasets like ImageNet. The comment suggests that the practical contribution of the paper could be significantly reduced without addressing this issue. However, the comment lacks specific examples or detailed reasoning to support the claim about the scalability problem. While it highlights a potential issue, the lack of concrete evidence or references makes the claim 3. The authors would need to infer the specific challenges and potential solutions based on the comment alone, which is not fully supported. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without addressing this issue. This feedback is valuable as it highlights a potential limitation of the proposed method and prompts the authors to consider scalability in their approach. However, the comment could be more helpful if it provided suggestions or examples of how the authors might address the scalability issue. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs further exploration or improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment explicitly suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the experiment part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of computation complexity and suggests that a comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines. It provides a specific explanation of the computation complexity issue by detailing the calculation involved in Algorithm 1, which is a logical and clear justification. However, the comment could be strengthened by including specific examples or references to support the claim about the comparison of computation complexity in the experiment part. Overall, the claim is 4, as it provides a solid foundation for the authors to address the issue, but it could benefit from additional details or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, offering the authors a direct path to improve their draft by addressing the computational complexity and providing a comparison with baselines. The comment is 5 as it provides specific guidance on how to enhance the paper\"s methodology and presentation, making it a valuable resource for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as increasing the font size in figures 1 and 2, making the words in the grey box larger, and ensuring that \"V_mem, Th_i, U_i^t\" are not too small. It also suggests adding a \"table\" to compare the number of epochs and parameters with other stateoftheart Transformer designs. These suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on font sizes and the clarity of certain elements, such as the grey box and labels like \"V_mem, Th_i, U_i^t.\" Additionally, it suggests improvements for the \"CTRL\" explanation and proposes a comparison with other stateoftheart Transformer designs using a table. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first part is a subjective opinion about the quality of the figures, which is not verifiable as it lacks specific evidence or reasoning. The second part suggests improvements, such as increasing font sizes and adding a table for comparison, which are factual and do not require verification. The third part critiques the lack of details in the comparison with other stateoftheart Transformer designs, which is a subjective claim that could be supported by examples or references. Overall, the comment is 4, as it provides some logical reasoning but lacks specific examples or references to fully substantiate the claims. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the visual presentation of the figures, suggesting improvements such as increasing font sizes and making certain labels larger. It also identifies a lack of detail in the comparison with other stateoftheart Transformer designs, recommending the inclusion of a table to emphasize the data and justify the improved accuracy. This feedback is clear and provides concrete suggestions for enhancing the clarity and comprehensiveness of the draft. However, the comment could be more helpful if it offered additional guidance on how to structure the table or what specific details should be included. Overall, the comment is 4, as it effectively guides the authors toward improving the visual presentation and comparison aspects of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include ATA in the comparison in Table 2, as it is better than FP according to the results in Table 1. This is an explicit action with clear guidance on what needs to be done to improve the draft. The comment provides a specific suggestion for enhancing the comparison, making it 5. The authors know exactly what action to take to address the feedback, which is to include ATA in the comparison in Table 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: including ATA in the comparison, as it is better than FP according to the results in Table 1. This provides clear guidance on how to enhance the comparison, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as ATA is better than FP according to the results in Table 1. This claim is based on a logical inference from the results presented in the paper, specifically comparing the performance of different methods. The reasoning is clear and straightforward, providing a sound basis for the suggestion. However, the comment could be strengthened by referencing specific results or data from Table 1 to further substantiate the claim. Overall, the claim is 4, as it provides a logical basis but lacks detailed references or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, given that ATA is better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the validity and persuasiveness of their results. By addressing this point, the authors can strengthen their argument and improve the overall quality of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It also questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment explicitly suggests that a formal definition would be beneficial for readers. While the action is clear, the comment could be more actionable by providing specific guidance on how to present the mathematical definitions or clarify the figure. However, the authors know exactly what needs to be addressed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general architecture of the model\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of mathematical definition in architectural details, such as multihead attention, and questions the split arrow in Figure 2. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment suggests that a formal definition would be beneficial for readers. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of mathematical definition in the architectural details of the model, particularly regarding multihead attention. It provides a clear and actionable suggestion by asking for a formal definition of this component, which would enhance the readers\" understanding. Additionally, the comment raises a question about the split arrow in Figure 2, seeking clarification on the inputs for the attention layer. This feedback is detailed and constructive, offering the authors a clear path to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer, but it does not specify which part of the paper is causing this issue. The authors cannot confidently determine which sections or aspects of the paper are problematic, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the presentation are unclear or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the presentation of the paper is difficult to follow, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow for the reviewer, which is a valid concern. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or structure of their paper. Without detailed guidance or examples, the authors are left without a clear understanding of what changes they should make to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include and compare their work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. The comment explicitly states that including these works and discussing the conceptual differences would be beneficial. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies the works to be included and the type of comparison to be made, ensuring the authors know exactly how to apply the feedback.", "grounding_specificity_rationale": "The comment suggests including and comparing the work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. While it does not explicitly mention a specific section of the paper, the authors can infer that this suggestion pertains to the discussion or related work sections. The comment is specific in suggesting the inclusion of these works and the need for conceptual comparisons. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that works such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. are important to include and compare to, at least conceptually. The reviewer provides specific references to external works, which supports the claim by offering a clear basis for comparison. However, the comment could be strengthened by explaining why these works are particularly relevant or how they relate to the current study. Despite this, the inclusion of references provides a solid foundation for the claim, making it 4. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment suggests that the authors should include and compare their work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. This feedback is clear and actionable, as it provides specific references and a clear direction for the authors to enhance their work by discussing conceptual differences and comparisons. By incorporating these suggestions, the authors can better contextualize their work within the existing literature and provide a more comprehensive understanding of their contributions. However, the comment could be more helpful if it offered additional guidance on how to structure the comparison or what specific aspects to focus on. Overall, the comment is 4, as it offers valuable insights for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides an example reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could serve as a basis for the clarification. While the action is explicit, the comment could be more actionable by providing specific guidance on how to make this clarification, such as suggesting particular aspects to focus on or how to structure the explanation. Nonetheless, the comment is 4 as it clearly identifies an area for improvement and provides a reference for further clarification.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, namely the difference between meta solvers and centralized RL where agents share weights. The reference to Foester et al. provides additional context and guidance on how to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between these and centralized RL where agents share weights. The comment provides a reference to Foester et al., \"Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which supports the claim by offering a relevant example of a similar concept. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting that they might be centralized controllers. It provides a specific reference to Foester et al., \"Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could serve as a basis for clarifying the difference between meta solvers and centralized RL where agents share weights. This feedback is clear and actionable, as it directs the authors to a relevant reference that could help them better articulate their approach. However, the comment could be more helpful if it included additional guidance on how to structure the clarification or what specific aspects of the meta solvers need to be addressed. Overall, the comment is 4, as it provides a valuable direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This comment implies that the authors should clarify the distinction between sequential and nonsequential information, particularly regarding the term \"chunk.\" However, it does not provide explicit guidance on how to address this issue or clarify the confusion. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"nonsequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the terminology used in the paper, specifically the phrase \"nonsequential information such as chunks.\" It raises a logical inquiry about whether \"chunk\" is considered sequential information, which is a reasonable question given the context. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim or clarify the confusion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the terminology used in the paper, specifically the phrase \"nonsequential information such as chunks.\" It points out a potential confusion regarding whether \"chunk\" is considered sequential information, which could be a critical clarification for the authors to make. However, the comment does not provide any suggestions or guidance on how to address this issue or clarify the terminology. While it identifies a potential area of confusion, it lacks depth and actionable feedback, making it 3. The authors are left with a clear question to address but without specific guidance on how to resolve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and suggests that Figure 1 might be misleading. Additionally, the reviewer proposes an alternative approach, suggesting that zooming on the region of interest using bilinear sampling could provide better results. While the comment identifies a potential issue and offers a suggestion, it does not provide explicit instructions on how to address the discrepancy or implement the suggested alternative. The action is mostly inferred, and the authors know what needs to be done but not exactly how to execute it. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, questioning the interpretation of the output patches and suggesting that Figure 1 might be misleading. Additionally, the comment provides a specific suggestion for improvement by proposing the use of bilinear sampling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions the correctness of this interpretation and suggests that Figure 1 might be misleading. Additionally, the reviewer proposes an alternative approach using bilinear sampling. While the comment raises a valid point about the discrepancy, it lacks specific references or detailed reasoning to fully substantiate the claim. The suggestion for an alternative approach is also not fully elaborated. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully supported.", "helpfulness_rationale": "The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning the interpretation of the output patches. It suggests that the output patches might not be cropped parts of the input image but rather masked versions of the input image with most pixels being black, which could make Figure 1 misleading. The reviewer also proposes an alternative approach using bilinear sampling, which could potentially provide better results. This feedback is clear and actionable, as it highlights a specific issue that needs clarification and offers a constructive suggestion for improvement. However, it could be more helpful if it provided additional context or examples to further support the suggestion. Overall, the comment is 4, as it directs the authors to a critical area that requires attention and offers a potential solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, suggesting a comparison with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be improved. The comment implies that the authors should consider the similarities between their work and the previous papers, but it lacks concrete steps or suggestions on how to enhance the novelty or differentiate their work. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the paper with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper this comparison should be made in, such as the introduction, methodology, or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint where the comparison should be included. The comment is specific in identifying the issue of limited novelty and the need for comparison, but it is not fully grounded as it does not specify the exact sections where this comparison should be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The reviewer provides a logical basis for the claim by noting that the idea, coattention mechanism, and architecture of the current paper are similar to those in the previous papers. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how the current paper lacks novelty. This would enhance the verifiability of the claim. As it stands, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty, suggesting that the idea, coattention mechanism, and architecture are similar to those in previous papers. It provides a basis for comparison by mentioning two specific papers (Xing and Tsang, 2022a, b), which could help the authors understand the context of their work. However, the comment lacks specific guidance on how the authors might address this issue or differentiate their work from the previous papers. While it highlights an area for improvement, the feedback is incomplete and does not offer actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare their model, CPEF, with another pretrained model, such as ExpertBert, to demonstrate the advantages of its pretraining module design. This recommendation is clear and provides a specific action for the authors to take, ensuring fairness in the comparison. The comment also explains why the current comparison is unfair, which helps the authors understand the reasoning behind the suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely that it is unfair due to the lack of a pretraining module in PMEF. The comment further recommends a fairer comparison with another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s pretraining module design. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pretraining module. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s pretraining module design. This claim is 3 as it provides a logical reasoning for the unfairness of the current comparison and suggests an alternative comparison. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Figure 3, where CPEF is compared to PMEF to demonstrate the advantages of the pretrained question representation model under data scarcity conditions. However, the comment points out that this comparison is unfair because PMEF lacks a pretraining module, which is a critical aspect of CPEF. The reviewer provides a constructive suggestion to address this issue by recommending a comparison with another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s innovative pretraining module design. This feedback is clear and actionable, offering the authors a specific path to improve the fairness and validity of their comparisons. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the attack methods used in the paper, labeling them as \"naive\" and suggesting that other classical attack methods in NLP should be considered. The reviewer provides an example of papers that could be referenced for alternative methods. While the comment implies that the authors should consider using more sophisticated attack methods, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the specific methods to consider, but it lacks directness in its instruction. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the attack methods used in the paper, specifically mentioning that they are \"naive\" and suggesting the use of more classical attack methods in NLP. However, it does not specify which part of the paper discusses these attack methods, making it weakly grounded. The comment is specific in suggesting the use of other attack methods and provides an example of papers to consider, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are \"naive\" and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example of papers that could be referenced for alternative methods, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of why the current attack methods are inadequate. Overall, the claim is 4, as it provides some justification but could benefit from additional evidence or explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by labeling the attack methods as \"naive\" and suggesting that more classical attack methods in NLP should be considered. It provides a specific example of papers that could be referenced for alternative methods, which is a constructive suggestion for improvement. However, the comment could be more helpful if it offered a detailed explanation of why the current attack methods are inadequate or how the suggested methods could enhance the paper. Despite this, the feedback is 4 as it directs the authors to consider more robust attack methods, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The reviewer asks the authors to clarify this point. Additionally, the comment suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. The feedback is explicit in asking for clarification and provides a specific issue to address, making it 4. The authors know exactly what needs to be clarified and can take concrete steps to address the confusion and the contradiction in the paper\"s motivation. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) and sections (lines 133136) of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of confusion regarding the relationship between uncertainty calibration and temperature calibration, particularly with the regularization term H. The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which seems contradictory. The comment also suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the paper to understand the context and the implications of this observation. Therefore, the comment is 3, as it provides a basis for further investigation but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically with the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which could be confusing. Additionally, the comment highlights a contradiction in the paper\"s motivation, as reducing entropy makes predictions more confident, which contradicts the goal of calibrating networks that are already overconfident. The reviewer provides specific lines of the paper where these issues are discussed, allowing the authors to clarify these points. This feedback is 4 as it identifies specific areas of confusion and provides clear guidance on how to address them, enabling the authors to improve the clarity and consistency of their draft. However, it could be more helpful if it offered suggestions on how to resolve the contradictions or clarify the relationships between these concepts. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an important reference that is missing from the paper, specifically mentioning the work \"Lista\" by Yann LeCun. It highlights the relevance of this reference to the idea of unrolling and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" This feedback provides a clear and concrete action for the authors to take, which is to include the missing reference and discuss its relevance to their work. The comment is 5 as it specifies exactly what needs to be done to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reference \"Lista\" and its relation to the idea of unrolling, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of this reference and a discussion of the similarities and differences between the proposed work and \"Lista.\" This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not provide specific details or examples of how the paper is related to \"Lista\" or why this reference is crucial. This lack of detailed justification makes the claim 3, as the authors would need to investigate the connection themselves to fully understand the importance of the reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the lack of reference to the work \"Lista\" by Yann LeCun, which is closely related to the idea of unrolling. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista\" to provide context. This feedback is clear and actionable, as it directs the authors to include a relevant reference and to discuss its implications. By addressing this gap, the authors can enhance the paper\"s context and relevance. However, the comment could be more helpful if it provided specific suggestions on how to integrate this reference or discuss the differences. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also provides specific details about the method used, which is padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment suggests that these decisions should be explained to readers without requiring them to check the code. This feedback is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the equation between lines 282 and 283,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of handling comparisons between episodes of different lengths and suggests that the authors should explain how they handle this in the paper. Additionally, it provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment also suggests that this decision should be explained to readers without requiring them to check the code. This level of detail and specific reasoning makes the claim 4, as it provides a clear explanation of the issue and its implications. However, the comment could be strengthened by referencing specific literature or studies that support the critique, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper regarding the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides detailed feedback by explaining the method used to handle this issue, such as padding the shorter sequence by replicating its last state, and notes the absence of a normalization factor of 1/T, which affects the distance calculation. The comment also suggests that these decisions should be explained to readers without requiring them to check the code. This level of detail and actionable feedback is highly valuable for the authors, as it guides them on how to clarify and improve their methodology. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the figures in the paper, specifically mentioning that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also notes that it is difficult to link the captions to specific parts of the main text. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to make the text larger, clarify the inputs and outputs, and improve the captions, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text size, unclear inputs and outputs, and nonselfcontained captions. Additionally, it highlights the difficulty in linking the captions to the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text size, unclear inputs and outputs, and nonselfcontained captions. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues. Therefore, the claim is considered 2, as it lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also points out the difficulty in linking the captions to certain parts of the main text. This feedback is clear and actionable, as it provides the authors with concrete areas to improve, such as increasing the text size, clarifying the inputs and outputs, and enhancing the captions. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of better practices. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also mentions recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback provides a clear and explicit action for the authors to take, which is to include GDSS as a baseline in Table 3 and consider the recent work as a potential baseline. The suggestion is concrete, as it specifies the action and provides a reference for further exploration. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. Additionally, it provides a reference to recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) in Table 2 and suggests that GDSS should be compared as a baseline in Table 3. The comment also references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This provides some support for the claim, as it references specific models and recent work. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the referenced work to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the continuous diffusion model (GDSS) outperforms the discrete diffusion model (DiGress) in Table 2. It recommends comparing GDSS as a baseline in Table 3, which is a conditional generation task. Additionally, the comment references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, suggesting this could be used as a baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft by incorporating GDSS as a baseline and considering the referenced work. However, the comment could be more helpful if it provided additional context or examples of how to implement this suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add a comparison against stateoftheart loss functions widely used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and concrete action for the authors to take, as it specifies exactly which loss functions should be included in the comparison. The comment is 5 because it gives the authors a direct and detailed instruction on how to enhance their draft.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. While it does not explicitly mention a specific section of the paper, the authors can infer that this suggestion relates to the experimental or results sections where comparisons are typically discussed. The comment is specific in detailing the loss functions that should be included in the comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, specifically mentioning CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides a clear suggestion for improvement by naming specific loss functions that should be considered. However, the comment lacks detailed reasoning or examples of why these loss functions are relevant or how they compare to the current methods used in the paper. Providing more context or explanation would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that the authors should consider including in their comparison. By addressing this suggestion, the authors can enhance the comprehensiveness and validity of their study by demonstrating how their approach compares to established methods. However, the comment could be more helpful if it offered additional context or rationale for why these specific loss functions are relevant or how they relate to the paper\"s focus. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer provides a clear action for the authors to take by suggesting that they should clarify the reference to avoid confusion. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reference to \"PointNet\" and provides a clear suggestion to clarify the reference to avoid confusion. The comment further specifies the issue by mentioning another paper with the same name, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to 15 as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to the other paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas, which supports the claim. This detailed reference helps to clarify the confusion and provides a clear basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, pointing out that the name does not appear in the paper and is confused with another paper. The reviewer provides a clear suggestion to clarify the reference by mentioning the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is actionable and provides a precise way for the authors to improve their draft by ensuring accurate referencing. The comment is 5 as it offers a direct and constructive suggestion that can significantly enhance the clarity and accuracy of the paper. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) with errorbars. It also emphasizes the importance of providing statistics due to the small size of the models. This feedback is clear and provides specific guidance on what the authors need to do to improve their draft. The action is explicit and concrete, leaving no ambiguity about how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results comparing standard vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting the results as a mean over many runs (at least 10) with errorbars, and justifying the need for statistics due to the small size of the models. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars to account for potential fluctuations. The reviewer argues that the models are small, making it necessary to provide statistics. This claim is supported by logical reasoning, as it highlights the importance of statistical analysis for small models to ensure reliability. However, the comment could be strengthened by providing specific examples or references to similar practices in the field. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed examples or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback regarding the presentation of results. It suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars to account for potential fluctuations. This is a clear and constructive suggestion that can help the authors improve the robustness and clarity of their results. By addressing this feedback, the authors can enhance the reliability and interpretability of their findings. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is important for the specific context of the paper. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this information is important, explaining its potential impact on training and inference speeds. Therefore, the comment is 5, as it provides a specific and concrete action for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically referencing the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment and its potential impact on training and inference speeds. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the logical reasoning that different versions of the experimental environment can affect training and inference speeds. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this detail and how it might impact their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, such as the CUDA and PyTorch versions. This feedback is clear and actionable, as it highlights a potential source of variability in the results that could impact training and inference speeds. By addressing this point, the authors can enhance the reproducibility and robustness of their study. However, the comment could be more helpful if it provided additional context or examples of how different versions might affect the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or concrete steps for improvement, the authors are left without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to specific sections or elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 as it does not identify a specific area of the paper, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the paper\"s strength, specifically questioning whether it is suitable for ICLR. However, it lacks any supporting evidence, reasoning, or examples to justify this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s doubt. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what changes are needed to enhance their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not offer any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to address the issue of reproducibility and the significance of improvements. It references a community effort towards reproducibility and suggests that this should be considered in the paper. The comment explicitly states the action of running multiple experiments and reporting statistics, providing a clear and concrete direction for the authors to follow. However, it does not specify which experiments should be run multiple times or how to report the statistics, which could be considered a minor limitation. Overall, the comment is 5 as it provides a direct and concrete action for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of reproducibility and the need for running multiple experiments and reporting statistics. The reference to a community effort towards reproducibility and the suggestion to consider this in the paper further enhance the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that experiments in deep reinforcement learning should be run multiple times to address issues of reproducibility and the significance of improvements. It references a community effort towards reproducibility and cites a specific paper, \"Deep reinforcement learning that matters\" by Henderson et al. (2018), as evidence. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific statistics on how running multiple experiments would improve reproducibility. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It suggests that running multiple experiments and reporting statistics is crucial for addressing these concerns. The comment also references a community effort towards reproducibility, providing a specific reference to a paper that highlights the importance of this issue. This feedback is 5 as it provides clear and actionable guidance on how to improve the reproducibility and significance of the experiments in the paper. By suggesting a specific approach and referencing relevant literature, the comment empowers the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not significantly differentiate between idiomatic and random data, as indicated by Figure 3. The comment implies that the results do not demonstrate the idiomspecificity of the proposed methods, instead suggesting that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs. random data is similar for most language and score combinations. The comment further specifies that the results do not demonstrate idiomspecificity, suggesting that better NMT systems are also better at idiomatic translations. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not demonstrate idiomspecificity, as the impact on idiomatic vs. random data is similar for most language and score combinations. The comment supports this claim by referencing Figure 3, which provides visual evidence of the similarity in impact. However, the comment could be strengthened by providing more detailed analysis or examples from the figure to fully substantiate the claim. Overall, the claim is 4, as it is supported by a reference to a specific figure, but it lacks additional detailed evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a critical evaluation of the proposed upweighing and KNN methods, suggesting that they do not demonstrate idiomspecificity. It points out that the impact of these methods on idiomatic vs. random data is similar for most language and score combinations, as shown in Figure 3. This observation leads the reviewer to conclude that the results simply indicate that better NMT systems are also better at idiomatic translations. While the comment identifies a potential weakness in the paper, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their methods. The feedback is 3 as it highlights a critical area for improvement but lacks actionable advice, making it incomplete for the authors to fully address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC in both language and vision tasks. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This feedback implies that the authors should include a direct comparison of test accuracy to demonstrate whether their approach is an improvement over the baseline. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a direct comparison but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that there is a lack of direct comparisons between the proposed approach and the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This claim is 3 as it highlights a gap in the evaluation process, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The comment points out the absence of direct comparisons, which is a valid observation, but it does not provide enough evidence or references to fully support the claim of a lack of improvement over the baseline. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy, which is crucial to determine if the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to substantiate their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method or address this issue. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this critique is based on. It lacks grounding as it does not identify a particular section, figure, or table where this issue is discussed. Additionally, the comment is not specific, as it does not provide details on what aspects of the improvement are considered unimpressive. Without clear guidance on where to address the issue or what specific aspects need improvement, the authors are left without a clear path for revision. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or comparisons to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the improvement of the proposed method over existing RL methods, suggesting that it is not impressive. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might enhance their method or address the perceived lack of improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what changes could be made to improve their work. As a result, the comment is 1, as it does not offer any constructive feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors provide a plot of the model illustration, pseudocode table, or code repository to clarify the model design and learning details. It also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2 Unclear model design,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the model architecture and learning details are fragmented or missing, and suggests providing a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details. It suggests providing a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility, especially since Neurochaos Learning is not a wellknown method. The comment provides a logical reasoning for the need to clarify the model design and learning details, which is a common practice in scientific publications. However, it lacks specific examples or references to support the claim that Neurochaos Learning is not wellknown, which would strengthen the argument. Therefore, the comment is 4, as it provides a clear rationale but could benefit from additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides actionable suggestions by recommending the inclusion of a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility. Additionally, the comment highlights the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is clear and constructive, offering specific ways for the authors to improve the transparency and reproducibility of their work. By addressing these points, the authors can significantly enhance the comprehensibility and credibility of their draft. Therefore, the comment is 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with pruning in large networks, specifically mentioning the need to consider global top Q values of the metric over the average of gradients. It suggests that this could break acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this aspect further but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning majorly works with large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on finding global top Q values of the metric over the average of gradients, which could potentially break acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks, which are typically trained in distributed settings, and suggests that the authors should consider the global top Q values of the metric over the average of gradients. The comment further implies that this consideration could break acceleration techniques like quantization and sparsification. However, the review does not provide specific examples, references, or detailed reasoning to support these claims, making it 3. The authors would need to infer the importance of this consideration and its potential impact on acceleration techniques. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of pruning in large networks, specifically highlighting the need to consider global top Q values of the metric over the average of gradients. It suggests that this consideration could break acceleration techniques like quantization and sparsification. While the comment points out a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or incorporate the necessary considerations into their work. The feedback is 3 as it prompts the authors to explore this aspect further, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it implies that the authors should verify this, it does not provide explicit instructions on how to check or correct the figures. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially correct the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also clearly specifies the issue by questioning whether some subfigures have been swapped by mistake. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question asking if some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the potential swapping of subfigures in Figs 1 and 2. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might verify or address this concern. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 1, as it does not contribute to the authors\" understanding of how to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifically mentions issues with the abstract font size and bottom page margins. The reviewer suggests that by fixing these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as ensuring the paper adheres to the NeurIPS formatting guidelines and adjusting the font size and margins accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the abstract font size and the bottom page margins, which are clear indicators of the parts of the paper being addressed. It also provides specific guidance on how to address these issues, such as ensuring the paper follows the NeurIPS formatting style and gaining space to include NLP experiments in the main body. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the formatting issues. The suggestion to fix the formatting to include NLP experiments in the main body is logical but lacks detailed justification or evidence. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It highlights two specific problems: the abstract font size is too large and the bottom page margins are altered. The reviewer suggests that by correcting these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with a concrete step to improve the presentation of their work. However, the comment could be more helpful if it offered additional guidance on how to ensure the paper adheres to the NeurIPS style or provided examples of how to adjust the formatting effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include a discussion and comparison of these methods, but it lacks concrete details on how to execute this action. The authors can infer that they need to add a section discussing these methods, but the comment does not specify which methods to include or how to compare them. Therefore, the comment is 3, as it provides an implicit action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the issue with the paper\"s coverage of exploration methods, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the relevance of these methods and their potential impact on the paper\"s soundness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors should include a discussion and comparison of these methods to enhance the paper\"s soundness. However, the comment lacks specific guidance on how to incorporate these methods or which aspects to focus on, which limits its helpfulness. To be more helpful, the comment could provide examples or suggestions on how to integrate these methods into the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit suggestions, it does not fully specify how to implement these suggestions, such as whether the brackets should be added in a specific place or how the term should be defined separately. The action is mostly concrete, as the authors know what needs to be done, but it lacks detailed guidance on execution. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the clarity of the definition, such as adding an extra pair of brackets or defining the bracketed term separately. This level of detail helps the authors understand what needs to be addressed and how to make the necessary changes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets or defining the bracketed term separately. However, the comment does not provide any reasoning or evidence to support why the current definition is confusing or how the suggested changes would improve clarity. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the quantile, noting that it is \"a little confusing.\" It provides two actionable suggestions to improve clarity: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. These suggestions are clear and offer concrete ways for the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a redundancy in RQ1, suggesting that it does not add any new information for the audience. It implies that the authors should consider analyzing the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. While the comment suggests an alternative analysis, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore this new analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with RQ1, stating that it adds no extra information for the audience and suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The reference to a specific paper (\"https://aclanthology.org/2023.findingseacl.9/\") provides additional context and supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and does not add new information for the audience. It suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The comment provides a reference to a specific paper, which could support the suggestion for an alternative analysis. However, the claim about RQ1 being redundant lacks detailed reasoning or evidence, making it 3. The authors would need to consider the context and the referenced paper to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a redundancy in RQ1, suggesting that it does not provide any additional information for the audience. It implies that the performance variation across multiple HS datasets in a crossdata setting is expected and therefore not novel. The comment also offers a constructive suggestion for an alternative analysis, focusing on the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. However, it could be more helpful if it included specific guidance on how to implement this new analysis or examples of how to incorporate the suggested perspective. Overall, the comment is 4, as it effectively points out a potential area for improvement and offers a valuable suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. It also specifies that the authors should mention the existing work 12 and its relation to their framework. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and lines 2930, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the distinction between the proposed solution being a \"fix\" of an existing work rather than a new approach. Additionally, it points out the need to mention the existing work 12 and its relation to the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors must clarify in the introduction that their proposed solution is a \"fix\" of an existing work, rather than a new approach. The reviewer supports this claim by referencing specific lines in the paper (2930) and mentioning the existing work 12. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the existing work relates to the authors\" framework. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by pointing out a potential confusion in the introduction. It highlights that the authors need to clarify that their proposed solution is a \"fix\" of an existing work, rather than a new approach, as initially introduced. This feedback is specific and helps the authors avoid misrepresenting their contribution. By suggesting that the authors should mention the existing work 12 and its relation to their framework, the comment offers a concrete step for improvement. However, it could be more helpful if it provided additional context or examples of how the existing work relates to the authors\" framework. Overall, the comment is 4 as it directs the authors to a critical area for clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. While it does not explicitly instruct the authors to address these questions, it implies that the authors should provide a rationale or explanation for this combination. The action is implicit, as the authors need to infer that they should clarify the reasoning behind the combination. However, the comment is 3 because it provides a clear direction for the authors to follow, even if it does not specify exactly how to address the questions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. However, it does not specify which part of the paper discusses this combination, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the rationale and requirements, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the rationale behind combining G4RL with HRAC (HRACG4RL) and whether G4RL requires HRAC\"s regularization in the latent space. This feedback is 3 as it prompts the authors to clarify their methodology and provide a clear explanation for the combination. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address these questions, which would make it more actionable. The authors are left with a general direction to explore but without detailed steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two specific comparisons that the authors should make: one with NeRFbased methods, such as Zero1to3, and another with pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be relevant to the method being proposed. While the comment implies that these comparisons and the evaluation of the occlusion experiment are necessary, it does not provide explicit instructions on how to conduct these comparisons or why the occlusion experiment is not relevant. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take and the reasoning behind the suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not specify which part of the paper these suggestions should be made in, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting comparisons and questioning the relevance of the occlusion experiment, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. The lack of specific examples or references makes the claim 3, as the authors would need to infer the importance of these comparisons and the relevance of the occlusion experiment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment highlights areas for improvement, it lacks depth and does not provide detailed guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out potential areas for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take: they need to include a discussion on how to set \u03b3 and its sensitivity. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion on arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion on how to set \u03b3 in practice for a given graph and an analysis of its sensitivity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which would make it difficult for researchers to follow. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why this discussion is crucial. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of discussing \u03b3 and its sensitivity based on general knowledge of hyperparameter tuning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion regarding the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs attention to enhance the comprehensibility and usability of the paper for researchers. By addressing this gap, the authors can provide valuable insights and practical advice, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. While the comment implies that the authors should focus on prompt design and discuss its effectiveness, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the discussion on prompt design without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. However, the comment does not specify which part of the paper should focus on prompt design or provide specific guidance on what aspects of prompt design need more emphasis. While the authors can infer that the discussion on prompt design should be enhanced, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. However, the comment lacks specific examples or detailed reasoning to support the claim that prompt design is a critical area for improvement. The suggestion is 3, as it provides a logical basis for the claim, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should place more emphasis on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to effectively design prompts. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent percentage errors or percentage correct values. This feedback provides a clear and direct action for the authors to take, ensuring that the legends are more informative and accurate. The comment is specific and concrete, offering a straightforward path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This is a factual statement requesting clarification, as it does not express an opinion or judgment that requires verification. It is purely descriptive and does not contain any subjective claims or suggestions that need justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct values. This feedback is clear and directly addresses a potential issue with the clarity and interpretability of the tables, which is crucial for readers to understand the results. By following this suggestion, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it included examples or further guidance on how to enhance the legends. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the concept of energy is introduced in Section 3.1, it would be beneficial to refresh the idea in Section 5.2, where it is used multiple times. The reviewer also suggests providing hints on how to interpret energy, such as its relation to splitting morphemes. Additionally, the comment points out that the concept of peak in Figure 5 is not described. These suggestions are explicit and provide concrete guidance on how to improve the draft by clarifying the use of energy and peak in the paper. The authors know exactly what actions to take to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing hints on how to interpret it. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy should be refreshed in Section 5.2, where it is used multiple times, and provides a hint about how to interpret it. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies areas for improvement, it lacks specific reasoning or evidence to support why these aspects are important or how they impact the paper. The suggestion is logical but not fully substantiated, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it suggests refreshing the concept of energy in Section 5.2, where it is used multiple times, and provides a hint on how to interpret it, such as its relation to splitting morphemes. Second, it points out that the concept of peak in Figure 5 is not described. These suggestions are clear and actionable, offering the authors concrete ways to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the coherence and readability of their work. Therefore, the comment is 4, as it provides valuable feedback that can guide the authors in refining their manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text, rather than human reading comprehension. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on what needs to be changed, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should be clarified to distinguish between machine comprehension of text and human reading comprehension. The comment provides a clear direction for improvement by suggesting how to clarify the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to distinguish between machine comprehension of text and human reading comprehension. The reviewer provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" typically refer to human reading abilities, not machine comprehension. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it could be clarified to distinguish between machine comprehension of text and human reading comprehension. This is a clear and actionable piece of feedback that can help the authors improve the clarity and specificity of their title. By addressing this issue, the authors can ensure that their work is accurately represented and understood by the intended audience. However, the comment could be more helpful if it provided additional suggestions or examples on how to rephrase the title for better clarity. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific claim made by the authors on line 238 regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. However, it does not provide any guidance or suggestions on how the authors should address these inaccuracies or improve their understanding of the CLT. The comment lacks explicit or implicit actions, leaving the authors without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made about the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides a detailed explanation of the inaccuracies, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Central Limit Theorem (CLT) is incorrect. It provides a clear explanation of why the statement is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and wellsupported, making the claim 5. The reviewer provides specific details to substantiate the claim, ensuring that the authors understand the basis of the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. It provides a clear explanation of why the claim is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is 5 as it directly addresses a critical error in the paper, allowing the authors to correct their understanding and presentation of the CLT. However, the comment could be more helpful if it offered suggestions on how to correct the statement or provided additional context for the authors to better understand the issue. Nonetheless, the comment is 5 and provides significant value to the authors, making it a 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for results and the limited evaluation on only two datasets, which are standard in the RNP community. It provides specific references to external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing, such as confidence intervals and additional datasets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes the limited evaluation on only two datasets, which are standard in the RNP community. The comment supports its claim by referencing external works, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. These references provide a basis for the claim that the evaluation should include more datasets and confidence intervals. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of confidence intervals affects the interpretation of results. Overall, the claim is 4, as it provides some support but could be further substantiated with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as 1 DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, 2 Controlling Selection Bias in Causal Inference. AISTATS 2012, 3 An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and 4 On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. This feedback is clear and actionable, as it directs the authors to include confidence intervals and evaluate on more datasets, potentially using the referenced works as benchmarks. However, the comment could be more helpful if it provided specific guidance on how to incorporate these elements or suggested additional datasets for evaluation. Overall, the comment is 4, as it offers valuable insights and references for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable steps or suggestions, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors might investigate this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is a relevant concern for the authors to address, as it could impact the practical applicability and robustness of their approach. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or address this issue. Without actionable feedback or detailed advice, the authors are left with a general area for improvement but without a clear path forward. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~1 and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this limitation or explore new applications. The action is implicit and somewhat vague, as it lacks concrete steps or detailed advice on how to implement the suggested exploration. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in applying the method to general MDPs, specifically mentioning navigation problems. It also references PRMRL~1 as a related work that has already discussed combining RL and planning. However, the comment does not specify which part of the paper discusses the method or where the limitation is explicitly stated. While it provides some context and references, it lacks full grounding as it does not explicitly mention sections or figures. The comment is specific in suggesting the exploration of more general tasks, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems, suggesting that combining RL and planning has already been discussed in PRMRL~1. The comment provides a reference to a specific work, which supports the claim by indicating that the idea is not novel. However, the comment could be strengthened by providing more detailed reasoning or examples of how the paper\"s contribution differs from or builds upon PRMRL. This would enhance the verifiability of the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional supporting details.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s scope, noting that the method discussed is primarily applicable to navigation problems and suggests that it could be more broadly applicable. It also references a related work, PRMRL~1, which has already discussed combining RL and planning. This feedback is 3 as it points out a potential area for expansion and provides a reference for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to broaden the application or integrate the ideas from PRMRL into the paper. Overall, the feedback provides some direction but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a specific suggestion to avoid this issue by individually standardizing feature dimensions. This feedback is explicit and concrete, as it clearly identifies the potential problem and offers a direct solution. The authors know exactly what needs to be done to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces being wellsuited for 1NN and provides a suggestion to avoid potential performance issues by individually standardizing feature dimensions. This level of detail guides the authors on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification, suggesting that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a logical reasoning by explaining the potential issue and offering a suggestion to avoid it by individually standardizing feature dimensions. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a constructive suggestion to avoid this issue by individually standardizing feature dimensions. This feedback is clear and actionable, offering the authors a specific way to improve their work by addressing a potential limitation. However, the comment could be more helpful if it provided additional context or examples to further illustrate the issue and its implications. Overall, the comment is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two actions: first, to include the bottomup method 9 in the tables, and second, to evaluate the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. The first suggestion is concrete, as it specifies the inclusion of a particular method in the tables, and the second is also concrete, as it outlines a specific evaluation to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the bottomup method 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, including the bottomup method in the tables and evaluating the performance on the standard MS coco dataset. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method 9 has reported results on the crowdpose dataset that outperform all methods in Table 4, even when using a ResNet50. It recommends including this method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. The claim is 3 as it provides a specific reference to the bottomup method 9 and suggests a comparison with the paper\"s results. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method 9 in the tables, as it has reported results outperforming all methods in Table 4, even with a ResNet50. This recommendation is clear and could help the authors improve the comprehensiveness of their results. Additionally, the comment suggests evaluating the performance of their method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This suggestion is also constructive, as it encourages the authors to consider a broader evaluation context. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these suggestions or why they are important. Overall, the feedback is 4, as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides an example from the TACRED slot filling guidelines, highlighting the depth of annotation guidelines in the IE domain. While the comment raises a concern about the paper\"s claim, it does not provide explicit guidance on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claim and possibly expand their annotation guidelines. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim of making use of \u201cannotation guideline\u201d\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing in the paper\"s claim, namely the depth of true guideline understanding, and provides a reference to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s use of \"annotation guidelines\" may be an overstatement, as it only considers label name, label description, and fewshot examples, whereas annotation guidelines in the IE domain are more complex and curated by linguists. The reviewer supports this claim by providing a specific example from the TACRED slot filling guidelines, which demonstrates the depth of annotation guidelines. This example provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by further elaboration or references to other examples or studies that highlight the complexity of annotation guidelines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides a specific example from the TACRED slot filling guidelines, which highlights the depth of annotation guidelines in the IE domain. This feedback is valuable as it prompts the authors to reconsider their claim and potentially expand their annotation guidelines to better align with the complexity of the domain. However, the comment could be more helpful if it offered suggestions on how to enhance the annotation guidelines or provided additional examples to support the claim. Overall, the comment is 4 as it identifies a potential weakness and provides a specific example for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. While it implies that the authors should consider this scenario, the comment does not provide any explicit guidance or suggestions on how to address it. The action is implicit and vague, as the authors are left to infer that they should explore this scenario but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving CAD models and BRDF maps. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. While it identifies a potential area of interest, it lacks depth and does not provide any guidance or suggestions on how the authors might address this scenario or its implications. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This is a clear and direct action that provides specific guidance on what needs to be done to improve the draft. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of the evidence for the motivation being indirect and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. While it does not explicitly mention a specific section or figure, the authors can infer that it relates to the introduction or motivation section, where the problem is described. The comment is specific in suggesting a particular type of figure that could support the claim, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. This claim is 3 as it provides a logical reasoning for why the evidence is lacking and offers a specific suggestion for improvement. However, the comment could be strengthened by providing examples or references to similar studies that have successfully demonstrated this decline in accuracy. Without these additional details, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence provided for the motivation, noting that it is not direct. It suggests a concrete action for the authors to take by recommending that they plot a figure showing the decline in accuracy of a predictor over time in different settings. This feedback is clear and actionable, providing the authors with a specific way to enhance the evidence supporting their claim. By addressing this suggestion, the authors can strengthen their argument and improve the clarity of their draft. Therefore, the comment is rated as 4, as it offers a constructive and actionable piece of feedback that can significantly enhance the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It questions the positivity of excessive risk values in Figures 3 and 7 and asks if these values are comparable across different groups. The comment explicitly requests explanations and justifications for these aspects, providing clear guidance on what the authors need to address. The feedback is explicit and concrete, as it specifies the areas that require clarification and provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the definition of excessive risk, its calculation in practice, and the representation of fairness. The comment raises questions about the positivity of excessive risk values and their comparability across different groups, providing clear guidance on what aspects need clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It questions the positivity of excessive risk values in Figures 3 and 7 and asks if these values are comparable across different groups. While the comment highlights areas that require clarification, it does not provide specific evidence, examples, or references to support the claims. The lack of detailed reasoning or supporting information makes the claims 3, as the authors would need to infer the basis of the questions and address them accordingly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It questions the positivity of excessive risk values in Figures 3 and 7 and asks if these values are comparable across different groups. The comment also requests clarification on how to calculate excessive risk in practice and why it is a good representation for fairness. These questions and requests for clarification are actionable and provide the authors with specific areas to address in their draft. By addressing these points, the authors can improve the clarity and comprehensiveness of their work. Therefore, the comment is 4, as it offers clear guidance for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations for occluded objects and the handling of uncertainty in amodal predictions. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide more detailed information on the motivation and potential applications of the work, as well as how uncertainty is handled. However, the lack of specific guidance makes the action vague, aligning with a score of 2.", "grounding_specificity_rationale": "The comment raises concerns about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not specify which part of the paper discusses the motivation or the potential applications, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the motivation section might be the relevant part, the comment lacks full grounding. It is specific in detailing the concerns about the motivation and potential applications, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a critical concern about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions, which is a valid point that could impact the validity and applicability of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their motivation. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take to address the comment. The feedback is concrete, as it specifies exactly what the authors need to provide to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors,\" which clearly specifies what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that requires clarification. By asking for examples of \"unreliable neighbors,\" the reviewer highlights a potential gap in the explanation or evidence provided in the paper. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or provide examples themselves. While it points out a specific area for improvement, it does not provide detailed guidance or actionable steps for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this concern. It lacks guidance on how the authors might address the issue or improve the practicality of their work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practicality of the paper\"s approach, which relies on known causal relationships between features. However, it does not specify which part of the paper this concern is related to, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the reliance on prior knowledge and the potential inaccuracies for specific subpopulations, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning by explaining the potential limitations of relying on prior knowledge and the common practice in the field. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this perspective and potentially address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. This feedback is 3 as it points out a potential limitation of the proposed method and encourages the authors to consider the practical implications of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the practicality of their work. While it provides some insight into a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point simply states that the contrastive learning framework is the same as SimCLR, without providing any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this observation or improve their work. As a result, the comment is 1, as it does not offer any direction for the authors to enhance their draft.", "grounding_specificity_rationale": "The comment claims that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this claim is being made. Additionally, the comment lacks specificity regarding what aspects of the framework are identical or how this similarity affects the paper. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment simply states that the contrastive learning framework is the same as SimCLR without providing any context, explanation, or suggestions for improvement. It lacks depth and does not offer any actionable feedback or guidance for the authors to enhance their draft. Without specific details or examples, the comment does not help the authors understand the implications of this observation or how to address it. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides a specific and explicit suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two separate tables, one for each measure (SFII and SPDI), to enhance clarity. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. The suggestion is explicit and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for each measure (SFII and SPDI). This detailed guidance helps the authors understand exactly what needs to be addressed to enhance the clarity of their presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. The reviewer provides a specific example of how this could be done, suggesting that the 8 SFII columns and 8 SPDI columns be separated. This suggestion is based on a logical reasoning that separating the measures would improve the clarity and readability of the tables. However, the comment does not provide any additional evidence or references to support the claim that this would be beneficial. Therefore, the claim is 4, as it provides a clear suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that each table be split into two, with one table per measure (SFII and SPDI), the reviewer offers a clear and concrete way for the authors to enhance the clarity and organization of their data presentation. This feedback is valuable as it directly addresses a potential issue with the current format of the tables, providing the authors with a straightforward path to improve the readability of their work. Therefore, the comment is rated as 5, as it offers detailed and actionable guidance that can significantly enhance the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors could improve their paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method, implying that the authors should provide a more detailed and structured comparison. While the comment is explicit in its suggestion, it lacks concrete guidance on how to implement this improvement, such as suggesting specific metrics or analysis techniques to use. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Originality\" and references the work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic by comparing the best performance of each method. This provides clear guidance on what the authors should focus on to enhance their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the closely related work of Zemel et al. (2013) more systematic. It suggests comparing the best performance of each method, which is a logical and reasonable suggestion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact improvements needed based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It recommends comparing the best performance of each method, which is a clear and actionable piece of feedback. This guidance can help the authors enhance the clarity and depth of their comparisons, making the paper more comprehensive and easier to understand. However, the comment could be more helpful if it included additional details or examples on how to structure these comparisons effectively. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to \"explicitly estimate the time complexity of the learning algorithm\" to prove the scalability properties. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the time complexity is discussed. Without explicit references, the authors may find it challenging to identify the exact area needing revision. The comment is specific in its request for estimation of time complexity but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This claim is 3 as it provides a logical reasoning for why estimating time complexity is important for assessing scalability. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the context and the expected outcome of estimating time complexity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This is a clear and actionable suggestion that can help the authors enhance the rigor and clarity of their work. By addressing this point, the authors can provide a more comprehensive understanding of their algorithm\"s scalability, which is crucial for readers and potential users. However, the comment could be more helpful if it provided additional guidance on how to estimate the time complexity or examples of similar approaches that have done so. Overall, the comment is 4 as it directs the authors to a significant improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit guidance on how the authors should improve the clarity of the discussion. There is no suggestion on what specific aspects need to be expanded or clarified, nor are there any concrete steps offered for enhancing the explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion around this equation, noting that it is \"very terse\" and \"not very clearly explained.\" This provides clear guidance on what needs to be improved. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and \"not very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is \"very terse\" and \"not very clearly explained.\" This feedback is clear and actionable, as it directs the authors to expand and clarify their discussion around this equation. However, the comment could be more helpful if it provided specific suggestions on how to enhance the clarity or offered examples of what additional information could be included. Despite this, the comment still provides valuable guidance for improving the draft, making it 4."}
