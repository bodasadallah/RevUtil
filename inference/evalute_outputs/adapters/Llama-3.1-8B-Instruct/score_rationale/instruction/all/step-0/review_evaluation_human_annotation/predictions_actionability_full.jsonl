{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the dataset, suggesting that it may contain noise due to its artificial creation. The reviewer notes that the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. While the comment identifies a concern, it does not provide explicit guidance on how the authors should address this issue. The suggestion to analyze the quality of the dataset and the amount of noise it contains is implicit, and the authors would need to infer that they should conduct additional analysis to address this concern. However, the comment lacks concrete details on how to conduct this analysis or what specific aspects to focus on. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the quality of the dataset, specifically mentioning that it is artificially created and may contain noise. It provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. However, it does not explicitly mention which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the dataset\"s quality and potential noise. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. This example provides a logical reasoning for the claim, making it 3. However, the comment could be strengthened by including references to similar issues in other datasets or studies, which would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and outofcontext images. This feedback is valuable as it highlights a critical aspect of the dataset that could impact the validity of the results. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as proposing methods to evaluate the dataset\"s quality or suggesting ways to mitigate the impact of noise. Despite this, the comment provides a clear direction for the authors to consider, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what aspects of the theory should be explored or how to demonstrate convergence properties. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, it does not specify which part of the paper this issue pertains to, such as a particular section or chapter where theoretical analysis is expected. Without explicit references or clear indications of where the authors should focus their efforts, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the theory should be explored or how to demonstrate convergence properties. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks an indepth exploration of the theoretical properties of the proposed algorithm, specifically regarding convergence. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks an indepth exploration of the theoretical properties of the proposed algorithm, particularly regarding convergence. This is a critical area for improvement, as understanding the theoretical foundations of an algorithm is essential for its validation and potential adoption. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap, such as recommending particular theoretical frameworks or methods to explore. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in resolving it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. While the comment does not explicitly instruct the authors to include these operators or explain their reasoning, it implies that the authors should provide a justification for their choice. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why certain operators were chosen over others. However, the comment provides a clear direction for the authors to consider alternative operators and their implications, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators and suggests considering the \"and\" operator or elementwise max, providing a clear direction for improvement. The comment explains the reasoning behind the suggestion by relating it to the concepts of union and intersection, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. The reviewer provides a logical reasoning by relating the \"and\" operator to the concept of union and intersection, suggesting that these operators might be more appropriate. However, the comment lacks specific examples or references to support the claim that these operators are better options. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the choice of operators used in the paper, specifically asking why the \"and\" operator or elementwise max were not considered. It provides a logical connection by relating these operators to the concepts of union and intersection, which could be relevant to the paper\"s context. This feedback is 3 as it prompts the authors to consider alternative operators and their implications, potentially leading to a more comprehensive analysis or discussion in the paper. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how the \"and\" operator or elementwise max could be applied. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the description of HIERENC and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify the description or address the potential issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the description and potentially reconsider their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the description of HIERENC, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the description, namely that the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary may introduce a lot of noise. The comment provides a detailed critique of the method, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment lacks specific examples or references to support the claim that this approach is problematic. The reasoning is somewhat logical, but it is not fully developed, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, questioning the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. This feedback is clear and highlights a potential weakness in the methodology, prompting the authors to reconsider their approach. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative methods. Overall, the comment is 3 as it directs the authors to a specific area needing clarification or improvement, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it implies that the authors should provide a justification or explanation for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the rationale behind this selection, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this selection is discussed. Without explicit references or context, the authors may find it challenging to determine where to address this concern. The comment is specific in its inquiry but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the rationale behind selecting 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain a claim or opinion that requires verification. It is a factual inquiry, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. By asking for a justification of this selection, the reviewer prompts the authors to clarify their methodology and its implications. This feedback is clear and actionable, as it encourages the authors to provide a rationale for their choice, which could lead to a more comprehensive understanding of their results. However, the comment could be more helpful if it suggested specific aspects to consider or potential alternatives. Overall, the comment is 4 as it directs the authors to address a critical aspect of their methodology, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data used. It suggests that the authors should clarify the description by mentioning Li et al. (2019a) earlier, which would make the text more precise and clear. This feedback provides a specific action for the authors to take, namely revising the description to include the earlier mention of Li et al. (2019a). The suggestion is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) where the issue is identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It is also specific because it details the inconsistency regarding the source of the data and suggests a revision to clarify the description by mentioning Li et al. (2019a) earlier. This provides clear guidance on what needs to be addressed to improve the clarity and precision of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential inconsistency in the paper regarding the source of the data used. It suggests that the authors should clarify the description by mentioning Li et al. (2019a) earlier. The comment provides a logical reasoning for the revision, pointing out the discrepancy between the lines mentioned and the need for clarity. However, it does not provide specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the source of the data used. It points out that the text seems to suggest that the authors selected sentences from raw data, but later mentions that the data already has syntactic information. The reviewer suggests revising the description to clarify this by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their paper. By addressing this inconsistency, the authors can enhance the readability and accuracy of their work. Therefore, the comment is 4, as it offers constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. While the comment implies that the authors should provide an explanation for the average duration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for clarification on whether it includes time spent by the user waiting for the model to generate a response. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the purpose of the average duration reported in Table 1, which is not clearly explained in the paper. It also asks whether this duration includes time spent by the user waiting for the model to generate a response. This feedback is 3 as it identifies a potential area of confusion in the paper and prompts the authors to clarify the explanation. However, it does not provide specific guidance on how to address the issue or suggest ways to improve the clarity of the explanation. Therefore, the comment is rated as 3, as it points out a need for clarification but lacks depth in terms of actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification regarding the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it specifies exactly what needs to be clarified. The comment provides a clear and actionable instruction, ensuring that the authors know exactly what to address in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting clarification on the splits used for obtaining the ATIS numbers in Table 4. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the understanding and reproducibility of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information. Overall, the comment is 4 as it guides the authors toward improving the clarity of their work, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" The reviewer suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance. However, the comment does not provide explicit guidance on how to correct this issue or suggest alternative wording. While the action is implicit, it is 3 as it points out a potential problem that the authors should address, even if the exact steps to take are not fully outlined. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"l.791\") where the issue is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias in the wording used to describe performance, suggesting that \"on par or better\" might be misleading. The comment provides a clear suggestion for improvement by recommending a correction in the wording. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to label instances where they perform worse as \"on par\" and instances where they perform better as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and evidence presented to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" It suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance, where instances of worse performance are labeled as \"on par\" and better performance is labeled as \"better.\" This feedback is 3 as it points out a potential problem with the language used in the paper, but it does not provide specific guidance on how to correct this issue or suggest alternative wording. While it highlights an area for improvement, the comment could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. However, it does not provide any explicit or implicit actions for the authors to take. The questions are more about seeking clarification rather than suggesting changes or improvements to the draft. As a result, the comment lacks actionable guidance for the authors, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the interpretation of results, specifically regarding the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the interpretation of results presented in Table 3. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises specific questions about the interpretation of results presented in Table 3, seeking clarification on the comparison of NVSB to GT Mel A for Chinese MOSQ and the overlap of 95% CI between Baseline and NVSB for Chinese and English MOSV. While it identifies areas that need further explanation, it does not provide suggestions or guidance on how the authors might address these questions or improve the clarity of their results. The feedback is 3 as it points out areas of confusion, but it lacks actionable advice or depth, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This inconsistency affects the appearance of the tables. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting a consistent formatting approach or offering examples of how to standardize the layout. The action is implicit and somewhat vague, as the authors can infer that they need to standardize the formatting but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects their appearance. This provides clear guidance on what needs to be addressed to improve the presentation of the data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the inconsistent spacing between accuracy and standard deviation in Tables 2 and 3 affects the appearance of the tables. However, it does not provide any reasoning or evidence to support why this inconsistency is problematic or how it impacts the reader\"s understanding of the data. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation affects the appearance of the tables, which is an important aspect of presenting data effectively. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting approach or offering examples of how to standardize the layout. While it highlights a potential problem, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out a specific area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the paper\"s contribution is merely applying similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the work or suggest potential avenues for innovation. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of novelty in the paper, specifically mentioning that adversarial attacks by perturbing text have been done on many NLP models and imagetext models. It notes that the paper\"s contribution is merely applying similar ideas to videotext models. However, the comment does not specify which part of the paper discusses these related works or where the authors could improve the novelty of their work. The authors can make an educated guess that it relates to the related work section, but the comment lacks full grounding. It is specific in identifying the issue of lack of novelty, but without clear references to specific parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, as it involves applying existing ideas of adversarial attacks to videotext models. The comment provides a logical reasoning by referencing the related work section, which suggests that the authors have summarized the existing work on adversarial attacks in NLP and imagetext models. However, the comment does not provide specific examples or references to support the claim of lack of novelty in the videotext model context. This makes the claim 3, as it lacks detailed evidence or examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that the work involves applying existing ideas of adversarial attacks to videotext models. It acknowledges that the related work section summarizes the existing work on adversarial attacks in NLP and imagetext models, but points out that the paper\"s contribution is merely an extension of these ideas to videotext models. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive suggestions, the comment is 2, as it highlights a problem but does not offer a path forward for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It suggests a clear and actionable solution by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback provides explicit guidance on how to improve the organization and clarity of the section, making it 5. The authors know exactly what changes to make to enhance the coherence and readability of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanations being intertwined and suggests a solution by recommending separate paragraphs for each type of feature. This provides clear guidance on how to improve the organization and clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are \"somewhat intertwined and thus confusing.\" However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to organize the section with separate paragraphs for each type of feature is a logical step, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of Section 3.2, noting that the explanations for features are intertwined and confusing. It provides a clear and actionable suggestion by recommending the use of separate paragraphs for each type of feature, such as lexical features and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and coherence of their draft. However, the comment could be more helpful if it included additional guidance on how to effectively separate these features or provided examples of how this reorganization could enhance the reader\"s understanding. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the usefulness of a section of the paper and its accompanying experimental results, suggesting that dedicating a whole section to this topic is excessive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for alternative ways to present the information. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that dedicating a whole section of the paper plus experimental results is not useful, indicating that it addresses the section where these assumptions are fleshed out. However, it does not specify which section this is, making it weakly grounded. The comment is specific in its critique of the space dedicated to this topic, but it lacks detailed guidance on how to address the issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion that the information presented in the paper is not useful, specifically regarding the section dedicated to fleshing out assumptions and the accompanying experimental results. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this information is not useful or how it could be improved. Without such details, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the usefulness of a section of the paper that dedicates a whole section to fleshing out assumptions and includes experimental results. While the reviewer acknowledges the value of fleshing out assumptions, they question the necessity of dedicating a full section to this topic. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or present the information more effectively. Without detailed guidance or alternatives, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct an ablation study to demonstrate the importance of the postprocessing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is required and figure out the details themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of integrated gradients for attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It suggests that the paper should include an ablation study to demonstrate the importance of these postprocessing steps. However, the comment does not specify which part of the paper discusses these methods, making it weakly grounded. The suggestion for an ablation study is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of the postprocessing steps proposed for filtering out \"falsepositive\" neurons. It suggests that an ablation study may be needed to address this issue. The comment provides a logical reasoning for the claim by pointing out the lack of demonstration of the postprocessing steps\" importance. However, it does not provide specific examples or references to support the claim, which makes it 3. The authors would need to infer the necessity of an ablation study based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the importance of the postprocessing steps for filtering out \"falsepositive\" neurons is not demonstrated. It suggests that an ablation study could be necessary to address this issue, providing a clear and actionable direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further exploration. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about how an antecedent is identified when the prediction is a pronoun, particularly when the head of the noun phrase is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this challenge. The authors are left to infer that they need to clarify or improve their method for handling pronouns, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the identification of antecedents when the prediction is a pronoun, specifically when the head of the noun phrase is not a pronoun. It questions the proposed method of matching the head of noun phrases for antecedent identification. However, the comment does not specify which part of the paper discusses this method or where the issue arises, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it difficult to pinpoint. The comment is specific in detailing the issue with pronoun predictions, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically when the head of the noun phrase is not a pronoun. The comment questions the proposed method of matching the head of noun phrases for antecedent identification, suggesting that this approach may not be effective when the head word is not a pronoun. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant issue or how it affects the overall methodology. The lack of supporting evidence or detailed explanation makes the claim 3, as the authors would need to infer the potential impact and address it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the identification of antecedents when the prediction is a pronoun, particularly when the head of the noun phrase is not a pronoun. It questions the proposed method of matching the head of noun phrases for antecedent identification, highlighting a potential limitation in the approach. This feedback is clear and actionable, as it prompts the authors to clarify or improve their method for handling pronouns. However, the comment could be more helpful if it provided additional suggestions or examples on how to address this issue. Overall, the comment is 4, as it directs the authors to a specific area needing further clarification or improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper should include more baselines based on related work. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to include these baselines or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional baselines but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison between the proposed models and those that only consider different senses but not sememes. The comment suggests that the emphasis on soft vs. hard word sense disambiguation is not sufficient and recommends including more baselines based on related work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and implies that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or detailed reasoning to support the claim that the current comparison is unclear or insufficient. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or references to substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison between the proposed models and those that only consider different senses but not sememes. It suggests that the MST baseline could be an example of such a model and points out that the emphasis is placed on soft vs. hard word sense disambiguation rather than this comparison. The comment provides a clear and actionable suggestion to include more baselines based on related work, which would strengthen the paper. However, it could be more helpful if it offered specific examples of additional baselines or detailed guidance on how to incorporate them. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a positive assessment of the abstract, noting that it is wellwritten and intriguing. It suggests that the abstract could be improved by including an example of the inconsistency between evaluating with gold answers and human evaluation, such as models getting ranked differently. While the comment implies that the authors should add an example to enhance the abstract, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to improve the abstract. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. The comment specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point praises the abstract for being wellwritten and intriguing, suggesting that it could be improved by including an example of the inconsistency between evaluating with gold answers and human evaluation. However, the comment does not provide specific examples or detailed reasoning to support the claim that the abstract could be improved in this manner. The suggestion is somewhat vague and lacks concrete evidence or references to substantiate the claim. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment provides a positive assessment of the abstract, noting that it is wellwritten and engaging. It suggests a potential improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is clear and actionable, as it offers a specific suggestion for enhancing the abstract. However, the comment could be more helpful if it provided additional guidance on how to effectively incorporate this example or what specific aspects of the inconsistency should be highlighted. Overall, the comment is 4 as it provides a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide any explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors can infer that they need to provide more information, but it is vague because it lacks specific details on what information should be added or how to clarify the selection process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the selection process, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how frame similarity factors and attributes similarity factors are selected. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide any guidance or suggestions on how the authors might clarify this aspect of their work. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights an issue but lacks depth or actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors need to include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit, as it clearly states what needs to be added to the paper. However, it lacks concrete guidance on how to structure these discussions or what specific aspects should be covered. While the authors know they need to address this issue, the comment could be more actionable with additional details on how to implement the suggested discussions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for discussions on convergence, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where these discussions should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that discussions on the convergence of the proposed joint learning process are necessary to help readers understand how stable points in the probabilistic metric space are obtained. However, the comment does not provide specific examples, references, or detailed reasoning to support why this discussion is crucial or how it would impact the reproducibility of the results. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of this discussion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the convergence of the proposed joint learning process for RNN and CopyRNN. It suggests that discussions on this topic are necessary to help readers understand how stable points in the probabilistic metric space are obtained, which is crucial for reproducibility. This feedback is clear and actionable, as it provides a specific area for improvement and highlights the importance of addressing it. However, the comment could be more helpful if it offered suggestions on how to structure these discussions or what specific aspects should be covered. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs the authors to discuss the results for the task of inferring knowledge on objects, which is a clear and concrete action. Second, it suggests including results for model (B) and recommends using consistent terminology across tables. Additionally, the comment points out a specific issue with the terminology used in Tables 1 and 2, providing a concrete suggestion for improvement. The feedback is explicit and provides detailed guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (\"681\" and \"778\") and references specific parts of the paper, allowing the authors to accurately identify the sections being addressed. It also provides specific suggestions for improvement, such as discussing results for the task of inferring knowledge on objects and including results for model (B), as well as recommending consistent terminology across tables. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim suggests that the authors should discuss results for the task of inferring knowledge on objects and include results for model (B). The second claim questions why objects are not mentioned in the context of \"latent in verbs.\" Both claims are factual and do not express opinions or judgments that require verification. They are descriptive in nature, making them \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it reminds the authors to discuss the results for the task of inferring knowledge on objects, which is a crucial aspect of the paper. Second, it suggests including results for model (B) and points out the inconsistency in terminology used across tables, recommending a correction. Additionally, the comment questions the absence of objects in the context of \"latent in verbs,\" prompting the authors to consider this aspect. The feedback is clear, specific, and provides concrete suggestions for enhancing the paper, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific sentence in line 212 that is not strictly correct and suggests a correction. It provides a clear and explicit action for the authors to take, which is to change the sentence to accurately reflect the use of a bidirectional encoder. The comment also offers a concrete suggestion by referencing Figure 2, providing a clear direction for the authors to follow. This level of detail and specificity makes the comment 5, as the authors know exactly what needs to be changed and how to implement the correction.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, suggesting a correction by explaining that a bidirectional encoder should be used to encode the source sentence into a set of vectors, rather than a single vector. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not strictly correct and suggests a correction. The reviewer provides a specific suggestion for improvement by recommending the use of a bidirectional encoder to encode the source sentence into a set of vectors, as seen in Figure 2. This feedback is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by explaining why the original statement is incorrect or providing additional context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording of a sentence in the paper, pointing out that it is not strictly correct. It provides a clear and actionable suggestion for improvement by recommending the use of a bidirectional encoder to encode the source sentence into a set of vectors, as opposed to a single vector. This feedback is valuable as it helps the authors correct a potential misunderstanding and ensures the accuracy of their description. However, the comment could be more helpful if it explained why the original statement was incorrect or provided additional context. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater impact."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work is a fairly straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to implement these baselines or which ones to include. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work is a fairly straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment addresses, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, which provides clear guidance on what the authors could do to improve their work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges that the work is a fairly straightforward extension of existing retrofitting work and suggests adding additional baselines, such as character embeddings. While it provides a clear suggestion for improvement, it lacks depth and does not offer specific guidance on how to implement these baselines or why they would be beneficial. The comment is 3 as it identifies a potential area for enhancement, but it does not provide detailed actionable advice or context to fully support the authors in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part critiques the adopted baseline models as weak and suggests that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This is an explicit suggestion for improvement, as it clearly indicates a specific comparison that should be made. The second part points out a grammatical error and suggests a correction. While the first part is explicit and actionable, the second part is also clear in its action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 277,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a grammatical error and suggests a correction, providing clear guidance on what needs to be addressed. Additionally, the comment critiques the adopted baseline models, suggesting comparisons with Campos et al. (2020) and other domain adaptation methods, which further specifies the areas needing improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests comparisons with Campos et al. (2020) and other domain adaptation methods. However, the comment does not provide specific reasons or evidence to support why the baseline models are weak or why these comparisons are necessary. The suggestion to compare with Campos et al. (2020) is based on the mention of a specific work, but without further explanation or context, the claim remains vague. Additionally, the comment includes a grammatical correction, which is not a claim. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully support the claim about the baseline models.", "helpfulness_rationale": "The review comment identifies two main issues with the paper. First, it critiques the adopted baseline models as weak, suggesting that the authors should compare their work with Campos et al. (2020), which also uses feedback in QA tasks. This feedback is actionable as it points out a specific area for improvement. Second, it notes the absence of comparisons with other domain adaptation methods, which is a relevant point for enhancing the paper\"s contribution. Additionally, the comment includes a grammatical correction, which is helpful for clarity. However, the comment could be more helpful if it provided specific suggestions on how to address the weaknesses in the baseline models or offered examples of domain adaptation methods to compare with. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" directly. This is an explicit action with clear guidance on what needs to be done to improve the draft. The authors know exactly what modification to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the figure by recommending the use of \"Exact Match ratio\" directly as the yaxis label. This level of detail gives the authors a precise understanding of what needs to be changed, making the comment 5.", "verifiability_rationale": "The review point suggests a change to the yaxis label in Figure 5, recommending the use of \"Exact Match ratio\" directly. However, the comment does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or effectiveness of the figure. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending the use of \"Exact Match ratio\" directly as the yaxis label. This feedback is clear and concise, offering a straightforward way for the authors to enhance the readability and understanding of their results. However, the comment could be more helpful if it explained why this change is necessary or how it would improve the figure. Despite this, the suggestion is actionable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the potential impact of societal biases on their work, but it lacks concrete steps or examples to help the authors implement this consideration. Additionally, the second part of the comment mentions a preference for addressing implicit offensive texts but does not offer actionable advice. Overall, the comment is vague and lacks specific guidance, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment also mentions \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig,\" which suggests a specific figure but does not clarify which figure or what aspect of it is being discussed. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment also mentions a preference for addressing implicit offensive texts but does not elaborate on why the current example is insufficient. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. This is a relevant point that could impact the validity and reliability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending methods to assess or mitigate societal biases. Additionally, the second part of the comment expresses a preference for addressing implicit offensive texts but does not offer actionable advice or examples. While the comment identifies a potential weakness, it lacks depth and specific guidance, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to demonstrate that a particular aspect of the paper, such as attention in seq2seq MTL, is not working, the true value lies in understanding why it fails and making adjustments to the attention mechanism to make it work. However, the comment does not provide explicit guidance or concrete steps on how to achieve this understanding or make the necessary adjustments. The action is implicit and vague, leaving the authors without a clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the difficulty of demonstrating that a particular aspect of the paper, such as attention in seq2seq MTL, is not working. It suggests that the value lies in understanding why it fails and making adjustments to the attention mechanism. However, the comment does not specify which part of the paper this observation pertains to, nor does it provide detailed guidance on how to address the issue. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what needs to be addressed or how to make the necessary adjustments. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that it is easier to demonstrate that a particular aspect of the paper, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making adjustments to the attention mechanism. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a critical aspect of the paper, noting that it is easier to demonstrate that a particular aspect, such as attention in seq2seq MTL, is not working. However, the comment suggests that the true value lies in understanding why it fails and making adjustments to the attention mechanism to make it work. This feedback is 3 as it points out a potential area for improvement and encourages the authors to delve deeper into understanding the limitations and potential solutions. However, the comment lacks specific guidance or actionable steps on how to achieve this understanding or make the necessary adjustments, which would make it more helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of strong baselines in Table 3, specifically mentioning the baselines in reference [1]. It asks the authors to justify the reason for not including these baselines. While the comment implies that the authors should provide a justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification and are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of strong baselines in the table, such as those mentioned in reference [1], and asks for a justification for this omission. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the absence of strong baselines in Table 3, specifically mentioning the baselines in reference [1]. The comment does not make a subjective claim or judgment but rather seeks clarification on the rationale behind the exclusion of these baselines. It is a factual inquiry that requires no verification, as it does not express an opinion or suggestion. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it lacks strong baselines, such as those mentioned in reference [1]. It asks the authors to justify the reason for not including these baselines, which is a clear and actionable request for improvement. By pointing out this omission and requesting a justification, the comment provides the authors with a specific area to address and a way to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate these baselines or what specific aspects of the baselines are relevant. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper relies heavily on supplemental space, which makes it not truly independent. It specifically mentions references to supplemental figures and model comparisons, indicating that these sections are not fully integrated into the main text. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the integration of supplemental material into the main text. The action is implicit and vague, leaving the authors to infer that they need to better integrate their supplemental material into the main text. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the paper relying on supplemental space, which makes it not truly independent, and highlights specific references that support this claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper relies heavily on supplemental space, making it not truly independent. It provides specific references to \"S3.1 reference to Sup. Fig. 6\" and \"model comparison and other details of the span vs. sentence investigation,\" which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the supplemental material impacts the paper\"s independence. Overall, the claim is 4, as it provides some evidence but could benefit from additional elaboration. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies heavily on supplemental space, which compromises its independence. It specifically points out references to supplemental figures and model comparisons, indicating that these sections are not fully integrated into the main text. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors need to better integrate their supplemental material into the main text to enhance the paper\"s independence. However, the comment could be more helpful if it provided specific suggestions on how to achieve this integration or offered examples of how to present the supplemental material in a more cohesive manner. Overall, the comment is 4, as it directs the authors to a key area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding information about the input being word embeddings, similar to the Lample et al. model, which is a clear and concrete instruction. Second, it questions whether the KNs in Figure 3 are in the source language or English, indicating a need for clarification. The authors are explicitly told to correct the figure, providing a direct action. Both suggestions are specific and actionable, allowing the authors to make precise changes to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need to add information about word embeddings and the clarification regarding the KNs in the figure. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. model, in section 2.3. It also questions whether the KNs in Figure 3 are in the source language or English, as the mentions have been translated to English. The comment provides a logical suggestion for improvement and a specific question for clarification, making it 4. However, it lacks detailed reasoning or references to support the claim that adding this information would be beneficial. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing two distinct areas for improvement. First, it suggests adding information about the input being word embeddings, similar to the Lample et al. model, which could enhance the clarity of the paper. Second, it questions the language of the KNs in Figure 3, pointing out that the mentions have been translated to English, which could be a source of confusion. The comment also acknowledges that the authors have already agreed to correct the figure, indicating that the reviewer is aware of the authors\" efforts to address previous feedback. This level of detail and specificity makes the comment 5, as it guides the authors in making targeted improvements to their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the paper, specifically related to the experiments. It mentions that the experiments are limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method could be applied to more NLP tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen their experiments or demonstrate the potential of their method on other tasks. The feedback is vague and lacks concrete actions for the authors to take, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiments in the paper, specifically mentioning the limitation to an extremely lowresource regime and the ease of sentence classification. It suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. However, the comment does not specify which part of the paper discusses the experiments or provide detailed guidance on how to address these issues. The authors can infer that the comment relates to the experimental section, but it lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak, particularly because they are limited to an extremely lowresource regime and focus on sentence classification, which is an easier task. The reviewer suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the experiments are weak or that the method has potential for broader applications. The reasoning is 3, as it highlights potential limitations, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper, particularly in the experimental section. It points out that the experiments are limited to an extremely lowresource regime, which may not fully demonstrate the potential of the proposed augmentation method. Additionally, it notes that sentence classification is an easier task, suggesting that the method could be applied to more challenging NLP tasks. However, the comment lacks actionable suggestions or guidance on how the authors might address these limitations or expand their experiments to demonstrate the method\"s broader applicability. While it highlights important areas for improvement, the feedback is incomplete and does not provide detailed steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether treating concept map extraction as a separate task is necessary. It provides a balanced perspective, acknowledging both the potential benefits of treating it as a separate task and the challenges that arise with increasing node numbers. However, the comment does not explicitly instruct the authors to take any action or provide specific guidance on how to address this issue. The authors are left to infer that they should consider the necessity of this task, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the necessity of treating concept map extraction as a separate task, providing a balanced perspective with both pros and cons. However, it does not specify which part of the paper this question pertains to, such as a particular section or methodology, making it weakly grounded. The comment is specific in its discussion of the potential benefits and challenges of treating concept map extraction as a separate task, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the necessity of treating concept map extraction as a separate task, providing a balanced perspective with both potential benefits and challenges. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. The reasoning is somewhat vague, making it difficult for the authors to fully understand the basis of the question. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of treating concept map extraction as a separate task. It provides a balanced perspective by acknowledging both the potential benefits of this approach and the challenges that arise with increasing node numbers. This feedback encourages the authors to consider the rationale behind their approach and potentially explore alternative methods or justifications. However, the comment could be more helpful if it offered specific suggestions or examples of how to address this issue or provided additional context to support the question. Overall, the comment is 3 as it prompts the authors to reflect on their methodology, but it could be more comprehensive with further guidance or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also asks specific questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what nonexperts would do, as well as whether it introduced any linguistic challenges. These questions and requests are clear and concrete, providing the authors with a direct and detailed guide on what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly relates to the first point mentioned in the review, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the traits of the experts involved in the annotation process and the justification for using expert annotation beyond its commercial value. The comment asks detailed questions about the nature of the experts and the differences in annotation compared to nonexperts, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the annotation process, specifically asking about the traits of the experts involved and the justification for using expert annotation. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking the authors to describe more about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also raises questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what nonexperts would do, as well as whether it introduced any linguistic challenges. These questions and requests for clarification are clear and direct, offering the authors a structured approach to enhancing their draft by providing more detailed information and justification. This level of guidance is highly beneficial for the authors, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with lines 102106, stating that they are misleading. It points out that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the text. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the reference, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically regarding the phrase \"such distribution.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, pointing out that lines 102106 are misleading. It highlights that while the intersection and probabilities are true, the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it directs the authors to clarify the reference to \"such distribution\" to ensure accuracy and coherence in their text. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the text. Overall, the comment is 4 as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, it does not provide specific guidance on how to implement this suggestion or what kind of examples would be most useful. The action is implicit, as the authors need to infer that they should include examples, and it is vague, as it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than just other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. Without explicit references or clear guidance on where these examples should be included, the authors may find it challenging to determine the exact area needing attention. This makes the comment weakly grounded, as the authors cannot confidently identify the part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of examples would be beneficial or how they should be presented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, the comment does not provide any reasoning, examples, or references to support why this would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that including examples of the system on actual texts would be beneficial, rather than just focusing on other components and models. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors could enhance the paper by providing more concrete examples. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what kind of examples would be most relevant. While it provides a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are in need of further analysis or provide guidance on how the authors might conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims require more depth and how to achieve it. Without explicit instructions or examples, the authors may struggle to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any details on what aspects of the analysis are lacking. This makes it difficult for the authors to identify the specific parts of the paper that need improvement. The comment lacks both grounding and specificity, as it does not provide any clear guidance or examples. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a number of claims from this paper would benefit from more indepth analysis.\" However, it does not specify which claims are being referred to or provide any reasoning or evidence to support this claim. Without specific examples or detailed justification, the authors may find it challenging to understand which claims need further analysis and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that several claims in the paper would benefit from more indepth analysis. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which claims are in need of further analysis or how the authors might conduct this analysis. Without detailed suggestions or examples, the authors are left with a general idea of what might need more attention but without actionable steps to take. Therefore, the comment is 2, as it provides minimal guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features (line 397) and requests a clearer definition of the variables in Equation (7), specifically whether E_i represents the type or identity of AC i. Additionally, it suggests that the lefthand side of the equation should be a conditional probability. These explicit requests provide clear actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 397 and 472) and equations (Equation 7), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, such as clarifying the pooling method used for embedding features and defining the variables in Equation (7). Additionally, it suggests that the lefthand side of the equation should be a conditional probability. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises specific questions and concerns about the presentation of the model, including the pooling method used for embedding features and the clarity of Equation (7). It provides detailed requests for clarification, such as defining whether E_i represents the type or identity of AC i, and suggests that the lefthand side of the equation should be a conditional probability. These requests are logical and provide a clear path for the authors to address the issues, making the comment 5. Therefore, the label is 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas that need improvement in the presentation of the model. It asks for clarification on the pooling method used for embedding features, which is a critical aspect of the model\"s architecture. Additionally, it requests a clearer definition of the variables in Equation (7), specifically whether E_i represents the type or identity of AC i, and suggests that the lefthand side of the equation should be a conditional probability. These detailed suggestions empower the authors to make significant improvements in the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional context or examples to further guide the authors. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the hypotheses presented in the paper and the actual content of the paper. It suggests that the hypotheses are not optimally phrased and could be tested as given, but notes that the paper does not actually study these hypotheses. The reviewer also expresses a desire for the paper to delve deeper into the respective topics. While the comment identifies an issue and suggests a potential improvement, it does not provide explicit guidance on how to address the problem or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should rephrase the hypotheses and potentially expand the discussion on the topics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 078086,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the phrasing of the hypotheses about multilinguality and country/languagespecific bias, and the lack of actual study or discussion of these hypotheses. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises hypotheses about multilinguality and country/languagespecific bias but does not actually study these hypotheses. The reviewer suggests that the hypotheses are not optimally phrased and could be tested as given. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed further in the paper. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises hypotheses about multilinguality and country/languagespecific bias but does not actually study or discuss these hypotheses further. The reviewer points out that this is misleading and suggests that the paper should delve deeper into these topics. This feedback is valuable as it highlights a critical gap in the paper\"s content and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as proposing additional experiments or analyses. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether feature engineering could improve the performance of the work. It references a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. While the comment implies an action\u2014exploring the use of feature engineering\u2014it does not explicitly instruct the authors to do so. The suggestion is concrete in terms of the specific feature set to consider, but it lacks directness in terms of action. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the potential benefit of using feature engineering to improve performance, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using handcrafted features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in suggesting the use of Uto et al. (2020)\"s feature set, but it is 1 as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about whether feature engineering could improve the performance of the work, referencing a study by Uto et al. (2020) that achieved a QWK of 0.801 using handcrafted features. The comment suggests that using the same feature set as Uto et al. (2020) might also improve the results of the current work. This claim is 3 as it provides a reference to a specific study and suggests a potential approach for improvement. However, the comment lacks detailed reasoning or examples of how the feature set could be applied or integrated into the current work, which would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefit of using feature engineering to improve the performance of the work. It references a study by Uto et al. (2020) that achieved a QWK of 0.801 using a set of handcrafted features, suggesting that using the same feature set could also improve the results of the current work. This feedback is 3 as it provides a specific suggestion for potential improvement and references a relevant study. However, it lacks depth and does not offer detailed guidance on how to implement feature engineering or integrate the suggested feature set into the current work. While it points the authors in a potentially beneficial direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. The reviewer requests clarification on the data split used. While the comment implies that the authors should provide more information about the use of the CS, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of the CS but are not given specific guidance on how to present this information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. It also requests clarification on the data split used. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections where the Challenge Set is discussed. The comment is specific in detailing what needs to be clarified regarding the use of the Challenge Set, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and aim to gather more information, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. It also requests clarification on the data split used. While the comment identifies a potential area of confusion and seeks clarification, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a gap in the paper that needs clarification, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the terminology used in the paper, specifically the claim that the model generalizes to different knowledge. The reviewer questions the use of \"knowledge\" in this context, suggesting that it might be misleading as it typically refers to external knowledge bases rather than syntax or semantics. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their terminology. The action is implicit and vague, leaving the authors to infer that they need to clarify their terminology but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim about generalizing to different knowledge, specifically questioning the use of \"knowledge\" in the context of substructure representation. The reviewer suggests that the substructure should be represented as a sequence of words and expresses hesitation about calling it \"knowledge,\" as it typically refers to external knowledge bases. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the terminology and its implications, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of the term \"knowledge\" in the context of the paper, suggesting that it is misleading as it typically refers to external knowledge bases rather than syntax or semantics. The reviewer provides a logical reasoning by explaining the difference between the usual meaning of \"knowledge\" and the context in which it is used in the paper. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reviewer\"s point and provide additional context or clarification to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the terminology used in the paper, specifically the claim that the model generalizes to different knowledge. The reviewer questions the use of \"knowledge\" in this context, suggesting that it might be misleading as it typically refers to external knowledge bases rather than syntax or semantics. This feedback is 3 as it identifies a potential confusion in the paper\"s terminology and encourages the authors to clarify their use of terms. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative terminology. Overall, the feedback is 3 as it prompts the authors to reconsider their terminology, but it lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the relatively poor performance of the model on nouns and the discrepancy between the oracle GAP for PPDBClus and most clustering approaches. The reviewer suggests that this issue contradicts the claim of generalizability to all parts of speech. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve the performance. It lacks actionable details, such as recommending specific experiments or analyses to conduct. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"relatively poor performance on nouns\" and references specific claims in the paper (124126) regarding generalizability to all parts of speech. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue with the performance on nouns and the discrepancy with the oracle GAP for PPDBClus, as well as the contradiction with the claim of generalizability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses concern about the relatively poor performance of the model on nouns, which contradicts the claim of generalizability to all parts of speech. The reviewer provides a logical reasoning by pointing out the discrepancy between the oracle GAP for PPDBClus and most clustering approaches, suggesting that this issue needs further explanation. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to delve deeper into the paper to understand the context and the specific claims being made, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the performance of the model on nouns, which is a critical aspect of the paper. It highlights a discrepancy between the expected performance of the model, given its nature, and the actual results, which are disconcerting. The comment also points out a contradiction with the claim of generalizability to all parts of speech, as the performance is not uniform. This feedback is valuable as it prompts the authors to investigate and address the issue of performance variability across different parts of speech. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the model\"s performance or clarify the generalizability claim. Overall, the comment is 3, as it directs the authors\" attention to a significant concern but lacks detailed actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify the discussion in section 5.2, which is currently too abstract. This request is clear and direct, providing a specific action for the authors to take to improve their draft. The comment is 5 as it gives a concrete step for the authors to follow, ensuring they know exactly what needs to be done to enhance their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion being too abstract and requests examples of spurious structures to clarify why the new model is better than MH. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the discussion in section 5.2, stating that it is too abstract and lacks examples of spurious structures to demonstrate why the new model is better than MH. The comment does not contain subjective opinions, suggestions, or claims that require verification. It is a request for clarification, which is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks clarity on why the new model is better than MH. The reviewer requests examples of spurious structures to help clarify this point. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can help the authors enhance the clarity and comprehensiveness of their discussion. However, the comment could be more helpful if it offered additional guidance on how to present these examples or what specific aspects of the discussion need more detail. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the maximum number of tasks done by any annotator. This is an explicit action that provides clear guidance on what needs to be added to the draft. The comment is specific and concrete, as it directly instructs the authors to include a particular piece of information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"241,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is the maximum number of tasks done by any annotator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the maximum number of tasks done by any annotator should be stated. However, it does not provide any reasoning or evidence to support why this information is necessary or how it would impact the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors include the maximum number of tasks done by any annotator, which is a specific and actionable piece of feedback. This recommendation can help improve the clarity and completeness of the paper by providing additional context about the annotation process. However, the comment could be more helpful if it explained why this information is important or how it would enhance the paper. Despite this, the feedback is clear and provides a concrete suggestion for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. While the comment identifies a gap in the paper\"s presentation, it does not provide explicit guidance on how the authors might address this issue. The authors are left to infer that they need to clarify the connections between the empirical results and the research question, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"many empirical results and analyses\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the overall understanding of the experiments and their connection to the research question and hypothesis. The comment provides clear guidance on what needs to be addressed, such as clarifying how the different pieces of the puzzle fit together. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different components fit together. However, the comment does not provide specific examples or detailed reasoning to support the claim that the experiments are unclear or disconnected. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite the presence of many empirical results and analyses, it is difficult to understand the overall picture of what the experiments reveal about the research question and hypothesis. This feedback is valuable as it highlights a critical gap in the paper\"s presentation and suggests that the authors need to clarify how the different components of the paper fit together. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a more structured approach to presenting the results or suggesting ways to integrate the findings more effectively. Despite this, the comment is 4 as it directs the authors to a key area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies what needs to be added to the table, giving the authors a concrete step to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This provides specific guidance on what needs to be added to the table, making it clear and actionable. However, the comment does not specify which part of the paper discusses Table 1, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to compare the performance increase of each method. This is a clear and actionable suggestion that could enhance the comprehensiveness and clarity of the results presented in the paper. By incorporating this baseline, the authors can provide a more complete picture of the performance improvements across different methods, which is valuable for readers. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the interpretation of the results. Overall, the feedback is 4 as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy (DP) algorithms. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include numerical results and comparisons, but it lacks concrete details on what specific algorithms to use or how to conduct the comparisons. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing its performance with existing differential privacy algorithms. However, it does not specify which part of the paper lacks numerical results or which algorithms are being referred to. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its request for numerical results and comparisons but lacks grounding, as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a curiosity about the application of the method to popular algorithms and its performance compared to existing differential privacy algorithms. However, it does not provide any specific examples, references, or reasoning to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the reviewer\"s interest in this aspect. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy algorithms. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or examples of algorithms to consider, leaving the authors with a general idea of what is missing but without detailed direction on how to improve their draft. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This provides a clear and explicit action for the authors to take, which is to conduct additional experiments with these wider backbones. The suggestion is concrete, as it specifies the exact experiments that should be performed to enhance the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This provides a specific suggestion for improvement, but it does not explicitly mention which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are insufficient and recommends testing the proposed InvP method with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to methods like MoCo and SimCLR. This claim is 3 as it provides a logical suggestion for enhancing the experimental comparisons by referencing established methods that have tested with wider backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, noting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7), similar to other methods like MoCo and SimCLR. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental setup to better compare the proposed method with existing ones. By following this advice, the authors can improve the comprehensiveness and robustness of their experimental results, which is valuable for the readers. However, the comment could be more helpful if it included additional guidance on how to implement these wider backbones or why this comparison is important. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not welldrawn and should be formalized or clarified. The reviewer provides a clear action for the authors to take, which is to either \"cement this connection more formally\" or \"adjust the language to clarify.\" This feedback is explicit and provides concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the probabilistic connection in the paper, suggesting that it is not formally established and should be clarified. However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors either formalize the connection or adjust the language to clarify it, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection in the paper is not welldrawn and suggests that it should be formalized or clarified. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the probabilistic connection, which is not formally established. It suggests that the authors either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific area to focus on for improvement. However, the comment could be more helpful if it offered additional guidance on how to formalize the connection or provided examples of how to clarify the language. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include additional evidence, it does not specify what kind of evidence or how it should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence and figure out how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without a clear reference to the section where this claim is made, the authors may struggle to identify the exact part that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or reasoning to substantiate why this evidence is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem. This is a clear and actionable suggestion that could help strengthen the paper by providing concrete evidence for the third contribution. However, the comment could be more helpful if it offered specific guidance on what kind of evidence or experiments would be most relevant or how to present the results effectively. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the robustness of their training scheme. The action is implicit and vague, as the authors are left to infer that they need to consider the scalability of their method but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment does not specify which part of the paper discusses the robust training scheme or the scalability issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the scalability issue but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The reasoning is somewhat vague and does not provide a clear basis for the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the robust training scheme to practical datasets, particularly those in highdimensional domains. It suggests that the accuracy might not scale favorably unless the size of V scales exponentially with the dimension. While the comment identifies a potential issue with the scalability of the method, it lacks specific suggestions or guidance on how the authors might address this concern or improve the robustness of their training scheme. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of the 4year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. While it implies that the authors should provide more information or justification regarding the dataset choice, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets, specifically questioning whether a 4year period is sufficient to study style shifts and what kind of style shifts occur within this timeframe. However, it does not specify which part of the paper discusses the dataset choice, making it weakly grounded. The comment is specific in its request for clarification on the dataset choice and its implications for understanding the model\"s captures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of a 4year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. However, it does not provide any specific evidence, examples, or references to support the claim that a 4year period is insufficient. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets, specifically questioning whether a 4year period is sufficient to study style shifts and what kind of style shifts occur within this timeframe. This is a relevant point that could impact the understanding and interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, it lacks actionable feedback, making it 3. The authors are left with a general direction for improvement but without detailed steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions: the first is to correct the callout to table 5 to refer to table 3, and the second is to ensure that the callout to figure 6 in page 7, section 5, is properly directed. These actions are clear and concrete, providing the authors with specific steps to take to improve their draft. The feedback is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5\" and \"table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout and provides a clear direction for correction. Additionally, it mentions \"page 7, section 5, last par.\" to further ground the comment, making it clear where the issue with the figure callout is located. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding the incorrect callouts in the paper, specifically mentioning that the callout to table 5 should refer to table 3 and that the callout to figure 6 is not properly directed. These statements are descriptive and do not contain subjective opinions, claims, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the incorrect callout to table 5, which should refer to table 3, and the improper direction of the callout to figure 6 in page 7, section 5. These are clear and actionable points that the authors can address to improve the accuracy and clarity of their draft. By providing specific corrections, the comment offers valuable guidance that can help the authors enhance the quality and coherence of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern with the experiments, specifically noting that the paper only includes selfcomparisons and lacks explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue and provides a specific suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with SketchRNN and provide a rationale for their experimental choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the lack of comparisons with other models like SketchRNN. It highlights the issue of only reporting selfcomparisons and the need for a better explanation of this choice. However, it does not specify which part of the experiments section this critique pertains to, such as a particular figure or table. While the authors can infer that it relates to the experimental methodology, the comment lacks full grounding. It is specific in detailing the issue with selfcomparisons and suggesting a comparison with SketchRNN, but without explicit references to specific sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a major concern due to the lack of comparisons with other models, specifically mentioning SketchRNN. The comment suggests that this limitation contributes to a poor motivation problem. However, the review does not provide specific examples or detailed reasoning to support why comparisons with SketchRNN are necessary or how they would enhance the paper\"s motivation. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of these comparisons and their potential impact on the paper\"s motivation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper, specifically the lack of comparisons with other models, such as SketchRNN, in the experiments. It highlights that the paper only reports selfcomparisons, which adds to the poor motivation problem. The comment provides a clear and actionable suggestion to include comparisons with SketchRNN, which could enhance the paper\"s motivation and provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or why they are important. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, providing specific examples and data to support this disagreement. The comment suggests that the authors should further explore and discuss the performance differences between DeiT models and CNNs as model capacity increases. This feedback is explicit and provides concrete guidance on what the authors should focus on, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trending of increasing the number of parameters for ViT (DeiT) and disagrees with the authors\" viewpoint on the benefits of increased model capacity. The comment specifies the need for more analysis and comments on the performance differences between DeiT models and CNNs as model capacity increases. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint on the performance of ViT (DeiT) and CNNs with increased model capacity is incorrect. It provides specific examples and data to support this claim, such as the performance of DeiTB models not outperforming DeiTT in APTOS2019 and DeiTS on APTOS2019, ISIC2019, and CheXpert. This detailed analysis and evidence make the claim 5, as it provides a clear and logical reasoning for the disagreement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending additional analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also challenges the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, offering detailed examples and data to support this disagreement. This level of detail and critique empowers the authors to address a critical aspect of their work, making the comment 5. The feedback is clear, actionable, and constructive, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the paper is generally easy to follow but identifies specific places that may cause confusion. However, it does not provide explicit guidance on which places are causing confusion or how the authors might address these issues. The comment implies that the authors should review their draft to identify and clarify these areas, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions that the paper is not difficult to follow but identifies several places that may cause confusion, referencing point 3. However, it does not specify which specific places or sections are causing confusion, making it weakly grounded. The authors can infer that it relates to the content discussed in point 3, but without explicit references, it is challenging to pinpoint the exact areas needing attention. The comment is specific in identifying the issue of potential confusion but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies several places that may cause confusion. However, it does not specify which places are causing confusion or provide any supporting evidence or examples to substantiate the claim. Without detailed information or references, the authors may find it challenging to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide detailed guidance or suggestions on how to address these potential sources of confusion. Without specific examples or actionable advice, the authors are left with a vague understanding of what needs improvement. This lack of clarity and detail limits the comment\"s usefulness, making it 2. The authors may need to infer the areas of concern and figure out how to address them on their own, which is not ideal for constructive feedback. Therefore, the comment is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point consists of a statement that a claim made in the paper is false, with a reference to additional information in the submitted paper and external references. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address the issue or what changes should be made to the draft. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the claim about the lack of tools for the reinforcement learning setting is made in. It also lacks specificity because it does not provide details on what specific tools are missing or how they could be addressed. Without clear references to the paper or specific examples, the authors cannot effectively identify the issue or know how to improve it. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that a statement in the paper is false, specifically regarding the absence of tools for the reinforcement learning setting. However, the reviewer does not provide any supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review point challenges a claim made in the paper, stating that it is false. However, it does not provide any further explanation or evidence to support this assertion, nor does it offer suggestions for how the authors might address the issue or clarify the claim. Without additional context or guidance, the comment lacks actionable value for the authors, leaving them without a clear path to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not immediately obvious and require technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of making the results more accessible or how to enhance the clarity of the techniques used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, noting that while the techniques used are considered \"standard,\" they are not immediately obvious and require a high level of technical expertise. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in its critique of the technical competency required to understand the results, but without explicit references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not immediately obvious, requiring a high degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 3, as it provides a general observation but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential issue with the accessibility of the results, noting that while the techniques used are considered \"standard,\" they may not be immediately obvious to all readers. This observation suggests that the authors should consider making their results more accessible or providing additional context to help readers understand the techniques used. However, the comment does not offer specific suggestions or guidance on how to achieve this, such as recommending additional explanations, examples, or references. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. This is an explicit action that the authors can take to clarify their work. However, the comment does not provide specific guidance on how to implement this distinction or which specific updates should be highlighted. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that update the frozen model and those that do not, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that update the frozen model and those that do not. This is a specific and actionable suggestion that could help clarify the paper and provide a clearer understanding of the experimental setup. However, the comment could be more helpful if it provided additional context or examples of how this distinction might be made or why it is important. Despite this, the feedback is clear and provides a direction for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used for training the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly better, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison between the two models. The action is implicit and vague, as the authors are left to infer that they should reconsider their conclusion or provide more detailed comparisons. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison between the text disambiguation model and the endtoend system, specifically mentioning the difference in data used for training. However, it does not explicitly mention which sections of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in questioning the conclusion based on the data difference and the small performance gap between the two systems. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difference in data used for training the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. The comment provides a logical reasoning by pointing out the small difference in performance between the two systems, which challenges the claim of superiority. However, it lacks specific examples or references to support the claim further, making it 3. The authors would need to consider this critique and potentially provide additional data or analysis to substantiate their claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential issue with the comparison between the text disambiguation model and the endtoend system, noting that the data used for training the models differs significantly. It questions the conclusion that the direct model is clearly better, given the small performance difference between the two systems. This feedback is 3 as it points out a potential weakness in the paper\"s argument and encourages the authors to reconsider their conclusions. However, it lacks specific suggestions or guidance on how to address this issue or improve the comparison between the models. To be more helpful, the comment could include recommendations for additional analysis or experiments to clarify the performance differences. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies two main issues: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. The comment explicitly suggests that the authors should provide evidence or justification for GaRare\"s advantages over GaLore and offer a more detailed algorithmic presentation. These are clear and concrete actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it details what is missing in terms of motivation and algorithmic presentation, providing clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clear motivation for GaRare and insufficient evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly regarding the recovery of updated parameters from projected gradients. The comment provides a logical reasoning for the claim by highlighting the need for theoretical analysis and a more detailed algorithmic presentation. However, it does not provide specific examples or references to support the claim, which would make it more verifiable. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of clear motivation for GaRare, emphasizing the need for evidence or justification for its advantages over GaLore based on theoretical analysis. Second, it suggests that a more detailed algorithmic presentation is necessary, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is actionable and provides specific guidance on how the authors can enhance the clarity and comprehensiveness of their work. By addressing these points, the authors can significantly improve the understanding and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for a specific experiment regarding the performance of ATT(+H) in figure 4 left, without considering the relevant attention retrieval from the attention memory. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what experiments to conduct and what results to report. The level of detail and specificity in the request makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and exploring the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This level of detail provides clear guidance on what the authors need to do to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also asks for a specific experiment regarding the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for additional experiments, it lacks detailed reasoning or references to support why these experiments are necessary or how they would contribute to the paper. The request for an ablation study is logical, but the lack of specific justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting an additional experiment to further validate the proposed visual reference resolution model. It requests an ablation study on the visDial dataset, which would help to strengthen the paper\"s claims. Additionally, the comment asks for a specific experiment regarding the performance of ATT(+H) without considering relevant attention retrieval from the attention memory. This feedback is clear and detailed, offering the authors a concrete way to enhance their draft by addressing a particular area of interest. The suggestion is wellstructured and provides a clear path for improvement, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should incorporate this information into their draft. The action is implicit, as the authors need to infer that they should include references to these works, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a link to these similar works that have a similar structure to the CRF and can perform exact inference. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. The claim is 3 as it references specific works, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to look up the referenced works to understand the context and relevance of the missing link. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the current paper. By mentioning these references, the comment provides the authors with a clear direction to enhance the context and relevance of their work. However, the comment could be more helpful if it included a suggestion on how to incorporate these references or why they are important for the paper. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input. It also questions whether any input could serve as a white paper and why Gaussian noise input does not work as well as WPA. The comment highlights the importance of understanding how WPA works, as it could lead to future research directions. While the comment implies that the authors should provide more insight into the workings of WPA, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should delve deeper into the explanation of WPA\"s functionality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the effectiveness of WPA with different inputs, such as np.ones and Gaussian noise, and suggests that the authors should provide more insight into how WPA works. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the effectiveness of WPA with different inputs and the lack of insight into how WPA works. While the comment highlights areas that could be explored further, it does not provide specific evidence, examples, or references to support the claims. The reasoning is logical, but it lacks detailed justification or examples, making it 3. The authors would need to infer the potential issues and explore them further to address the comment effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could significantly enhance the paper. It suggests that the authors should provide a deeper explanation of why WPA works, particularly with respect to the model\"s predictions when given np.ones input. This is a valuable suggestion as it could help clarify the underlying mechanisms of WPA and potentially lead to future research directions. Additionally, the comment questions whether any input could serve as a white paper and why Gaussian noise input does not work as well as WPA, which are relevant and actionable questions. The comment also highlights the importance of understanding how WPA works, as it could spark future research directions. However, the feedback could be more helpful if it provided specific guidance on how to address these questions or offered examples of how to explore these areas further. Overall, the comment is 4 as it identifies important areas for improvement and provides some direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the authors to provide more clarification on this issue. While the action is clear, the comment does not specify how the authors should clarify the similarity or what specific aspects need further explanation. The request for clarification is direct, but the lack of detailed guidance on how to address the issue makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"method part\" and references a specific related work, \"Generating Adversarial Disturbances for Controller Verification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the similarity between the method part and the related work, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any specific examples or detailed reasoning to support the claim of similarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a valid concern that could impact the originality and contribution of the paper. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or differentiate their work from the related work. While it points out a potential problem, it does not offer actionable advice for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods, given that it uses a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, leaving the authors uncertain about what steps to take to address these issues. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also mentions that the authors have adequately addressed the limitations and potential negative societal impact of their work, but this part is not specific enough to guide further improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the questions. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO. It also questions whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies potential areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider these issues but does not fully support them in making improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the setting of two important parameters/thresholds, specifically the minimum cluster size and the conductance threshold. It notes that these parameters are not discussed in the experimental section (Sec. 3), which is crucial for understanding the sensitivity of performance with respect to these parameters. The comment implies that the authors should address this gap by discussing how these parameters are set and how they affect the results. While the action is implicit, it is concrete in suggesting that the authors should include a discussion on parameter setting and sensitivity analysis. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"End of Sec.2\" and \"Sec. 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the absence of discussion on the setting of two important parameters/thresholds (minimum cluster size and conductance threshold) in the experimental section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of discussing these parameters and their impact on performance, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the experimental section (Sec. 3) does not discuss how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a critical oversight that could impact the validity and reliability of the results. The comment provides clear guidance by suggesting that the authors should include a discussion on these parameters, which would enhance the comprehensiveness and robustness of the paper. However, the comment could be more helpful if it offered specific suggestions on how to address this issue, such as recommending a sensitivity analysis or providing examples of how these parameters affect the results. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written too briefly and could be improved by a slower development for easier readability. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the section. The action is implicit and somewhat vague, as the authors can infer that they need to expand the section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the section is \"tersely written\" and suggests that a slower development would improve readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is \"tersely written\" and suggests that a slower development would improve readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the assertion that the section is too brief or that a slower development would enhance readability. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is \"tersely written\" and suggests that a slower development would improve readability. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance or suggestions on how to achieve a slower development or what changes could be made to enhance readability. While it provides some insight, the comment could be more helpful if it included actionable advice or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this potential weakness or suggestions for alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. However, it does not specify which part of the paper this issue is discussed in, nor does it provide specific details on how this weakness could be addressed. The authors cannot confidently determine which section of the paper this comment pertains to, making it weakly grounded. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might improve the approach. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the need for reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train models that use gradient descent. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The reasoning is somewhat vague and does not provide a clear basis for the assertion, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting it may make the approach less dataefficient and harder to train models that use gradient descent. While the comment identifies a potential issue, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential issue but does not offer sufficient direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is 5 as it offers concrete steps for improvement, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a table showing the distribution of video lengths across the dataset and explains how the authors should ensure a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what specific information is missing and how it should be addressed. The comment is also specific because it details the exact information that needs to be included and how it should be presented. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how a balanced representation of different video lengths was ensured across the 11 categories. While the claim is logical and based on a reasonable assumption, it lacks specific examples or references to support the importance of this distribution. The suggestion for including a table and explanation is clear, but the claim itself is 3 due to the lack of detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical aspect of the paper that is missing: the distribution of video lengths within the benchmark and how it affects the assessment of reasoning ability and robustness. It provides a clear and actionable suggestion by instructing the authors to include a table showing the distribution of video lengths and to explain how they ensured a balanced representation across the 11 categories. This feedback is highly valuable as it guides the authors on how to enhance the comprehensiveness and clarity of their work. By addressing this point, the authors can significantly improve the robustness and validity of their analysis. Therefore, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests clarifying the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. While the comment provides clear guidance on what needs to be clarified, it does not explicitly instruct the authors to make these clarifications. The action is implicit but concrete, as the authors can infer that they need to address these points. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the differences between the implemented bilinear layer and other approaches that use bilinear pooling, particularly regarding the dimensionality of embeddings and the swapping of the bilinear layer with other approaches. Additionally, it questions whether the compression of representations using Equation (3) is still done in this case. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the differences between the implemented bilinear layer and other approaches that use bilinear pooling. It asks specific questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these questions. Without additional context or justification, the authors may find it challenging to address these points effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for clarification regarding the implemented bilinear layer and its differences from other approaches that use bilinear pooling. It raises questions about the dimensionality of embeddings, the swapping of the bilinear layer with other approaches, and whether the compression of representations using Equation (3) is still done. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar approaches have been discussed in the literature. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a cautious approach should be taken regarding the contribution of the dataset until it is made publicly available. However, it does not provide explicit guidance on what actions the authors should take to address this issue. The comment implies that the authors should wait for the dataset to be publicly accessible before considering it a significant contribution, but it does not specify how the authors should handle this situation or what steps they should take to ensure the dataset is made available. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, suggesting a cautious approach until it is made accessible. However, it does not specify which part of the paper discusses the dataset or where this issue is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to be cautious, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, suggesting a cautious approach until it is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the contribution of the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment highlights a critical issue regarding the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is made publicly accessible. This feedback is important as it points out a potential limitation in the paper\"s contribution, which could impact its credibility and impact. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they could take to ensure the dataset is made available. While it identifies a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider the dataset\"s availability but does not fully support them in resolving the issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It mentions that the group attention design is related to ResNeSt but not discussed in the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their method from existing ones. The action is implicit and vague, as the authors are left to infer that they need to discuss the differences or provide a more detailed comparison with existing works. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relation to ResNeSt. However, it does not explicitly mention which part of the paper discusses these similarities or the proposed method, making it weakly grounded. The comment is specific in detailing the issue of limited novelty and the similarity to existing works, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works [1, 2, 3] and noting the similarity to ResNeSt [4]. However, the comment lacks detailed comparisons or specific examples of how the proposed method is similar to or different from these works. This makes the claim 3, as the authors would need to conduct their own analysis to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that the proposed method lacks novelty due to its similarity to other attentional modules in previous works. It highlights the similarity to ResNeSt and notes that while the previous works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. This feedback is valuable as it points out a critical weakness in the paper, prompting the authors to address the lack of novelty and differentiate their work from existing ones. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or offered examples of how to better distinguish the proposed method from existing ones. Overall, the comment is 3 as it directs the authors to a key area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the similarity in preactivation values of two networks and suggests that the output cosine similarity will be high. It then asks why the results of the latter loss term of Eqn 13 are not directly illustrated. While the comment implies that the authors should provide more detailed results or explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed results or explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the results of the latter loss term of Eqn 13 are not directly illustrated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the similarity in preactivation values of two networks and suggests that their output cosine similarity will be high. It then asks why the results of the latter loss term of Eqn 13 are not directly illustrated. The comment provides a logical reasoning for the expected outcome of the similarity in preactivation values, but it lacks specific examples or references to support the claim about the results of the latter loss term. This makes the claim 3, as it provides a basis for the question but requires further elaboration or evidence to fully substantiate the suggestion for improvement.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, questioning why the results of the latter loss term of Eqn 13 are not directly illustrated. It provides a logical explanation for the expected outcome of the similarity in preactivation values of two networks, suggesting that their output cosine similarity will be high. This feedback is clear and actionable, as it prompts the authors to include more detailed results or explanations that could enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the comparison with testtime adaptation (TTA) methods, specifically mentioning the need to compare with [AB] methods. The reviewer suggests that a comparison should be made based on experimental results to prove whether data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the topic of \"robustness in video action recognition\" and the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the need for a comparison with TTA methods, particularly in terms of experimental results, to prove the superiority of data processing over model parameter adjustment. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison with testtime adaptation (TTA) methods, which are relevant for adapting to outofdistribution data. The reviewer suggests that a comparison should be made to prove the superiority of data processing over model parameter adjustment. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to TTA methods, making it 3. The authors would need to conduct additional research to understand the relevance and applicability of TTA methods in their context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, which are relevant for adapting to outofdistribution data. It suggests that a comparison with these methods could help prove the superiority of data processing over model parameter adjustment. This feedback is clear and actionable, as it provides a specific area for improvement and a potential direction for the authors to explore. However, the comment could be more helpful if it included specific examples of TTA methods or detailed guidance on how to conduct the comparison. Overall, the comment is 4, as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This provides clear and direct guidance on what needs to be corrected in the draft. The action is explicit and concrete, as the authors know exactly what needs to be changed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the first expression for J(\u03b8), indicating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) is incorrect and should be Q(s_t0, \u03c0\u03b8(s_t0)). However, the comment does not provide any reasoning or evidence to support this claim, such as explaining why the current expression is incorrect or how Q(s_t0, \u03c0\u03b8(s_t0)) is the correct form. Without additional context or justification, the claim remains 1, as the authors would need more information to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J(\u03b8) in Section 3.2.1, stating that it should be Q(s_t0, \u03c0\u03b8(s_t0)). This feedback is clear and actionable, providing the authors with precise guidance on what needs to be corrected in their draft. By addressing this error, the authors can improve the accuracy and validity of their work. However, the comment could be more helpful if it explained why the current expression is incorrect or how the correction impacts the overall analysis. Nonetheless, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple observations and corrections regarding formatting and capitalization issues in the references and the text. It explicitly lists specific instances of incorrect capitalization and formatting, such as \"s/expensive approaches2) allows/expensive approaches,2) allows/\" and \"p.8: s/estimates3) is/estimates, and3) is/.\" Additionally, it points out the need for capitalization in references like \"ai\" in Amodei et al. (2016) and \"bayesian\" in various papers. The comment provides clear and explicit actions for the authors to take, such as correcting the formatting and capitalization errors. This level of detail ensures that the authors know exactly what changes to make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections and references, allowing the authors to accurately identify the parts of the paper being addressed. It provides detailed guidance on formatting and capitalization issues, such as correcting \"s/expensive approaches2) allows/\" to \"expensive approaches,2) allows/\" and ensuring proper capitalization in references like \"ai\" in Amodei et al. (2016). The comment is also specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding formatting and capitalization errors in the references and text. It lists specific instances of incorrect capitalization and formatting, such as \"s/expensive approaches2) allows/\" and \"p.8: s/estimates3) is/estimates, and3) is/.\" These are factual observations that do not require verification or justification, as they are straightforward corrections. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific formatting and capitalization errors in the references and text, such as incorrect use of \"s/\" and missing capitalization in words like \"ai\" and \"bayesian.\" It also corrects references to conferences like ICML and NeurIPS. While the comment is detailed and identifies clear issues that need correction, it lacks broader context or suggestions for improvement beyond the specific formatting errors. The authors will benefit from this feedback in terms of accuracy and professionalism, but the comment could be more helpful if it offered guidance on how to ensure consistency in formatting and capitalization throughout the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the model parameters, specifically asking for the values of parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details about the parameter selection process. However, the comment lacks concrete guidance on how to present this information, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the model parameters, specifically asking for the values of parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where these parameters are discussed. The comment is specific in detailing what information is missing, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific details about the model parameters and their selection. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and aim to gather information, making the comment \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the model parameters, specifically asking for the values of parameters for task 1 and the choice of lambda for the Boltzmann policy. It also inquires about the method used to choose the parameters, suggesting maximum likelihood estimates. While the comment identifies a gap in the information provided in the paper, it does not offer specific guidance or suggestions on how the authors might address these questions or improve their draft. The feedback is 3 as it points out a need for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results and suggests that the performance is primarily due to the first step, implying that comparisons with existing detection methods are necessary. However, the comment does not provide explicit guidance on how to conduct these comparisons or what specific experiments should be performed. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks and questions the validity of this claim. It suggests that the performance is primarily due to the first step, implying that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in detailing what needs to be addressed, namely the need for comparisons with existing detection methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results, suggesting that the performance is primarily due to the first step. The reviewer implies that comparisons with existing detection methods are necessary to substantiate this claim. However, the comment lacks specific examples or references to existing works that the authors could use for comparison. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or references to support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to substantiate this claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or conduct the necessary comparisons. The feedback is 3 as it points out a critical area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment explicitly requests the authors to provide an explanation for this observation, which is a clear and direct action. However, it does not specify how the authors should approach this explanation or what specific aspects to focus on. While the action is explicit, the lack of detailed guidance on how to address the issue makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance impact of applying Conditional Batch Norm to different layers, particularly why applying it to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically asking why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment does not make a claim or provide an opinion but rather seeks clarification from the authors. It is a request for explanation and does not contain any subjective claims or suggestions, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, as observed in Table 2. It points out a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance for the GuessWhat?! task. The comment requests the authors to provide an explanation for this observation, which is a clear and actionable request for clarification. By addressing this question, the authors can gain a deeper understanding of their model\"s behavior and potentially make improvements. However, the comment could be more helpful if it provided additional context or suggestions on how to approach the explanation. Overall, the comment is 4 as it identifies a specific area for further investigation and provides a clear direction for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should include a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It also references a specific reference [1] that proposes a similar approach. This provides clear guidance on what action the authors need to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, which allows the authors to identify the specific part of the paper that needs attention. It also specifies the issue by pointing out the absence of method or performance comparisons, particularly referencing a specific reference [1] that proposes a similar approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning \"intertask ensemble\" and \"intratask\" ensemble. It references another work [1] that proposes a similar approach, providing some context for the claim. However, the comment does not fully substantiate the claim by explaining why this comparison is crucial or how it would impact the paper\"s contributions. While the reference to [1] offers some support, the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It references another work [1] that proposes a similar approach, highlighting the importance of including this comparison to enhance the paper\"s contributions. This feedback is clear and actionable, providing the authors with a specific area to address and a reference to consider for their comparison. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the \"required implicit call to the Witness oracle,\" indicating that it is confusing. However, it does not provide any explicit guidance or suggestions on how to clarify or address this confusion. The action is implicit, as the authors can infer that they need to clarify the call, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"required implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is located in, such as a particular section or figure. Without explicit references or detailed guidance, the authors may find it challenging to pinpoint the exact area needing clarification. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this call is confusing or how it could be clarified. Without additional context or justification, the authors may find it difficult to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"required implicit call to the Witness oracle\" is confusing. This feedback is 3 as it points out a potential area of confusion that the authors should address. However, the comment lacks depth and does not provide any suggestions or guidance on how to clarify the issue or improve the clarity of the paper. While it highlights a specific problem, it does not offer actionable advice for resolution, limiting its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the proposed method, specifically its inability to handle headpose, and questions why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021) does. While the comment identifies a specific issue and references a relevant work, it does not provide explicit guidance on how the authors should address this limitation or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should explore ways to condition headpose parameters similar to the referenced work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the issue of handling headpose, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the problem by referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, and it questions why the proposed method cannot condition headpose parameters similarly. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method cannot handle headpose and questions why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). The comment provides a specific reference to a previous work that addresses the issue, which is a good starting point for justification. However, the comment lacks detailed reasoning or examples of how the proposed method could be adapted to handle headpose, making the claim 3. The authors would need to delve deeper into the referenced work and the proposed method to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose, which is a critical aspect of facial expression control. It questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021), which is able to control both facial expression and headpose. This feedback is valuable as it highlights a specific area for improvement and provides a reference to a related work that could serve as a basis for addressing this limitation. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might adapt their method to handle headpose. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Sections 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing only a few times in the training set. It references examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the concept. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue in their draft. While it points out a potential problem, it lacks actionable advice on how to mitigate it or improve the draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the spurious features being similar to backdoor triggers and provides examples from Chen et al. (2017) and Gu et al. (2019) to support the claim. This level of detail helps the authors understand what needs to be addressed in the sections mentioned. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Sections 3.1 and 3.2 are similar to backdoor triggers and notes that these artificial patterns can have a significant impact on the trained model. The comment supports this claim by referencing examples from Chen et al. (2017) and Gu et al. (2019), which use random noise patterns and singlepixel triggers, respectively. This provides a logical reasoning and specific examples to substantiate the claim, making it 4. However, the comment could be strengthened by further elaboration on how these similarities might affect the model or by providing more detailed references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the concept, which helps the authors understand the potential impact of these features on the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a critical area for consideration, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component of the paper, but it appears to be directly taken from previous works. The reviewer finds this confusing and suggests that it reduces the contribution of the paper. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting alternative optimization algorithms or explaining how their contribution differs from previous works. The action is implicit and vague, leaving the authors to infer that they need to clarify the originality of their optimization algorithm. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the structural optimization, which is mentioned as a main component of the paper, and notes that the optimization algorithm seems to be directly taken from previous works. However, it does not specify which part of the paper discusses this optimization or where the previous works are referenced. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the optimization algorithm, but it lacks grounding as it does not clearly reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the structural optimization is directly taken from previous works, which reduces the contribution of the paper. However, the comment does not provide specific references or examples of these previous works, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or references, the claim is 3, as it lacks the necessary support to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the structural optimization is a main component but appears to be directly taken from previous works. This observation suggests that the contribution of the paper may be reduced due to the lack of originality in this aspect. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending alternative optimization algorithms or explaining how their approach differs from previous works. While it highlights a potential weakness, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not provide specific guidance on how to improve the introduction of the baseline models or how to enhance the results of the pipeline style method. The lack of actionable advice or concrete suggestions makes it difficult for the authors to know exactly what steps to take to address these issues. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method involving two models on XVNLI and MaRVL, indicating that it does not yield better average results. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which sections of the paper discuss these experiments or baseline models, making it difficult for the authors to pinpoint the exact parts that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. Additionally, while the comment identifies the issue with the results and the introduction of baseline models, it does not provide specific guidance on how to address these issues. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the pipeline style method, including two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment lacks specific details or evidence to support these claims, such as comparisons with other methods or references to studies that have achieved better results. Without such supporting information, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, is not better than the baseline models for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. However, the comment lacks specific suggestions or guidance on how the authors might improve the performance of the pipeline style method or enhance the introduction of the baseline models. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issues but no clear path forward for improvement. Therefore, the comment is 2, as it identifies areas for improvement but does not provide sufficient guidance to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature using a \"coarse\" methodology. It questions the necessity of this observation, given that it has been made at each step of the evolution of language models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or address the critique, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used by the authors to reproduce a wellknown result in the literature, specifically the left political bias in ChatGPT and LLMs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the methodology, questioning the necessity of reproducing a wellknown observation using a \"coarse\" approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the evolution of language models, from word2vec to BERT to ChatGPT, to support the claim that this observation is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the evolution of language models, from word2vec to BERT to ChatGPT, to support the claim that this observation is not novel. However, the comment lacks actionable suggestions or guidance on how the authors might address this critique or improve their work. While it highlights a potential weakness in the paper, it does not offer specific advice or direction for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include related work on modular networks for VQA, specifically mentioning a reference \"[A]\" that should be cited. This provides a clear and direct action for the authors to take, ensuring that the introduction accurately reflects the current state of research in modular architectures for VQA. The comment is 5 because it specifies exactly what needs to be added and provides a concrete reference to guide the authors. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"When discussing related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that related work on modular networks for VQA should be included, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction lacks a mention of related work on modular networks for VQA, which could give the impression that no one uses modular architectures for VQA. This claim is 3 as it highlights a potential gap in the literature review, but it lacks specific examples or references to support the assertion. The mention of \"[A]\" suggests that there is relevant work that should be included, but without further details, the authors may find it challenging to identify and incorporate this work effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper\"s discussion of related work, noting the importance of mentioning modular networks for VQA. It suggests that the current introduction may give the impression that no one uses modular architectures for VQA, which is not accurate. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors improve the comprehensiveness and accuracy of their literature review. However, the comment could be more helpful if it included specific examples or references to guide the authors on which works to include. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more detailed to fully support the authors\" efforts."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include comparisons with these methods, but the comment lacks concrete details on which specific aspects to focus on or how to conduct these comparisons. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area of focus in the paper, namely the authors\" emphasis on SSC and the lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the methods that should be considered for comparison, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The claim is 3 as it provides a logical reasoning for the comparison, noting the computational efficiency and similar guarantees of the mentioned methods. However, the comment lacks specific examples or references to these methods, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is 3 as it points out an area where the authors could enhance their work by including comparisons with other methods. However, the comment lacks specific suggestions on how to conduct these comparisons or which aspects to focus on, leaving the authors with a general direction but not detailed guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. It provides a specific suggestion for renaming a column in Table 1 to better reflect the semisupervised version of the method. Additionally, it offers a more comprehensive approach by suggesting the use of two columns to specify the data used for training each model. This feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and the \"proposed framework row,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training, and suggests renaming a column in Table 1. Additionally, it provides a detailed suggestion for improving the clarity of the table by using two columns to specify the data used for training each model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training in their proposed method. It provides a specific example from Table 1, where the authors are advised to rename a column to better reflect the semisupervised version of the method. The suggestion to use two columns to specify the data used for training each model is also offered. While the comment provides a clear and logical reasoning for the suggested changes, it lacks specific references or examples from the literature to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the suggestion but could benefit from additional references or detailed explanations.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by identifying a specific area where the authors need to clarify the distinction between weak supervision and semisupervised training in their proposed method. It suggests renaming a column in Table 1 to better reflect the semisupervised version of the method and offers a more comprehensive approach by proposing two columns to specify the data used for training each model. This feedback is detailed and provides concrete steps for the authors to improve the clarity and transparency of their work. By addressing these suggestions, the authors can enhance the readability and comprehensibility of their paper, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper for making small contributions over previous methods, such as NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issues raised or improve the paper. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for making small contributions over previous methods, specifically mentioning NCNet and Sparse NCNet. However, it does not specify which part of the paper these comparisons are based on, making it difficult for the authors to identify the exact sections that need attention. The comment also lacks specificity regarding what aspects of the contributions are considered small or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods, specifically NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique. The absence of concrete evidence or references makes the claim 2, as it provides some basis for the critique but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment critiques the paper for making small contributions over previous methods, specifically NCNet and Sparse NCNet, and suggests that the work is mostly engineering. It also notes that it is challenging to differentiate the current work from its predecessors due to similar performance. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their work. Without actionable feedback or detailed insights, the authors are left without a clear path for enhancing their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to remove statements about semantic segmentation being a lowlevel cue from the paper. This is a direct and clear action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the removal of statements about semantic segmentation being a lowlevel cue. This provides clear guidance on what the authors should revise in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel since categories are specified for each pixel. This claim is based on a logical reasoning that challenges the categorization of semantic segmentation as a lowlevel cue. However, the comment does not provide specific examples or references to support this claim, which could strengthen the argument. As a result, the claim is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the categorization of semantic segmentation as a lowlevel cue, pointing out that the categories are specified for each pixel. This feedback is clear and actionable, as it instructs the authors to remove statements that inaccurately describe semantic segmentation. By addressing this point, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between lowlevel and highlevel cues. Overall, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem or what specific changes they should make to their tables. The action is implicit and somewhat vague, as the authors can infer that they need to include these missing cases in the tables, but they are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation experiment\" and \"the two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the tables, which is the lack of cases where both dependency tree and RL are not used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree and points out that the tables do not include cases where both dependency tree and RL are not used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the tables do not include cases where both dependency tree and RL are not used. This feedback is clear and actionable, as it highlights a gap in the experimental setup and suggests that the authors should include these missing cases in the tables. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or address the observed performance differences. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This feedback provides a clear direction for the authors to expand their experimental evaluation by considering additional datasets and models, which would enhance the comprehensiveness of their work. However, the comment could be more actionable by specifying which datasets or models the authors should consider. Overall, the comment is 4 as it gives a concrete direction for improvement, even if it lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The comment further suggests consulting specific works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experimental evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types. This claim is 3 as it provides a logical reasoning for the limitation in the experimental scope and suggests a specific direction for improvement by referencing relevant literature. However, the comment could be strengthened by providing more detailed examples or specific references to datasets that should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which are only conducted on the CIFAR10 dataset without considering other datasets from Federated learning benchmarks. It suggests that the authors should consult relevant works like FedProx and FedMAX for details on different datasets and model types, providing a clear direction for improvement. This feedback is actionable and constructive, as it highlights a critical area for expansion and offers specific references to enhance the comprehensiveness of the experimental evaluation. By addressing this feedback, the authors can significantly improve the depth and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim made in the paper regarding the improvement in accuracy and completeness. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider using alternative datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different datasets for their study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly refers to a specific claim made in the paper regarding the improvement in accuracy and completeness, which can be identified by the authors. It also provides a specific suggestion to use another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This level of detail allows the authors to understand exactly what needs to be addressed and how to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to test the robustness of the claim, as using different datasets can provide a more comprehensive evaluation. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks complete evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment questions the validity of a specific claim made in the paper regarding the improvement in accuracy and completeness. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is 3 as it points out a potential weakness in the paper and offers a specific suggestion for improvement. However, it could be more helpful if it provided additional context or reasoning for why the current dataset might not be sufficient or why the alternative dataset would be beneficial. The authors are given a direction to consider, but the comment lacks depth and detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It contrasts this approach with previous work that considers multiple CVEs or CWEs simultaneously. The reviewer asks whether the authors intend to focus on identifying one vulnerability at a time and questions the interpretability of the results. While the comment highlights a potential issue with the methodology, it does not provide explicit guidance on how the authors should address these concerns or suggest specific changes to improve the study. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their methodology and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It contrasts this with previous work that considers multiple CVEs or CWEs simultaneously and raises concerns about the ecological validity of the study. The comment also questions the interpretability of the results, suggesting that they may be marginal improvements at best. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing the concerns about the methodology and the interpretation of results, but it lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It contrasts this with previous work that considers multiple CVEs or CWEs simultaneously, suggesting that the current approach may lack ecological validity. The reviewer also questions the interpretability of the results, suggesting they may be marginal improvements at best. While the comment provides some context by referencing previous work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed evidence or references makes the claim 3, as the authors would need to delve deeper into the literature to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the approach of considering a single vulnerability at a time. It contrasts this with previous work that considers multiple CVEs or CWEs simultaneously, suggesting that the current approach may lack ecological validity. The reviewer also questions the interpretability of the results, suggesting they may be marginal improvements at best. This feedback is 3 as it identifies a potential weakness in the methodology and raises questions about the study\"s validity and results. However, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their methodology. To be more helpful, the comment could provide examples of how previous work has addressed similar issues or suggest alternative approaches. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive. While the comment identifies an area that needs further explanation, it does not provide specific guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the relationship between the community structure and degree bias is not intuitive enough, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between the community structure and degree bias is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the exact nature of the lack of intuition and how it relates to the theorems. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by noting that the relationship between the community structure and degree bias is not intuitive enough, despite Theorem 1 and 2 providing evidence of a clearer community structure. This feedback is clear and actionable, as it directs the authors to provide more explanations on how a small degree of bias can be obtained from a clear community structure. However, the comment could be more helpful if it offered suggestions on how to enhance the explanation or provide additional insights. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with specific guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While it highlights a potential inconsistency or lack of clarity in the paper, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors are left to infer that they need to clarify or provide more information on this point, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies an area for clarification but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183 and Figure 2.c, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and the computation of the denominator in Figure 2.c for ResNet50 and ATResNet50 networks. The comment highlights a potential inconsistency or lack of clarity in the paper, but it does not make a subjective claim or suggestion that requires verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for nonstochastic networks, pointing out a potential inconsistency in the paper. It also questions how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment identifies a specific area of confusion, it does not provide detailed guidance or suggestions on how the authors might address this issue or clarify the methodology. The feedback is 3 as it highlights a potential weakness in the paper, but it lacks actionable advice or depth, making it incomplete for the authors to fully understand and address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential source of confusion in the paper, specifically the notation and the explicit split between \"static\" and temporal features. The reviewer suggests that more information is needed to clarify this point, mentioning the variables \"S\" and \"Xt.\" However, the comment does not provide explicit guidance on how to address this issue or what specific information should be added to clarify the notation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a potential source of confusion regarding the notation and the explicit split between \"static\" and temporal features. It mentions the variables \"S\" and \"Xt,\" indicating that the authors need to provide more information to clarify these aspects. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what needs to be clarified, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the notation and the explicit split between \"static\" and temporal features, suggesting that it is confusing and requires more information. However, the comment does not provide specific examples or references to support why this notation is confusing or how it could be clarified. The lack of detailed reasoning or evidence makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically regarding the notation and the explicit split between \"static\" and temporal features. It highlights the need for more information, mentioning the variables \"S\" and \"Xt,\" which the authors should clarify to improve the paper\"s clarity. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it points out a weakness, it lacks actionable feedback, making it 3. The authors are informed of a potential area for improvement but are not given detailed steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment identifies areas where more detail is needed, it does not provide explicit instructions on how to incorporate these details or what specific information should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing graph notions and Algorithm 1. This provides weak grounding, as the authors can make an educated guess but cannot pinpoint the exact part. The comment is specific in suggesting what details could be added, such as definitions and explanations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, without making any subjective claims or opinions that require verification. It describes the content of the paper and suggests additional details that could be provided, such as definitions and explanations. Since it does not contain any claims or opinions that need justification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. This feedback is 3 as it identifies areas where more detail is needed to improve the clarity of the paper. However, it lacks specificity and does not provide detailed guidance on how to incorporate these suggestions, such as specific examples or additional information that could be included. While it offers some direction for improvement, it could be more comprehensive and actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, such as suggesting new ideas to incorporate or ways to differentiate their approach. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper discusses variable splitting or the algorithm, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could improve the novelty of their work. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific examples, references, or suggestions on how the authors could address this issue or improve the originality of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of how to enhance the novelty of their paper. This lack of detail and specificity makes the comment unhelpful, as it does not offer any meaningful insights or directions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking for quantitative results on testing images. While it does not explicitly instruct the authors to conduct such an evaluation, it implies that this is a necessary step to fully prove the point. The action is implicit, as the authors need to infer that they should include quantitative results on testing images. However, the comment provides a clear direction on what needs to be done, making it 3. The authors know that they need to focus on evaluating the shape model invariance on testing images, but the comment does not specify how to conduct this evaluation or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether there are quantitative results on testing images, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images are needed to fully validate the point. However, the comment does not provide any specific examples, references, or detailed reasoning to support why testing images are necessary or how they would improve the evaluation. This lack of supporting evidence makes the claim 3, as the authors would need to infer the importance of testing images based on the context of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the evaluation of shape model invariance, specifically questioning whether the evaluation on transformations of training images is sufficient to prove the point. It suggests that quantitative results on testing images are needed to fully validate the claim. This feedback is clear and actionable, as it directs the authors to consider an important aspect of their study that could impact the validity of their findings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the evaluation on testing images or what metrics to use. Overall, the comment is 4 as it identifies a critical area for improvement and guides the authors toward a more comprehensive evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment explicitly instructs the authors to discuss and compare this work to provide a better understanding of the stateoftheart. This feedback is clear and direct, providing a concrete action for the authors to take. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is a clear reference point for the authors. It also specifies what needs to be addressed, namely discussing and comparing this work to provide a better understanding of the stateoftheart. This level of detail allows the authors to accurately identify the part of the paper that requires revision and understand the nature of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this work should be discussed and compared to provide a better understanding of the stateoftheart. While the claim is based on a specific reference, it lacks detailed reasoning or examples of how this work relates to the authors\" paper. The comment provides a clear suggestion for improvement but lacks sufficient justification or explanation to fully support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or reasoning to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a related work, the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. It suggests that this work should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance the context and depth of their paper. By incorporating this comparison, the authors can provide a more comprehensive overview of their work in relation to existing research. However, the comment could be more helpful if it offered specific suggestions on how to integrate this comparison or what aspects to focus on. Overall, the comment is 4 as it provides a valuable direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the scalability of the approach, specifically questioning how it performs on machines with fewer cores. It also questions the method used to compute the optimal transport distance, particularly the transition from the doubly stochastic matrix obtained by the Sinkhorn method to the optimal transport. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to follow. The authors are left to infer that they should address these concerns by providing more information on scalability and the computation process. However, the lack of specific guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the approach used in the paper, specifically the computation of optimal transport distance. It questions the scalability of the method, particularly on machines with fewer cores, and seeks clarification on how the optimal transport is computed from the doubly stochastic matrix obtained by the Sinkhorn method. The comment is fully grounded as it explicitly mentions the \"approach\" and the specific aspects of the computation that need clarification. It is also specific because it clearly identifies what needs to be addressed: the scalability and the computation process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the approach, specifically questioning how it performs on machines with fewer cores. It also questions the method used to compute the optimal transport distance, particularly the transition from the doubly stochastic matrix obtained by the Sinkhorn method to the optimal transport. While the comment highlights potential issues, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors are left to infer the exact nature of the scalability concerns and the computational process. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises important concerns about the scalability of the approach, specifically questioning how it performs on machines with fewer cores. It also seeks clarification on the method used to compute the optimal transport distance, particularly the transition from the doubly stochastic matrix obtained by the Sinkhorn method to the optimal transport. This feedback is valuable as it highlights potential limitations and areas where the authors could provide more detailed information or explanations. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these concerns. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of their work. There is no guidance on how to enhance the experimental procedures or evaluations to make them more understandable. Without specific suggestions or recommendations, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 as it does not identify a specific area, and it is also not specific because it lacks detailed feedback on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper was \"extremely hard to follow,\" specifically mentioning difficulty in understanding the experimental procedures and evaluations. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to particular sections or experiments that were unclear, the authors may find it challenging to identify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their work. Without actionable feedback or detailed recommendations, the authors are left without a clear path for improvement. This lack of specificity and actionable advice makes the comment 2, as it identifies a problem but does not offer any meaningful guidance for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the draft. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this characteristic is not an advantage. The comment provides a clear critique of the paper\"s claim, making it specific. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the broader context and implications of this characteristic to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer argues that a model that can only handle a single time series data is almost useless, which provides a clear critique of the paper\"s claim. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests introducing specific aspects of the model that are relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the bounded nature of certain parameters like acceleration and scaling parameters. This feedback is clear and actionable, as it directs the authors to include specific details that would enhance the clarity and understanding of their work. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, such as introducing specific aspects of the model relevant to the example being discussed. The comment suggests highlighting that certain parameters are bounded, which is a precise suggestion for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the bounded nature of certain parameters like acceleration and scaling parameters. However, it does not provide any reasoning or evidence to support why these aspects are important or how they impact the understanding of the model. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors clarify certain aspects of the model, such as the bounded nature of parameters like acceleration and scaling parameters. This guidance is clear and helps the authors improve the clarity and comprehensibility of their work. By addressing these points, the authors can enhance the reader\"s understanding of the model and its specific characteristics. However, the comment could be more helpful if it offered additional suggestions or examples of how to present this information effectively. Overall, the feedback is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the experiments, specifically noting that most experiments are limited to RoBERTabase and lack generalizability to other models with learnable APEs. It suggests investigating the generalizability to differences in model size, objective function, and architecture, and provides a specific example by requesting results for GPT2. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of limited experiments, particularly the lack of generalizability to other models like GPT2, and suggests including more analysis and discussion for this model. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions the generalizability of the results to other models with learnable APEs. It suggests investigating the impact of differences in model size, objective function, and architecture, such as GPT2. While the comment highlights a potential limitation, it does not provide specific examples or detailed reasoning to support the claim. The suggestion to include more analysis and discussion for GPT2 is a logical step, but the comment lacks concrete evidence or references to substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experiments, noting that most experiments are limited to RoBERTabase and lack generalizability to other models with learnable APEs. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, such as GPT2. The comment provides specific guidance by requesting results for GPT2, as shown in Figure 2, which is a concrete and actionable suggestion. This feedback is 5 as it directs the authors to a critical area for improvement, offering a clear path to enhance the robustness and applicability of their findings. By addressing this limitation, the authors can strengthen their paper and provide more comprehensive insights into the generalizability of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should consider broader applicability, it does not explicitly instruct them to do so. The suggestion is implicit and somewhat vague, as it lacks specific guidance on how to conduct these explorations or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the parameters and experiments to other areas, such as NLP or simpler models in the image domain. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the applicability of the parameters and experiments presented in the paper, suggesting that they are limited to image data and ViT. The reviewer questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the method cannot generalize to different architectures and tasks. This makes the claim 3, as it provides a basis for the concern but requires further elaboration or evidence to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the experiments and parameters presented in the paper, suggesting that they are primarily focused on image data and ViT. It questions whether the authors have explored applying these principles to other areas, such as NLP or simpler models in the image domain, which could demonstrate the method\"s generalizability. This feedback is 3 as it prompts the authors to consider broader applicability and potential extensions of their work. However, it could be more helpful if it provided specific suggestions or examples of how to explore these other areas or what benefits such explorations might bring. Overall, the comment encourages the authors to think about the broader implications of their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors evaluate TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS as a potential benchmark. While the comment implies an action for the authors to take, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects of WILDS should be considered. The action is inferred and somewhat vague, as the authors need to deduce the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors evaluate TTA on more conditions of natural distribution shift, such as WILDS, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks many popular TTA methods and recommends evaluating TTA on more conditions of natural distribution shift, such as WILDS. The claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or detailed references to support the claim about the performance of TTA methods on nonstandard benchmarks. While the suggestion to use WILDS is a good starting point, the comment could be strengthened by providing more detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies an interesting observation regarding the performance of TTA methods on nonstandard benchmarks, suggesting that this could be a valuable area for further exploration. It provides a specific suggestion to evaluate TTA on more conditions of natural distribution shift, such as using WILDS, which could strengthen the paper. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their work. However, it could be more helpful if it included additional guidance on how to implement this suggestion or what specific aspects of WILDS should be considered. Overall, the comment is 4, as it provides valuable insights and actionable feedback, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the scalability of the learning rate condition, which is not seen in practice and could lead to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the learning rate condition, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer provides a logical reasoning by stating that in practice, the step size does not grow with the sample size, which supports the claim. However, the comment could be strengthened by providing specific examples or references to datasets where this issue is observed. Overall, the claim is 3 as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. This feedback is 3 as it highlights a potential weakness in the approach and encourages the authors to reconsider their condition. However, the comment could be more helpful if it provided suggestions or alternatives for addressing this issue, such as proposing different scaling methods or discussing potential workarounds. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the utility of the tensor networks in representing the probability mass function (PMF) of discrete variables and questions their significance in the context of machine learning algorithms. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of clarity or improve the significance of the paper. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the utility of tensor networks in representing the probability mass function (PMF) of discrete variables and questions their significance in the context of machine learning algorithms. However, it does not specify which part of the paper discusses these tensor networks or their application, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on how to address the issue of clarity or significance. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the significance of the paper is poor because it does not clearly demonstrate how the tensor networks can be useful to machine learning algorithms or for analyzing algorithms. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the utility and significance of the paper, specifically questioning how the tensor networks can be used to represent the probability mass function (PMF) of discrete variables and their relevance to machine learning algorithms. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, as it does not offer any meaningful insights or directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). This implies an action for the authors to take, which is to modify their approach to better align with realworld applications. However, the comment does not provide specific guidance on how to implement this change or what specific aspects of the current approach need to be adjusted. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the data being perfectly balanced, which is impractical in realworld applications, and suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests that the authors should use a more realistic setting, as done in a referenced paper, by sampling unlabeled data from millions of reviews. The comment provides a logical reasoning by contrasting the current approach with a more practical one, and it references a specific paper for further justification. However, the comment could be strengthened by providing more detailed examples or explanations of how the referenced paper\"s approach addresses the issue. Overall, the claim is 4, as it offers a clear direction for improvement but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a practical issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications. It suggests that the authors should adopt a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This feedback is clear and actionable, providing the authors with a specific direction for improving their approach to better align with realworld scenarios. However, the comment could be more helpful if it included additional details or examples of how to implement this change effectively. Overall, the comment is 4, as it offers valuable guidance for enhancing the practicality of the study."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing Equation (10) and line 130. It also compares this issue to sampling from the leverage score in [3], questioning the ease of sampling from the DPP. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their sampling method. The action is implicit and vague, leaving the authors to infer that they need to clarify or address the sampling process, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when eigenfunctions are inaccessible, and by comparing it to sampling from the leverage score in [3]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when eigenfunctions e_n are inaccessible, referencing Equation (10) and line 130. It also compares this issue to sampling from the leverage score in [3], questioning the ease of sampling from the DPP. The comment provides a logical comparison and highlights a potential problem, but it lacks specific examples or detailed reasoning to fully substantiate the claim. While the comparison to [3] provides some context, the comment could be strengthened with more explicit evidence or examples to fully support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires additional detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in sampling from the DPP when the eigenfunctions e_n are inaccessible. It references Equation (10) and line 130, providing a clear indication of where the issue is located. The comment also makes a relevant comparison to sampling from the leverage score in [3], which helps the authors understand the context of the problem. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue, such as proposing alternative methods or providing examples of how to clarify the sampling process. Despite this, the comment provides valuable insight into a potential weakness in the paper, making it 3 for the authors to consider in their revisions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper regarding the generalizability of the observations to fewshot learners beyond Prototypical Networks. It suggests that the scope of the submission\"s contributions might be limited due to this lack of evaluation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and vague, as the authors are left to infer that they need to conduct additional evaluations but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper regarding the generalizability of the observations to fewshot learners beyond Prototypical Networks. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of limited scope but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the extent to which the observations generalize to fewshot learners beyond Prototypical Networks, which may limit the scope of the submission\"s contributions. This claim is 3 as it highlights a potential gap in the evaluation of the paper\"s findings. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the observations presented do not generalize to fewshot learners beyond Prototypical Networks. This is a valuable insight as it highlights an area where the paper could be strengthened by evaluating the generalizability of its findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or conduct additional evaluations to improve the scope of their contributions. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality (e.g., modality A) while others perform well with another (e.g., modality B). It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how to deal with this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the problem but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential difference in contributions of different modalities across instances and questioning how to deal with this problem. The comment provides a clear direction for the authors to address the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this issue, specifically referencing Equation 3. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim or explain why this is a problem. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the contribution of different modalities across instances, noting that some instances may perform well with one modality while others perform well with another. It questions how to address this problem, specifically referencing Equation 3, which removes the modal subset of all instances. This feedback highlights a specific area where the authors may need to clarify or address the implications of their method, particularly in terms of modality performance. However, the comment lacks detailed guidance or suggestions on how to resolve this issue, which limits its helpfulness. The authors are left with a general understanding of the problem but without concrete steps to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the abstract effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. It mentions \"minor language issues,\" which could imply a need for editing or clarification. However, the comment does not provide specific guidance on how to address these issues or what language changes are needed. The action is implicit and somewhat vague, as the authors can infer that they need to improve the abstract by adding evaluation details and addressing language issues, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the abstract effectively explains the proposed idea but lacks details on evaluation and outcome. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the evaluation or outcome that is missing. The comment is 3 as it highlights a potential gap in the abstract, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear observation about the abstract, noting that it effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. This feedback is 3 as it identifies a specific area for improvement, suggesting that the authors should include more information about the evaluation and results in the abstract. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of what additional information could be included. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on other settings, even simulated ones. While the comment highlights a gap in the experimental section, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should conduct experiments on additional settings, but the comment lacks concrete details on which settings or how to implement these experiments. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value functions,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on certain settings, such as those involving thresholded rewards or privacypreserving data collection. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are not convincing and questions the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on other settings. However, the comment lacks specific examples or references to support the claim that the experimental results are not convincing. It also does not provide detailed reasoning or evidence to substantiate the claim that the experiments are not useful. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail and evidence to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on other settings, even simulated ones. This feedback highlights a potential gap in the experimental section, suggesting that the authors should consider including experiments on a broader range of settings to strengthen the paper\"s claims. However, the comment could be more helpful if it provided specific suggestions on which additional settings should be explored or how to design these experiments. Overall, the comment is 3 as it identifies a weakness and prompts the authors to consider expanding their experimental scope, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out inconsistencies in the notation and questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. While the comment identifies specific areas of confusion and references the original paper for context, it does not provide explicit instructions on how to clarify or address these issues. The authors are left to infer that they need to clarify the notation and the use of unlabeled data in source domains. The action is implicit and somewhat vague, as it lacks detailed guidance on how to resolve the confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Method Section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the description of the MFDA setting, including the confusion caused by the notation for the target domain and the use of labeled and unlabeled data. The comment provides specific examples and references to the original MFDA paper, which helps the authors understand what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting is confusing, specifically mentioning inconsistencies in notation and the use of labeled and unlabeled data. The reviewer references the original MFDA paper (Yue et al., 2021a) to support their claim, noting that the target data is unlabeled. This provides a clear basis for the claim, as it highlights a potential misunderstanding in the paper\"s description. However, the comment could be strengthened by providing more detailed examples or explanations of the specific issues with the notation. Overall, the claim is 4, as it is supported by a reference to the original paper, but it could benefit from additional details to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the MFDA setting in the first paragraph of the Method Section, pointing out confusion in the notation and the use of labeled and unlabeled data. It references the original MFDA paper (Yue et al., 2021a) to highlight the inconsistency and questions whether the unlabeled data in source domains are used during training, as in the original paper. This feedback is clear and actionable, as it directs the authors to clarify the notation and the use of data in their description. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity of the description. Overall, the comment is 4, as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an epochwise analysis, particularly for finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment implies that the authors should consider conducting an epochwise analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. This suggestion is specific in terms of what could be analyzed, but it does not specify which part of the paper should include this analysis. The authors can infer that it relates to the experimental or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes investigating the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. While the comment provides a logical reasoning for the potential benefits of such an analysis, it lacks specific examples or references to support the claim. The suggestion is 3 as it offers a clear direction for improvement but requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a potential area for improvement by proposing an epochwise analysis, particularly for finite sum settings, to gain insights into the behavior of optimization algorithms. It provides specific examples of what could be investigated, such as the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this analysis could aid in comparative studies of deterministic and stochastic methods. While the comment offers a clear direction for enhancing the paper, it could be more helpful by providing specific guidance on how to implement this analysis or suggesting potential metrics to use. Overall, the comment is 4 as it identifies a valuable area for exploration and provides some actionable suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but the comment lacks specificity on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to identify the specific parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, essentially a combination of GraphRAG and GraphCare, and that key baselines were not cited. It also suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. The claim is 3 as it provides a logical reasoning for the incremental nature of the contribution and highlights specific missing references. However, the comment lacks detailed examples or references to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides several specific points for improvement, including the observation that the contribution is incremental and primarily a combination of existing works like GraphRAG and GraphCare. It also notes the absence of key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. This feedback is clear and actionable, as it directs the authors to address these gaps in their work. However, the comment could be more helpful if it offered suggestions on how to integrate these missing elements or provided examples of how to effectively cite the baselines. Overall, the comment is 4 as it identifies key areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, namely the difficulty in distinguishing between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance. The reviewer also raises a question about the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies a problem and provides specific examples, it does not explicitly instruct the authors to address these issues or suggest how to improve the clarity of the distinction between the two types of extreme speech. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the need for a clear distinction between the three classes of extreme speech. It also references specific instances and lines in the paper, allowing the authors to accurately identify the parts being addressed. The comment is specific because it provides a detailed example from the sample data file, questioning the classification of an instance and raising concerns about the role of local regulation in annotations. This level of detail helps the authors understand what needs to be clarified or addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of distinguishing between derogatory and exclusionary extreme speech, citing a specific example from the sample data file. It questions the classification of an instance and suggests that local regulation may play a role in annotations. While the comment identifies a potential issue, it lacks specific references or detailed reasoning to fully substantiate the claim. The mention of \"local regulation\" and \"zeroshot crosscountry classification\" hints at a deeper analysis, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear distinction between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file, questioning the classification of a particular instance and raising concerns about the role of local regulation in annotations. This feedback is actionable as it prompts the authors to clarify the definitions and address the confusion in the classification. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the definitions or provided additional guidance on addressing the issue. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take. Additionally, the comment offers a rationale for why this graph is important, explaining that it can help determine whether performance improvements are due to network design or the nature of ImageNet. This provides concrete guidance on how to implement the suggested action, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on what specific part of the paper needs to be addressed. The comment is also specific because it explains the importance of this graph in understanding whether performance improvements stem from network design or the nature of ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph to better understand whether performance improvements are due to network design or the nature of ImageNet. The comment provides a logical reasoning by explaining that the graph would help determine if the performance gain is from exploiting spatial redundancies or from the characteristics of ImageNet, such as a large fraction of images that can be represented with lower resolution. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened with specific examples or references to similar studies, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of a graph to plot T vs the number of images and Expectation(T) over the ImageNet test set. This suggestion is important because it can help the authors understand whether the performance improvement is due to the network design or the nature of ImageNet, which is a critical aspect of evaluating the robustness of the results. The comment also offers a rationale for why this graph is necessary, explaining the potential impact of ImageNet\"s characteristics on the results. By providing a specific and actionable suggestion, the comment is 5 as it empowers the authors to make a significant improvement in their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current formulation needs to be changed to be mathematically correct, implying that the authors should revise their equations. It also questions the use of \"L_l\" instead of \"L\" and suggests introducing the notation beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make the changes or introduce the notation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current formulation needs to be changed to be mathematically correct and questions the use of \"L_l\" instead of \"L,\" suggesting that the notation should be introduced beforehand. However, it does not specify which part of the paper this issue pertains to, such as a specific equation or section. The mention of \"Fig.\" implies that there is a figure involved, but without further context, the authors cannot confidently determine which figure is being referred to. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the current formulation needs to be changed to be mathematically correct and questions the use of \"L_l\" instead of \"L.\" However, it does not provide specific examples or detailed reasoning to support why the current formulation is incorrect or how the change would improve the mathematical correctness. The comment lacks sufficient evidence or justification, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical formulation of the paper, suggesting that it needs to be changed to be mathematically correct. It also questions the use of \"L_l\" instead of \"L\" and recommends introducing the notation beforehand. This feedback is 3 as it points out a specific area that requires attention and provides a clear suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to address the mathematical issues or provided examples of how the notation should be introduced. Overall, the comment provides some actionable feedback but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to improve their work. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of noise accumulation in the context of homomorphic encryption for sequential ensembling, but it does not specify which part of the paper this concern is related to. The authors may infer that it pertains to the methodology or results sections, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the issue of noise accumulation and its impact on the use of homomorphically encrypted data, but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that studying the effect of noise accumulation in the context of homomorphic encryption is important for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights an important consideration for sequential ensembling in the context of homomorphic encryption, specifically the issue of noise accumulation. It points out a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment identifies a critical area for further study, it lacks specific suggestions or guidance on how the authors might address this limitation or explore potential solutions. The feedback is 3 as it directs the authors to a specific area needing attention, but it could be more beneficial with additional actionable advice or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the performance of the proposed method compared to the baseline model when trained and evaluated at the same timestep. It questions the effectiveness of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation timesteps differ. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should explore scenarios with different timesteps to demonstrate the method\"s effectiveness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of the proposed methods when trained and evaluated at the same timestep, questioning their effectiveness. The comment further suggests that the proposed method might be beneficial in scenarios where the training and evaluation timesteps differ. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the timeaware model when trained and evaluated at the same timestep. The reviewer questions the value of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation timesteps differ. However, the comment lacks specific examples or references to support the claim that the proposed methods are ineffective under the current conditions. The reasoning is somewhat logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the timeaware model when trained and evaluated at the same timestep. This observation questions the value of the proposed methods under the current conditions. The comment suggests that the proposed method might be more beneficial in scenarios where the training and evaluation timesteps differ. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative scenarios. The feedback is 3 as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the disentanglement process, noting that it is not clear how disentanglement is guaranteed. While it mentions that the \"Broader Impacts and Limitations\" section acknowledges obtaining fully disentangled latent vectors as a limitation, the comment emphasizes the need to clarify how disentanglement is realized and guaranteed without certain bias types. This feedback implies that the authors should provide more detailed information on the disentanglement process, but it does not specify exactly how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the disentanglement process, but they are not given explicit guidance on what specific details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, where the authors mention obtaining fully disentangled latent vectors as a limitation. However, the comment suggests that more clarification is needed on how disentanglement is realized and guaranteed without certain bias types. This provides a clear direction for improvement, making the comment specific. The authors can identify the relevant section and understand what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, where the authors acknowledge obtaining fully disentangled latent vectors as a limitation. However, the comment suggests that more detail is needed on how disentanglement is realized and guaranteed without certain bias types. While the comment provides some context by referencing the \"Broader Impacts and Limitations\" section, it lacks specific examples or detailed reasoning to fully substantiate the claim. This makes the comment 3, as it provides a basis for the concern but requires more elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the disentanglement process, noting that it is not clear how disentanglement is guaranteed. It references the \"Broader Impacts and Limitations\" section, where the authors acknowledge obtaining fully disentangled latent vectors as a limitation. The comment suggests that the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology. However, it could be more helpful if it provided specific suggestions on how to enhance the explanation or examples of disentanglement. Overall, the comment is 4, as it effectively guides the authors to improve their draft by addressing a key limitation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the comment implies that this is necessary for a fair comparison, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to apply the regularization trick or what specific standard regularization method to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the comparison is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide detailed guidance on which standard regularization trick should be used or how it should be applied. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While it identifies a potential area for improvement by suggesting a specific approach, it lacks detailed guidance or explanation on how to implement this suggestion. The comment does not provide context or examples of standard regularization tricks that could be used, nor does it offer any rationale for why this approach is necessary. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the figure for comparison. The comment is 5 because it gives precise guidance on how to enhance the draft, allowing the authors to know exactly what to do to improve their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added to the left graph in Fig. 3, namely, the learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure for better comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3 to compare the effect of these components on learning. This claim is 3 as it provides a logical reasoning for the suggestion, which is to better understand the impact of mean teacher and pi regularization on the learning process. However, the comment lacks specific examples or references to support the claim that including this comparison would be beneficial. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It recommends including a learning curve for a model without mean teacher or pi regularization in the left graph of Fig. 3, which would allow for a direct comparison of the impact of these components on the learning process. This feedback is clear and constructive, offering a concrete way for the authors to enhance their analysis and presentation. By addressing this suggestion, the authors can gain a deeper understanding of the effects of mean teacher and pi regularization, which could lead to a more comprehensive and insightful paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how to address this issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the impact on the number of parameters but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 2 in line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for a clearer discussion on the effect of the proposed objective equation on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed objective equation (Eq. 2) requires optimization over both the transformation parameters and the shared model parameters, and that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. The comment provides a specific reference to AlignFlow, which supports the claim by indicating a relevant work for comparison. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed objective equation differs from prior work. Overall, the claim is 4, as it provides a basis for the critique but lacks comprehensive evidence or detailed comparisons. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the transformation parameters and the shared model parameters. It also points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is clear and actionable, as it highlights a gap in the discussion that the authors need to address. By suggesting that the authors should discuss the impact on the number of parameters, the comment provides a specific direction for improvement. However, it could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct issues. First, it questions how the paper addresses different types of inputs, such as biomedical signals or speech, and suggests that discussing and presenting solutions for these inputs would be valuable. This is an explicit suggestion for the authors to expand their discussion and provide solutions. Second, it mentions that the citation seems disordered, which is an implicit action for the authors to reorder or clarify their citations. While the first part is explicit and provides a clear direction for improvement, the second part is implicit and lacks specific guidance on how to address the citation issue. Overall, the comment is 4 as it provides a clear direction for one part and an implicit suggestion for the other, but the authors need to infer the details for the citation issue.", "grounding_specificity_rationale": "The comment raises two distinct issues: the handling of different types of inputs and the order of citations. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that the discussion on inputs might be related to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting that the authors discuss and present solutions for different types of inputs and that the citations are disordered, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two separate issues: the handling of different types of inputs and the order of citations. The first issue is a suggestion for the authors to discuss and present solutions for different types of inputs, which is a logical request for improvement. However, it lacks specific examples or references to support why this is necessary or how it would enhance the paper. The second point about the disordered citations is a factual observation that does not require verification, as it is a straightforward statement about the organization of references. Therefore, the comment is 4, as the first part requires more detailed justification, while the second part is factual.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it suggests that the authors should discuss and present solutions for handling different types of inputs, such as biomedical signals or speech, which is a valuable suggestion for enhancing the paper\"s scope and applicability. Second, it points out that the citations seem disordered, which is a practical suggestion for improving the paper\"s organization and clarity. However, the comment could be more helpful if it provided specific examples or guidance on how to address the citation issue or how to effectively discuss and present solutions for different types of inputs. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the questions or improve the results, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the implications of Eq. 4 and the value of u^l in Eq. 3, indicating that it is related to the equations and their analysis. However, it does not specify which part of the paper these equations are located in, making it weakly grounded. The comment also critiques the improvement in the designed solutions presented in Table 5, specifically mentioning the marginal improvement on the OfficeHome dataset. While it identifies the issue with the improvement, it does not specify what needs to be addressed or how to improve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, suggesting a potential inference. It also critiques the improvement in the designed solutions presented in Table 5, specifically noting a marginal improvement on the OfficeHome dataset. However, the comment lacks specific reasoning or evidence to support the claim that the improvement is not significant. Without detailed analysis or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and the value of u^l in Eq. 3, which could be an important clarification for the authors to address. Additionally, it critiques the improvement in the designed solutions presented in Table 5, specifically noting that the proposed solution achieves only a marginal improvement on the OfficeHome dataset. This feedback is 3 as it points out a potential area for improvement and encourages the authors to consider the significance of their results. However, the comment could be more helpful if it provided specific suggestions on how to address the marginal improvement or offered additional insights into what might be causing it. Overall, the comment provides some useful feedback but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of certain stateoftheart references in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer also compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. While the comment identifies a gap in the references and provides a specific example, it does not explicitly instruct the authors to include these references or to address the comparison with the mentioned work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and references a specific work by Baidu, \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\" along with a link to the results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the missing stateoftheart references and provides a comparison with the results in Table 3, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the experiment on face recognition, specifically mentioning a work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a specific reference to the Baidu work and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This provides a clear and specific comparison, making the claim 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the missing references impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the references used in the experiment on face recognition, pointing out the omission of a stateoftheart work by Baidu that uses the triplet loss and reports results on a dataset similar to Webface. The reviewer provides a detailed reference to the work, including a link to the results, and compares the results of the VRF with those in Table 3 of the paper, noting that the VRF achieves a better result on LFW. This feedback is clear and actionable, as it directs the authors to include these references and consider the comparison with the mentioned work. By addressing this gap, the authors can enhance the credibility and relevance of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of template mapping in question answering, specifically mentioning the potential for poor generalization to questions that are not \"Whtypes\" or transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with template mapping, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the generalization of the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a specific concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or depth, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the idea of utilizing a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1] in the context of realtime dynamic reconstruction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of using a volumetric representation in the deformation field, specifically mentioning VolumeDeform [1] as a reference. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in pointing out the lack of novelty in the volumetric representation approach, but it lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform [1] as a reference. This claim is supported by the mention of a specific external work, which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed information about how VolumeDeform [1] addresses the issue or by explaining why the authors\" approach is not novel. Despite this, the reference to VolumeDeform [1] makes the claim 4, as it provides a clear direction for the authors to explore and address the issue of novelty. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that the idea of utilizing a volumetric representation in the deformation field is not novel, as it has been proposed by VolumeDeform [1] in the context of realtime dynamic reconstruction. This feedback is 3 as it highlights a potential weakness in the originality of the approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing approaches. While it prompts the authors to consider the novelty of their method, it does not offer actionable advice for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ICLHAR, noting that it has improved consistency and verifiability but has negatively impacted accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss or acknowledge the impact of ICLHAR on accuracy scores. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the impact on accuracy scores, from 70.4 to 55.6 on TRIP, and suggests that this should be discussed or acknowledged in the main text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has negatively impacted accuracy scores, citing a specific drop from 70.4 to 55.6 on TRIP. This claim is supported by the provided numerical evidence, which offers a clear and quantifiable basis for the assertion. The mention of specific accuracy scores and the reference to TRIP provide a robust foundation for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impairs accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs further exploration or explanation. By pointing out the tradeoff between consistency, verifiability, and accuracy, the comment provides the authors with a specific area to address and potentially improve their draft. However, it could be more helpful if it offered suggestions on how to discuss or acknowledge this tradeoff effectively. Overall, the comment is 4, as it directs the authors to a significant area of improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a specific and actionable step, ensuring that the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not citing the source of the example, which is inspired by previous work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and requests that the authors cite the source. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the claim or understand the basis of the suggestion. Without additional context or evidence, the authors may struggle to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and requests that the authors properly cite the source. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide proper attribution. By addressing this issue, the authors can ensure the integrity and transparency of their work. However, the comment could be more helpful if it provided additional context or examples of similar work, which would further assist the authors in understanding the relevance and importance of proper citation. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the innovations in network architecture design and constraint embedding, suggesting that they are limited. It also mentions that the authors discussed the performance being limited by the oracle expert. However, the comment does not provide any explicit or implicit actions for the authors to take to address these limitations. It lacks guidance on how the authors might improve the innovations or discuss the performance in a more meaningful way. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the innovations in network architecture design and constraint embedding, suggesting that they are limited. It also mentions that the authors discussed the performance being limited by the oracle expert. However, the comment does not specify which part of the paper discusses these innovations or where the discussion about the oracle expert is located, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the innovations are limited or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, and it references the authors\" discussion about the performance being limited by the oracle expert. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the innovations in network architecture design and constraint embedding, suggesting that they are limited. It also mentions that the authors discussed the performance being limited by the oracle expert. However, the comment does not provide any specific suggestions or guidance on how the authors might address these limitations or improve their work. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is 1, as it lacks actionable feedback or constructive suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments to demonstrate the significance of the proposed projection errors. The suggestion is concrete, as it specifies the type of experiments needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results section, but the comment lacks full grounding. It is specific in detailing what needs to be addressed, namely the need to demonstrate the importance of the proposed projection errors. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The reviewer provides a logical reasoning by explaining that finetuning on realworld datasets with different losses is necessary to fully evaluate the model\"s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair or to substantiate the importance of the proposed projection errors. This makes the claim 3, as it provides a logical basis but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically the unfair comparison of the model\"s performance when only pretrained on synthetic data. It suggests that a more comprehensive evaluation would involve demonstrating the importance of the proposed three projection errors by comparing the performance of models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, providing the authors with a specific direction to enhance their experimental design and analysis. However, it could be more helpful if it included examples or specific suggestions on how to implement this comparison. Overall, the comment is 4 as it guides the authors toward a more robust evaluation of their model\"s performance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests that it is common to average over subword representations, referencing a specific work by Hewitt and Manning (2019). This comment implies that the authors should consider averaging over subword representations as an alternative approach, but it does not explicitly instruct them to do so. While the suggestion is concrete, it is not explicitly stated as an action, leaving the authors to infer that they should consider this alternative. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular statement regarding the use of subword token embeddings and suggests an alternative approach by referencing a specific work by Hewitt and Manning (2019). This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an alternative approach to handling subword representations, specifically mentioning the practice of averaging over subword representations. It references a specific work by Hewitt and Manning (2019) as an example of this practice. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how this alternative approach might impact the paper\"s results or methodology. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific line in the paper (L.490) where the authors mention taking the embedding of the first subword token as the verb embedding. The reviewer suggests an alternative approach, which is to average over subword representations, and references a specific work by Hewitt and Manning (2019) that demonstrates this practice. This feedback provides the authors with a clear suggestion for improvement and a reference to consider, which can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included a detailed explanation of why averaging over subword representations might be beneficial or how it could impact the results. Overall, the comment offers a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these analyses or what specific aspects of the traditional method should be discussed. The actions are explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as demonstrating the consistency between predicted scores and actual risks, and suggests conducting calibration curves to show agreement. Additionally, it encourages discussing the feasibility of the generated scoring system and the differences between the traditional method and the proposed approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It encourages the use of calibration curves to show agreement, which is a common practice in evaluating predictive models. The comment also suggests discussing the feasibility of the generated scoring system and comparing it with traditional methods. While the suggestion is logical and based on common practices in model evaluation, it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It points out that while the model AUC can assess discriminant ability, it may not demonstrate consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The comment encourages the authors to conduct calibration curves to show this agreement, which is a valuable suggestion for enhancing the paper\"s credibility and relevance. Additionally, it suggests discussing the feasibility of the generated scoring system and comparing it with traditional methods, offering a direction for further analysis and differentiation. This feedback is detailed and constructive, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues: the lack of change in the range of ID and OOD by sparsification, as observed in Figure 4, and the requirement for Lemma 2 to have an approximately identical mean as the assumption. The comment emphasizes that these conditions are crucial for DICE but notes that they are not well discussed. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to discuss these conditions further but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the range of ID and OOD does not change much by sparsification and that the conditions for Lemma 2 are not well discussed. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much by sparsification, as observed in Figure 4, and that Lemma 2 requires an approximately identical mean as the assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed. However, the comment lacks specific examples or detailed reasoning to support the claim that these conditions are not met or how they impact the paper. The absence of concrete evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, particularly regarding Figure 4 and Lemma 2. It points out that the range of ID and OOD does not change much by sparsification, which is a crucial condition for DICE. Additionally, it notes that the assumption in Lemma 2 requires an approximately identical mean, which is not well discussed. The comment highlights the importance of these conditions and suggests that the authors should discuss how to ensure DICE meets these conditions. While the comment provides clear areas for improvement, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to important aspects of their work that need further clarification and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part raises a question about the integration of the update over all possible environments, which is an implicit action for the authors to clarify or address this point in their draft. However, it does not provide specific guidance on how to do so, making it vague. The second part explicitly suggests breaking out bolded sections into paragraphs to improve readability, which is a concrete action. Overall, the comment is 3 because it provides a clear suggestion for improvement but lacks detailed guidance on the first point.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6\" and the \"bolded sections,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the bolded sections should be broken out into paragraphs to improve readability, which is a clear and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part raises a question about the integration of the update over all possible environments, which is a logical inquiry that seeks clarification. However, it does not contain a claim that requires verification. The second part suggests breaking out bolded sections into paragraphs for better readability, which is a factual statement and not a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part raises a question about the integration of the update over all possible environments, which could be a critical aspect of the methodology. However, it does not offer any suggestions or guidance on how the authors might address this issue. The second part is more actionable, suggesting that the bolded sections on page 6 should be broken out into paragraphs to improve readability. This feedback is clear and provides a specific action for the authors to take, making it 3. Overall, the comment offers some value but could be more comprehensive and actionable, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their experiments, use default settings for baselines, include missing baselines, and discuss limitations and societal impacts. However, the lack of specific guidance on how to implement these changes makes the comment 3. The authors know what needs to be done but may struggle with the exact steps to take.", "grounding_specificity_rationale": "The comment raises several concerns about the experiments, including the strength and fairness of the results, the use of position kernels, and the absence of certain baselines. It also mentions the need to discuss limitations and societal impacts. However, the comment does not specify which sections of the paper these issues relate to, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors can make an educated guess about the general areas being addressed, the comment lacks full grounding. It is specific in detailing the issues but 1 in terms of identifying the exact parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the experiments, including concerns about their strength and fairness, the use of position kernels, and the absence of certain baselines. The reviewer questions the choice of baselines and suggests that the paper should use default settings from the literature. Additionally, the comment points out the lack of discussion on limitations and societal impacts. While the reviewer provides some reasoning for their concerns, such as questioning the use of position kernels and the absence of certain baselines, the comment lacks specific examples or references to support these claims. The reasoning is 3, as it highlights potential issues but requires more detailed evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including concerns about the strength and fairness of the experiments, the use of position kernels, and the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. It suggests that the paper should compare its proposed approach with these missing baselines and discuss limitations and societal impacts. These points are actionable and provide clear guidance for the authors to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of relevant baselines to include. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes a drop in correlation after a short period of training, followed by an increase with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue, such as suggesting ways to improve the model\"s performance or stability over time. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to a specific observation about the correlation after a short period of training and its increase with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a particular figure, table, or section. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how this observation impacts the overall analysis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point describes an observation about the correlation after a short period of training and its increase with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the correlation after a short period of training and its increase with more training iterations. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or insights into potential causes or solutions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern that all sparsity patterns seem to perform equally well, without providing any insight into what is happening. It also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment identifies a potential issue and offers a specific correction, it does not provide guidance on how the authors might address the lack of insight into the sparsity patterns. The action is explicit but somewhat vague, as it lacks detailed instructions on how to improve the analysis or presentation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that all sparsity patterns seem to perform equally well and lacks insight into what is happening. Additionally, it suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all sparsity patterns perform equally well and questions whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform equally well without providing any insight into what is happening. This observation raises a question about whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). The comment also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment highlights an area for further analysis and provides a specific suggestion for improvement, it lacks depth and does not offer detailed guidance on how the authors might address the lack of insight or explore the implications of the observed performance. Therefore, the comment is 3, as it points out a potential area for improvement but could be more comprehensive in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, which is to include the temperature \u03c4 in the derivation or mention it in the paper. The comment is explicit and concrete, offering a specific step for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing the temperature \u03c4 in the derivation and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This claim is 3 as it points out a potential gap in the derivation, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer provides a clear suggestion for improvement, but without additional context or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the derivation of the paper, noting that the temperature \u03c4 is missing in the transition from Eqn. 3 to Eqn. 4. It provides a clear and actionable suggestion by recommending that the temperature should be shown in a rigorous way or mentioned in the paper. This feedback is valuable as it directs the authors to a precise area where the paper may lack clarity or completeness, allowing them to make targeted improvements. However, the comment could be more helpful if it offered additional context or examples of how the temperature should be integrated into the derivation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to add a citation on differential privacy, specifically suggesting a standard work like [2]. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a concrete suggestion with a specific reference, leaving no ambiguity about how to implement the change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear action for the authors to take. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically recommending a standard work like [2]. This is a factual statement that does not express an opinion or require verification. It is a request for clarification or addition, fitting the \"No\" label.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for improving the draft. By recommending the addition of a citation on differential privacy, the reviewer offers a clear direction for enhancing the paper\"s clarity and credibility. This feedback is valuable as it guides the authors on how to strengthen their work by incorporating relevant references, which can significantly enhance the paper\"s academic rigor and appeal. The comment is detailed and constructive, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This part of the comment does not provide explicit guidance or suggestions for the authors to address the claim. The second part points out an error in the inequality on line 310, suggesting a comparison with line 227. While this part is more actionable, as it identifies a specific error that needs correction, the overall comment lacks concrete guidance on how to address the first part of the claim. Therefore, the comment is 3, as it provides a clear action for the second part but lacks explicit guidance for the first part.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the claim about additional assumptions and the error in the inequality on line 310, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the methodology requiring significant additional assumptions and a factual statement about an inequality on line 310 having the wrong sign. The first part is subjective and lacks specific evidence or references to support the claim that the assumption is too extreme. The second part is factual and does not contain a claim, as it simply points out an error. Therefore, the comment is primarily factual, and the first part is not verifiable. However, since the second part is factual, the overall comment is best categorized as \"No.\"", "helpfulness_rationale": "The review comment addresses two distinct issues. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural in many machine learning settings. This feedback prompts the authors to reconsider their claim and potentially provide more context or justification. Second, it points out an error in the inequality on line 310, suggesting a comparison with line 227. This feedback is actionable as it identifies a specific mistake that needs correction. However, the comment could be more helpful if it provided additional guidance on how to address the first issue or offered suggestions for improving the clarity of the assumptions. Overall, the comment is 3 as it identifies specific areas for improvement but lacks depth and actionable suggestions for the first part of the claim."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors need to provide a more robust argument for using Shapely values over other methods by comparing them experimentally with methods like CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional work but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as comparing Shapely values with other methods like CaCE or raw gradients, and discussing the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide a more robust argument for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends a discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. While the comment provides a logical reasoning for the need for comparison and discussion, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to infer the exact methods and comparisons needed to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to strengthen their argument, namely, the justification for using Shapely values over other methods. It suggests that the authors should experimentally compare Shapely values with other methods like CaCE or raw gradients to provide a more robust argument. Additionally, the comment recommends a detailed discussion on the advantages and disadvantages of each method for transforming highdimensional data to lowdimensional latent space. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the rigor and comprehensiveness of their paper. However, the comment could be more helpful if it included examples or specific suggestions for the discussion on advantages and disadvantages. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should compare the perspective taken in the present manuscript to the contributions of prior efforts, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the related work section is comprehensive, it could benefit from comparing the current manuscript\"s perspective to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why such a comparison is necessary. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, specifically suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by contextualizing their contributions within the broader literature. However, the comment could be more helpful if it offered examples or guidance on how to conduct this comparison effectively. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not explicitly instruct the authors to conduct this examination or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should explore the impact of varying the number of scenarios, but they are not given specific instructions on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental setup or results section, but this inference is not direct. The comment is specific in suggesting an area for exploration, but it lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a potential relationship between the number of scenarios used for training and the performance of the model. However, it does not provide any evidence, reasoning, or references to support this claim. The suggestion to examine the performance with different numbers of scenarios is logical but lacks specific examples or data to substantiate the claim. As a result, the comment is considered 2, as it provides a plausible suggestion but lacks sufficient evidence or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the performance of the model is likely related to the number of scenarios used for training, which is fixed at 200 in the paper. It recommends examining the performance with different numbers of scenarios, which could provide valuable insights into the model\"s robustness and generalizability. This feedback is clear and actionable, as it identifies a potential area for exploration that could lead to a deeper understanding of the model\"s capabilities. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it offers a constructive suggestion for improving the paper\"s depth and analysis."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests considering whether disturbances in the training data could affect the model\"s performance in generating correct quality labels. However, the comment does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and vague, as the authors are left to infer that they should investigate this issue but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating quality labels and the model\"s ability to predict them, suggesting that disturbances in the training data might affect the model\"s performance. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questioning of the model\"s ability to predict quality labels under certain conditions, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating quality labels and the model\"s ability to predict them, suggesting that disturbances in the training data might affect the model\"s performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations that would help the authors understand the issue or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to evaluate or improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the relationship between generating quality labels and the model\"s ability to predict them. It suggests considering whether disturbances in the training data could affect the model\"s performance in generating correct quality labels. This feedback is 3 as it prompts the authors to think critically about the robustness of their model and its ability to generalize under different conditions. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing experiments or modifications to the training data. While it identifies a potential area for improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, clarification, or additional analysis that the authors should consider. As a result, the comment lacks any actionable guidance, leaving the authors without a clear understanding of how to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and crossdomain imitation. However, it does not specify which part of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact sections being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments need further elaboration or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a factual statement describing the experiments conducted by the authors to validate the efficacy of CATER. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any specific feedback, suggestions, or critiques that could help the authors improve their work. The comment lacks depth and does not offer any actionable advice for enhancing the draft. As a result, it is 2, as it does not provide the authors with any meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the current setting is only partially strategic or game theoretic because the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the strategic aspect of the setting or suggestions for improving the opponent\"s behavior. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l28,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the setting, noting that it is only partially strategic or game theoretic due to the opponent\"s behavior. The comment provides a detailed critique of the strategic aspect of the predictions, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current setting is only a \"very first step\" towards real strategic settings, as the opponent does not behave strategically. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar settings or studies that demonstrate the potential for more strategic behavior, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the current setting, noting that it is only partially strategic or game theoretic because the opponent does not behave strategically. This feedback highlights a potential area for improvement, suggesting that the authors should consider enhancing the strategic aspect of their setting. However, the comment lacks specific suggestions or guidance on how to achieve this enhancement, such as proposing alternative opponent behaviors or strategies. While it points out a weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that Appendix A.2 does not clearly illustrate the state space representation of the environment. This provides a direct action for the authors to take, which is to clarify or improve the illustration in Appendix A.2. However, the comment does not specify how to improve the illustration or what specific aspects need clarification, leaving the authors with a general direction but lacking detailed guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not clearly illustrate the state space representation of the environment. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides the authors with a clear direction for improvement, suggesting that they need to enhance the illustration or explanation of the state space representation in this appendix. However, the comment does not offer specific suggestions or guidance on how to improve the illustration or what aspects should be clarified. While it highlights an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that truly large problems will overwhelm current LPsolvers. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this limitation. It lacks guidance on how the authors might address this issue or improve their approach to handle larger problems. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the authors\" approach, specifically mentioning that it is only suitable for small or mediumscale problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the approach\"s scalability but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable for small or mediumscale problems, as truly large problems will overwhelm current LPsolvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant limitation of the authors\" approach, noting that it is only applicable for small or mediumscale problems and that truly large problems will overwhelm current LPsolvers. This feedback is valuable as it highlights a critical constraint of the method, which the authors should consider addressing in their work. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or improve the scalability of their approach. While it points out an important issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their draft. The references to other works imply that the authors should consider these extensions, but the comment lacks concrete instructions on how to incorporate this information into their paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"bounded noise assumption\" in the context of stochastic optimization literature, suggesting that it is somewhat restrictive. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which provide extensions to these noise conditions. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The comment is specific in suggesting that the authors consider these extensions, but it lacks detailed guidance on how to incorporate this information into their work. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they are recent and relevant studies that have explored extensions to the noise conditions. However, the comment could be strengthened by providing more detailed explanations or examples of how these works address the limitations of the bounded noise assumption. Overall, the claim is 4, as it is supported by references to relevant literature, but it could benefit from more detailed justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a potential limitation in the paper\"s use of the bounded noise assumption, noting that it is somewhat restrictive in the context of stochastic optimization literature. It references specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou, which have explored extensions to these noise conditions. This feedback is 3 as it points out a specific area for improvement and provides references to relevant literature. However, it lacks detailed guidance on how the authors might incorporate these extensions into their work or how they might address the limitations of the bounded noise assumption. To be more helpful, the comment could include suggestions or examples of how to apply these extensions or discuss their implications. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the clarity of the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the motivation or what specific aspects of the motivation need further explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the motivation for using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be improved. Without explicit references or detailed guidance, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the motivation for using characteristic function regularization. However, it does not provide any specific suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes to make to address the issue. As a result, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might enhance their contribution or improve the novelty of their work. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the existing techniques used, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. The reviewer provides specific references to support the claim, which makes the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these existing techniques are combined, which would further solidify the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. It suggests that the contribution could be considered incremental due to the lack of novelty in combining these existing techniques. However, the comment does not provide any actionable suggestions or guidance on how the authors might enhance their contribution or improve the novelty of their work. Without specific feedback or directions for improvement, the authors are left without a clear path to address the critique. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referenced. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be clarified and how to address the issue, ensuring that they can make the necessary improvements to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and \"aggregation operation after \"Integration,\"\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified\u2014more details about the aggregation operation and proper acknowledgment of other architectures if referenced. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and requests more details in the main paper. It also advises acknowledging the structure of other architectures if referenced. However, the comment does not provide specific examples or references to support the claim that the aggregation operation is unclear or that other architectures should be acknowledged. This lack of detailed justification makes the claim 3, as the authors would need to infer the specific issues and address them without explicit guidance.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the aggregation operation after \"Integration\" in the context of multiscale modeling. It provides a clear and actionable suggestion for improvement by asking the authors to provide more details in the main paper. Additionally, it advises acknowledging the structure of other architectures if they are referenced, which is a constructive feedback that can help the authors enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific examples or further guidance on how to clarify the aggregation operation. Overall, the feedback is 4 as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what steps to take to rectify the problems. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide examples or details about the specific writing issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand and address the issues. Without detailed examples or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete examples or suggestions for improvement, the authors may find it challenging to understand and rectify the problems. The comment highlights areas for improvement but lacks actionable feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It instructs them to run experiments for untrained networks and add the results to the figures and Table 1. Additionally, it requests clarification on the use of random data in Figures 3c and 3, specifically asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. The comment also suggests clarifying whether the nonrandom data was normalized and, if so, whether the additional \"unitball\" noise is small or large compared to the data. Finally, it recommends showing examples of the random data in the appendix. These instructions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 3c and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific requests for clarification and additional experiments, such as running experiments for untrained networks and adding results to the figures and Table 1. Additionally, it asks for clarification on the use of random data in Figures 3c and 3, and suggests showing examples of the random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as running experiments for untrained networks, clarifying the use of random data in figures, and providing examples of random data in the appendix. These requests are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback, addressing several areas for improvement in the paper. It requests additional experiments to include results for untrained networks, which would enhance the understanding of the figures and Table 1. The comment also seeks clarification on the use of random data in Figures 3c and 3, asking whether the network was trained on random data or if the dotted lines represent networks trained on unaltered data evaluated with random data. Furthermore, it suggests clarifying whether the nonrandom data was normalized and recommends showing examples of the random data in the appendix. These detailed suggestions offer clear guidance on how to improve the clarity and comprehensiveness of the paper, making the comment 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1. It asks whether this refers to 100 sampled strategies. While the comment does not explicitly instruct the authors to clarify or change anything, it implies that the authors should provide a clear explanation of this term. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"100 steps.\" However, the comment provides a clear direction on what needs to be clarified, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"100 steps,\" which is a clear and direct question that requires an explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"100 steps\" in the context of search models comparison. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of search models comparison in section 5.1, specifically asking if it refers to 100 sampled strategies. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this point or improve the clarity of their work. The feedback is limited in its actionable nature, offering only a question without any constructive advice for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. While the comment highlights an area for further exploration and a potential overlap with existing work, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is 3 as it identifies a potential area for improvement but lacks concrete steps or detailed advice on how to proceed. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation and goals of the model\" and the \"related work review part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the similarity between the model\"s goals and those of a prior VAE paper, suggesting that the authors should be aware of this overlap. This provides clear guidance on what needs to be addressed in the related work section. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to a prior VAE paper. The comment provides a logical reasoning by comparing the novelty of energy models to GANs and VAEs, and by referencing a specific prior work in the related work section. However, the comment lacks specific details or references to the prior VAE paper, which would strengthen the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could be further supported with more detailed references or examples.", "helpfulness_rationale": "The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more nuanced discussion of the model\"s goals in relation to existing work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the model\"s contributions or how to address the similarity with the prior VAE paper. Overall, the feedback offers some guidance but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers, as the current results do not provide enough information to determine the significance of the improvements. This is a clear and direct action for the authors to take, providing concrete guidance on how to improve their draft. The comment also suggests rejecting the paper due to limited novelty and marginal improvement, which is an explicit recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the results, such as the lack of mean and standard deviation, and the difficulty in determining statistical significance. The suggestion to repeat the experiments and conduct statistical significance analysis provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and questions the statistical significance of the results. It also points out that the results in Table 1 and Fig.5 do not report the mean and standard deviation, making it difficult to assess the significance of the differences. The reviewer suggests repeating the experiments and conducting statistical significance analysis to address these issues. While the claim about the small improvement is supported by the percentage range, the comment lacks specific examples or references to substantiate the claim further. Additionally, the suggestion to repeat experiments and conduct statistical analysis is logical but could be more detailed. Therefore, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the improvement over previous methods is small, ranging from 0.2% to 1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine the statistical significance of the differences. The reviewer provides a clear and actionable suggestion to repeat the experiments and conduct statistical significance analysis to address these issues. Additionally, the comment suggests rejecting the paper due to limited novelty and marginal improvement. This feedback is 5 as it not only identifies specific areas for improvement but also provides a clear path forward for the authors to enhance their work. However, the suggestion to reject the paper could be more nuanced, as it might not be the only outcome based on the improvements made. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability to other domains. It also suggests verifying whether the method works with discrete action spaces and highdimensional observations. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The recommendation is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation being conducted only on the Meta World domain, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of limited generalizability and recommends running experiments on a different benchmark, such as Atari, to verify the method\"s applicability to other domains. The comment provides a clear suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited to a single domain, Meta World, and suggests that this makes it difficult to judge the method\"s generalizability to other domains. The reviewer recommends running experiments on a different benchmark, such as Atari, to verify the method\"s applicability to other domains. This claim is 3 as it provides a logical reasoning for the need to evaluate the method on multiple domains. However, the comment lacks specific examples or references to support the claim that Atari is a commonly used benchmark or that it would be an appropriate choice for testing the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, which is only tested on the Meta World domain. It highlights the difficulty in judging the method\"s generalizability to other domains due to this limited evaluation. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a different benchmark, such as Atari, which is commonly used in the literature. This suggestion not only helps the authors to broaden the evaluation scope but also to verify the method\"s applicability to different domains, including those with discrete action spaces and highdimensional observations. The feedback is detailed and constructive, offering a clear path for the authors to improve their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete. However, it suggests that there is a missing analysis of what the model does, which could be interesting. The comment implies that the authors should include this analysis, but it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. However, it does not specify which part of the paper lacks this analysis, making it weakly grounded. The comment is specific in suggesting that an analysis of the model\"s behavior could be interesting, but it does not provide detailed guidance on what aspects of the model should be analyzed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. The comment suggests that this analysis could be interesting, but it does not provide specific examples or reasoning to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the presentation of the method and the completeness of the experiments, which is a positive observation. However, it points out a missing analysis of what the model does, suggesting that this could be an interesting aspect to explore. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects of the model\"s behavior should be examined. This limits the comment\"s usefulness, as it does not provide actionable feedback for the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the task setup, specifically questioning which notes from the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to provide more detailed information about the task setup, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3, as it points out a problem but does not fully direct the authors on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"task setup\" and provides specific examples of what is unclear, such as which notes in the EHR are used as input and how far away the outcomes are from the last note date. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the task setup, specifically regarding the use of EHR notes and the timing of outcomes. However, it does not make a claim or provide an opinion that requires verification. It is a factual question seeking clarification, which aligns with the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the lack of clarity in the task setup. It raises questions about which notes from the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it directs the authors to clarify these aspects of their methodology. By addressing these questions, the authors can improve the comprehensibility and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or offered examples of how similar studies have addressed similar issues. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension. The reviewer also references a specific paper by Timothy Nguyen, Zhourong Chen, and Jaehoon Lee, which implies that the authors should consider including a similar approach section in their paper. However, the comment does not provide specific guidance on how to incorporate this section or what it should contain. While the action is explicit, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by noting that the supplementary material should be used as additional information rather than an extension. Additionally, the comment references a specific paper, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section\" is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension. The reviewer provides a reference to a specific paper, \"Dataset metalearning from kernel ridgeregression,\" which supports the claim that the approach section is missing. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The addition of the reference provides some support, but the comment could be strengthened with more explicit justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the lack of an \"approach section\" in the main paper. It highlights that the supplementary material is being used as an extension rather than additional information, which is not appropriate. The comment also references a relevant paper, \"Dataset metalearning from kernel ridgeregression,\" which provides a basis for the authors to consider including a similar approach section in their paper. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a reference for further exploration. However, the comment could be more helpful if it offered suggestions on how to integrate the approach section or what specific aspects should be included. Overall, the comment is 4, as it provides valuable guidance for enhancing the paper."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement in the introduction regarding the biological plausibility of backpropagation is too weak and contradicts the widely accepted view that backpropagation is biologically implausible. However, it does not provide explicit guidance on how the authors should revise this statement or what specific changes should be made to strengthen the argument. The action is implicit, as the authors need to infer that they should revise the statement to align with the accepted view, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"statement in the introduction regarding the biological plausibility of backpropagation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that it may be too weak and contradicts the widely accepted view that backpropagation is biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. The reviewer provides a logical reasoning by stating that the current statement contradicts the accepted view, which is a clear and straightforward justification. However, the comment could be strengthened by providing specific references or examples to support the claim that backpropagation is widely considered biologically implausible. Despite this, the claim is 4 due to the logical reasoning provided, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, questioning the statement regarding the biological plausibility of backpropagation. It suggests that the current phrasing may be too weak, as it contradicts the widely accepted view that backpropagation is biologically implausible. This feedback is clear and actionable, as it prompts the authors to reconsider and strengthen their argument regarding the biological plausibility of backpropagation. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative phrasing. Overall, the comment is 4, as it directs the authors to a critical area that needs improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions whether it might lead to scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the modulator\"s design. The comment lacks actionable details, such as recommending alternative approaches or methods for addressing scalability issues. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, it does not specify which part of the paper discusses the modulator or provide details on how the scalability issue might be addressed. The authors can infer that the comment relates to the methodology or experimental sections, but without explicit references, it remains weakly grounded. The comment is specific in identifying the issue with the modulator\"s design and potential scalability problems, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, the comment lacks specific examples or references to support the claim that the modulator might lead to scalability issues. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it provides some basis for the concern but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the heuristic design of the modulator, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. This feedback identifies a potential weakness in the paper\"s methodology, prompting the authors to consider the implications of their design choices. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or methods for improving scalability. While it highlights an important area for improvement, the feedback could be more actionable and helpful if it provided more detailed advice or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experiments performed, noting that while f_R and f_P can be adapted over time, they incorporate a significant amount of domain knowledge. The comment suggests that a less informed version of f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their experiments. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment discusses the experiments and the adaptation of f_R and f_P over time, incorporating domain knowledge. However, it does not specify which part of the paper this discussion is based on, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in its critique of the experiments and the potential need for more data, but it lacks grounding due to the lack of explicit references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments performed in the paper incorporate a significant amount of domain knowledge, which might make a less informed version of f_R/f_P require an impractical amount of data to learn. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment highlights a potential issue with the experiments, noting that while f_R and f_P can be adapted over time, they incorporate a significant amount of domain knowledge. The comment suggests that a less informed version of f_R/f_P might require an impractical amount of data to learn. This feedback is 3 as it points out a potential limitation in the experimental setup and the potential need for more data. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their experiments. To be more helpful, the comment could provide recommendations or examples of how to adapt the experiments or incorporate more data. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The comment implies that the authors should conduct experiments to explore these challenges and their impact on performance, but it does not specify what kind of experiments or analyses are needed. This makes the action implicit and somewhat vague, as the authors would need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of experiments on obtaining labeled data for imitation learning and how performance changes with varying data sizes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely experiments on data difficulties and performance changes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulties of obtaining labeled data for imitation learning and how performance changes with varying data sizes. This claim is 3 as it highlights a potential gap in the paper, but it lacks specific examples or references to support the assertion. The comment provides a logical reasoning for the importance of such experiments, but without detailed evidence or examples, the authors may find it challenging to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It highlights the importance of conducting experiments to explore these issues, which is a crucial aspect of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap or what kind of experiments would be most beneficial. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks actionable guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion but considered a serious question. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore this connection further but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the authors acknowledge this in the conclusion, the comment suggests it is a serious question. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the connection between robust memorization and generalization, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the implications of the necessary conditions for robust memorization and generalization bounds. It suggests that the constructions of ReLU networks for robust memorization may not necessarily lead to robust generalization, which is acknowledged in the conclusion. However, the comment does not provide specific evidence, examples, or references to support this claim, making it 3. The authors are left to infer the reasoning behind the concern, which could be clarified with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the relationship between the necessary conditions for robust memorization and generalization bounds. It points out that while the paper acknowledges this issue in the conclusion, it is a serious question that warrants further exploration. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this limitation or suggestions for further exploration. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide specific guidance on how to address this issue. The authors may infer that it relates to the discussion or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. As a result, the claim is considered 1 due to the lack of supporting information or detailed justification.", "helpfulness_rationale": "The review comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant and could prompt the authors to consider expanding their work to include a broader analysis of the method\"s applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore the implications for other NLP tasks. While it identifies an area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. However, it does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should clarify or redefine the term to avoid misinterpretation. The comment lacks concrete details on how to implement this change, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 267\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology \"certificate\" and its potential misinterpretation due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests that the term \"certificate\" might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the potential misinterpretation. This lack of supporting information makes the claim difficult for the authors to address effectively, rendering it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. This feedback is 3 as it points out a potential source of confusion that could impact the clarity of the paper. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative terminology or clarifying the context in which \"certificate\" is used. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the use of untrained neural networks (like deep image prior) for solving inverse problems across a wide class of images, as shown in recent papers. It also recommends comparing the current method with these types of methods. While the comment implies that the authors should include this information and comparison, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on the context and comparison with existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to mention the use of untrained neural networks (like deep image prior) for solving inverse problems and to place the current method in context by comparing it with those methods. This level of detail guides the authors on what needs to be addressed and how to improve their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s claim of strong OOD generalization by the trained network is interesting but notes that recent papers have shown that untrained neural networks can solve inverse problems across a wide class of images. The reviewer recommends mentioning this in the paper and comparing the current method with those approaches. While the comment provides a logical reasoning for the suggestion, it lacks specific references to the papers that demonstrate the effectiveness of untrained neural networks. This makes the claim 3, as the authors would need to conduct further research to fully understand the context and make the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the interest in the OOD experiments, noting the strong OOD generalization of the trained network. However, it suggests that the authors should place their method in context by mentioning recent papers that have shown the effectiveness of untrained neural networks (like deep image prior) in solving inverse problems across a wide class of images. The comment provides a constructive suggestion for the authors to expand their discussion by comparing their method with these existing approaches. While the feedback is clear and actionable, it could be more helpful if it included specific references to the papers mentioned or more detailed guidance on how to integrate this information into the paper. Overall, the comment is 4 as it offers a valuable direction for enhancing the paper\"s context and comparison, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. However, the comment does not provide explicit guidance on how to address this issue or which specific realworld problems should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their experiments to include realworld data sets. While the suggestion is clear, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments being restricted to toy data and suggests that it would be interesting to demonstrate the method\"s performance on realworld problems. However, it does not specify which part of the paper discusses the experiments or where the authors should include the additional examples. The authors can infer that it relates to the experimental section, but the comment lacks full grounding. It is specific in suggesting the inclusion of realworld examples, but without explicit references to specific sections or examples, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that it would be interesting to demonstrate the method\"s performance on realworld problems. However, the comment lacks specific examples or references to realworld problems where barycenters could be applied, making it difficult for the authors to understand the scope of the suggestion. The claim is 3 as it provides a general direction for improvement but lacks detailed justification or examples to fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope. However, the comment could be more helpful if it included suggestions on which realworld problems or datasets would be most relevant or how to adapt the method for these scenarios. Despite this, the comment offers a valuable insight that can guide the authors in enhancing the applicability and robustness of their work. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the types of experiments and references examples, but it is implicit in the sense that the authors need to infer that they should conduct these experiments. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to papers that could serve as examples or inspiration for these experiments. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the types of experiments and providing references, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. It provides references to specific papers ([1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing) that could serve as examples or inspiration for these experiments. This provides a clear rationale for the suggestion, as the references offer concrete examples of how deeper networks and other structures have been explored in related work. The inclusion of references enhances the verifiability of the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would contribute to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from additional experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) to further strengthen its findings. It provides specific references to relevant papers, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as examples or inspiration for these experiments. This feedback is clear and actionable, as it directs the authors to a specific area for expansion and provides concrete references to guide their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these experiments into the paper or what specific aspects to focus on. Overall, the comment is 4, as it provides valuable direction for enhancing the paper, but could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit guidance on how the authors might address this issue. There is no suggestion for additional experiments, modifications, or clarifications that could help resolve the ambiguity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper discusses this mechanism, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the mechanism are unclear or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the clarity of why the proposed sample selection mechanism helps preserve the label distribution. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a concern about the limited scope of the models evaluated in the results/analysis, noting that only two relatively old and small models are considered. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should evaluate more models, newer models, or larger models, or how they might expand their analysis to include a broader range of models. Without specific actions or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results/analysis section, indicating that it is detailed and comprehensive but limited in scope due to the evaluation of only two relatively old and small models. However, it does not specify which part of the results/analysis section this critique pertains to, such as specific tables, figures, or sections. The authors can make an educated guess about the general area being discussed, but the comment lacks full grounding. It is specific in pointing out the limitation in model evaluation, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results/analysis are detailed and comprehensive but limited because only two relatively old and small models are evaluated. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples of how the evaluation could be expanded or improved, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the analysis, noting that only two relatively old and small models are evaluated. While it identifies a potential weakness in the scope of the analysis, it does not provide specific suggestions or guidance on how the authors might address this issue or expand their evaluation to include a broader range of models. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should explore this reformulation to improve the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions on how to implement this reformulation or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the steps to take and how to apply the suggested reformulation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which makes the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning for the equivalence, but it lacks specific examples or references to support the assertion fully. The authors would need to explore the reformulation to fully understand and verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation implies that the motivation for Algorithm 1 may not be as unique or necessary as claimed. The comment provides a clear and actionable suggestion for the authors to explore this reformulation, which could lead to a better understanding of the algorithm\"s purpose and potential improvements. However, the comment could be more helpful if it offered specific guidance on how to implement this reformulation or what implications it might have for the paper. Overall, the feedback is 4 as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that knowledge distillation (KD) and label smoothing (LS) are not identical but suggests that KD can be viewed as a special form of LS under certain conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment provides some insight into the theoretical relationship between KD and LS but lacks specificity in terms of how this understanding should influence the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point makes a claim about the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment acknowledges the distinction between knowledge distillation (KD) and label smoothing (LS) but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides some insight into the theoretical relationship between the two concepts. However, the comment lacks depth and does not offer any actionable suggestions or guidance for the authors to improve their draft. It does not address specific weaknesses or areas for improvement in the paper, leaving the authors without a clear path for enhancement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include more recent works in the comparison and provide results on largescale datasets, including ImageNet, to further verify the effectiveness of their proposed method. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to update the comparison and include additional results. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of outdated methods and suggests including more recent works and results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the competing dynamicpruning methods are outdated and suggests including more recent works. It also points out that only results on smallscale datasets are provided and recommends including results on largescale datasets like ImageNet. While the comment provides a logical basis for the suggestion by noting the lack of recent works and the limited scope of the results, it lacks specific references or examples of recent works that should be included. This makes the claim 3, as the authors would need to conduct their own research to identify relevant recent works. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the inclusion of more recent dynamicpruning methods and results on largescale datasets, such as ImageNet. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s scope and credibility. By addressing this point, the authors can strengthen their work by demonstrating the effectiveness of their proposed method on a broader range of datasets. However, the comment could be more helpful if it offered specific examples of recent works or detailed guidance on how to incorporate these results. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is explicit and concrete, as it specifies exactly what information is needed to clarify the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks the authors to clarify why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the performance degradation observed in the FBN results when using additional information about missing, wrong, or redundant data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with the FBN results, namely the degradation in performance when using additional information about missing, wrong, or redundant data. By asking the authors to provide an explanation for this degradation, the comment prompts the authors to clarify a potential weakness in their analysis. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out an area for improvement, it does not provide actionable feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs them to make the captions more descriptive, which is a clear and concrete action. Second, it suggests explaining the scramble network better, which is also a direct and actionable request. The comment provides specific guidance on how to improve the clarity of the figures and the explanation of the scramble network, making it 5. The authors know exactly what steps to take to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captions\" and \"the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the captions more descriptive and explaining the scramble network better. This provides clear guidance on what the authors should focus on to enhance their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive and that the explanation of the scramble network is lacking. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks concrete evidence or references to substantiate the need for more descriptive captions or a better explanation of the scramble network. As a result, the claim is considered 1, as it does not offer sufficient justification or evidence to support the suggestions for improvement.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the clarity and comprehensibility of the paper. First, it advises making the captions more descriptive, which would help readers understand the figures without having to search through the text for interpretations. Second, it suggests explaining the scramble network better, which could enhance the reader\"s understanding of the methodology. These suggestions are clear and actionable, offering the authors concrete steps to enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it provided examples or specific guidance on how to improve the captions or explanation of the scramble network. Overall, the feedback is 4 as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for a justification of why this particular dimension of difficulty is interesting. This provides a clear and direct action for the authors to take, which is to provide a motivation or explanation for this choice. The comment is explicit and concrete, as it specifies exactly what the authors need to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the images used in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, asking for a justification of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. The comment asks for a justification of why this particular dimension of difficulty is interesting, which is a reasonable request for clarification. However, the comment does not provide any specific evidence, examples, or references to support the claim that this choice is not wellmotivated. Without additional context or reasoning, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It questions the interest in this particular dimension of difficulty and asks for a justification. This feedback is 3 as it prompts the authors to clarify their reasoning and provide a more detailed explanation for this choice. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches that might be more motivating. Overall, the comment identifies a potential weakness and encourages the authors to improve their justification, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the analysis regarding the flatness of the minima found by the proposed method. It explicitly states that the authors need to provide an analysis on the losses of the noiseinjected models after training to support their claim about the flatness of the minima. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what additional analysis is required to strengthen their argument, ensuring they can implement the suggested change effectively.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis regarding the flatness of the minima, namely the analysis on the losses of the noiseinjected models after training. This provides clear guidance on what needs to be addressed to strengthen the claim about the flatness of the minima. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about flatness is missing, despite the paper arguing that the proposed method finds flat minima. The reviewer provides a logical explanation by pointing out that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by referencing specific sections or studies that support the need for additional analysis on the losses of the noiseinjected models. Overall, the claim is 4, as it provides a solid foundation for the argument but could benefit from more detailed references or examples.", "helpfulness_rationale": "The review comment identifies a critical gap in the analysis regarding the flatness of the minima found by the proposed method. It points out that the loss used for training the base model is the averaged loss for the noiseinjected models, and while the authors have provided convergence analysis on this loss, it does not ensure the flatness of the minima. The comment provides a clear and actionable suggestion for the authors to conduct an analysis on the losses of the noiseinjected models after training to support their claim about the flatness of the minima. This feedback is 5 as it directs the authors to a specific area where additional analysis is needed to strengthen their argument, offering a clear path for improvement. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the text inside the figure and the labels are too small to read without zooming and suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, ensuring that the text and labels are legible. The comment is specific and concrete, offering a straightforward solution to improve the readability of the figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text size being too small and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be addressed to improve the readability of the figures. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming. This is a factual statement that describes a specific issue with the figure\"s presentation. It does not express an opinion, judgment, or suggestion that requires verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the figures in the paper, noting that the text and labels are too small to read without zooming. It provides a clear and actionable suggestion by recommending that the text and labels should be roughly the same size as the manuscript text. This feedback is direct and helpful as it guides the authors on how to improve the readability of their figures, which is crucial for the clarity and accessibility of their work. However, the comment could be more helpful if it suggested specific ways to achieve this, such as using a larger font or adjusting the figure size. Overall, the comment is 4, as it effectively points out a critical issue and offers a straightforward solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is unclear and suggests that the introduction should be revised to make the paper easier to follow. However, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the motivation is unclear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction is unclear or what aspects of the motivation need clarification. This makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is 1 as it does not identify a specific section or part of the paper, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation is unclear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It provides a clear and actionable suggestion to revise the introduction to make the paper easier to follow. However, the comment lacks specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. While it points out a critical area for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to clarify the motivation. Therefore, the comment is 3, as it directs the authors to a key area for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of varying features and positions across categories or how to incorporate multiple local prompts effectively. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation is based on, nor does it provide guidance on how to address the issue of varying features and positions. The authors may infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions differ across categories. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the potential benefit of including multiple local prompts but points out that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the validation process. The action is implicit, as the authors need to infer that they should focus on validating the alignment, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as it does not provide a clear reference to the relevant section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. While the comment highlights a potential weakness in the paper, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or improve the validation process. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it points out a concern but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation of the model in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides specific and concrete actions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. These suggestions are explicit and provide clear guidance on how to enhance the presentation, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting improvements in the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model\"s presentation in section 4 is complicated and requires careful reading, possibly with reference to the supplement. It provides a specific suggestion to improve the presentation by replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. However, the comment does not provide any evidence or examples to support the claim that the current presentation is complicated or how the suggested changes would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the necessity of the suggested changes based on the reviewer\"s feedback.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the model in section 4, noting that it is somewhat complicated and requires careful reading. It provides actionable feedback by suggesting ways to improve the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to show the attention mechanisms. These suggestions are clear and concrete, offering the authors a direct path to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or further elaboration on how to implement these suggestions. Overall, the feedback is 4 as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and only provides indistribution testing for these samples. The reviewer suggests that the value of the method would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their experiments. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to a broader range of molecules or exploring alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the paper for conducting experiments on a limited number of molecules and only providing indistribution testing for these samples. It suggests that the value of the method would be limited if it requires training for each molecule individually. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the limitation of the experiments, but without clear grounding, the authors may struggle to identify the exact parts that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a small number of molecules and indistribution testing. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar studies or experiments that demonstrate the potential impact of a broader scope of molecules or outofdistribution testing. Without such evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s scope, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the value of the method would be limited if it requires training for each molecule individually, which could be a major drawback. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand their experiments to a broader range of molecules. While it highlights an important area for improvement, the lack of actionable advice or detailed feedback makes it 3. The authors are left with a general understanding of the issue but without clear steps to take to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment indicates that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not provide any explicit or implicit suggestions on how to simplify the symbols or improve their clarity. Without guidance on what specific aspects of the symbols are causing the complexity or how to address it, the authors are left without a clear path for improvement. As a result, the comment lacks actionable advice, making it 1.", "grounding_specificity_rationale": "The comment suggests that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not specify which symbols are causing the issue or where in the paper they are used. This lack of detail makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is 1 as it does not mention specific sections, tables, or figures, and it is also not specific about what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Symbols are a little bit complicated and takes a lot of time to understand.\" However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the symbols used in the paper are complicated and timeconsuming to understand. However, it lacks specificity and does not provide any actionable advice or suggestions on how to simplify the symbols or improve their clarity. Without guidance on what aspects of the symbols are causing the complexity or how to address it, the authors are left without a clear path for improvement. This makes the comment 2, as it identifies a potential issue but does not offer any constructive feedback or direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to clarify the source of the test data and the existence of a ground truth, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, asking about the source of the test data and the existence of a ground truth. This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the red line in Figure 3, specifically asking about the source of the test data and the existence of a ground truth. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about Figure 3, asking about the source of the test data and whether there is a ground truth. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this issue or improve the figure. The comment is clear in its questioning but lacks actionable feedback or constructive suggestions, making it 3. The authors are left to infer that they need to address the question, but without specific guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It suggests that the comparison model cannot capture periodic relationships and questions whether adding periodicity to the spectral kernel would be enough to achieve similar results to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of periodicity on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It references the comparison model and the experiments, specifically mentioning Experiment 1b, which implies that the authors can identify the relevant parts of the paper being discussed. However, the comment does not specify what needs to be addressed or how the authors should investigate this issue further. While it provides some context, it lacks specificity in terms of actionable steps or detailed guidance. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It provides a logical reasoning by comparing the comparison model, which cannot capture periodic relationships, to the experiments where periodicity is involved. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to delve deeper into the experiments and results to fully understand and address the question posed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity versus compositionality. It highlights a potential limitation in the comparison model\"s inability to capture periodic relationships and suggests that adding periodicity to the spectral kernel might be sufficient to achieve similar results to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the role of periodicity in their results and encourages them to explore this aspect further. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or if it offered a more detailed analysis of the implications of periodicity on the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the paper is not wellwritten and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the paper\"s writing quality and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are problematic, nor does it provide detailed guidance on how to improve the presentation or formatting. This makes it difficult for the authors to identify the exact areas that need attention. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"not very wellwritten\" and suggests it may have been written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without concrete evidence or examples, the claim remains vague and 1, making it difficult for the authors to understand and address the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a general critique of the paper\"s writing quality, suggesting that it may have been written in a hurry, which makes it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing, presentation, or formatting. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to enhance their draft. Therefore, the comment is 2, as it identifies a general issue but does not offer actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction need more detail or how the authors might enhance it. The action is implicit, as the authors need to infer that they should add more detail, but it is vague because it lacks concrete suggestions on what specific details to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of Part 2 is being referred to, nor does it provide details on what aspects of the introduction need more detail. This makes it difficult for the authors to pinpoint the exact section that needs improvement. The comment is 1 as it lacks specific references, and it is also not specific in terms of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand what aspects of the introduction need more detail or how to improve it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed, indicating a potential area for improvement. However, it lacks specificity and does not provide guidance on what aspects of the introduction need more detail or how the authors might enhance it. Without actionable suggestions or examples, the authors are left with a general idea of what might need attention but without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper\"s results in relation to prior work. It suggests that if the paper\"s contribution is not as novel as claimed, it should do a better job of highlighting its originality. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper\"s results in relation to prior work, specifically mentioning the occurrence of samplewise multiple descent in linear regression. It suggests that the paper should better highlight its contribution, particularly in anisotropic settings. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for the authors to clarify the novelty of their results, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper\"s results in relation to prior work, specifically mentioning that prior work has already theoretically shown samplewise multiple descent in linear regression. The reviewer suggests that the paper\"s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings. However, the comment lacks specific references or detailed reasoning to support the claim that the paper\"s contribution is not novel. The reviewer also mentions that they are not familiar with the techniques and tools used, which makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence or detailed justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper\"s results in relation to prior work. It points out that prior studies have already theoretically shown samplewise multiple descent in linear regression, which could impact the perceived originality of the paper\"s contribution. The reviewer suggests that if the paper\"s contribution is not as novel as claimed, it should do a better job of highlighting its originality in relation to prior results. This feedback is 3 as it prompts the authors to clarify the novelty of their findings and potentially differentiate their work from existing literature. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to highlight the paper\"s original contributions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically mentioning \"contrastive training objective\" and \"contrastive search.\" However, it does not specify which part of the paper these methods are discussed in, making it weakly grounded. The comment is specific in identifying the lack of connection between these methods in terms of intuition and algorithm, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack an inner connection in terms of intuition and algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed methods, specifically noting that the contrastive training objective and contrastive search are two independent methods with little inner connection in terms of intuition and algorithm. This observation highlights a potential weakness in the paper, suggesting that the authors may need to clarify or strengthen the connections between these methods. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or theoretical analysis to demonstrate the relationship between the methods. While it points out a relevant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model with a proofofconcept test, it should be clearer and justified with a future useful application. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue, such as suggesting specific comparisons or justifications to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and justification for their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper\" and references a specific existing work, \"PhaseNetDas, Zhu et al. 2023,\" which helps the authors identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison with existing DAS earthquake detectors and the need for a clearer justification of the benefit of the proposed method. Additionally, it suggests that if the paper claims to be a foundation model, it should provide a clearer explanation and justification for its future applications. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model, it should be clearer and justified with a future useful application. The comment provides a specific reference to PhaseNetDas, which supports the claim that such detectors exist. However, it lacks detailed reasoning or examples to fully substantiate the claim that the paper\"s goal is unclear or that comparisons are necessary. The reference to PhaseNetDas is a good starting point, but more detailed justification or examples would strengthen the argument. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a critical concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It points out that no comparison was made, nor was there a justification for the benefit of the proposed method over existing ones. The comment suggests that if the paper claims to be a foundation model, it should be clearer and provide a justification for its future applications. This feedback is 4 as it identifies a significant gap in the paper and provides a clear direction for improvement. However, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on for justification. Overall, the comment provides valuable guidance for the authors to enhance the clarity and relevance of their work, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the ablation studies of MCT without adaptive metrics. While it identifies areas of potential concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to investigate and clarify these discrepancies, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the alignment of results and the absence of ablation studies for MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the alignment of results between Table 6 and Table 1 (MCTpair), as well as the absence of ablation studies for MCT without adaptive metrics. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises two specific questions about the results presented in the paper. It questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Additionally, it asks about the absence of ablation studies for MCT without adaptive metrics, suggesting that this could be an important aspect to explore. While the comment identifies potential issues, it does not provide detailed guidance or suggestions on how to address these concerns. The authors are left with a clear understanding of what needs to be clarified but without specific steps to take. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. However, the comment does not explicitly instruct the authors to address this issue or suggest how to differentiate their work from existing research. The action is implicit, as the authors can infer that they need to discuss the novelty and originality of their work in relation to prior studies. The feedback is 3 because it points out a potential weakness but lacks specific guidance on how to address it. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses are already present in prior works, making the results not particularly surprising. This provides clear guidance on what needs to be addressed in terms of novelty and originality. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses are already present in prior works, making the results in the current paper not particularly surprising. It supports this claim by referencing specific prior works, such as RobustBench and [Croce et al. (2021)], which have studied the robustness of CIFAR10 models on distribution shifts. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from or builds upon these prior studies. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. This feedback is 3 as it highlights a potential weakness in the paper, namely the lack of novelty in the analyses presented. However, it does not offer specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing research. While it provides some insight into the need for originality, it lacks depth and actionable advice, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the 10 subtasks are too simplistic for bAbi and that the authors could solve all of them with their final model. It implies that the authors should provide more discussions on this aspect. However, the comment does not explicitly instruct the authors to add these discussions or provide specific guidance on how to enhance the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to add more discussion but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the 10 subtasks in the context of bAbi, suggesting that they are too simplistic and that the authors could solve all of them with their final model. However, it does not specify which part of the paper these subtasks are discussed in, making it weakly grounded. The comment is specific in its suggestion that more discussions are required, but it lacks detailed guidance on what aspects should be discussed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for bAbi and that the authors could solve all of them with their final model. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks in the context of bAbi, suggesting that the authors could solve all of them with their final model. It implies that the authors should provide more discussions on this aspect, which could help clarify the relevance and challenge of the subtasks. However, the comment lacks specific guidance or suggestions on how to enhance the discussion or address the issue, leaving the authors with a general idea of what needs improvement but without actionable steps. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this is a fundamental limitation or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or what steps to consider in extending the approach. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the limitation but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this is a fundamental limitation or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the approach. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It prompts the authors to consider whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This feedback encourages the authors to reflect on the scope and applicability of their method, potentially leading to a deeper exploration of its limitations and potential enhancements. However, the comment lacks specific suggestions or guidance on how to address this limitation, which limits its helpfulness. Therefore, it is 3, as it provides a direction for further consideration but does not offer detailed actionable steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct issues. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This implies that the authors should clarify the meaning of this term. Second, it points out the absence of related work, suggesting that the paper seems to be related but does not negate its novelty. While the comment identifies areas for clarification and suggests the inclusion of related work, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the term \"sqeuence of episodes\" and suggesting that practice and evaluation might be the types of sequences being referred to. Additionally, it points out the absence of related work, which is a specific area for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two distinct claims. The first claim questions the term \"sqeuence of episodes\" and suggests that practice and evaluation might be the types of sequences being referred to. This is a subjective opinion that requires clarification, but it is not entirely 1 as it points out a potential ambiguity in the text. The second claim points out the absence of related work, suggesting that the paper seems related but does not negate its novelty. This claim is 3 as it provides a logical reasoning for the absence of related work, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this term. Second, the comment points out the absence of related work, noting that the paper seems related but does not negate its novelty. This is a valuable observation that could help the authors contextualize their work within the existing literature. However, the comment could be more helpful if it provided specific examples of related work or suggested how to address the issue of novelty. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes might be necessary to clarify the nature of the study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the study\"s classification, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This claim is based on a logical reasoning that ablation studies typically involve removing or varying a specific component to assess its impact. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the context of their study and the typical definitions of ablation studies to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This feedback is 3 as it points out a potential misunderstanding or mislabeling in the study\"s methodology. However, it lacks depth and does not provide specific guidance on how the authors might clarify or correct this classification. The comment identifies a potential issue but does not offer actionable steps for improvement, leaving the authors with a general direction but not a clear path forward. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. While it suggests exploring this idea, it does not provide explicit instructions or concrete steps for the authors to take. The comment implies that the authors should consider this possibility, but it lacks specificity and detail on how to implement or evaluate this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion by asking whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. This level of detail provides clear guidance on what the authors should consider, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be beneficial or how it relates to the current work. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. This suggestion provides a potential direction for the authors to explore, offering a way to enhance the applicability and utility of their work. However, the comment lacks depth and does not provide specific guidance on how to integrate AccNet into a larger predictor or what benefits this might bring. While it offers a starting point for further exploration, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, implying that the authors should expand their testing to multiple datasets to validate the metric\"s robustness. However, the comment does not provide explicit guidance on which datasets to use or how to conduct the testing. The action is implicit and somewhat vague, as the authors can infer that they need to test the metric on more datasets but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the testing of the new proposed metric, specifically mentioning that it is only tested on a single dataset. However, it does not specify which dataset this is or where in the paper this information is presented, making it weakly grounded. The comment is specific in its critique, as it highlights the limitation of testing on a single dataset, but without more detailed information, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, which could be a limitation in the evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this limitation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is relevant as it highlights a potential weakness in the validation process, suggesting that the authors should consider testing their metric on multiple datasets to ensure its robustness. However, the comment lacks specific suggestions or guidance on which datasets to use or how to conduct the testing, which would make it more actionable. While it identifies an important area for improvement, the feedback is 3 as it provides a direction for further work but does not fully support the authors in making those improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN, in addition to the proposed TransferNorm architecture. This implies that the authors should include these competitors in their evaluation to make the comparison more comprehensive. However, the comment does not provide specific guidance on how to implement this suggestion, such as which specific experiments to conduct or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not fully understand the scope of the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation would be stronger if the base DA methods were compared with and without architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This provides clear guidance on what needs to be addressed to enhance the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. The comment provides a logical reasoning for the suggestion, as it implies that including these competitors would provide a more comprehensive comparison. However, the comment lacks specific examples or references to support the claim that AutoDial and AdaBN are direct competitors to TransferNorm, which would strengthen the argument. Therefore, the claim is 3, as it provides a logical basis but requires additional evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment provides a constructive suggestion for enhancing the evaluation section of the paper. It acknowledges the current evaluation as a good start but suggests that it could be strengthened by including comparisons with architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This feedback is actionable and offers a clear direction for the authors to improve their evaluation methodology, making it 4. However, the comment could be more helpful if it provided specific guidance on how to incorporate these competitors into the evaluation or what aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their evaluation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies two specific issues: undefined abbreviations and superscript notation in an equation. It provides examples of the abbreviations that are not defined, such as \"NE\" on line 73, and notes that the superscript notation in Equation 6 is not defined until much later, which hinders understanding. The comment also includes references to relevant literature, which could help the authors understand the context and importance of defining these elements. However, the comment does not explicitly instruct the authors to define these abbreviations or superscript notation, leaving the action implicit. While the authors can infer that they need to address these issues, the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and equations, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with undefined abbreviations and superscript notation, providing clear guidance on what needs to be addressed. The inclusion of references to relevant literature further supports the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined and that superscript notation in an equation is not defined until later, which hinders understanding. The comment provides specific examples, such as \"NE\" on line 73, and references relevant literature to support the claim. This level of detail and reference to external works makes the claim 4, as it provides a clear basis for the authors to address the issues. However, the comment could be strengthened by providing more detailed guidance on how to address the undefined abbreviations and notation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues that hinder the understanding of the paper: undefined abbreviations and superscript notation in an equation. It provides examples, such as \"NE\" on line 73, and notes that the superscript notation in Equation 6 is not defined until much later, which can cause confusion during the initial read. The inclusion of references to relevant literature, like [1], [2], and [3], offers context and suggests that the authors should define these elements to improve clarity. This feedback is clear and actionable, as it directs the authors to address these specific issues, which can significantly enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to strengthen the evaluation or which alternative baselines might be more suitable. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used are not designed for fair classification. However, it does not specify which part of the paper discusses the evaluation or the baselines, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved for fair classification. This lack of grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific examples or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation methodology, specifically noting that the baselines used are not designed for fair classification. This is a critical observation that highlights a potential flaw in the paper\"s evaluation process. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative baselines that could be more appropriate. Without detailed suggestions or examples, the authors may find it challenging to understand how to improve their evaluation methodology. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to clarify the setting in the first three paragraphs of section 2. It implies that the current presentation may give the impression of a more general contribution than what is actually made, which \"muddles the exposition.\" However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be detailed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more clarity but are not given concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the need for clearer exposition regarding the setting, suggesting that the authors may be claiming a more general contribution than what is actually presented. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their contribution. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references leaves the claim 3, as the authors would need to infer the exact areas that require clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their contribution. It points out that this lack of clarity \"muddles the exposition,\" which is a valuable observation for the authors to address. However, the comment could be more helpful if it provided specific suggestions or examples of how to clarify the setting or what aspects need more detail. Despite this, the feedback is 3 as it directs the authors to a critical area that needs improvement, even if it lacks detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the authors should either test their method on these newer approaches or explain the advantage of their method compared to these alternatives. While the action is implicit, it is concrete in suggesting specific alternatives to consider or compare with. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment is fully grounded as it explicitly mentions the experiments section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the proposed method works on these newer 3D CNNs and what advantage it offers compared to them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the proposed method should be tested on these newer approaches or compared to them to demonstrate its advantage. However, the comment lacks specific examples or references to support the claim that these newer approaches are more effective or relevant. This makes the claim 3, as it provides a logical suggestion but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment also prompts the authors to clarify whether their method works on these newer 3D CNNs and what advantage it offers compared to them. This feedback is clear and actionable, providing the authors with specific guidance on how to improve their experimental setup and presentation. By addressing these points, the authors can enhance the credibility and relevance of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks for clarification on how the attention module is attached to the ResNet20 architecture during the search process. It specifically requests information on the number of attention modules used and their placement, such as after each block or stage. This provides clear and direct guidance for the authors to address the issue by providing detailed explanations or visualizations. The comment is 5 as it specifies exactly what needs to be clarified and how the authors can improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and \"backbone ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the exact placement and number of attention modules used during the search process. The comment provides detailed guidance on what information should be included to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the attachment of the attention module to the ResNet20 architecture during the search process. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module into the ResNet20 architecture during the search process. It asks for clarification on the number of attention modules used and their placement, such as after each block or stage. This feedback is clear and actionable, as it provides the authors with a precise direction for improving the clarity and comprehensiveness of their draft. By addressing these questions, the authors can enhance the understanding of their methodology and its implementation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct issues. First, it questions the precise bitrate range used for the BDrate comparison, implying that the authors should provide more detailed information on this aspect. Second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, specifically referencing a paper by Guo Lu et al. from ECCV 2020. Both points are explicit and provide clear actions for the authors to take: they should specify the bitrate range and consider discussing or comparing their work with the mentioned paper. The feedback is concrete and actionable, as it directly instructs the authors on what steps to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the precise bitrate range used for the comparison and suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The reference to a specific paper by Guo Lu et al. provides additional guidance on what aspect to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the performance of the proposed method, stating that it is stronger at high bitrate but closer to baselines at low bitrate. However, it does not provide any specific data, examples, or references to support this claim, making it difficult for the authors to understand the basis of the comparison. The suggestion to discuss or compare with a related work is a separate point that is not directly related to the claim about the method\"s performance. Therefore, the comment is considered 1 due to the lack of supporting evidence or detailed reasoning.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it questions the precision of the bitrate range used for the BDrate comparison, which is an important detail that could impact the interpretation of the results. This feedback is clear and actionable, as it prompts the authors to specify the exact bitrate range used. Second, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, specifically referencing a paper by Guo Lu et al. from ECCV 2020. This suggestion is valuable as it could enhance the paper\"s context and relevance by exploring additional approaches. However, the comment could be more helpful if it provided a more detailed explanation of how this comparison might benefit the paper or what specific aspects to focus on. Overall, the feedback is 4 as it identifies areas for improvement and provides a constructive suggestion, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should distinguish between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that this distinction is necessary, it does not provide explicit guidance on how to make this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests distinguishing between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. The authors may infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests distinguishing between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a distinction between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or why it is important. The authors are left with a general idea of what might need improvement but without actionable steps to take. Therefore, the comment is 2, as it offers some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the improvements over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is insufficient. However, it does not provide explicit guidance on what specific aspects of the analysis should be expanded or how the authors should address the marginal improvements. The action is implicit and vague, as the authors are left to infer that they need to conduct more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements over previous works and selfimplemented baselines, suggesting that they are marginal. However, it does not specify which tasks or experiments are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures, and it is also not specific about what aspects of the analysis are insufficient. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, and that further analysis beyond the main experiments is insufficient. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the improvements over previous works and selfimplemented baselines are marginal. It suggests that further analysis beyond the main experiments is necessary to substantiate these claims. However, the comment lacks specificity and does not provide actionable guidance on what additional analysis should be conducted or how it should be framed. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer sufficient direction for the authors to make meaningful changes."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the clarity of Theorem 8, which is crucial for understanding the linear convergence rates. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the proof of Theorem 8, but it does not specify how to do so or what changes are needed. This makes the action vague and inferred, aligning with a score of 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the clarity of the proof of Theorem 8, particularly its location at the end of the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any specific details or examples to support this claim, nor does it offer suggestions for improving the clarity of the proof. This lack of supporting evidence or detailed reasoning makes the claim difficult for the authors to address effectively, rendering it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and has a proof that is not clear enough. This feedback is valuable as it points out a potential obstacle for readers who may struggle to understand the theoretical foundation of the paper. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the proof or where it could be moved to a more accessible location in the main text. Despite this, the comment is 3 as it directs the authors\" attention to a critical area that needs improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two separate issues. The first part addresses a potential inaccuracy in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to state that all works are based on simple SGD for decentralized optimization. This is an explicit action for the authors to correct the statement. The second part points out a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. Both parts provide explicit actions with clear guidance on how to address the issues. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inaccuracies in the statements regarding the Walkman algorithm and the lack of clarity in the reference to \"it.\" The comment provides clear guidance on what needs to be corrected or clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim challenges the statement that all works are based on simple SGD for decentralized optimization, pointing out that the Walkman algorithm (Mao et al., 2020) uses ADMM with two versions. This claim is 4 as it provides specific details about the Walkman algorithm, but it could be strengthened by referencing the exact sections where the SGD statement is made. The second claim points out a lack of clarity in the reference to \"it\" in Section 3, which is a factual observation requiring no justification or evidence. Therefore, the overall comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by addressing two distinct issues in the paper. First, it corrects an inaccuracy in the Related Work section regarding the Walkman algorithm, pointing out that it uses ADMM with two versions, not just SGD. This feedback is clear and helps the authors improve the accuracy of their work. Second, it identifies a lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors should clarify the reference. This feedback is also actionable, as it directs the authors to enhance the clarity of their writing. By addressing these specific issues, the comment is 5, as it provides detailed guidance for improving the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a limitation in the paper, specifically that the main theoretical result provides utility guarantees only under the assumption of Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific issue and suggests a comparison with existing literature, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it details the issue with the theoretical result, noting that it provides utility guarantees only under the assumption of Gaussian features and noise, and highlights the need for comparison with existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only under the assumption of Gaussian features and noise, which is a strong requirement on the data. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. The claim is 3 as it provides a logical reasoning about the limitation of the theoretical result and suggests a comparison with existing literature. However, the comment lacks specific references or examples of existing rates in the literature, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically that the main theoretical result provides utility guarantees only under the assumption of Gaussian features and noise. This is a critical observation that highlights a strong requirement on the data, which may limit the applicability of the proposed algorithm. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which would provide a more comprehensive understanding of the algorithm\"s performance. This feedback is clear and actionable, as it directs the authors to address a specific theoretical limitation and to provide a comparison with existing literature, which could significantly enhance the paper\"s impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how this comparison should be conducted or what aspects should be focused on, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the comparison are missing. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in suggesting a comparison but does not provide detailed guidance on how to conduct it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any reasoning or justification for why this comparison is necessary or how it would enhance the paper. Without supporting evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of the importance or relevance of this comparison. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a useful comparison between the proposed extension and the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including a comparative analysis. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or what aspects to focus on. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It implies that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., [1,2,3]), are necessary. However, the comment does not specify which additional works should be included or how the experiments should be conducted. While the action is clear, the lack of detailed guidance on implementation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, referencing specific works ([1,2,3]) that focus on the same questions. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It supports this claim by referencing specific works ([1,2,3]) that focus on the same questions, suggesting that these additional comparisons are necessary. However, the comment lacks detailed reasoning or examples of how these additional comparisons would enhance the paper, making it 3. The authors would need to infer the specific improvements and how to implement them, which adds to the complexity of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that additional experimental comparisons with other works that focus on the same questions would be beneficial to demonstrate the effectiveness of the proposed method. The comment provides a clear direction for improvement by referencing specific works ([1,2,3]) that could be included in the comparisons. However, it could be more helpful if it offered specific suggestions on how to conduct these additional experiments or which aspects to focus on. Overall, the comment is 4 as it provides actionable feedback that can guide the authors in enhancing their experimental section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This is a direct and concrete action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting the average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Tables 1 and 2, which are based on the dev set, are not convincing. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it provides a logical reasoning for why the current presentation of results may not be sufficient for convincing the audience. However, the comment lacks specific examples or references to support the claim that the current results are not convincing, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the best results are reported on the dev set after hyperparameter search and model selection on the dev set. The reviewer suggests that presenting average results on the test set with clearly defined error bars under different random seeds would be more convincing. This feedback is clear and actionable, providing the authors with a specific direction to improve the robustness and credibility of their results. By addressing this suggestion, the authors can enhance the reliability and impact of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the methodology and dataset used in the paper. It asks for the number of topics used, how topicword parameters were obtained for the \"real\" dataset, and the size of the AG news dataset. Additionally, it requests that the main paper describe the number of documents in the train and test sets and the number of vocabulary words. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should include these details in the paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the questions. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset used in the paper, specifically asking about the number of topics used, how topicword parameters were obtained, the size of the AG news dataset, and the number of documents in the train and test sets, as well as the number of vocabulary words. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its requests for information but lacks grounding, as it does not provide a clear reference to the sections where these details should be addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the methodology and dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and aim to gather more information about the paper, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and dataset used in the paper. It asks for specific details such as the number of topics used, how topicword parameters were obtained, the size of the AG news dataset, and the number of documents in the train and test sets, as well as the number of vocabulary words. These questions are relevant and could help the authors clarify and improve their methodology and presentation. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered guidance on what information should be included in the paper. Despite this, the comment is 4 as it identifies areas that need clarification and improvement, providing the authors with a clear direction for enhancing their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should expand their comparison to include a broader range of NAS approaches, but the comment lacks concrete details on which specific approaches to consider or how to incorporate them into the analysis. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of BRPNAS, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This provides full grounding as it explicitly mentions the specific part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what is missing in the analysis, namely a comparison with other NAS approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of BRPNAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment highlights a potential limitation in the analysis, it lacks specific examples or references to support the claim that other NAS approaches should be included. The reasoning is somewhat vague, as it does not provide detailed justification or evidence for why these additional approaches are relevant or necessary. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This feedback is 3 as it points out a gap in the analysis that the authors could address by expanding their comparisons to include a broader range of NAS approaches. However, the comment lacks specific suggestions or guidance on which additional approaches to consider or how to incorporate them into the analysis. While it provides some direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a subjective opinion about the content of the paper, suggesting that the zeroshot version and its connection to density estimation are distracting from the main point. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this perceived distraction or whether it should be included in the paper. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of the zeroshot version and its connection to density estimation, suggesting that it distracts from the main point of the paper. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by explaining the perceived distraction, but without clear grounding, the authors cannot confidently determine where to make changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the content of the paper, suggesting that the zeroshot version and its connection to density estimation are distracting from the main point. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. It lacks specific examples or detailed explanations of how these elements are distracting or how they could be improved. As a result, the claim is 1, as it does not offer any basis for the authors to understand or address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a subjective opinion about the content of the paper, suggesting that the inclusion of the zeroshot version and its connection to density estimation is distracting from the main point. However, the comment acknowledges that this is more of an aesthetic argument than a technical one, implying that it may not be a critical issue. While the comment identifies a potential distraction, it does not offer any actionable advice or suggestions on how to address this issue or whether it should be included in the paper. As a result, the comment provides limited guidance for the authors, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information about the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This feedback is clear and direct, giving the authors a concrete action to take: they should include detailed information about these processes to enhance the assessment of the dataset\"s quality. The comment is 5 as it specifies exactly what needs to be added to the draft, providing the authors with a clear path forward.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset\"s quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking. It suggests that more information on the translation and filtering methodology is needed to assess the dataset\"s quality. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these details and how they impact the dataset\"s quality. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset\"s quality. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for evaluating the dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects of the methodology should be emphasized. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and determine the thresholds to test. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. Additionally, while the comment identifies areas for enhancement, it does not provide specific guidance on how to address these issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that the current results are insufficient or that the suggested enhancements would be beneficial. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiment results, suggesting that the inclusion of attacks with different strengths and an exploration of how different thresholds influence detection performance could enrich the results. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis. However, the comment could be more helpful if it offered specific suggestions on how to implement these enhancements or provided examples of thresholds to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It also notes a difference between this approach and Figure 4, where the discriminator is coadapting with the generator and might get stuck at a local optimum. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is somewhat inferred and lacks detailed guidance on how to implement the suggested evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that to evaluate the claim of reducing exposure bias, the authors should train a discriminator on generations from the learned model, similar to Figure 1. It notes a difference between this approach and Figure 4, where the discriminator is coadapting with the generator and might get stuck at a local optimum. The comment provides a logical reasoning for the evaluation process, suggesting a specific method to confirm the claim. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to consider the suggestion and potentially conduct additional experiments to fully verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for evaluating the claim of reducing exposure bias in the paper. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. This feedback is actionable and offers a clear direction for the authors to improve their evaluation methodology. However, the comment could be more helpful if it included additional details or examples of how this evaluation should be conducted or what specific aspects to focus on. Overall, the comment is 4 as it provides a constructive suggestion for enhancing the evaluation process, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more information about the performance differences resulting from using different image sizes and variations of ResNets. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion or analysis of the performance differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the performance differences resulting from using different image sizes and variations of ResNets. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information about the performance differences resulting from using different image sizes and variations of ResNets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more information about the performance differences resulting from using different image sizes and variations of ResNets. This feedback is clear and actionable, as it directs the authors to a specific area where additional analysis or discussion could enhance the paper. By addressing this point, the authors can provide a more comprehensive understanding of their results and their implications. However, the comment could be more helpful if it offered specific suggestions on how to present this information or why it is important. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. While the comment implies that the authors should provide more detailed information about the algorithm, it does not specify what aspects of the algorithm need to be detailed or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but are not provided with concrete guidance on what those details should be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references or clear indications of where the algorithm is presented, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this level of detail is necessary or how it would improve the paper. The comment lacks verifiable evidence or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on what aspects of the algorithm need more detail or how to present them. The comment does not offer suggestions on how to enhance the clarity or depth of the algorithm description, leaving the authors with a general idea but no concrete steps to take. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they should consider adding a runtime comparison but are not given specific instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Chebyshev polynomials, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular aspect that could be explored further: a runtime comparison at test time. This provides clear guidance on what the authors could add to enhance their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. The suggestion is based on a logical inference but lacks detailed explanation or examples, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment suggests that it would be interesting to see a runtime comparison at test time, given the mention of using Chebyshev polynomials for a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific experiment or analysis that could be added to the paper. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what specific aspects to focus on. While it offers a direction for enhancement, it does not fully support the authors in making the necessary changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader realworld applications compared to digit or text images. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further testing, modification, or discussion regarding the method\"s applicability to natural images. Without any guidance or direction, the authors are left without a clear understanding of how to address this concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader realworld applications compared to digit or text images. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questioning of the method\"s applicability but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader realworld applications compared to digit or text images. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, which has broader realworld applications compared to digit or text images. This is a relevant concern that could impact the practicality and relevance of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or explore the method\"s applicability to natural images. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how to improve the organization of the prompts. The authors are left without guidance on how to address this issue, making it difficult for them to know what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the prompts, noting that they are not wellorganized and that all sentences are squeezed together. This provides clear guidance on what needs to be addressed to improve the presentation of the prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a potential area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide specific suggestions or guidance on how to reorganize the prompts or improve their clarity. While it highlights a weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies issues with the clarity of the figures, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear and direct actions for the authors to take, which is to improve the clarity of the figures and ensure all components are labeled. The feedback is explicit and concrete, offering specific guidance on how to enhance the visual presentation of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2\" and \"some modules,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figures, such as the confusion in the relation of subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules are not labeled. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback is clear and actionable, as it provides the authors with concrete areas to improve the visual presentation of their work. By addressing these issues, the authors can enhance the readability and understandability of their figures, which is crucial for the paper\"s overall impact. However, the comment could be more helpful if it offered suggestions on how to improve the labeling or organization of the figures. Overall, the comment is 4, as it directs the authors to specific areas that need improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether there is existing work that offers a way to approximate the contribution of FFNs, given that a linear decomposition cannot be obtained. It suggests that if no such work exists, the authors should add a statement indicating that it is an open problem. This feedback is explicit in its request for additional information and provides a clear direction for the authors to follow. The suggestion to add a line or two to address the issue is concrete, as it specifies what action the authors should take to improve the readability and clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider existing work that might offer a way to approximate the contribution of FFNs, and if not, to acknowledge the lack of a solution and label it as an open problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, and it suggests that the authors should consider whether existing work offers a way around this limitation. The comment implies that the absence of such work is a gap in the paper, but it does not provide specific references or detailed reasoning to support this claim. While the suggestion to acknowledge the lack of a solution and label it as an open problem is reasonable, the comment lacks sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or references to be 5.", "helpfulness_rationale": "The review comment raises a relevant question about the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider whether existing work offers a way to approximate the contribution of FFNs, and if not, to acknowledge the lack of a solution and label it as an open problem. This feedback is helpful as it prompts the authors to address a potential gap in their work and provides a clear direction for improvement. By acknowledging the limitation and framing it as an open problem, the authors can enhance the readability and clarity of their paper. However, the comment could be more helpful if it provided specific examples or references to existing work that might offer approximations. Overall, the comment is 4, as it offers actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically the use of perplexity as a measure of the model retaining semantic information after finetuning. It highlights the need to consider domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not provide explicit guidance on how to address these concerns or control these factors. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore methods to mitigate domain drift and catastrophic forgetting but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about \"questionable design choices\" related to the use of perplexity as a measure of the model retaining semantic information after finetuning. It mentions the need to consider aspects of domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the design choices and the need to control domain drift and catastrophic forgetting, but without explicit references to specific sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of the model retaining semantic information after finetuning, suggesting that it may not fully capture the impact of domain drift and catastrophic forgetting. The comment questions how these factors are controlled, implying that the authors should provide a more comprehensive explanation or analysis of these issues. However, the comment lacks specific examples, references, or detailed reasoning to support the claim, making it 3. The authors would need to infer the exact nature of the concern and how to address it, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the design choices in the paper, specifically the use of perplexity as a measure of the model retaining semantic information after finetuning. It highlights the need to consider aspects of domain drift and catastrophic forgetting, which are separate from the original task. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or control for these factors. While it points out a potential weakness, it lacks actionable feedback, leaving the authors with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is 3, as it provides insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the impact of the number of images on the model performance and another about the explanation of BYOL in the abstract. While the questions are clear and imply that the authors should address these points, they do not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and report on the impact of image numbers and provide a detailed explanation of BYOL. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on the model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image numbers and the explanation of BYOL, but without clear references to specific sections or parts of the paper, the authors may find it challenging to pinpoint where these issues need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on the model performance and requests clarification on the explanation of BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two important questions about the paper. First, it questions how the number of images impacts the model performance, which is a critical aspect of understanding the robustness and generalizability of the model. Second, it requests clarification on the explanation of BYOL in the abstract, which is a relevant point for readers who may not be familiar with the acronym. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their explanation. While it identifies areas for improvement, the feedback is 3 as it points out important aspects that need clarification but does not provide detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that while the observed effects are strong, the paper lacks clarity on why the method works, particularly regarding the L_pixel component. It explicitly recommends providing stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and justification of the method\"s effectiveness. The comment provides a specific and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the clarity of the paper regarding the effectiveness of the method, specifically the L_pixel component. It suggests that while the observed effects are strong, the paper lacks explanation on why the method works, particularly in relation to this component. The comment provides a clear direction for improvement by recommending stronger arguments or intuitions to explain the benefits of the particular losses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for improvement, as it clearly outlines what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the observed effects are strong but questions the clarity of why the method works, particularly regarding the L_pixel component. The reviewer suggests that stronger arguments or intuitions are needed to explain why these particular losses are beneficial. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim that the current explanation is insufficient. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specific issues and address them accordingly. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, which is the lack of clarity regarding why the method works, particularly concerning the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and justification of the method\"s effectiveness. By addressing this point, the authors can strengthen their paper and provide a more comprehensive understanding of their approach. However, the comment could be more helpful if it offered specific suggestions or examples of how to enhance the explanation. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning several types of methods that should be discussed. It also suggests positioning SSMs appropriately within this context. The comment provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what is lacking in the section, specifically suggesting the inclusion of a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail provides clear direction for the authors on how to improve the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details, specifically regarding longcontext language models. It suggests that the authors should provide a more comprehensive overview of existing methods and their limitations, including specific types of methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment provides a clear and detailed list of what is missing, which is a specific and actionable suggestion. However, it does not include references or examples to support the claim that these methods are not adequately discussed, which would make the claim more verifiable. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks specific references to substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the Related Work section, which is deemed lacking in details. It provides a clear and actionable suggestion by specifying the types of methods that should be discussed, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and depth of their Related Work section, particularly in the context of longcontext language models. However, the comment could be more helpful if it included examples or references to illustrate the specific limitations or gaps in the current discussion. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training of LLMs on trillions of tokens, implying that the dataset is insufficient. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size or diversity, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training of LLMs on trillions of tokens, implying that the dataset is insufficient. However, the comment does not specify which part of the paper discusses the dataset or training data, making it weakly grounded. The comment is specific in detailing the concern about the dataset size and its implications, but without explicit references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training of LLMs on trillions of tokens, suggesting that the dataset is insufficient. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is based on a general comparison, which makes the claim 3. The authors would need to consider the context and evidence to fully understand the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training of LLMs on trillions of tokens, suggesting that the dataset may be insufficient. This feedback is 3 as it highlights a potential limitation in the dataset, prompting the authors to consider whether their dataset is adequate for their purposes. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional data sources or methods to enhance the dataset. Therefore, while it identifies a relevant concern, it could be more helpful with additional actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the baseline metric but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. While it identifies a potential issue with the baseline, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their baseline metrics. The comment lacks actionable feedback, leaving the authors with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or expand their method to include other types of features. The comment implies that the authors should consider the broader applicability of their method, but it lacks concrete steps or recommendations for how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the limitation of the work and suggests that the method should be tested with a mix of feature types. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. This is a subjective opinion that suggests a limitation in the current approach. However, the comment does not provide specific examples, references, or detailed reasoning to support why the method should be applicable to other types of features. The lack of supporting evidence or detailed justification makes the claim 3, as it requires the authors to infer the potential applicability based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the work by noting that it only uses binary features, whereas realworld data often includes a mix of binary, real, and categorical features. This observation highlights a potential gap in the applicability of the method, suggesting that the authors should consider whether their approach can be extended to handle other types of features. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore the applicability to real and categorical features. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing need improvement or which points are unclear. The comment lacks explicit or implicit actions that the authors can take to address the issue. Without detailed feedback, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not mention a specific section or part of the paper and does not provide detailed feedback on what needs to be clarified or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"The writing should be improved\" and mentions that \"some points in the paper are unclear.\" However, it does not provide any specific examples or details about what aspects of the writing are unclear or how they could be improved. Without supporting evidence or examples, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it lacks specificity and does not provide any detailed guidance or examples of what aspects of the writing need improvement or which points are unclear. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issues identified. This makes the comment 2, as it identifies a general area for improvement but does not provide sufficient guidance for the authors to make meaningful changes to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors use other metrics, specifically BERTScore, to evaluate the results. This is an explicit action with a concrete suggestion, as it provides a specific alternative metric that the authors can use. The comment is clear and direct, leaving no ambiguity about what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify where to implement the change. Additionally, while the suggestion is specific in recommending an alternative metric, it lacks detail on why BERTScore might be more appropriate or how it would improve the evaluation. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning or justification for why BERTScore would be a better choice or how it would improve the evaluation. Without supporting evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests using alternative metrics, such as BERTScore, to evaluate the results. While this provides a specific suggestion for improvement, it lacks depth and does not explain why BERTScore might be a better choice or how it would enhance the evaluation. The comment does not offer any additional context or guidance on how to implement this suggestion or what specific aspects of the evaluation could be improved. As a result, the feedback is 3, as it identifies a potential area for improvement but does not provide comprehensive guidance for the authors to act upon. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench for language generation. It implies that the authors should provide a clearer understanding of when to use SynTextBench over other metrics. While the comment explicitly suggests a comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to make a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and \"the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of SynTextBench with other metrics proposed in the literature, such as MMLU or Big Bench for language generation. The comment provides a clear direction for improvement by suggesting a comparison and highlighting the need for clarity on when to use SynTextBench over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench for language generation. The reviewer acknowledges that some metrics may not satisfy the proposed desiderata but emphasizes the importance of comparing SynTextBench with existing metrics. This claim is 3 as it provides a logical reasoning for the comparison, but it lacks specific examples or references to support the claim. The authors would need to conduct their own research to fully understand the comparison, making the comment 4.", "helpfulness_rationale": "The review comment suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU or Big Bench for language generation. It highlights the importance of understanding under what conditions SynTextBench should be used over other metrics. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing a gap in the evaluation of their metric. However, the comment could be more helpful if it offered examples or specific guidance on how to conduct this comparison. Overall, the comment is 4, as it directs the authors to a meaningful area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the algorithm for constructing coreset is not novel, as it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of novelty or suggestions for improving the originality of the work. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the algorithm for constructing coreset, specifically mentioning that it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper discusses this algorithm, making it weakly grounded. The comment is specific in detailing the lack of novelty, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the algorithm for constructing coreset is not novel, as it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This claim is 3, as it provides a logical reasoning that the novelty lies in the extension of existing frameworks rather than the algorithm itself. However, the comment lacks specific references or examples to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a lack of novelty in the algorithm for constructing coreset, noting that it extends existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. While this feedback identifies a potential weakness in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the originality of their work. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that the writing and annotations are \"a little hard to follow,\" but it does not provide any specific guidance or suggestions on how to improve the clarity or readability of the text. There is no explicit or implicit action for the authors to take, such as revising certain sections or providing additional explanations. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which part of the paper is affected by these issues. The authors cannot confidently determine whether it refers to the introduction, methodology, results, or discussion sections. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are problematic, such as unclear sentences, missing explanations, or inadequate labeling. Without clear guidance on where to focus improvements, the comment is 1 and highly unspecific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that \"poor writing and annotations are a little hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or examples of where the writing or annotations are unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing and annotations being \"a little hard to follow,\" which is a common problem in academic papers. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or readability of their work. Without detailed guidance or examples of what needs to be addressed, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential issue but does not offer any actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under the \"Twitter2017 \u2192 Twitter2015\" setting. While the comment highlights areas of concern, it does not provide explicit instructions or suggestions for the authors to address these issues. The authors are left to infer that they should investigate and clarify these discrepancies, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for further investigation but does not provide detailed steps for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed method\"s performance, noting that only 8 out of 14 evaluation metrics achieve stateoftheart performances. Additionally, it raises a question about the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the performance of the proposed method in Table 2, specifically noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. While the comment highlights areas of concern, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the critique, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the performance of the proposed method in Table 2, noting that only 8 out of 14 evaluation metrics achieve stateoftheart (SOTA) performances. It also questions the discrepancy in the overall F1 score versus the F1 score for single types under a specific setting. This feedback is 3 as it identifies a potential issue with the method\"s performance and prompts the authors to investigate and clarify these discrepancies. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their approach, but it lacks concrete details on what changes should be made or how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its questioning of the methodology, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the decision to only consider ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, the comment does not provide any supporting evidence, reasoning, or references to justify why including all reports would be easier or more beneficial. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the methodology used in the paper, specifically why only ECG segments with one label are considered. It suggests that including all reports might be more beneficial, implying that the current approach might be limiting. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or why including all reports would be beneficial. Without actionable advice or further explanation, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on what specific aspects of the solution need to be addressed or how the authors might enhance their work. Without actionable feedback, the authors are left without a clear understanding of what changes to make to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this incremental step is discussed in, nor does it provide any specific feedback or suggestions for improvement. The authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity regarding what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any further explanation, evidence, or reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step based on the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or critique, the authors are left without a clear understanding of how to enhance their work. The comment is vague and does not offer any meaningful insights or directions for improvement, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements or computational complexity. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a more detailed discussion on scalability, but without specific suggestions on what aspects to focus on or how to present this information, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Limited Discussion of Scalability Bounds,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of thorough exploration of the upper limits of FedDES\"s scalability, including no clear discussion of memory requirements or computational complexity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements or computational complexity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the limited discussion on scalability bounds. It highlights the lack of thorough exploration of the upper limits of FedDES\"s scalability and the absence of clear discussions on memory requirements or computational complexity. This feedback is clear and actionable, as it directs the authors to expand their discussion on scalability, which is an important aspect of evaluating the practicality and applicability of their method. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to consider. Overall, the comment is 4 as it points out a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This implies that the authors should increase the complexity of their instances to better test the capabilities of LLMs. However, the comment does not provide specific guidance on how to achieve this or what specific constraints or variables should be added. While the action is implicit, it is somewhat concrete in suggesting a direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This implies a concern about the ability of LLMs to model problems with large instance sizes. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in suggesting the need for more complex instances, but without clear grounding, the authors may struggle to identify the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This claim is based on the observation that few instances in the paper have more than 7 variables, which raises a concern about the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that instances with more variables are necessary for testing LLMs\" capabilities. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is considered 2, as it provides some justification but requires more detailed support.", "helpfulness_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the current instances have fewer than 8 variables. This feedback is 3 as it identifies a potential limitation in the experimental setup and suggests a way to improve it. However, the comment lacks specific guidance on how to increase the complexity of instances or what specific variables or constraints should be added. Additionally, it does not provide a clear rationale for why this is important or how it would impact the results. While the suggestion is actionable, it could be more helpful with additional context or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several improvements to the results presentation, including labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and adding a scatter plot with x/y axes representing runtime and performance. It also recommends highlighting the best results in tables. While the comment provides explicit actions, it lacks detailed guidance on how to implement these suggestions, such as specific instructions on how to label the yaxis or create the scatter plot. The feedback is 4, as it gives the authors a clear direction but requires more detailed instructions for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the yaxis labeling and suggests improvements, such as using a scatter plot with x/y axes representing runtime and performance. Additionally, it recommends highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the results presentation can be improved by labeling the yaxis in Figures 2 and 3 as \"runtime\" instead of \"performance,\" and by adding a scatter plot with x/y axes representing runtime and performance. It also recommends highlighting the best results in tables. While the comment provides specific suggestions for improvement, it lacks detailed reasoning or examples to fully substantiate the claim that these changes would enhance the clarity and effectiveness of the results presentation. Therefore, the comment is 3, as it provides a clear direction for improvement but could benefit from more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the presentation of results. It identifies issues with the labeling of the yaxis in Figures 2 and 3, suggesting that \"performance\" is ambiguous and recommending that \"runtime\" be used instead. Additionally, it suggests creating a scatter plot with x/y axes representing runtime and performance to enhance understanding and interpretation. The comment also recommends highlighting the best results in tables. This feedback is clear and provides concrete suggestions for enhancing the clarity and effectiveness of the results presentation, making it 5 for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It asks whether this means the base node affects the ordering, key nodes for attention, and ultimately the model performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what specific aspects of the paper need clarification or improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"NodeSort\" and \"base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node, asking whether this affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It does not contain a claim or opinion that requires verification. It is a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It seeks clarification on whether this affects the ordering, key nodes for attention, and ultimately the model performance. While the comment identifies a potential area of confusion, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the implications in their paper. The lack of actionable feedback limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i), implying that the current direction might not align with this purpose. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the direction of the arrow. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the purpose of the arrow and its direction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in Figure 2 and suggests that it should be from the latent space to n^(i) instead of from a Gaussian space. This provides clear guidance on what needs to be clarified or corrected in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of an arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space. This is a logical observation that challenges the current representation in the figure. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this change is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of an arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is 3 as it prompts the authors to clarify the purpose and direction of the arrow, which could be important for understanding the figure and its implications. However, the comment lacks depth and does not provide suggestions on how to address the issue or improve the clarity of the figure. To be more helpful, the comment could include additional guidance or context. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the use of abbreviations in the paper, noting that many lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to avoid confusion. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of abbreviations lacking definition, providing a concrete example with \"AR\" in Table 5. This feedback is clear and actionable, guiding the authors on what needs to be addressed to improve the clarity of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, providing a specific example with \"AR\" in Table 5. This claim is verifiable as it is supported by a concrete example, which helps the authors understand the issue and take action to address it. The mention of \"domain adaptation tasks and algorithms\" provides a clear context for the abbreviation, making the claim 4. However, the comment could be strengthened by suggesting how the authors might define these abbreviations or provide a list of undefined abbreviations. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to improve clarity. By addressing this issue, the authors can enhance the readability and understanding of their work for readers. The comment is 4 as it provides a direct and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not provide any explicit guidance or suggestions on what these considerations might be or how the authors should address this issue. The action is implicit and vague, leaving the authors without a clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the technical considerations but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"advantage\" is more common in practice or what specific technical considerations might be involved. This lack of supporting information makes the claim difficult for the authors to address or understand, rendering it 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. While it identifies a potential area of interest, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might address this issue or explore the technical considerations. The feedback is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the setting of Unsupervised Online Adaptation, suggesting that it is \"a little bit strange\" because the model requires a training set with documents, queries, and labels, which implies the need for annotations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the setting. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the setting of Unsupervised Online Adaptation, pointing out that the model requires a training set with documents, queries, and labels, which seems to contradict the \"unsupervised\" nature of the adaptation process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the setting of Unsupervised Online Adaptation, suggesting that it is \"a little bit strange\" because the model requires a training set with documents, queries, and labels, which implies the need for annotations. This claim is 3 as it highlights a potential contradiction in the terminology used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the terminology used for the \"Unsupervised Online Adaptation\" setting. It points out that the model requires a training set with documents, queries, and labels, which seems to contradict the \"unsupervised\" nature of the adaptation process. This feedback is 3 as it highlights a specific area of confusion or potential mislabeling in the paper. However, it lacks depth and does not provide suggestions on how to address this issue or clarify the terminology. The authors are left with a general understanding of the problem but without actionable guidance on how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the performance comparison in Table 1, specifically that VINS sets different sample weights, while most compared baselines set all sample weights as 1. This implies that the comparison may not be fair due to the different sample weights. However, the comment does not provide explicit guidance on how to address this issue or suggest a way to make the comparison fair. The action is implicit and somewhat vague, as the authors need to infer that they should either adjust the sample weights for the compared baselines or clarify the methodology used for the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance comparison, specifically highlighting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed to ensure a fair comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights, while most compared baselines set all sample weights as 1. This claim is 3 as it highlights a potential issue with the comparison methodology. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining how the different sample weights might affect the outcome or suggesting alternative methods for a fair comparison. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance comparison in Table 1, specifically that VINS sets different sample weights while most compared baselines set all sample weights as 1. This observation highlights a potential unfairness in the comparison, which could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how to address this issue or ensure a fair comparison. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider this aspect but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the reply buffer being too large, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize the buffer size or proposing alternative methods to reduce complexity. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"reply buffer\" and references a specific paper, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning,\" which provides some grounding by indicating the context of the issue. However, it does not specify which part of the paper discusses the reply buffer or how the time complexity issue is addressed. The authors can infer that it relates to the methodology or results section, but the comment lacks full grounding. The comment is specific in identifying the potential issue with the time complexity of a large reply buffer, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning.\" However, the comment does not provide detailed reasoning or examples to support why this would be the case, nor does it explain how the referenced paper relates to the issue. This lack of detailed justification makes the claim 3, as the authors would need to delve deeper into the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could lead to high computational costs. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as proposing methods to optimize the buffer size or suggesting alternative approaches to reduce complexity. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines or perspectives should be included or how to implement these suggestions. The action is explicit but lacks concrete details, making it 3. The authors know they need to involve other baselines, but they may not be entirely sure how to execute this suggestion effectively.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. It provides specific examples of these perspectives, such as \"optimizing the discretization schedule or by modifying the original SGM formulation.\" However, the comment does not explicitly mention which part of the paper this suggestion should be applied to, making it weakly grounded. The authors can infer that it relates to the experimental or results section, but this inference is not direct. The comment is specific in detailing what needs to be addressed, so it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. It provides a list of references ([16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45]) that could be used to support this suggestion. However, the comment does not explain why these references are relevant or how they relate to the suggestion, making it 3. The authors would need to infer the relevance of these references themselves, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. It provides specific examples of these perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is clear and actionable, as it offers concrete suggestions for enhancing the paper by providing a more comprehensive comparison. However, the comment could be more helpful if it included a rationale for why these additional baselines are important or how they would contribute to the paper\"s impact. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a brief conclusion and a summary of the paper\"s contributions. This is a clear and direct action that the authors can take to improve their draft. The comment specifies exactly what needs to be added, providing concrete guidance on how to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions are needed. However, it does not specify which part of the paper this should be included in, such as the abstract, introduction, or conclusion sections. Without explicit references to these sections, the authors may find it challenging to determine where to make these additions. The comment is specific in its request for a conclusion and summary but lacks grounding due to the absence of specific references. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions are necessary. However, it does not provide any reasoning, examples, or references to support why these elements are missing or why they are important. Without additional context or justification, the authors may find it challenging to understand the significance of this feedback or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a clear need for a brief conclusion and a summary of the paper\"s contributions. This feedback is actionable and provides a specific direction for the authors to enhance their draft. By addressing this point, the authors can better conclude their work and highlight its significance, which is crucial for readers and reviewers. However, the comment could be more helpful if it offered suggestions on how to structure the conclusion or what aspects to emphasize in the summary. Overall, the comment is 4 as it directs the authors toward a necessary improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is explained in relation to the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or explain the relationship between the data distribution and the network model, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is explained in relation to the network model. This provides full grounding as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of explaining the data distribution in relation to the network model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation of the data distribution illustrated in Figure 1 in relation to the network model, particularly in a nonseparable case. However, it does not provide any specific reasoning, examples, or references to support the claim that the data distribution is inseparable from the network model. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is explained in relation to the network model. This feedback highlights a specific area where the authors may need to provide more clarity or justification for their experimental setup. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential weakness, it lacks actionable advice, making it 3. The authors are given some insight into a potential area for improvement but are left without detailed guidance on how to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not fully demonstrate the framework\"s capabilities. While the comment implies that the authors should conduct this additional comparison, it does not provide specific guidance on how to identify or implement this comparison. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not know exactly how to execute the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the current comparison with APEGAN may not fully demonstrate the framework\"s capabilities. However, it does not specify which part of the paper this suggestion should be addressed in, such as the results section or the discussion. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting a comparison with a method defending against multiple attacks, but it lacks full grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not fully demonstrate the framework\"s capabilities. The comment provides a logical reasoning for the suggestion, implying that such a comparison would enhance the meaningfulness of the results. However, it lacks specific references or examples of methods that defend against multiple attacks, which would strengthen the claim. Therefore, the comment is 3, as it provides a rationale but requires additional evidence or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not fully demonstrate the framework\"s capabilities. This feedback is clear and actionable, providing a specific direction for the authors to enhance the comprehensiveness of their study. By suggesting this additional comparison, the comment offers a valuable opportunity for the authors to strengthen their results and make them more meaningful. However, the comment could be more helpful if it included specific examples or references to methods that defend against multiple attacks, which would further guide the authors in implementing this suggestion. Overall, the comment is 4 as it provides a clear and actionable direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should clarify or justify their approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the presentation of results. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the reasoning behind their results presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and \"safety violations of the agent in the first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the presentation of results, specifically the disregard for safety violations, and questions the reason for this presentation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted manner and questions the reason for disregarding safety violations in the first 1000 episodes. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of supporting evidence or detailed explanation renders the claim 3, as the authors would need to infer the specific issues and make efforts to clarify the presentation of results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations in the first 1000 episodes. It questions the reason for this presentation, which is unclear. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and prompts the authors to clarify their approach. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to present the results in a clearer manner. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define the bounds for \tau_i^l at line 111, emphasizing its importance for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5. The authors know exactly what to do to enhance their paper, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: defining the bounds for \tau_i^l to understand the timewarp function. This provides clear guidance on what the authors need to revise. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the bounds for \tau_i^l to better understand the timewarp function. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, requesting that the authors define the bounds for \tau_i^l at line 111. This feedback is actionable and provides a direct suggestion for improving the clarity and comprehensibility of the paper, particularly in understanding the timewarp function. By addressing this request, the authors can enhance the readability and transparency of their work. However, the comment could be more helpful if it provided additional context or explained why defining these bounds is important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not provide explicit instructions on how to correct these errors or suggest specific actions for the authors to take. The comment implies that the authors should review their manuscript for such errors and correct them, but it lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies specific writing errors on pages 5 and 1, providing full grounding as the authors can accurately pinpoint these sections. It specifies the issues, such as \"informative informative\" and the lack of a title for \"performance,\" which are clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are writing errors in the paper, specifically mentioning \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any further explanation or justification for these claims, such as examples of how these errors affect the paper\"s clarity or impact. Without additional context or evidence, the authors may find it challenging to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it directs the authors to review their manuscript for such errors and correct them. However, the comment could be more helpful if it provided suggestions on how to improve the writing or offered examples of better phrasing. Despite this, the comment is 4 as it highlights a specific area for improvement, allowing the authors to make targeted revisions. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion regarding Theorem 4.1. The first part points out a limitation related to the standard sigmoid function and its dependence on the maximum slope. While it highlights an issue, it does not provide explicit guidance on how to address it. The second part suggests elaborating on why Theorem 4.1 holds, particularly in the context of the RNN and URNN convergence to the nearest fixed point. This suggestion is more explicit, as it provides a clear action for the authors to take. However, the comment could be more actionable if it included specific details on what aspects of Theorem 4.1 need elaboration. Overall, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the elaboration of why the statement on line 134 holds, particularly in the context of the RNN and URNN convergence to the nearest fixed point. This provides clear guidance on what the authors need to revise. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a comment about a statement on line 134 and a suggestion regarding Theorem 4.1. The first part points out a limitation related to the standard sigmoid function, but it does not provide specific reasoning or evidence to support the claim. The second part suggests elaborating on why Theorem 4.1 holds, but it lacks detailed justification or references. The comment is 3 as it provides some context but lacks sufficient evidence or detailed reasoning to fully substantiate the claims. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it addresses a statement on line 134, pointing out that it is only true for the standard sigmoid function and depends on the maximum slope. This feedback is 3 as it highlights a potential limitation in the statement, but it does not offer specific guidance on how to address this issue. Second, the comment suggests elaborating on Theorem 4.1, particularly in the context of the RNN and URNN convergence to the nearest fixed point. This suggestion is more actionable, as it provides a clear direction for the authors to enhance their explanation. However, the comment could be more helpful if it included specific examples or further details on what aspects of Theorem 4.1 need elaboration. Overall, the comment is 3, as it identifies areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the efficiency of the pairwise matching or suggestions for alternative approaches. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, suggesting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the efficiency are problematic or how they could be improved. Without clear guidance or references to specific sections or elements of the paper, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or data to demonstrate the inefficiency, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the efficiency of pairwise matching, suggesting that it may be too low for practical application. However, it does not provide any specific suggestions or guidance on how the authors might improve the efficiency or address this concern. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment does not provide specific guidance on how to improve the allocation or what aspects of the figure could be edited to make it more effective. The action is implicit and vague, leaving the authors without clear direction on how to address the issue. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1\" and suggests that its allocation is too naive, implying that the authors could have edited the space of the main paper more wisely. However, it does not specify what aspects of Figure 1 are problematic or how the allocation could be improved. The authors can infer that the comment relates to the figure, but it lacks specificity in terms of what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific details or examples to support this claim, such as explaining what aspects of the figure are problematic or how the allocation could be improved. Without these details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to improve the allocation or what aspects of the figure could be enhanced. Without actionable feedback or examples, the authors are left with a general idea of what might need improvement but without a clear path forward. Therefore, the comment is 2, as it identifies a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed with the suggested improvements. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the planbased method and its limitations, specifically mentioning the need for manual design of a plan based on ground truth and the difficulty in generalizing to new datasets without ground truth summaries. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the problem with the planbased method and its implications for generalizability, but without explicit references to sections or tables, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. The comment provides a logical reasoning by highlighting the impracticality of manual plan design and the lack of comparability with predefined plans. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the implications of this claim and potentially provide additional evidence or comparisons to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. This feedback highlights a critical issue with the generalizability of the proposed method, suggesting that it may struggle to adapt to new datasets without access to ground truth summaries. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. While it raises an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to rewrite the first sentence of the abstract. This is a direct and clear action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. The authors know exactly what action to take and how to implement it, as they are told to rewrite the first sentence of the abstract. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first sentence of the abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the rewriting of the first sentence of the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten, but it does not provide any reasoning or justification for this claim. There is no explanation of what is wrong with the current sentence or how it could be improved. Without supporting evidence or examples, the authors may find it challenging to understand the basis of the suggestion and make the necessary changes. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a clear and specific suggestion for improvement by instructing the authors to rewrite the first sentence of the abstract. This feedback is actionable and directly addresses a particular aspect of the paper that can be improved. However, the comment lacks further guidance or explanation on what specific issues with the current sentence need to be addressed or how the rewrite should be structured. While it offers a clear direction for improvement, it could be more helpful if it included additional details or examples to guide the authors. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment encourages the authors to perform this exercise, it does not provide specific guidance on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the details of the suggested experiment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the use of a single heldout test set in nearly all experiments. It suggests that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental methodology section. The suggestion is specific, as it provides a clear direction for improvement by recommending a standard practice in the field. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance, as is standard practice in most papers on Gaussian Processes (GPs). The reviewer acknowledges that the size of the datasets might make this process timeconsuming but encourages the authors to carry out this exercise. The comment is 4 as it provides a logical reasoning for the suggestion and references common practice in the field. However, it lacks specific examples or references to support the claim fully, making it 4. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup, noting that the results are reported for a single heldout test set. It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method\"s performance. While the comment acknowledges the potential timeconsuming nature of this exercise due to the size of the datasets, it encourages the authors to consider this approach. This feedback is clear and actionable, providing the authors with a specific suggestion for improving the robustness and comprehensiveness of their experimental results. However, it could be more helpful if it offered guidance on how to implement this suggestion or addressed potential challenges. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their experimental methodology."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method appears more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer that they should explore simplification but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method is more complex than it needs to be and implies the existence of a simpler underlying principle. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the method are overly complex or how the simpler principle could be identified. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might simplify the method. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method appears more complex than necessary and implies the existence of a simpler underlying principle. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without concrete evidence or examples of how the method could be simplified, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the method appears more complex than it needs to be, implying that there might be a simpler underlying principle driving the quality gains. While this observation identifies a potential area for simplification, it lacks specific guidance or suggestions on how the authors might achieve this simplification. The comment does not provide actionable steps or examples of how to identify or apply a simpler principle, leaving the authors with a general idea but no clear path forward. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that adding a method to improve transferability is a good approach but notes that it cannot be considered a significant contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or what specific aspects need to be addressed to make the addition more significant. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the addition of a method to improve transferability, suggesting it is a good approach but not a significant contribution. However, it does not specify which part of the paper this method is added to or how it relates to other methods. The authors can infer that it might be related to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in suggesting that the addition is not considered a significant contribution, but it does not provide detailed guidance on how to enhance the contribution. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that adding a method to improve transferability is good but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition is not considered significant. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the addition of a method to improve transferability as a good approach but questions its significance as a contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance the contribution or address the reviewer\"s concerns. Without actionable guidance or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the hGRU architecture appears adhoc and lacks motivation, but it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might address this issue or what specific aspects of the architecture need more motivation. Without actionable advice or concrete steps, the authors are left without a clear path for revision. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture, describing it as \"adhoc\" and lacking motivation. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or how it could be better motivated. This lack of grounding and specificity makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears \"adhoc\" and lacks motivation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what makes the architecture adhoc or how it could be improved, the claim remains 1. The authors are left without a clear understanding of what aspects of the architecture need improvement or how to address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the hGRU architecture, describing it as \"adhoc\" and lacking motivation. However, it does not provide any specific suggestions or guidance on how the authors might address these issues or improve the architecture. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes are needed to enhance their work. This lack of direction makes the comment unhelpful, as it does not offer any meaningful guidance for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment provides a reference to a GitHub repository, which could be useful for further exploration. While the comment identifies a potential issue and suggests a specific action (using \"s_n\" instead of \"s_t\"), it does not fully specify how to implement the change or provide detailed guidance on the asymptotic performance analysis. The action is 4, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of \"s_n\" instead of \"s_t\" and expresses curiosity about the asymptotic performance of the proposed method. Additionally, it requests average return results with more environment steps and provides a reference to a GitHub repository. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, and expresses curiosity about the asymptotic performance of the proposed method. It also requests average return results with more environment steps and provides a reference to a GitHub repository. While the comment raises valid points and questions, it lacks detailed reasoning or evidence to fully substantiate the claims. The reference to the GitHub repository is a starting point for further exploration but does not provide comprehensive support for the claims. Therefore, the comment is 3, as it provides a basis for inquiry but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment raises a specific question about the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which could be a critical error in the implementation. It also expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. Additionally, the comment provides a reference to a GitHub repository, which could be useful for further exploration. While the comment identifies a potential issue and suggests a specific action, it could be more helpful by providing a detailed explanation of why the use of \"s_n\" might be incorrect or how the asymptotic performance could be improved. However, the feedback is 4 as it directs the authors to a specific area of concern and offers a potential resource for further investigation. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of clarity and specify the challenges. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the analysis of Adam under the (L0,L1)smoothness condition, suggesting that the authors should clarify the challenges involved. It implies that the authors should explain the differences between their analysis and that of Zhang et al. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the explanation of challenges and differences. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition, suggesting that standard analysis could be applied directly. The comment implies that the authors should explain the challenges and differences with Zhang et al. However, it does not provide specific examples or references to support the claim that standard analysis is applicable or to clarify the differences with Zhang et al. This lack of detailed justification makes the claim 3, as the authors would need to infer the specific issues and differences based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the challenges of analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should clarify these challenges and explain the differences between their analysis and that of Zhang et al. This feedback is clear and actionable, as it directs the authors to address a particular gap in their explanation. However, the comment could be more helpful if it provided specific examples or further guidance on how to articulate these differences. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests toning down a specific statement regarding the neural network memorizing critical points, which is a clear and direct instruction. Second, it advises compressing the method section to focus on essential definitions, which is a concrete suggestion for improvement. Additionally, it instructs the authors to doublecheck grammatical errors, particularly those involving plurals and articles, providing a specific area of focus. These actions are explicit and provide concrete guidance, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"to force the neural network to memorize them\" and the reference to TopoNet [24], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests toning down a particular statement and provides a reason for this suggestion, relating it to the understanding of how neural networks function in TopoNet. Additionally, the comment points out minor issues with the method section, such as wordiness and grammatical errors, offering specific areas for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first claim about toning down the statement regarding the neural network memorizing critical points is 3, as it provides a rationale based on the understanding of TopoNet [24]. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compress the method section is a minor point and does not require verification. The final suggestion to doublecheck grammatical errors is factual and does not constitute a claim. Overall, the comment is 3 due to the lack of detailed evidence for the first claim, but it is mostly factual and descriptive, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides several points of feedback that are helpful for the authors. It suggests toning down a statement regarding the neural network memorizing critical points, which could be seen as overly assertive or inaccurate based on the understanding of TopoNet. This feedback is actionable and could help the authors refine their language. Additionally, the comment points out that the method section is wordy and could be compressed to focus on essential definitions, which is a clear suggestion for improvement. The reviewer also identifies grammatical errors, such as those involving plurals and articles, and suggests doublechecking these. While the comment could be more detailed in its suggestions, it offers valuable insights and actionable feedback that can help the authors improve their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point provides a general observation about the basis of person reID methods, mentioning that most are built on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the basis of person reID methods, mentioning that most are built on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how this information should be addressed in the paper. The authors cannot confidently determine which section of the paper this comment relates to, and it lacks specificity regarding what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a factual statement about the basis of person reID methods, mentioning that most are built on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. This statement is descriptive and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely informative and does not necessitate any justification or evidence beyond the statement itself. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review point provides a general observation about the basis of person reID methods, noting that most are built on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. While this information is factual and could be useful for the authors to consider in the context of their work, it does not offer any specific guidance or suggestions for improvement. The comment lacks depth and does not provide actionable feedback, leaving the authors without a clear understanding of how to address this information in their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests adding a first sentence to introduce Section 3.2, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be done, making it 5. The authors know exactly how to apply this feedback to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2, which is a factual statement and does not contain any subjective claims or opinions. It is purely descriptive and does not require verification or justification. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to improve the draft by recommending the addition of a first sentence to introduce Section 3.2. This feedback is specific and directly addresses a structural issue in the paper, guiding the authors on how to enhance the clarity and organization of their work. By suggesting a straightforward change, the comment is 5 as it offers a concrete step for the authors to take in improving their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the initial rationale selector being \"perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the initial rationale selector is \"perfect,\" suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"perfect\" in the context of the initial rationale selector, suggesting that if it were perfect, no additional work would be needed. This feedback identifies a potential ambiguity or confusion in the paper and prompts the authors to clarify their rationale. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it highlights a point that needs attention, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a clarification to improve the clarity of the paper. It explicitly states that the uncertainty is defined based on the posterior distribution and provides a detailed explanation of how the epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This feedback is clear and provides specific guidance on how to enhance the clarity of the paper. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of uncertainty based on the posterior distribution, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the paper by explaining how the epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This detailed guidance helps the authors understand what needs to be addressed to enhance the clarity of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a clarification regarding the definition of uncertainty based on the posterior distribution. It provides a detailed explanation of how the epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This explanation is logical and provides a clear rationale for the suggested clarification, making the claim 5. The reviewer offers a specific suggestion for improvement, which is wellsupported by the reasoning provided. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity of the paper. It identifies a specific area where the definition of uncertainty is based on the posterior distribution and offers a detailed explanation of how the epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This feedback is 5 as it guides the authors on how to enhance the clarity and precision of their work, allowing them to better communicate their concepts to readers. The comment is specific, detailed, and provides a clear path for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct questions. The first question is about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. This is an implicit action, as the authors are being asked to clarify their experimental approach. However, it is not explicitly stated, and the authors may need to infer that they should provide additional information on this aspect. The second question is about the number of questions created for the zeroshot intent classifier and its accuracy. This is also an implicit action, as the authors are being asked to provide specific details about their experimental setup. Both questions are somewhat vague, as they do not provide explicit instructions on how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the experimentation with domain ontologies to avoid placeholder generation and the details about the zeroshot intent classifier, such as the number of questions created and its accuracy. This provides clear guidance on what aspects of the paper require further clarification or elaboration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions seeking clarification about the experimental setup and results. The first question asks if the authors experimented with domain ontologies to avoid placeholder generation, and the second question inquires about the number of questions created for the zeroshot intent classifier and its accuracy. These are factual questions that require clarification and do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two distinct questions that could help the authors improve their draft. The first question seeks clarification on whether the authors experimented with the use of domain ontologies to avoid the generation of placeholders in the evaluated responses. This is a relevant inquiry that could provide insight into the robustness of the experimental setup. The second question asks for specific details about the zeroshot intent classifier, including the number of questions created and its accuracy. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the comprehensiveness and clarity of their results. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how similar experiments have been conducted in the field. Overall, the comment is 4, as it identifies areas for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing aspect in the paper, which is the lack of citations to set the work in the context of other MultiAgent Reinforcement Learning (MARL) research, specifically mentioning recent papers on selfplay and populationplay. The reviewer provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This feedback is clear and provides concrete guidance on how to improve the draft by including relevant citations. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the work in the context of other MARL work, specifically referencing recent papers on selfplay and populationplay. It provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail allows the authors to accurately identify the parts of the paper that need revision and understand what is missing. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks citations to set it in the context of other MARL work, specifically mentioning recent papers on selfplay and populationplay. The reviewer provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which supports the claim. This level of detail provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by explaining why these specific papers are relevant or how they relate to the work being discussed. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of citations to set the work in the context of other MultiAgent Reinforcement Learning (MARL) research. It provides examples of recent papers on selfplay and populationplay, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which could be relevant to the work. This feedback is clear and actionable, as it guides the authors on how to enhance the context and relevance of their paper by including these citations. However, the comment could be more helpful if it explained why these specific papers are relevant or how they relate to the work being discussed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify which specific methods should be compared or how the comparison should be conducted, leaving some room for interpretation. Despite this, the action is concrete in its suggestion to explore alternative selfsupervised learning methods. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods not based on contrastive learning. However, it does not specify which part of the paper this suggestion should be applied to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding which alternative methods should be considered or how the comparison should be conducted. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper would benefit from comparing its results with other selfsupervised learning methods not based on contrastive learning. However, the comment does not provide any specific examples or references to support this claim, nor does it explain why such a comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This is a clear and actionable suggestion that could help the authors broaden the scope of their study and provide a more comprehensive evaluation of their approach. By considering alternative methods, the authors can better understand the strengths and weaknesses of their work and potentially identify areas for improvement. However, the comment could be more helpful if it specified which specific methods should be considered or how the comparison should be conducted. Overall, the feedback is 4 as it provides a clear direction for enhancing the paper, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It requests clarification from the authors. While the comment does not explicitly instruct the authors to make changes, it implies that they should provide clarification on this point. The action is implicit and somewhat vague, as it does not specify exactly what clarification is needed or how it should be presented. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"abstention process,\" allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it questions the nature of the abstention process, specifically asking how it differs from a decision threshold used by models. The comment requests clarification, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It requests clarification from the authors, which is a clear and actionable step for them to take. By addressing this question, the authors can provide a more detailed explanation of their approach, potentially enhancing the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to differentiate the abstention process from a decision threshold. Overall, the comment is 4 as it directs the authors to clarify an important aspect of their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. It questions the claim of parameter efficiency for COCOLM and suggests that the conclusion could be applicable to other related works. Additionally, the comment poses two questions: one about the experimental setup regarding the switch from uncased to cased BPE vocabulary and another about the potential impact of this change on performance variance. While the comment raises valid points and questions, it does not provide explicit instructions or concrete actions for the authors to take. The questions are implicit and require the authors to infer the need for clarification or further explanation. Therefore, the comment is 3, as it provides guidance but lacks detailed instructions on how to address the issues.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and questions the claim of parameter efficiency for COCOLM. It suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This provides specific feedback on the comparison and the claim of parameter efficiency. However, the comment does not explicitly mention which part of the paper discusses the comparison with Megatron, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is \"a little overrated\" and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This claim is 3 as it provides a logical reasoning based on the similarity in performance and model sizes. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider this feedback and potentially provide more detailed comparisons to strengthen their argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa, which are of similar sizes. This feedback is 3 as it points out a potential issue with the claim of parameter efficiency for COCOLM. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative ways to present the comparison. Additionally, the comment poses questions about the experimental setup and the impact of switching BPE vocabulary types, which could be beneficial for the authors to clarify. Overall, the comment identifies a potential weakness but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer questions the reasoning behind the observation that this indicates GSP50 learns better representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this critique or improve their analysis. The action is implicit and vague, as the authors are left to infer what changes might be needed without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (128149) and references a figure (Fig 3), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, questioning the reasoning behind the observation that GSP50 learns better representations. The comment provides a clear critique of the analysis and suggests that the authors should explain why this observation supports the claim. Additionally, it references external works to support the critique, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, questioning the conclusion that GSP50 learns better representations. It provides a specific observation about the histogram in Fig 3, noting that GSP50 has a smaller class selectivity score, indicating it shares more features, while ResNet50 learns more classspecific features. The reviewer suggests that additional context may allow the network to reduce its dependency, but does not fully explain why this observation supports the claim that GSP50 learns better representations. While the comment references external works, it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment critiques the analysis from line 128 to 149, questioning its convincingness. It provides a specific observation about the histogram in Fig 3, noting that the GSP50 model has a smaller class selectivity score, which suggests it shares more features, while ResNet50 learns more classspecific features. The reviewer hypothesizes that additional context may allow the network to reduce its dependency, but challenges the reasoning behind the observation that this indicates GSP50 learns better representations. The comment references external works, such as SqueezeandExcitation Networks and Understanding the Effective Receptive Field in Deep Convolutional Neural Networks, to support the critique. However, it does not offer specific suggestions or guidance on how the authors might address this critique or improve their analysis. While the comment identifies a potential weakness in the analysis, it lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some conclusions in the paper are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It implies that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should explore more combination methods or consider the referenced works, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3, as it identifies an area for improvement but does not provide clear instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, allowing the authors to identify the exact parts of the paper being addressed. It also provides specific examples and references to recent works that have shown potential in featurereplay methods for continual learning, such as [R1], [R2], and [R3]. This level of detail helps the authors understand what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically questioning the claim that continuous learning with unlabeled data accumulates noise. The reviewer suggests that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claim. The references to [R1], [R2], and [R3] are mentioned but not elaborated upon, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3, as it provides some support but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions drawn in the paper, questioning their convincingness. It provides a detailed critique by suggesting that the results might be due to the limited exploration of combination methods. The reviewer also references recent works that have shown potential in featurereplay methods for continual learning, such as [R1], [R2], and [R3], which could be relevant to the authors\" work. This feedback is 4 as it points out a potential weakness in the paper and offers references that could guide the authors in improving their draft. However, it could be more helpful if it included specific suggestions on how the authors might address the issue or integrate the referenced works into their analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines despite mentioning various model criticism techniques. The reviewer suggests that the authors could compare with a chainofthought prompting approach. This feedback is explicit and provides a concrete suggestion for improvement, indicating that the authors should consider adding more robust baselines to their comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of meaningful baselines and suggests a particular approach, such as comparing with a chainofthought prompting method, to enhance the comparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests that the authors could compare with a chainofthought prompting approach. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to consider the suggestion and potentially conduct additional comparisons to strengthen their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that despite mentioning various model criticism techniques, the authors only compare with simple naive baselines. The reviewer suggests a specific alternative, such as comparing with a chainofthought prompting approach, which could provide a more robust evaluation. This feedback is clear and actionable, offering the authors a concrete suggestion for enhancing the validity and depth of their comparisons. By addressing this feedback, the authors can significantly improve the rigor and comprehensiveness of their study. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. While the comment implies that the authors should clarify their pretraining approach and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about their pretraining method and its generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or methodology description. Without explicit references or clear indications of where this information is discussed, the authors may find it challenging to identify the exact part of the paper being addressed. The comment is specific in its inquiry but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the pretraining of the cardiac signal representation learning model. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. This feedback is valuable as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address these concerns. Overall, the comment is 3 as it identifies a potential area for clarification, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential dependency or what specific aspects of the design might be affected. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects are hardware or software dependent. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, noting that some observations and design decisions might be hardware and software dependent. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples, the authors are left without a clear understanding of how to improve their draft. The comment highlights a potential concern but does not offer any constructive steps for resolution, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not provide explicit or implicit actions for the authors to take. The questions posed are more exploratory in nature, seeking clarification rather than directing the authors to make specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment does not provide specific details on what aspects of the ground truth or the ablation study are being questioned, further reducing its specificity. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions seeking clarification on the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and seeks information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. It prompts the authors to consider whether the small differences are noticeable or due to noise or randomness in the training process. However, the comment lacks specificity and does not provide actionable guidance or suggestions for how the authors might address these questions or improve their analysis. Without detailed feedback or recommendations, the authors may find it challenging to incorporate these insights into their draft. Therefore, the comment is 3, as it identifies areas for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that important experimental details are missing or relegated to the appendix, and the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback provides a clear and explicit action for the authors to take: they should include detailed explanations and interpretations of the experimental results, particularly for the PCA experiments mentioned. The comment is 5 as it specifies exactly what needs to be addressed and provides concrete guidance on how to improve the draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of missing explanations and interpretations for the PCA experiments in these figures. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the appendix, and that the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This claim is 3 as it highlights a specific issue with the presentation of experimental results, but it lacks detailed examples or references to support the claim fully. The authors would need to review their appendix and experimental sections to understand the extent of the issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the presentation of experimental details, noting that many important details are missing or relegated to the appendix. It specifically points out that the PCA experiments in Figures 3, 7, and 8 lack explanations or interpretations. This feedback is clear and actionable, as it directs the authors to include detailed explanations and interpretations of their experimental results, particularly for the mentioned figures. By addressing this feedback, the authors can enhance the clarity and comprehensiveness of their paper, making it more accessible to readers. However, the comment could be more helpful if it provided suggestions on how to present these details effectively. Overall, the comment is 4, as it effectively guides the authors toward improving the presentation of their experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of new evaluation metrics and the need for an indepth exploration of the experimental results. While it identifies these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they should propose new evaluation metrics and conduct a more detailed analysis of the experimental results. However, the comment lacks concrete details on what specific new metrics should be proposed or how the experimental results should be explored indepth. This makes the action implicit and somewhat vague, as the authors are not provided with clear steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the need for an indepth exploration of the experimental results. It mentions the experimental analysis section, providing some grounding by specifying the part of the paper being addressed. However, it does not specify which specific results need further exploration or why the current evaluation metrics are insufficient. This makes the comment weakly grounded, as the authors can infer the general area but not the exact parts needing attention. The comment is specific in identifying the need for new evaluation metrics and a deeper analysis of experimental results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons for the experimental results. While the comment identifies a potential issue with the lack of new evaluation metrics, it does not provide specific examples or references to support this claim. Additionally, the suggestion for a deeper analysis of the experimental results is vague and lacks detailed guidance. Therefore, the comment is 3, as it highlights an area for improvement but lacks sufficient evidence or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that no new evaluation metrics are proposed, and only existing metrics are linearly combined. This is a valid concern, as the lack of innovative evaluation metrics may limit the paper\"s contribution. Second, it suggests that the experimental analysis section lacks an indepth exploration of the reasons behind the experimental results. This feedback is actionable, as it prompts the authors to consider developing new evaluation metrics and to provide a more detailed analysis of their results. However, the comment could be more helpful if it offered specific suggestions on how to develop new evaluation metrics or what aspects of the experimental results should be explored further. Overall, the comment is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the notation \"K\" being used for both a known kernel function and the number of layers. However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit, as the authors need to infer that they should clarify or change the notation to avoid confusion. The comment lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L166 and L176) where the notation \"K\" is used for different purposes, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that \"K\" is used for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused by being used for both a known kernel function and the number of layers. This claim is supported by specific line references (L166 and L176), which provide evidence of the notation\"s misuse. The mention of specific lines allows the authors to verify the claim and understand the context of the notation\"s use. Therefore, the comment is 5, as it provides clear and direct evidence to support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K\" being used for both a known kernel function and the number of layers. This feedback is clear and actionable, as it directs the authors to clarify or change the notation to avoid confusion. By pointing out this inconsistency, the comment helps the authors improve the clarity and consistency of their notation, which is crucial for the reader\"s understanding. However, the comment could be more helpful if it suggested alternative notations or provided examples of how to resolve the issue. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the weak recovery problem studied is of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived limitation or improve the practical impact of the work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the weak recovery problem studied in the paper and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its critique of the theoretical interest and practical impact of the work, but it lacks detailed guidance on how to address these concerns. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion about the limited practical impact. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical impact of the AMP algorithm for nonGaussian problems, suggesting that the weak recovery problem studied may be of limited theoretical interest. However, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the practical utility of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\" statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison. However, it does not explicitly instruct the authors to make these clarifications or provide specific guidance on how to incorporate additional citations. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" statement about the problem being fairly reductionist and the reference to \"Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether selforganization will fail or succeed than previously appreciated.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition and suggests that the authors need to clarify their claim and provide more citations for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of connections to human cognition in the context of the paper, specifically the statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR. The reviewer challenges the authors\" claim by pointing out that the problem is described as fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that it would be surprising for a behavioral economist to ignore these aspects and requests more citation for comparison. While the comment provides some logical reasoning and references to the authors\" own statements, it lacks specific examples or detailed references to support the claim fully. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\" statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The reviewer points out that it would be surprising for a behavioral economist to ignore these aspects and suggests that the authors need to clarify their claim and provide more citations for comparison. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to address it. However, it could be more helpful if it provided specific suggestions on how to incorporate these aspects or offered examples of relevant literature. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an issue with the wording in the conclusion, specifically mentioning that it is \"overly exaggerated\" and \"flamboyant.\" The reviewer suggests that the word choice is too elaborate, providing a clear action for the authors to take: to revise the language in the conclusion to make it more modest and less flamboyant. This feedback is direct and provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the wording being \"overly exaggerated\" and suggests that the word choice is \"flamboyant\" in multiple places. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the conclusion, noting that it is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it directs the authors to revise the language to make it more modest and less elaborate. By pointing out this issue, the comment helps the authors refine their writing style and present their contributions in a more balanced manner. However, the comment could be more helpful if it provided specific suggestions or examples of alternative phrasing. Overall, the feedback is 4, as it guides the authors toward improving the clarity and tone of their conclusion."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, along with specific criteria for the experiments. The comment is 5 because it specifies exactly what needs to be done and how to implement the suggested action, leaving no ambiguity for the authors. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion should be implemented in, nor does it provide details on how to conduct these experiments or what specific aspects need to be addressed. The authors can infer that it relates to the experimental section, but the lack of explicit grounding and specificity makes it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is 3 as it provides a logical suggestion for improving the paper by comparing the proposed method with existing ones. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and offers a concrete way for the authors to enhance the comprehensiveness and rigor of their study. By suggesting a direct comparison with existing methods, the comment helps the authors to better evaluate the performance and efficiency of their proposed approach. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment implies that the authors should conduct such comparisons to prove the effectiveness of their proposed approach, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s biggest weakness is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification for why such comparisons are necessary or how they would impact the paper\"s effectiveness. Without this information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility. This is a critical observation that highlights an important gap in the paper\"s evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular baselines to include or suggesting ways to integrate them into the evaluation framework. While the comment points out a key area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests exploring other bit operations, which is a direct request for additional analysis. It also asks for more explanations regarding Fig. 5a, providing a clear action for the authors to enhance the clarity of their work. Additionally, it requests an explanation of how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, which are specific areas needing clarification. Finally, it suggests analyzing energy consumption as a reference did, offering a concrete suggestion for improvement. Each of these actions is explicit and provides clear guidance on what the authors need to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"11,\" \"Fig. 5 a,\" and \"aer format,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear requests for additional explanations and analysis, such as exploring other bit operations, clarifying the appearance of Fig. 5a, and explaining how the input is handled in the \"aer format.\" Additionally, it suggests analyzing energy consumption as a reference did, which provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, but it lacks specific evidence or detailed reasoning to support each claim. The comment suggests exploring other bit operations, questions the appearance of Fig. 5a, and asks for explanations regarding the handling of DVS input in the \"aer format.\" It also suggests analyzing energy consumption as a reference did, but without providing the reference or detailed justification. This makes the claims 3, as the authors would need to infer the basis of the suggestions and provide their own evidence to support them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the paper. It starts by expressing appreciation for the work on bit operations, suggesting that the authors explore other bit operations, which could enhance the depth of their analysis. The comment also questions the appearance of Fig. 5a, prompting the authors to provide more explanations, which could clarify any confusion or ambiguity in the figure. Additionally, it raises a question about how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, indicating areas where the authors might need to provide more detailed explanations. Finally, the comment suggests analyzing energy consumption as a reference did, which could strengthen the paper\"s solidity. Each of these points offers clear and actionable feedback that could significantly improve the draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific information should be included or how to present it. Therefore, the comment is 3, as it points out areas for clarification but does not fully direct the authors on how to improve their draft.", "grounding_specificity_rationale": "The comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. The comment is fully grounded as it explicitly mentions the need for clarification on the combination of embeddings and their input into the CSCM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be clarified, providing clear guidance on how to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It also requests clarification on how embeddings are combined and fed into the CSCM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, particularly in the context of differences in sequence lengths. It highlights the need for clarification on how embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations on this aspect of their methodology. By addressing this point, the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of how similar issues have been addressed in other works. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the approach by stating that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their work. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach by mentioning the introduction of multigranularity and multiscale to enhance model performance, which is a common approach in convolutional networks. It also discusses the use of algorithms from object detection and their limitations in MLMs. However, the comment does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. While the comment provides some specificity by detailing the critique of the approach, it does not specify what needs to be addressed or improved. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim 3, as it provides a general critique but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment critiques the novelty of the approach by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. This feedback highlights a potential weakness in the paper\"s contribution and provides some insight into the limitations of the approach. However, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies an area for improvement, the comment could be more helpful with additional details or constructive feedback. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples, which could impact generalization performance. The reviewer suggests conducting more experiments on different downstream tasks and across various domains to address these concerns. While the comment identifies specific areas for further experimentation, it does not provide explicit instructions on how to conduct these experiments or what specific metrics or analyses should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing and generalization performance. It suggests conducting more experiments on different downstream tasks and across various domains. However, the comment does not specify which part of the paper these concerns or suggestions relate to, making it difficult for the authors to pinpoint the exact sections that need revision. The authors can make an educated guess that it might relate to the experimental section, but the comment lacks full grounding. It is specific in detailing the concerns and suggestions for additional experiments, but the lack of explicit references to specific sections or parts of the paper limits its grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples. The reviewer suggests that this could lead to lower generalization performance and recommends conducting more experiments on different downstream tasks and across various domains. However, the comment does not provide specific evidence, examples, or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The reasoning is somewhat logical but lacks detailed justification or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples. It suggests that this could lead to lower generalization performance and recommends conducting more experiments on different downstream tasks and across various domains. While the comment identifies a potential issue and provides a direction for further experimentation, it lacks specific guidance on how to address the concerns or what specific experiments should be conducted. The feedback is 3 as it points out a potential weakness and encourages additional research, but it could be more actionable with detailed suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether fast SMP is less expressive than SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide guidance on how to address the question or what specific aspects of the discussion should be expanded upon. The authors cannot confidently determine which part of the paper this comment addresses, and it lacks specificity regarding what needs to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or justify the need for additional discussion. Without any context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded upon. The comment does not offer detailed suggestions or examples, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This comment implies that the authors should consider using different trainvaltest splits in their evaluation, but it does not explicitly instruct them to do so. While the action is clear, it is not explicitly stated, making it 3. The authors can infer the need to explore different splits, but the comment lacks specific guidance on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what needs to be changed or how to implement the suggested evaluation approach. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This claim is based on a logical reasoning that different splits can provide a more comprehensive evaluation of the methods\" robustness. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this suggestion and potentially conduct additional experiments to fully understand the impact of different splits on the robustness of their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that evaluating methods across different splits of trainvaltest would be more robust than relying solely on different initialisation seeds. This feedback is clear and provides a specific suggestion for improving the robustness of the results. However, it lacks further guidance on how to implement this suggestion, such as which specific splits to use or how to integrate this into the existing experimental setup. While the comment identifies a potential area for improvement, it could be more helpful with additional details or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on how to combine these bullets or what changes should be made to ensure clarity and coherence. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first two bullets about contributions\" at the end of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to combine these two bullets, which gives the authors a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any reasoning or justification for why this combination is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests combining the first two bullets about contributions at the end of the introduction. While this feedback identifies a potential improvement in the organization and clarity of the contributions section, it lacks depth and does not provide specific guidance on how to effectively combine these bullets or what benefits this change would bring. The comment is 3 as it points out a potential area for improvement, but it does not offer detailed suggestions or rationale to support the change. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or specify these aspects, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. Therefore, the comment is 1, as it does not identify a specific part of the paper, and it is also not specific, as it lacks detailed guidance on what needs to be clarified. This aligns with a score of 1.", "verifiability_rationale": "The review point claims that the types of situations or social norms discussed in the main paper are not clear, specifically mentioning physical and psychological safety. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, particularly mentioning physical and psychological safety. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify these aspects. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the paper\"s unique contribution to the neuroscience community but raises a question about its potential improvement over existing solutions. It suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. While the comment implies that the authors should refer to more recent trends in the vision community, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate these trends or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s unique contribution to the neuroscience community but raises a question about its potential improvement over existing solutions. It suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries, particularly for bottomup methods. The comment implies that the authors should refer to more recent trends in the vision community, but it does not specify which part of the paper this feedback pertains to. While the authors can infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in suggesting what needs to be addressed, but the lack of explicit references to specific sections makes it weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the paper\"s potential improvement over existing solutions and suggests that the authors need to demonstrate the algorithm\"s ability to correctly find closed contours and show stronger robustness against weak boundaries. The comment implies that this is particularly important for bottomup methods. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the current paper lacks in this regard. The lack of concrete evidence or detailed justification makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s unique contribution to the neuroscience community and its potential benefits. However, it raises a critical question about the paper\"s ability to improve over existing solutions, particularly in terms of finding closed contours and robustness against weak boundaries. The comment suggests that the authors need to demonstrate these capabilities, especially for bottomup methods, and implies that referring to recent trends in the vision community could be beneficial. While the comment identifies a key area for improvement, it lacks specific guidance or examples on how to address these issues, making it 3. The authors are given a direction to explore but need more detailed feedback to fully understand and implement the suggested improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly requests the inclusion of more baselines and domains to be tested, as well as stronger empirical results with different design choices. It also asks for stronger motivation for the current choices of weighting and learning density functions. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to implement these changes or which baselines and domains to consider. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for more baselines and domains to be tested, as well as stronger empirical results with different design choices. It also references the lack of motivation for the current choices of weighting and learning density functions. This provides clear guidance on what aspects of the paper need improvement, allowing the authors to accurately identify the parts that require revision. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks sufficient baselines and domains for comparison, and that the choices of weighting and learning density functions are not strongly motivated. The reviewer requests stronger empirical results with different design choices and more domains. While the comment highlights areas for improvement, it does not provide specific examples or references to support the claim that the current choices are inadequate. This makes the claim 3, as the authors would need to infer the specific issues and address them based on the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the need for more baselines to be compared and more domains to be tested. It also points out that the choices of weighting and the way of learning density functions are not strongly motivated, prompting the authors to provide stronger empirical results. While the comment highlights important aspects that could enhance the paper, it lacks specific suggestions or examples of additional baselines or domains that could be considered. Additionally, it does not provide detailed guidance on how to strengthen the motivation for the current choices. This limits the comment\"s usefulness, as it offers a general direction but lacks actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be clarified, leaving no ambiguity about the action required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB and 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the dashed lines in specific figures. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment is clear and specific, requesting that the authors define the dashed lines in figures 2AB and 4B. This feedback is actionable and provides a direct way for the authors to improve their draft by clarifying an aspect that may be unclear to readers. However, the comment could be more helpful if it provided additional context or explained why the definition of these dashed lines is important. Nonetheless, it is 4 as it guides the authors toward a specific improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results comparable or what specific changes could be made to enhance the significance of the proposed methods. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not specify which results or sections of the paper are being referred to, making it difficult for the authors to identify the exact parts that need attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, implying a lack of significance for the proposed methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing methods, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature. It notes that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. The feedback is implicit and vague, leaving the authors without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. However, the comment does not specify which part of the paper discusses these issues or where the authors could provide more insights. While the authors can infer that the discussion of novelty and contribution is relevant, the comment lacks full grounding as it does not explicitly mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. The reviewer provides some justification by mentioning the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim of limited novelty. While it highlights the modifications proposed, such as different penalty coefficients, it does not provide enough evidence or references to support the assertion that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. Therefore, the claim is 3, as it provides some basis for the critique but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also notes the proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment points out a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the novelty and depth of their contribution, but it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights ambiguity in Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies areas of ambiguity and potential issues, it does not provide explicit guidance on how to address these concerns or clarify the symbols. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the symbols and address the issues of redundancy and interference, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that some symbols are not explained clearly. Additionally, it raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the ambiguity of Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multisphere icosahedral discretization process. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific problems and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific weaknesses, but it lacks actionable advice or examples to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper, specifically the assumption that the spectrum of a kernel is subgaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this limitation or whether it should be explored further. The comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the limitation of the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, whose spectrum decays polynomially. However, the comment does not specify which part of the paper discusses these assumptions or limitations, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the implications for the results, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. The reviewer provides a logical explanation by contrasting the behavior of Gaussian and Matern kernels, which supports the claim. However, the comment could be strengthened by providing specific examples or references to Matern kernels to further substantiate the claim. Overall, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the assumption of a subgaussian spectrum for kernels is restrictive, as it excludes other popular classes like Matern kernels. This feedback is valuable as it highlights a potential gap in the study\"s scope and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided suggestions on how to address this limitation, such as exploring the implications of using Matern kernels or discussing potential extensions to include them. Despite this, the comment offers a clear direction for the authors to consider, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the pretraining method in the main paper, as it is a key factor in the performance gain. While the comment implies that the authors should provide a more detailed discussion on the unsupervised pretraining, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a more detailed discussion on the pretraining method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining and its importance compared to other modules. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. It also suggests that the main paper lacks a detailed discussion on this aspect, which is a problem. The reviewer further supports this claim by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or references to support the claim about the importance of unsupervised pretraining. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the unsupervised pretraining is a key factor in the performance gain, as indicated by the data in Table 4. However, it points out that there is no detailed discussion on this aspect in the main paper, which could be a problem. The reviewer further supports this by comparing the importance of unsupervised pretraining with other modules presented in the paper, as shown in Table 5. This feedback is clear and actionable, as it suggests that the authors should focus more on the pretraining method in the main paper. By highlighting this critical aspect, the comment provides valuable guidance for the authors to improve their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors can infer that they need to consider the gender detection model in their pipeline but are not given concrete instructions on how to integrate it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of gender detection, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. The comment suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. This claim is 3 as it provides a logical reasoning about the potential drawback of the current approach. However, it lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of ELM (male/female) and whether it requires prior knowledge of the speaker\"s gender. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. This feedback is 3 as it identifies a potential drawback in the current approach and provides a direction for improvement. However, it lacks specific suggestions or examples on how to integrate the gender detection model or address the issue, which would make the feedback more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide any specific guidance or examples on how to achieve this simplification. The action is implicit, as the authors can infer that they need to make their writing clearer, but it is vague because it lacks concrete details on how to simplify the writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and can be simplified. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This makes it difficult for the authors to identify the exact areas that need improvement. The comment lacks both grounding and specificity, as it does not provide any details or references to specific sections or elements of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests it can be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it can be simplified. However, it lacks specificity and does not provide any actionable guidance or examples on how to achieve this simplification. Without detailed feedback or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of their writing. This makes the comment 2, as it highlights a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to a reference [31]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived lack of technical substance or suggestions for enhancing the paper. Without actionable advice or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, it does not specify which part of the paper this claim is based on, such as a particular section or methodology. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the paper are considered incremental or lacking in substance, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived issues. The comment lacks depth and does not provide any constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several improvements, including providing intuition for the proof of Theorem 1, exploring how the invertible function $f^*$ depends on the fixed $P^*$, and determining which distributions $P^*$ make it easier to determine $f^*$. Additionally, it raises a practical question about how to choose the $P^*$ to fix. While the comment implies that these are areas for improvement, it does not explicitly instruct the authors to address them. The actions are inferred and somewhat vague, as the authors need to deduce the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific questions and suggestions regarding the proof of Theorem 1, such as the intuition behind it and the dependence of the invertible function $f^*$ on the fixed $P^*$. Additionally, it raises practical questions about determining which distributions $P^*$ make it easier to determine $f^*$ and how to choose $P^*$ in practice. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the proof of Theorem 1 and the invertible function $f^*$, which are based on logical reasoning and a desire for clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it 3. The authors would need to infer the potential issues and address them based on their understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should include an intuition of the proof of Theorem 1. It also raises questions about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions $P^*$ make it easier to determine $f^*$. Additionally, it asks for practical guidance on how to choose the $P^*$ to fix. These suggestions are clear and provide the authors with concrete areas to address, making the comment 5. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inconsistency in the use of variables in Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to resolve the inconsistency. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by questioning the inconsistency in the use of variables \"X\" and \"H^(1)\" in these equations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the use of variables in Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". This is a factual observation that does not express an opinion or make a subjective claim. It is a request for clarification, which is a normal statement and does not require verification. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inconsistency in the use of variables in Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1)\". While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this inconsistency or clarify the use of these variables. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\"s ability to capture these phenomena. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the empirical evidence or what specific aspects of the model should be tested. The action is implicit and somewhat vague, as the authors can infer that they need to provide empirical evidence but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for empirical evidence, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate its effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the model is not applicable in realworld scenarios. This lack of supporting evidence makes the claim 3, as the authors would need to infer the basis of the concern and address it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the proposed model to realworld diffusion processes. It acknowledges the interest and elegance of the problem but emphasizes the need for empirical evidence to demonstrate the model\"s effectiveness in capturing realworld diffusion phenomena. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide more evidence to strengthen their work. However, the comment could be more helpful if it offered suggestions on how to conduct the empirical evidence or what specific aspects of the model should be tested. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited scope of the method\"s testing, noting that it is only evaluated on two datasets. The comment suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. However, it does not provide specific guidance on which additional datasets to use or how to conduct the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to expand their dataset testing but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the limited scope of the method\"s testing, noting that it is only evaluated on two datasets. However, it does not specify which part of the paper this issue is addressed in, such as the results section or the discussion of experimental methodology. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment pertains to. The comment is specific in its request for additional dataset testing, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the method is only tested on two datasets, suggesting that the authors should test it on more datasets to better understand its performance. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method is only tested on two datasets. It suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. This feedback is 3 as it points out a potential area for improvement, but it lacks specificity and does not provide guidance on which additional datasets to use or how to conduct the evaluation. While it prompts the authors to expand their testing, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in Section 4.2 regarding the use of the question to learn an attention on the image feature. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests clarifying these points and raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback provides explicit actions for the authors to take, such as clarifying the description and addressing the potential numerical instability issue. The guidance is clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description and equation in this section, particularly the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description in Sec. 4.2 does not match the equation, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer suggests that the equation might be illconditioned and numerically unstable due to the multiplication of two sigmoid activations. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors might need to infer the exact nature of the problem and how it affects the equation. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description in Section 4.2, where the use of the question to learn an attention on the image feature is not clearly explained. It points out that the description does not match the equation provided, specifically noting the absence of the term \"r^q\" and the unclear meaning of \"\u03c3.\" The reviewer also raises a concern about the potential numerical instability of multiplying two sigmoid activations. This feedback is clear and actionable, as it provides specific guidance on what needs to be clarified and addressed in the paper. By highlighting these issues, the comment helps the authors improve the clarity and accuracy of their work, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the main contribution of combining attention with other linear mechanisms is not novel and that many alternatives exist, as noted in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in noting that the contribution is not novel and that many alternatives exist, as mentioned in the paper. This provides clear guidance on what the authors need to address, but without explicit references to sections or specific elements, the comment remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, noting that many alternatives exist. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as many alternatives exist. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance their contribution. Without actionable feedback or constructive advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This feedback is clear and direct, providing a concrete action for the authors to take. The suggestion is specific and actionable, as it outlines exactly what needs to be done to enhance the clarity and understanding of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method\" and \"each layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing a plot of how different weights of the model move, particularly focusing on the relative weight change after unlearning to see which layers are affected the most. This provides clear guidance on what additional information should be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot to illustrate how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This suggestion is based on a logical reasoning that providing such a plot would enhance the understanding of the model\"s behavior. However, the comment does not provide any specific examples or references to support the claim that this information is necessary or beneficial. Therefore, the claim is 3, as it lacks detailed justification or evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for enhancing the clarity and understanding of the paper. It recommends plotting the relative weight change after unlearning to see which layers are affected the most, which would help the authors better illustrate the impact of their method on different parts of the model. This feedback is clear and constructive, offering a concrete way for the authors to improve their draft by providing more detailed insights into the model\"s behavior. However, the comment could be more helpful if it explained why this information is crucial or how it would contribute to the overall understanding of the paper. Nonetheless, it is 4 as it provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or how they could enhance their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which section of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the perceived lack of novelty, particularly regarding the ENCODE part and the decomposition contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part. However, the comment does not provide any supporting evidence or detailed reasoning to substantiate this claim. Without specific examples or references to the decomposition part, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, specifically noting that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part. However, it does not provide any specific suggestions or guidance on how the authors might address this perceived lack of novelty or enhance their contribution. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify the domain of the inputs, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include information about the domain of the inputs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the domain of the inputs, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location where this information should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the domain of the inputs, suggesting that they are in the same sphere but not explicitly mentioned in the paper. This is a factual observation that does not contain a subjective claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While it identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. The comment lacks actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. While it implies that the authors should include a performance comparison, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a performance comparison but are not provided with specific guidance on how to do it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where the CLN is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its request for a performance comparison, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. However, it does not provide any supporting evidence, reasoning, or references to justify why a performance comparison is necessary or how it would impact the paper. The comment lacks specific details or examples, making it difficult for the authors to understand the basis of the request. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance comparison of the proposed CLN (region proposal generation algorithm) with existing work. While it identifies a potential area for improvement by suggesting a comparison, it lacks specificity and does not provide any guidance on how to conduct such a comparison or what aspects should be considered. The comment does not offer actionable advice or detailed suggestions for improvement, leaving the authors with a vague understanding of what is needed. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and clarity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues with the presentation: it is too equationdriven and the notation is convoluted, particularly in Chapter 3. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment explicitly suggests adding a figure, it does not provide specific guidance on how to improve the notation or reduce the equationdriven nature of the presentation. The action is explicit but somewhat vague, as the authors know they need to add a figure but may not be entirely sure how to address the notation issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3\" and \"section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the presentation being too equationdriven and the notation being convoluted, suggesting that an illustrative figure of the key concepts would be helpful. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. The suggestion to include an illustrative figure of the key concepts in Section 3 is provided to help clarify the content. However, the comment lacks specific examples or detailed reasoning to support the claim about the equationdriven nature and the convoluted notation. This makes it 3, as the authors would need to infer the exact issues and how to address them based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the presentation: it is too equationdriven and the notation, particularly in Chapter 3, is convoluted and hard to follow. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the content. By addressing these issues, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to simplify the notation or reduce the equationdriven nature of the presentation. Overall, the comment is 4, as it directs the authors toward a specific improvement that can enhance the quality of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the visual presentation of Figure 3, particularly the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide specific guidance on how to achieve this improvement, such as suggesting alternative formatting or design options. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to enhance the visual presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the visual presentation, specifically suggesting enhancements for better readability and aesthetic appeal, such as improving the subscripts. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be enhanced. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact issues and potential improvements based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of Figure 3, suggesting that the subscripts could be enhanced for better readability and aesthetic appeal. While the comment highlights a potential issue, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left with a general idea of what needs to be improved but without specific steps or examples to follow. This limits the comment\"s usefulness, as it does not provide actionable feedback that would significantly aid the authors in improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the differences between the two normalization methods. Without actionable suggestions or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Batch Normalization\" and \"Online Normalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. The comment raises a question about the difference between the two normalization methods, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the claim or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. It points out a potential confusion in the paper regarding the estimation of the real gradient distribution. However, the comment does not provide any specific suggestions or guidance on how the authors might clarify this issue or address the confusion. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, it does not provide any actionable advice on how the authors should address this issue or suggest ways to improve the formatting to meet the page limit. The comment lacks concrete guidance on how to revise the draft to comply with the formatting requirements. Therefore, the comment is 3, as it identifies a problem but does not offer specific steps for resolution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, including crammed equations and captions too close to figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the formatting issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, which is a violation of the 9page paper limit. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples of where the whitespace has been reduced or how it affects the page count. Without such details, the claim remains 1, as the authors may not be able to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in crammed equations and captions that are too close to the figures. This is a critical issue that could impact the readability and overall quality of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending ways to improve the layout or suggesting alternative formatting options. While it highlights a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the technical details and formulations in the paper are limited and that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion to clarify or expand on the novelty of the scheme or procedure. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations in the paper are limited and that the main novelty lies in the scheme or procedure. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are limited or how the novelty could be better highlighted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"technical details and formulations are limited\" and suggests that the main novelty lies in the scheme or procedure. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations presented in the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance the technical details or clarify the novelty. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this concept. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify the concept of local interactions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its questioning of the concept, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"local interactions\" in the paper, specifically asking whether it refers to interactions within a time window or within the same modality. This is a request for clarification rather than a claim or opinion, as it does not express a subjective judgment or suggestion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential area of confusion regarding the concept of \"local interactions\" in the paper. It raises a specific question about whether the term refers to interactions within a time window or within the same modality. This feedback is 3 as it prompts the authors to clarify this concept, which could improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as recommending specific examples or explanations to include. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The comment implies that the authors should reconsider their claims or provide additional analysis, but it lacks concrete steps or actionable advice. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in Table 3, questioning the claim of better results and suggesting that the proposed constrained method may actually yield lower validity and diversity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion of better results in the Molecule generation experiment is incorrect, suggesting that the proposed constrained method actually yields lower validity and diversity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. This feedback is 3 as it points out a potential issue with the paper\"s claims, prompting the authors to reconsider their results and potentially revise their conclusions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. To be more helpful, the comment could include recommendations for additional experiments, data analysis, or statistical methods to validate the claims. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the process of updating archetype positions after initialization, specifically asking for clarification on how the archetype positions are updated after being initialized with the FurthestSum procedure. While the comment does not provide explicit instructions, it implies that the authors should address this gap in their explanation. The action is implicit, as it requires the authors to infer that they need to provide additional information, and it is somewhat vague because it does not specify exactly how the authors should address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how archetype positions are updated after initialization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the process of updating archetype positions after initialization. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking additional information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the process of updating archetype positions after initialization, which is an important aspect of the algorithm. By asking for clarification on this point, the reviewer highlights a potential area of confusion that could impact the understanding and reproducibility of the results. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of how similar updates are handled in related work. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several areas that are missing from the empirical study and suggests that they should be included in the supplement or main text. It specifies the types of information that are missing, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. Additionally, it suggests mentioning the number of regions in the parcellation in the main text. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to implement the changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, the condition under which restingstate recordings were made, and a brief explanation of the harmonization technique. It also suggests mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that important information about the empirical study is missing, specifically regarding the recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also requests a brief explanation of the harmonization technique and the number of regions in the parcellation. While the comment identifies areas that could be improved, it does not provide specific examples or references to support the claim that this information is crucial or missing. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for MRI, preprocessing steps, and the condition under which restingstate recordings were made. It also suggests providing a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, as it specifies what information is lacking and how it could be included to enhance the clarity and comprehensiveness of the paper. By addressing these points, the authors can improve the transparency and detail of their study, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential risk in methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It suggests that crossdataset experiments could be a good way to test the generalization of such work, as the paper currently lacks. While the comment implies that the authors should conduct crossdataset experiments, it does not provide specific guidance on how to implement this suggestion or which datasets to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential risk of methods exploiting relationships between action units and the need for crossdataset experiments to test generalization. The comment provides a clear example of how the relationships can differ across datasets, such as the cooccurrence of AU1 and AU12 in Figure 1. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units may not generalize well across datasets due to differences in cooccurrence patterns. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and notes that this cooccurrence differs between datasets like SEMAINE and UNBC pain. The comment also references Figure 1, which illustrates the different cooccurrences of AU1 and AU12. This detailed explanation and reference to specific examples make the claim 4, as it provides a clear rationale for the concern about generalization. However, the comment could be strengthened by including more detailed references or examples from the literature to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can vary significantly across different datasets. It provides a specific example by mentioning AU6, which can occur in both pain and happiness expressions, and highlights the difference in cooccurrence patterns between datasets like SEMAINE and UNBC pain. The comment suggests that crossdataset experiments could be a good way to test the generalization of such work, which is a valuable and actionable piece of feedback. However, the comment could be more helpful if it offered guidance on how to conduct these experiments or which datasets to use. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for further research, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not specify what aspects of the environment should be described or how detailed the description should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting where the additional information could be included, but without explicit references to sections or figures, the authors may still find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks a detailed description of the Starcraft environment, implying that this is a necessary addition. However, the comment does not provide specific examples or reasoning to support why this description is crucial or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more detailed description of the Starcraft environment. While it implies that this information could be included in an appendix, it does not provide specific guidance on what aspects of the environment should be described or how this would enhance the paper. The comment lacks actionable details, leaving the authors with a general idea of what might be missing but without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a contradiction between the statement that overparametrization leads to overfitting and worse performance, and the observation that it is beneficial for supervised learning of deep neural networks in practice. The reviewer also mentions theoretical works that support the benefits of overparametrization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this contradiction or incorporate the theoretical works into their paper. The action is implicit and vague, as the authors are left to infer that they should clarify or reconcile the apparent contradiction, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 4748, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a contradiction between the statement about overparametrization leading to overfitting and the observation that it is beneficial for supervised learning of deep neural networks in practice. The comment further supports this observation by referencing theoretical works that show the benefits of overparametrization. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparametrization is beneficial for supervised learning of deep neural networks in practice, contradicting the statement that it leads to overfitting and worse performance. The reviewer supports this claim by referencing theoretical works that show the benefits of overparametrization, such as [1]. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed references to the theoretical works, which would further enhance the verifiability of the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of overparametrization on deep neural networks. It points out that the statement \"overparametrization invariably overfits the data and results in worse performance\" seems to contradict the observation that overparametrization is beneficial for supervised learning in practice. The reviewer supports this observation by referencing theoretical works that show the benefits of overparametrization. This feedback is helpful as it highlights a critical inconsistency in the paper and provides a reference to theoretical works that could help the authors clarify and address this issue. However, the comment could be more helpful if it offered specific suggestions on how to reconcile the contradiction or integrate the theoretical works into the paper. Overall, the comment is 4, as it provides valuable insights and references that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the timeconsuming nature of the shape model training, which is due to the pixellevel training and the independent training of the model on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or specific examples of existing work to compare with. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on processing efficiency and comparisons with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the shape model training, which is due to the pixellevel training and the independent training of the model on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, namely the description and comparison of processing efficiency with existing work. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its pixellevel training and independent training on all font images and characters. It also mentions the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment provides some rationale for the timeconsuming nature of the model, it lacks specific examples or references to existing work for comparison. This makes the claim 3, as the authors would need to conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the shape model training, which is due to its pixellevel training and independent training on all font images and characters. It also highlights the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. This feedback is 3 as it points out areas where the paper could be improved by providing more detailed information on processing efficiency and comparisons with existing work. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these issues. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the authors for combining existing techniques without innovation, specifically mentioning that the domain adaptation method used is old and simple. The reviewer suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. While the comment implies that the authors should explore alternative methods, it does not provide specific guidance on which methods to consider or how to integrate them into their framework. The action is implicit and somewhat vague, as the authors are left to infer the need for change but without detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing techniques and the use of an old and simple domain adaptation method, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of an outdated method and suggests that the authors consider using more effective domain adaptation methods proposed in recent years. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the authors combine existing techniques without innovation, specifically mentioning that the domain adaptation method used is old and simple. The reviewer suggests that the authors should consider using more effective domain adaptation methods proposed in recent years to improve performance. This claim is 3 as it provides a logical reasoning for the critique, noting the age of the method used and the existence of more recent and effective alternatives. However, the comment lacks specific references to these alternative methods, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that the authors have combined existing techniques without introducing any innovation. It points out that the domain adaptation method used is old and simple, suggesting that more effective methods proposed in recent years could be used to improve performance. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a potential solution. However, the comment could be more helpful if it offered examples of more effective domain adaptation methods or provided guidance on how to integrate them into the framework. Overall, the comment is 4, as it directs the authors to a critical area that could enhance the novelty and effectiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include a discussion on the prompt dataset creation and its source for the fewshot case. This is a clear and direct action for the authors to take, providing them with a specific area to focus on in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5. Therefore, the comment aligns with a score of 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation and its source for the fewshot case should be included. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a discussion on the prompt dataset, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be integrated. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation and its source for the fewshot case should be included. However, it does not provide any reasoning, evidence, or examples to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source for the fewshot case. This is a clear and actionable suggestion that can help improve the paper by providing additional context and information about the dataset used in the study. However, the comment could be more helpful if it offered specific guidance on what aspects of the dataset creation should be discussed or how this discussion could be integrated into the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of their work. Without actionable advice or concrete steps for improvement, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is causing this difficulty or provide any details about what aspects of the motivation are unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is \"very difficult to follow the motivation of this paper\" and labels it as an \"incremental engineering paper.\" However, the comment lacks any supporting evidence, reasoning, or examples to justify why the motivation is difficult to follow or why it is considered incremental. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the motivation of the paper is difficult to follow and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of their work. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, the comment is 1, as it lacks actionable insights or constructive suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study on the weighting method of the crossentropy loss. It provides a specific example from the paper where the authors mention that their method underperforms in a particular scenario, suggesting that weighting might have helped improve performance. This feedback is explicit and concrete, as it clearly instructs the authors to conduct an ablation study on the weighting method and provides a rationale for why it could be beneficial. The authors know exactly what action to take and how to apply it, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the weighting method of the crossentropy loss and references a specific scenario mentioned in the paper where the authors note that their method underperforms due to \"repetitive background sounds\" in the Atlantis game. This provides a clear direction for the authors to address, as it specifies the area of improvement and references a particular example from the paper. However, it does not explicitly mention which part of the paper this suggestion is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed, so it aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the weighting method of the crossentropy loss, providing a specific example from the paper where the authors mention underperformance in the Atlantis game due to \"repetitive background sounds.\" The reviewer implies that weighting might have helped remedy this issue, offering a logical reasoning for the suggestion. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to infer the potential benefits of the ablation study based on the provided context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which could provide valuable insights into the performance of the method. It references a specific scenario mentioned in the paper where the authors note that their method underperforms due to \"repetitive background sounds\" in the Atlantis game, suggesting that weighting might have helped remedy this issue. This feedback is clear and actionable, as it identifies a potential area for improvement and provides a rationale for why it could be beneficial. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for further investigation, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or incremental nature of the work, or how to enhance the dataset or benchmark. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it references another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the lack of novelty and incremental nature of the work, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature. It supports this claim by explaining that the paper addresses a specific problem of column operations in designing semantic parsers for TexttoSQL and that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template, which further substantiates the claim of lack of novelty. However, the comment could be strengthened by providing more detailed comparisons or references to specific works that have addressed similar problems, which would make the claim more 5. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional supporting evidence.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. This feedback is 3 as it points out a significant issue with the paper\"s originality and suggests that the authors should consider how their work contributes to the existing literature. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. To be more helpful, it could provide examples of how to improve the dataset or benchmark or suggest alternative approaches to increase the paper\"s originality. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be conducted on more than one game environment, implying that the authors should expand their experimental scope. However, the comment does not provide specific guidance on which additional game environments should be considered or how to conduct these experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be conducted on more than one game environment, implying that the current scope is limited. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or results. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify the exact area needing revision. Additionally, the comment lacks specificity regarding which additional game environments should be considered or how the experiments should be expanded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment lacks specific reasoning or evidence to support why additional game environments are needed or how this would improve the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point for improvement. However, the comment lacks specificity and does not provide guidance on which additional game environments should be considered or how the experiments should be expanded. This makes it 3, as it points out a potential area for improvement but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback is clear and provides a direct action for the authors to take, making it 5. The authors know exactly what they need to do to improve their draft, which is to provide examples to justify the importance of this contribution. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain the importance of removing certain assumptions, such as bounded variance and bounded gradients, by providing solid examples. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for examples to support the claim, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors need to explain the importance of removing certain assumptions, such as bounded variance and bounded gradients, by providing solid examples. However, the comment does not provide any reasoning or evidence to support why these assumptions are significant or how their removal contributes to the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification for their work. It points out the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that this should be supported by solid examples. This feedback is clear and actionable, as it directs the authors to enhance the clarity and justification of their contributions. However, the comment could be more helpful if it provided specific examples or guidance on how to present these examples. Overall, the comment is 4, as it guides the authors toward improving the depth and clarity of their explanation, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no suggestion for improvement, such as optimizing the implementation or discussing potential reasons for the slow performance and low accuracy. Without any guidance or direction, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the implementation, such as the time it takes to test an ImageNet picture and the accuracy achieved. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the implementation of ImageNet is slow and has low accuracy, citing specific times (\"1 day and 2.5 days\") and accuracy (\"around 70%\") for testing an ImageNet picture using AlexNet and ResNet18. This provides concrete evidence to support the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or references to similar works for a more comprehensive evaluation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details, such as the time it takes to test an ImageNet picture using AlexNet and ResNet18, and the accuracy achieved. This feedback is valuable as it highlights a critical aspect of the paper that needs attention and provides concrete data to support the claim. However, the comment could be more helpful if it offered suggestions on how to improve the implementation or address the low accuracy. Despite this, the comment is 4 as it directs the authors to a significant area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, including adding more sentences to explain the experimental setting for continual learning and providing explanations for the learning curves in Fig 3. It also asks specific questions about the correspondence between the learning curves and MPHATE, the impact of worse performance on structural collapse, and the accuracy number for the last task or average. These questions and requests for clarification are concrete and provide clear guidance on what the authors need to address in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as explaining the correspondence between the learning curves and MPHATE, and providing additional information about the experimental setting for continual learning. The comment is specific in its requests for clarification and additional details, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional information, such as explaining the experimental setting for continual learning and providing details about the learning curves in Fig 3. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting additional explanations and clarifications in the paper. It suggests adding more sentences to explain the experimental setting for continual learning, which is a clear and concrete action for the authors to take. Additionally, it asks for detailed explanations about the learning curves in Fig 3, including the correspondence between the learning curves and MPHATE, and questions the relationship between worse performance and structural collapse. These requests are specific and provide a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what the authors might include. Overall, the feedback is 4 as it guides the authors toward improving the clarity and comprehensiveness of their paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. While the comment implies that the authors should consider using labeled data for consistency training, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the potential benefit and the references provided, but it lacks direct action or detailed guidance on how to implement this suggestion. Therefore, the comment is 4, as it provides a clear direction for the authors to consider but does not specify the exact steps to take.", "grounding_specificity_rationale": "The comment raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this is not explicitly stated. The comment is specific in suggesting the use of labeled data and referencing relevant literature, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using labeled data for consistency training could be beneficial for graph anomaly detection tasks. It references two specific papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which provide a basis for the claim. However, the comment does not fully explain why labeled data would be beneficial or how it would improve the consistency training process. While the references offer some support, the lack of detailed reasoning or examples makes the claim 3. The authors would need to delve into the referenced papers to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a thoughtful question about the potential benefits of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, which is a valuable insight for the authors to consider. The comment references specific papers that could provide further guidance on this topic, offering a concrete direction for the authors to explore. However, the comment could be more helpful if it provided a clearer explanation of how labeled data might enhance consistency training or offered specific suggestions on how to incorporate this approach into the paper. Overall, the comment is 4 as it prompts the authors to consider an alternative approach and provides some direction for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. It implies that the current organization and content do not effectively convey the benefits of the method. However, it does not provide specific guidance on how to reorganize the experimental section or what changes should be made to improve it. The suggestion to include specific experimental suggestions is vague and lacks concrete details on what those suggestions should be. As a result, the authors are left with a general idea of what needs to be done but without clear instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. It implies that the current organization and content do not effectively convey the benefits of the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in suggesting that the experimental content should be reorganized to highlight the method\"s superiority, but it lacks detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental part needs to be reorganized and improved to better highlight the superiority of the method. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to include specific experimental suggestions is vague and lacks concrete evidence or references to substantiate the need for reorganization. Without additional context or examples, the claim remains 1, as it does not provide sufficient justification for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a need for improvement in the experimental section, suggesting that it should be reorganized to better highlight the superiority of the method. It provides a specific suggestion to include certain experimental content in the main text, which could help clarify the benefits of the method. However, the comment lacks detailed guidance on how to reorganize the experimental section or what specific content should be included. While it points out a potential area for improvement, it does not offer comprehensive or actionable advice, leaving the authors with a general direction but without specific steps to take. Therefore, the comment is 3, as it provides some insight but lacks depth and detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model\"s performance is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a suggestion for theoretical justifications. While the comment implies that the authors should provide additional data and theoretical support, it does not explicitly instruct them to do so. The action is somewhat vague, as it does not specify exactly how the authors should report the classification accuracy or what kind of theoretical justifications are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the classification network proposed by the authors, expressing doubt about its classification error compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a suggestion for theoretical justifications. However, the comment does not specify which part of the paper discusses the proposed network or where the classification accuracy should be reported. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting the need for additional data and theoretical justifications, but without explicit references to specific sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a suggestion for theoretical justifications. However, the comment lacks specific examples or references to support the claim that the proposed network may lose classification accuracy. The suggestion for reporting classification accuracy on ImageNet data is a logical step, but without additional evidence or reasoning, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data, which is a specific and actionable request for additional data. Additionally, the comment suggests providing theoretical justifications for the issue, which could help clarify the advantages of the new model. While the comment identifies a potential weakness and offers clear suggestions for improvement, it could be more helpful by providing more detailed guidance on what kind of theoretical justifications are needed. Overall, the comment is 4 as it directs the authors to address a specific concern and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing and testing predictions based on exhaustive lists of items available in memory, especially in the context of recognition lists being recalled based on items. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the argument about recognition lists being recalled based on items. However, it does not specify which part of the paper this argument is presented in, making it weakly grounded. The comment is specific in detailing the issue with the argument, particularly in the context of old vs. new judgments and the feasibility of implementing and testing predictions with simulations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of implementing and testing predictions based on exhaustive lists of items available in memory, particularly in the context of recognition lists being recalled based on items. The reviewer provides a logical explanation of why this approach might be challenging, noting that in common cases of recognition, new items comprise a list of all items available in memory minus those seen. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing and testing predictions based on exhaustive lists of items available in memory, particularly in the context of recognition lists being recalled based on items. It provides a logical explanation of why this approach might be challenging, noting that in common cases of recognition, new items comprise a list of all items available in memory minus those seen. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. While it identifies a potential weakness, it does not offer actionable feedback, making it 3. The authors gain some insight into a potential challenge but are left without detailed guidance on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar scale pretrained model as the proposed method. It highlights a potential issue with the experimental setup, suggesting that the proposed method without SSL performs inferior to most compared methods. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pretraining conditions for the compared methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness due to the pretraining stage and the potential difference in pretrained models used by the compared methods. The comment provides a clear critique of the experimental setup and suggests that the proposed method without SSL performs inferior to most compared methods. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to the pretraining stage of the proposed method. It questions whether the compared methods were initialized with the same or similar scale pretrained model, which could impact the fairness of the comparison. The comment provides a logical reasoning by pointing out the potential discrepancy in pretraining conditions, which could affect the results. However, it does not provide specific examples or references to support the claim fully. Therefore, the comment is 4, as it offers a clear rationale but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were pretrained with the same or similar scale as the proposed method. This is an important point that could impact the validity of the results, as the pretraining stage can significantly influence the performance of the models. The comment provides a clear and actionable suggestion for the authors to clarify the pretraining conditions for the compared methods, which would help to ensure a fair comparison. However, the comment could be more helpful if it offered specific guidance on how to address this issue or suggested alternative experimental designs. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests exploring these options for better performance. The comment explicitly instructs the authors to update the paper with the performance of their method using better metadata embeddings. This feedback is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metadata used for zeroshot learning on the CUB dataset and suggests exploring better metadata embeddings options, referencing a specific paper for further guidance. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these better metadata embeddings options could improve performance. The reference to the external work is a good start, but the claim could be more fully verified with additional supporting evidence or examples. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the use of \"attribute\" metadata is good for fair comparison but suggests that better metadata embeddings options are available. It references a relevant paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which could offer insights into improving performance. The comment is actionable as it suggests exploring these better metadata embeddings options and provides a specific reference for further investigation. This feedback is clear and constructive, offering the authors a concrete direction for enhancing their work. Therefore, it is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to directly compare the flexibility of SGC with LoRA. This is an explicit action with concrete details on how to implement it, as it specifies the type of plot and the variables to be included. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment addresses the limited applicability of SGC and suggests a plot to compare its flexibility with LoRA. It provides a specific suggestion for visualization, which is to include a plot with sparsity on the xaxis and performance on the yaxis. This makes the comment fully grounded as it explicitly mentions the need for a specific type of plot, allowing the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of this plot to demonstrate the practical benefits of SGC\"s finegrained control. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but notes that PEFT methods typically target computeconstrained scenarios where such granular control may require extra tuning, reducing practicality. The reviewer suggests including a plot to compare the flexibility of SGC with LoRA, which could more intuitively demonstrate whether SGC\"s finegrained control offers practical performance benefits at different sparsity levels. This claim is 3 as it provides a logical reasoning for the potential limitation of SGC in practical scenarios and suggests a method to visually demonstrate the difference. However, the comment lacks specific examples or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s claim about the flexibility of SGC compared to PEFT methods. It suggests that the finegrained control offered by SGC may not be practical in computeconstrained scenarios, where extra tuning could be required. The comment provides a constructive suggestion to include a plot with sparsity on the xaxis and performance on the yaxis to visually compare the flexibility of SGC with LoRA. This feedback is actionable and offers a clear way for the authors to demonstrate the practical benefits of SGC\"s finegrained control. By addressing this point, the authors can enhance the clarity and persuasiveness of their argument, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. While the comment implies that the authors should address the discrepancy in training times and consider publishing the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the training time issue and consider publishing the code. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiment 2\" and \"ERM and plugin,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. Additionally, it suggests that the code should be published, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage is its computation time. However, the comment lacks specific evidence or references to support the claim that the training times are unreasonable or to substantiate the suggestion for publishing the code. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the German and Law school dataset having shorter training times in Gerrymandering compared to Independent. It also suggests that the code should be published, as the main advantage of the method is its computation time. This feedback is 3 as it points out a potential inconsistency in the experimental results and suggests a way to improve the paper by making the code available. However, the comment could be more helpful if it provided additional context or examples to clarify the issue with the training times or if it offered suggestions on how to address the discrepancy. Overall, the comment provides some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information CD captures beyond Predictive Uncertainty. It also questions why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides specific areas for improvement, such as explaining the additional information CD captures and justifying the choice of measure. While the action is explicit, the comment could be more actionable by providing concrete examples or suggestions for alternative formulations. Overall, the comment is 4 as it clearly identifies areas for improvement and provides some guidance on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 115\" and \"line 113,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for alternate formulations for Confidence Diversity (CD) and the explanation of why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should describe alternate formulations for Confidence Diversity (CD) and questions the choice of entropy as a measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current formulation and suggesting an alternative perspective. However, it lacks specific examples or references to support the claim that entropy is not a good measure, which would strengthen the argument. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the current formulation, specifically asking why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a clear direction for the authors to explore and clarify the additional information that CD captures beyond Predictive Uncertainty. However, it could be more helpful if it offered specific suggestions or examples of alternative formulations or measures. Overall, the comment is 4 as it directs the authors to a critical area of clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that it only follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. The comment also references Section 4.1, which mentions additional factors contributing to the human baseline\"s weakness. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the human baseline. The action is implicit and vague, as the authors are left to infer that they need to clarify or address the discrepancy in the human baseline\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline and the discrepancy in the duration of speech recordings it follows, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline is weaker due to this limitation, and it references Section 4.1 for additional factors contributing to this weakness. Additionally, the comment critiques the abstract for being misleading regarding the comparison with the human baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings, rather than the full 15 hours. The comment also critiques the abstract for being misleading regarding the comparison with the human baseline. While the comment highlights a potential issue with the human baseline, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to Section 4.1 provides some context but does not fully support the claim. Therefore, the comment is 3, as it provides some justification but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only follows a little more than 1 hour of speech recordings, making it weaker compared to the model baseline. It also points out that the abstract is misleading in its comparison with the human baseline. This feedback is valuable as it highlights a critical flaw in the experimental setup and suggests that the authors should clarify or correct this discrepancy. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or improve the human baseline. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the assumption for termination states of instructions being quite strong and notes that labeling a large number of data manually can be very expensive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods for labeling data or proposing ways to reduce the expense. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment highlights the issue of labeling a large number of data manually being expensive, but it does not provide specific guidance or suggestions on how to address this concern. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong\" and notes that labeling a large number of data manually can be very expensive. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the strength of the assumption or the expense of manual labeling. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption for termination states of instructions, noting that it is quite strong and that labeling a large number of data manually can be very expensive. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the expense of manual labeling. Without actionable advice or further elaboration, the feedback is limited in its usefulness to the authors, who may still struggle to understand how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the paper regarding the contribution related to ECE_sweep. It explains that the contribution involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. The reviewer suggests that the paper should be more upfront about this contribution. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address the issue or what specific changes should be made to clarify the contribution. The action is implicit and somewhat vague, as the authors know they need to clarify the contribution but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the contribution, namely that it involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. The reviewer suggests that this is not fundamentally different and should be clarified in the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the nature of the contribution related to ECE_sweep is not clearly described in the text. The reviewer provides a detailed explanation of the contribution, stating that it involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. This explanation is supported by logical reasoning, as it breaks down the concept and highlights the need for clarity. However, the comment could be strengthened by referencing specific sections of the paper where this issue is observed, which would make it more 5. Overall, the claim is 4, as it provides a clear explanation but lacks detailed references to the paper.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity regarding its contribution, particularly with respect to ECE_sweep. It provides a detailed explanation of the contribution, noting that it involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. The reviewer suggests that this is not fundamentally different and should be clarified in the paper. This feedback is clear and actionable, as it directs the authors to explicitly describe their contribution and its implications. By addressing this point, the authors can improve the clarity and comprehensiveness of their paper. Therefore, the comment is 4, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as Reinforcement Learning (RL) methods, but none of these methods are used as a baseline. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, how to incorporate them, or what specific aspects of the RL methods should be explored. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This provides clear guidance on what needs to be addressed in the related work section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This claim is 3 as it highlights a potential gap in the paper\"s methodology. However, the comment lacks specific examples or references to the RL methods mentioned, which would strengthen the justification. Providing more detailed information or examples of these methods would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a gap in the related work section by noting that it discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This feedback is 3 as it identifies an area where the paper could be improved by incorporating additional baselines or methods for comparison. However, the comment lacks specific suggestions or guidance on how to address this gap, such as recommending which RL methods to include or how to integrate them into the analysis. While it highlights an important area for improvement, the lack of detailed advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a confusion in the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" However, it does not provide explicit guidance or suggestions on how to clarify this ambiguity in the draft. The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" but it does not offer concrete steps for the authors to take to resolve the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the confusion regarding whether the authors are referring to a particular efficient proxy or a general category of efficient proxies. This provides clear guidance on what needs to be clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" which suggests that the authors may be referring to a family of efficient proxies. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text regarding the reference to \"efficient proxy.\" It points out the ambiguity in whether the authors are referring to a particular proxy or a general category of proxies, noting the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy.\" This feedback is 3 as it highlights a potential confusion in the paper and prompts the authors to clarify their intent. However, it could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of how to clarify the text. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes a specific methodological approach used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Grouplearning setting, followed by the use of DBSCAN for clustering. However, it does not provide any explicit or implicit suggestions for improvement or changes. The comment lacks actionable guidance, such as recommending alternative methods, explaining the rationale behind the chosen approach, or suggesting how to enhance the clustering process. Without any direction or specific advice, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020, and the Grouplearning setting, followed by the use of DBSCAN for clustering. This allows the authors to accurately identify the specific part of the paper being addressed. The comment is also specific because it details the methodological approach used, providing clear information about the methods stacked and the clustering method employed. This level of detail helps the authors understand what needs to be addressed or improved in their methodology. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point describes a specific methodological approach used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Grouplearning setting, followed by the use of DBSCAN for clustering. However, it does not provide any claims, opinions, or suggestions that require verification. It is purely descriptive, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a factual description of the methodological approach used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Grouplearning setting, followed by the use of DBSCAN for clustering. However, it lacks any analysis, critique, or suggestions for improvement. Without any actionable feedback or guidance, the authors are left without a clear understanding of how to enhance their work or address potential weaknesses. Therefore, the comment is 1, as it does not provide any value in terms of improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of different projection matrices on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an investigation into the resilience of the metric, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that such matrices are unlikely with random projections but still suggests investigating the resilience of the metric to different projection choices. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the variability in results due to the choice of random projection matrix. It suggests that the authors should investigate the resilience of the metric to different projection matrices, which is a reasonable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Additionally, the mention of potentially pathological projection matrices adds depth to the concern, but the comment could benefit from more detailed suggestions or examples. Overall, the comment is 3 as it identifies a potential issue and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It explicitly asks for examples of synthetic data, clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and requests that the model used be explicitly written down, possibly in the appendix. These requests are clear and direct, providing the authors with specific actions to take to improve their draft. The feedback is concrete and actionable, as it guides the authors on what information to include and how to present it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and specific terms like \"support data\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it requests examples of synthetic data, clarification on the terms mentioned, and asks for the model used to be explicitly written down, possibly in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the synthetic data, Figure 1, and the model used. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, which is not a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas that require clarification and additional information. It asks for examples of synthetic data, requests clarification on the terms \"support data\" and \"predicted training count data\" in Figure 1, and suggests that the model used should be explicitly written down, possibly in the appendix. These requests provide clear and actionable feedback that can help the authors improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present the examples or clarify the terms, or if it provided additional context for the model description. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This implies that the authors should expand the evaluation of FGT to include its use in comparing the proposed method with other methods. However, the comment does not provide specific guidance on how to implement this change or what aspects of FGT should be evaluated. The action is implicit and somewhat vague, as the authors can infer the need for a broader evaluation but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This claim is 3 as it provides a logical reasoning for the evaluation process. However, it lacks specific examples or references to support why this change is necessary or how it would improve the evaluation. The comment could be strengthened by providing more detailed justification or examples, making it 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is only used in the ablation study and suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation process. However, the comment could be more helpful if it offered additional guidance on how to implement this change or why it is important for the evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the model appears overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the model should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered simple or how this simplicity affects the model. Without explicit references to sections, figures, or specific elements of the model, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is \"overly simple,\" both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the model are considered overly simple, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes could be made to enhance their work. As a result, the comment is 1, as it lacks the necessary depth and direction to assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might expand their work to increase its impact or suggestions for broader applications. As a result, the comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the work are limited or how the authors might address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might broaden the impact of their work. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s focus on a narrow task (climate change QA) in a specific language (Arabic) may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. While this observation highlights a potential limitation of the work, it does not provide any actionable suggestions or guidance for the authors to address this issue. The comment lacks depth and does not offer any specific advice on how the authors might expand their work to increase its impact or relevance. As a result, the comment is 2, as it identifies a potential weakness but does not provide sufficient direction for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions would be beneficial. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the paper\"s contribution to the understanding of the winnertakeall property, particularly in the context of simplified settings and previous works. The comment highlights the lack of novelty in the findings, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty in its contribution to the understanding of the winnertakeall property, particularly given its simplified settings and the fact that most findings have been reported in previous works. The reviewer supports this claim by referencing previous works that have used the winnertakeall property, such as NNbased clustering algorithms, and by mentioning that the findings in Section 5 have been reported before. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more specific examples or references to the previous works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution, prompting the authors to consider how their work differs from existing research. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their findings. To be more helpful, the comment could provide examples of how previous works have addressed similar issues or suggest potential avenues for novel contributions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to aid readers who might apply the method. This feedback is explicit and provides concrete actions for the authors to take, such as including a brief mention of computational cost and providing examples of runtimes. The suggestions are clear and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only discussed in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments for readers who might apply the method. The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely, the inclusion of computational cost information and examples of runtimes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that mentioning the negligible computational cost of CHR in the main paper could help motivate the method. It also recommends providing a rough example of runtimes in the experiments to aid readers. However, the comment does not provide specific examples or detailed reasoning to support why this information is crucial or how it would enhance the paper. The suggestion is logical but lacks concrete evidence or references to substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion to enhance the paper by recommending that the authors mention the negligible computational cost of CHR in the main paper. This would help motivate the method and provide readers with a clearer understanding of its practical implications. Additionally, the comment suggests including a rough example of runtimes in the experiments to aid readers who might apply the method. This feedback is clear and actionable, offering specific ways for the authors to improve the clarity and applicability of their work. However, the comment could be more helpful if it provided examples of how to present the computational cost or suggested specific metrics to include. Overall, the comment is 4 as it offers valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends that the authors provide more detailed elucidation of the EEG token quantization process, specifically regarding the role of the spatial arrangement of EEG sensors. This suggestion is clear and provides a concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The comment is 5 as it offers specific guidance on how to enhance the clarity and interpretation of the results presented in Figure 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of ambiguity in interpretation and suggests that the authors provide more detailed elucidation of the EEG token quantization process, particularly regarding the role of the spatial arrangement of EEG sensors. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 presents EEG topography plots that lead to ambiguity in interpretation, recommending that the authors provide more detailed elucidation of the EEG token quantization process. The comment is 3 as it identifies a potential issue with the interpretation of the results but lacks specific examples or references to support the claim of ambiguity. While the suggestion for further explanation is reasonable, the comment could be strengthened by providing more detailed reasoning or examples to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It provides a clear and actionable suggestion for the authors to elucidate this procedure in greater detail, specifically asking whether the spatial arrangement of EEG sensors played a role in the process. This feedback is valuable as it directs the authors to clarify a critical aspect of their methodology, potentially enhancing the understanding and reproducibility of their results. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested specific ways to address the ambiguity. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the issue or what specific changes could be made to improve the directness of their approach. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the authors\" use of the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some insight into the perceived indirectness of the approach but lacks specificity in terms of what needs to be addressed or how the authors might improve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors\" approach to leveraging the complexity of checking on the Witness oracle is not direct. However, it does not provide specific guidance or suggestions on how the authors might improve their approach or address the issue. The comment lacks actionable feedback, such as recommending alternative methods or providing examples of more direct approaches. Without detailed guidance, the authors are left without a clear path to enhance their work. Therefore, the comment is rated as 1, as it does not offer any meaningful insights or improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), and implies that this should be discussed in the context of various approaches to DRL. The comment explicitly suggests that the authors should include this discussion, even though the paper still uses quantile regression. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL), and it references a specific paper by NguyenTang et al. (AAAI\u201921) for further context. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching instead of quantile regression in distributional reinforcement learning (DRL). It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which supports the claim. This provides a clear and specific reference that substantiates the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be applied or compared to quantile regression in the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature, namely the discussion of moment matching in distributional reinforcement learning (DRL) compared to quantile regression. It references a specific paper, \"Distributional Reinforcement Learning via Moment Matching\" by NguyenTang et al. (AAAI\u201921), which provides a relevant example of an alternative approach. The comment suggests that this should be discussed in the context of various approaches to DRL, even though the present paper still uses quantile regression. This feedback is clear and actionable, as it directs the authors to include a discussion on moment matching, which could enhance the comprehensiveness and depth of their work. However, it could be more helpful if it provided specific suggestions on how to integrate this discussion into the paper. Overall, the comment is 4, as it offers valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also provides a concrete action by recommending testing on a smaller subset of RepoEval and comparing with stateoftheart code completion systems. This feedback is clear and provides specific guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment suggests adding baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing on a smaller subset of RepoEval and comparing with stateoftheart code completion systems. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or results section where baselines are discussed. The authors can infer that this comment relates to the evaluation or comparison section. The comment is specific in suggesting the inclusion of Copilot and the importance of comparing with stateoftheart systems. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The suggestion is based on the importance of comparing with stateoftheart code completion systems, which is a logical and reasonable claim. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or that it is essential to compare with it. This makes the claim 3, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of additional baselines for code completion tasks. It explicitly recommends comparing with existing commercial applications, such as Copilot, and provides a clear rationale for why this comparison is important. The suggestion to test on a smaller subset of RepoEval and compare with stateoftheart code completion systems offers actionable guidance for enhancing the evaluation and validation of the work. This feedback is clear, specific, and provides a concrete direction for the authors to improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on their selection criteria and potentially explore other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context and potentially conduct further evaluations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses the evaluation on MTEB, making it weakly grounded. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting that the authors should provide more information on their selection criteria and consider alternative datasets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. The comment provides a logical reasoning by questioning the representativeness of the results based on the limited evaluation scope. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully substantiate the claim, hence the score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and potentially expand their evaluation to other datasets or tasks. By addressing this concern, the authors can enhance the robustness and applicability of their findings. However, the comment could be more helpful if it provided specific examples of alternative datasets or tasks that could be considered. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the introduction, the second paragraph discusses modelling curves, but it is unclear what is being modelled. However, it does not provide explicit guidance or suggestions on how to clarify this point or what specific information should be added to make it clear. The action is implicit and vague, as the authors can infer that they need to provide more context or clarification but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"second paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that it is not immediately clear what is being modelled, presumably tumour growth. This provides clear guidance on what needs to be clarified in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph of the introduction discusses modelling curves but does not clarify what is being modelled. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the introduction, where the second paragraph discusses modelling curves but does not clearly specify what is being modelled. This feedback is 3 as it points out a potential area for clarification, allowing the authors to improve the clarity and coherence of their introduction. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific details to include or examples to provide. Overall, the comment offers a useful insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2), and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. While the comment implies that the authors should provide additional information or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question and provide the requested information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why shift=0 is better than shift~N(0,\u03c3^2) and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2), and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why shift=0 is better or why this comparison is relevant. Without additional context or explanation, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2), and suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in)distribution. This feedback identifies a potential area of confusion or lack of clarity in the paper and provides a specific suggestion for improvement. By addressing this point, the authors can enhance the comprehensiveness and clarity of their results. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in understanding and addressing the issue. Overall, the comment is 4 as it provides actionable feedback that can lead to improvements in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not provide specific guidance on what aspects of the experiment description need more detail or how the authors might improve clarity. The comment refers to \"Questions\" for further details, but without elaboration, the authors are left without concrete steps to take. This makes the comment 3, as it identifies an area for improvement but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The comment highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its suggestion that the description should be clearer, but it lacks detailed guidance on how to achieve this clarity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment description lacks detail, making it difficult for readers to judge the results. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or suggestions for improvement. The comment refers to \"Questions\" for further details, but without elaboration, it remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experiment description, noting that it lacks detail, which makes it difficult for readers to understand the results. This is a critical observation that could impact the clarity and comprehensibility of the paper. However, the comment does not provide specific suggestions or guidance on how to improve the experiment description, such as what details should be included or how to present them in a clearer manner. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a key issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected outcomes, particularly regarding the optimization strategies and their results. It explicitly mentions the need for a discussion on the impact of minimizing both inter and intra terms in Eq 3 or only the first term. This feedback is clear and provides specific guidance on what the authors should address in their paper. The action is explicit and concrete, as it directs the authors to include a detailed discussion on the optimization strategies and their effects. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected outcomes and discussing the optimization strategies and their results. The comment suggests specific examples, such as what happens when minimizing both inter and intra terms or only the first term, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected outcomes, particularly regarding the optimization strategies and their results. It questions what would happen if both inter and intra terms in Eq 3 are minimized or if only the first term is minimized. This claim is 3 as it highlights a potential gap in the paper\"s explanation but lacks specific examples or references to support the need for additional discussion. The authors would need to infer the importance of this clarification based on the context of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected outcomes of their work. It highlights the importance of discussing different optimization strategies and their corresponding results, particularly in relation to the CBR (CaseBased Reasoning) contribution. The comment also provides a concrete example by asking what would happen if both inter and intra terms in Eq 3 are minimized or if only the first term is minimized. This feedback is clear and actionable, offering the authors a specific direction for enhancing the clarity and depth of their discussion. However, it could be more helpful if it included additional suggestions or examples to further guide the authors. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include a formal or intuitive definition of treewidth, as it is central to all the proofs in the paper. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies the need for a definition, which gives the authors a concrete step to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or chapter. This makes it difficult for the authors to pinpoint the exact location where the definition should be added. The comment is specific in its suggestion to include a definition, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. However, the comment does not provide any reasoning or evidence to support why this definition is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the clarity and comprehensibility of the paper. By addressing this suggestion, the authors can ensure that their readers, particularly those unfamiliar with the concept of treewidth, have a better understanding of the theoretical foundations of their work. However, the comment could be more helpful if it offered additional guidance on how to present the definition or its implications. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the paper analyzes under which cases Algorithm 1 converges to permutations as local minima, it would be beneficial to also analyze the quality of these local minima, such as their approximation ratio under certain assumptions. This comment implies that the authors should expand their analysis to include the quality of the local minima, but it does not provide specific guidance on how to conduct this analysis or what assumptions to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the details of the analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment refers to \"Algorithm 1\" and mentions the analysis of local minima, which provides some grounding as it suggests a specific part of the paper being addressed. However, it does not specify which section or part of the paper discusses Algorithm 1 or the analysis of local minima, making it weakly grounded. The comment is specific in suggesting that the quality of local minima should be analyzed, such as the approximation ratio under certain assumptions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by noting that it only analyzes under which cases Algorithm 1 converges to permutations as local minima. It suggests that the quality of these local minima should also be analyzed, such as the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their analysis and potentially improve the depth of their findings. However, the comment could be more helpful if it offered examples or further guidance on how to conduct this additional analysis. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper, which is understandable given the NIPS format. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly requests the release of the source code, it does not provide specific guidance on how to ensure reproducibility or what aspects of the code should be made available. The action is explicit but somewhat vague, as it lacks detailed instructions on implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not being selfcontained, which is understandable given the NIPS format. It mentions that the supplementary material is necessary to understand large parts of the main paper and to allow reproducibility. The comment also requests the authors to release the source code of their experiments to facilitate reproducibility. However, the comment does not specify which parts of the paper are not selfcontained or how the supplementary material could be improved to enhance understanding. While it provides a clear request for the release of source code, the lack of specific guidance on the content or structure of the supplementary material makes it 3. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is not selfcontained, which is understandable given the NIPS format, but notes that the supplementary material is necessary to understand large parts of the main paper and to allow reproducibility. The comment also requests the authors to release the source code of their experiments to facilitate reproducibility. While the claim about the paper\"s selfcontainment is supported by the context of the NIPS format, the request for source code release is a logical suggestion for ensuring reproducibility. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the paper\"s selfcontainment. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also highlights the importance of reproducibility by requesting the authors to release the source code of their experiments. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for enhancing the paper\"s quality. However, the comment could be more helpful if it offered additional guidance on how to address the selfcontainment issue or provided examples of how the supplementary material could be improved. Overall, the comment is 4, as it directs the authors toward important improvements that can enhance the paper\"s clarity and reproducibility."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms. It also references a specific sentence regarding the robustness of Cans and the information redundancy in the weight pool. However, the comment does not provide explicit instructions or suggestions on how the authors should address this question or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or elaborate on the information redundancy aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and references a specific sentence regarding the information redundancy and the robustness of Cans. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions how information redundancy is built into the algorithms and references a specific sentence for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, specifically referencing a sentence about the robustness of Cans. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the need for clarification on this point. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, which is a specific and relevant aspect of the paper. It also references a sentence regarding the robustness of Cans and the information redundancy in the weight pool, indicating that the authors should clarify how this redundancy is built into the algorithms. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology, which could enhance the understanding and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor and suggests that the added complexity should be evaluated. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The comment implies that the authors should consider ablation studies to determine the impact of this design choice, but it does not specify how to conduct such studies or what metrics to use. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper discusses this feature, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine the impact of using multiple INs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of using multiple INs at different speeds in the dynamics predictor and suggests that the added complexity should be evaluated. However, it does not provide any supporting evidence, reasoning, or references to justify why this aspect is crucial or how it impacts the model\"s performance. The comment lacks specific examples or detailed analysis, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of using multiple INs at different speeds in the dynamics predictor. It points out that this design choice has not been ablated, which is a critical aspect of evaluating the model\"s performance. The comment prompts the authors to consider whether the added complexity is necessary and whether a single IN would suffice. This feedback is clear and actionable, as it encourages the authors to conduct an ablation study to determine the impact of this design choice. However, the comment could be more helpful if it provided specific suggestions on how to conduct the ablation study or what metrics to use. Overall, the comment is 4 as it directs the authors to a significant area for improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation regarding the experiments, noting that it is not surprising the opponent is outperformed in terms of the multiagent payoff proposed by the authors. The comment explains that this is because the opponent does not aim to maximize the multiagent payoff but instead focuses on classical SE and AE. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by explaining why the opponent can be outperformed in terms of the multiagent payoff proposed by the authors. The comment provides a clear rationale for this observation, noting that the opponent does not aim to maximize the multiagent payoff but instead focuses on classical SE and AE. This level of detail helps the authors understand the critique and potentially address it in their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is not surprising the opponent is outperformed in terms of the multiagent payoff because the opponent does not aim to maximize it. The comment provides a logical explanation by noting that the opponent maximizes classical SE and AE instead. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific observation about the experiments, noting that it is not surprising the opponent is outperformed in terms of the multiagent payoff proposed by the authors. The comment explains that this is because the opponent does not aim to maximize the multiagent payoff but instead focuses on classical SE and AE. This feedback is 3 as it offers a logical explanation for the observed outcome, which could help the authors understand and potentially address the issue in their draft. However, the comment lacks actionable suggestions or guidance on how the authors might improve their work or address the critique. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm over PPO. It implies that the choice might be related to the attention model paper being iterated upon, but it does not explicitly state this as the reason. While the comment provides a clear direction for the authors to explain their choices, it lacks specific guidance on how to articulate these explanations. The action is explicit but somewhat vague, as the authors know they need to explain their choices but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm over PPO. It implies that this choice might be related to the attention model paper being iterated upon, but it does not specify which part of the paper this relates to. While the authors can infer that it pertains to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a section or figure. The comment is specific in suggesting that the authors should explain their choice of algorithm, but it does not provide detailed guidance on how to address this point. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a description of why certain choices were made, specifically the use of the REINFORCE algorithm over PPO. The comment implies that this choice might be related to the attention model paper being iterated upon, but it does not provide specific evidence or references to support this claim. The suggestion is logical and based on common knowledge in the field, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm over PPO. This feedback is clear and actionable, as it directs the authors to clarify their methodology and provide rationale for their decisions. By addressing this point, the authors can enhance the transparency and comprehensibility of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to articulate these explanations. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to clarify or address the confusion, making it 1. The authors are left without a clear understanding of what steps to take to improve their draft based on this feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion regarding the statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a specific statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. While the comment identifies a potential issue, it lacks depth and does not provide any actionable suggestions or guidance on how the authors might clarify or address this confusion. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an area of confusion but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, which is crucial for task domain adaptation. While the comment highlights an important area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more detailed information on this aspect, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a gap in the paper but does not offer specific guidance on how to fill it.", "grounding_specificity_rationale": "The comment raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in detailing what needs to be addressed, namely the need for more information on domain adaptation and morphologic segmentation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. The reviewer questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of this issue and how it relates to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the application of morphologic segmentation across different domains. It questions whether morphologic segmentation should be conducted differently for various domains and highlights the importance of this consideration in the context of task domain adaptation. The comment points out that the paper assumes morphologic segmentation is invariant across domains, which is a critical oversight. By raising this issue, the comment provides the authors with a clear direction for improvement, encouraging them to address the lack of insight into domain adaptation and morphologic segmentation. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the feedback is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. The comment specifies the exact action and provides a concrete suggestion, making it 5. The authors know exactly what needs to be done to address the feedback, which is to conduct additional experiments and report the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that experimental results should be included to demonstrate the pure contribution of the proposed method by excluding the mixup technique. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results excluding the mixup technique to demonstrate the pure contribution of the proposed method. This claim is based on a logical reasoning that by excluding the mixup technique, the authors can isolate the contribution of their method. However, the comment does not provide specific examples or references to support why this exclusion is necessary or how it would impact the results. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental setup of the proposed method. It suggests that the authors should include experimental results that exclude the mixup technique to demonstrate the pure contribution of their method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the experimental design and analysis. By following this advice, the authors can better isolate the impact of their method and provide a more comprehensive understanding of its effectiveness. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or why it is important for the paper. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions on how to address the questions or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or experimental setup sections, where such details would typically be discussed. The comment is specific in its request for clarification, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detection based attention, specifically whether it is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field. These are factual questions that do not express opinions, judgments, or suggestions, and they do not require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the object detection based attention, asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their methodology, which could help readers understand the paper better. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to clarify an important aspect of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing discussion about the Set Transformer and other related works that use summary tokens. It provides a specific reference to the Set Transformer paper, which gives the authors a clear action to take: they should include a discussion about this work and other related works in their paper. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a reference to the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any reasoning or evidence to support this claim, such as explaining why this discussion is important or how it relates to the paper\"s content. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. By mentioning a specific reference (https://arxiv.org/abs/1810/00825), the comment provides a clear and actionable suggestion for the authors to include a discussion about these works. This feedback is valuable as it directs the authors to a relevant area that could enhance the comprehensiveness and depth of their paper. However, the comment could be more helpful if it offered additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features. It implies that the authors should provide an analysis or explanation of this aspect, as it is considered essential for the theoretical support of Fourier features. However, the comment does not explicitly instruct the authors to include this analysis or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for analysis but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations that would help the authors understand the importance of this aspect or how it relates to the paper. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the acceleration of NTK convergence in the highfrequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. While it identifies a potential gap in the analysis, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors with a general idea of what might be missing but without a clear path to improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit guidance on what the authors should do to address this issue. There is no suggestion for additional information, experiments, or modifications that could clarify this aspect of the paper. As a result, the authors are left without a clear understanding of how to improve their draft in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of fitting the residual, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of details on how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the network\"s architecture, specifically the lack of details on how it fits the residual instead of directly learning the inputoutput mapping. This is a relevant observation that could help the authors clarify their methodology and improve the clarity of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific details should be included to clarify the network\"s design. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification on the experiment setup in Section 3.3, specifically requesting information about data augmentation methods and learning rates. This is a direct and concrete action for the authors to take, as it clearly specifies what information is needed to improve the draft. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides additional context and guidance on how to address the request. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the experiment setup, including data augmentation methods and learning rates. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides additional context and guidance on how to address the request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual question about the experiment setup in Section 3.3, along with a reference to a relevant paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that lacks clarity, namely the experiment setup in Section 3.3. By asking for details about data augmentation methods and learning rates, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Additionally, the inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" provides some context but does not fully address the need for detailed guidance on how to enhance the experiment setup. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, it does not provide explicit guidance or suggestions on how the authors should investigate or address this issue. The comment implies that the authors should look into the calibration steps, but it lacks concrete steps or actions for the authors to take. As a result, the comment is 3, as it identifies a potential area for investigation but does not provide clear guidance on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps (steps 1 & 2) might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. However, the comment does not provide any evidence, examples, or references to support this claim. It lacks specific details or reasoning to substantiate the suggestion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the potential source of speed disparities observed between RSPs and FDs, suggesting that an error in the initial calibration steps might be the cause. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might investigate or address this concern. The comment does not provide actionable steps or detailed feedback, leaving the authors with a general direction but without a clear path for improvement. Therefore, the comment is 3, as it points out a potential area for investigation but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern that artificial networks trained using ASAP (and similar methods) may not necessarily resemble biological networks, except for the weight transport problem, which is considered of arguable importance. However, the reviewer explicitly states that they do not hold the authors accountable for this observation and that it does not affect the review. This comment does not provide any actionable advice or suggestions for the authors to address the issue or improve their work. It lacks explicit guidance or concrete steps for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the resemblance of artificial networks trained using ASAP to biological networks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique, pointing out that the weight transport problem is of arguable importance and questioning the claim that ASAP networks resemble biological networks more than other techniques like backprop. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP and similar methods do not necessarily resemble biological networks, except for the weight transport problem, which is considered of arguable importance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the resemblance of artificial networks trained using ASAP to biological networks, questioning the significance of the weight transport problem. However, the reviewer clarifies that this observation does not affect the overall review and does not hold the authors accountable for this issue. While the comment identifies a potential critique, it lacks actionable feedback or suggestions for the authors to address this concern. The lack of guidance or constructive advice makes the comment 2, as it does not provide the authors with a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not explicitly instruct the authors to perform such a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider statistical significance but are not given specific instructions on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not specify which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in its suggestion to consider a statistical significance test, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, the comment does not provide any evidence, examples, or references to support the claim that the numbers are close or to justify the need for a statistical significance test. Without additional context or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. This is a valid point that could help the authors improve their draft by ensuring that their results are statistically significant and not merely coincidental. However, the comment lacks specificity and does not provide detailed guidance on how to conduct such a test or what specific aspects of the comparison might be problematic. While it identifies a potential issue, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. While the comment does not provide explicit instructions or suggestions for improvement, it implies that the authors should clarify this aspect of their work. The action is implicit and somewhat vague, as it does not specify how the authors should address the issue or what specific information should be included. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. The comment is specific in its inquiry but lacks grounding, as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this clarification. It lacks specific examples or detailed explanations that would help the authors understand the context or importance of this question. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a critical question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NPSPECHMM. This question highlights a potential gap in the paper\"s explanation and could prompt the authors to clarify or expand their discussion on this topic. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a relevant area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, it does not explicitly instruct the authors to perform this analysis or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a deeper analysis but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, suggesting that the authors should provide an analysis of the underlying reasons for this outcome. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing an analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this analysis and how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient analysis of experimental results. It points out that the authors mention the poor performance of the scope prompting method on GPT3.5turbo but do not provide any analysis of the underlying reasons for this outcome. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, the comment could be more helpful if it suggested specific methods or approaches for conducting this analysis. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the decision to only consider 10 out of 120 datasets for comparison between batch and greedy methods, as mentioned in references [7] and [12]. It suggests that the authors should compare these methods in the remaining 110 datasets. While the comment implies an action\u2014comparing batch and greedy methods in more datasets\u2014it does not provide specific guidance on how to conduct this comparison or which datasets to use. The action is implicit and somewhat vague, as the authors would need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific datasets (10 out of 120) and references [7,12], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the decision to only consider a subset of the datasets and suggests comparing batch and greedy methods in the remaining datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the decision to only consider 10 out of 120 datasets for comparison between batch and greedy methods, as mentioned in references [7] and [12]. The comment suggests that the authors should compare these methods in the remaining 110 datasets. However, the comment does not provide any reasoning or evidence to support why this comparison is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the decision to only consider 10 out of 120 datasets for comparing batch and greedy methods, as mentioned in references [7] and [12]. It suggests that the authors should compare these methods in the remaining 110 datasets. This feedback is 3 as it points out a potential limitation in the analysis and encourages the authors to expand their comparison. However, it lacks specific guidance on how to conduct this expanded comparison or which datasets to prioritize. While it provides a direction for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. It implies that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment does not provide specific guidance on how to incorporate these implications or where to discuss them in the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the implications but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation in the introduction\" and the \"main result,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation for lowrank factorization and suggests that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the motivation for lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer implies that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment does not provide specific examples or references to support why the motivation is unnecessary or how the implications should be discussed. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning and provide additional context to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation presented in the introduction, suggesting that it may be unnecessary given the focus on polytopes. It also provides a constructive suggestion by asking the authors to explicitly discuss any implications for lowrank matrix factorization if such implications exist. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the motivation and to potentially expand their discussion to include relevant implications. However, the comment could be more helpful if it provided specific examples or further guidance on how to integrate these implications into the paper. Overall, the comment is 4, as it offers valuable insights and prompts the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify the labels for each dataset in Section 4.1, specifically questioning whether they come from the dataset itself or from another source. This request is clear and direct, providing the authors with a specific action to take to improve their draft. The comment also provides context by mentioning the ease of labeling for generated datasets but highlights the need for clarification regarding the labels for specific datasets like caspealr1 and mugshot. This level of detail ensures that the authors know exactly what needs to be addressed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking for clarification on the labels for each dataset, particularly for caspealr1 and mugshot. The comment provides a clear direction for the authors to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the labels for each dataset in Section 4.1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual question seeking information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of confusion regarding the labels for each dataset in Section 4.1. It explicitly asks for clarification on where the labels are coming from, whether they are derived from the dataset itself or from another source. This feedback is clear and actionable, guiding the authors to provide more detailed information about their labeling process. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar datasets are typically labeled. Overall, the comment provides valuable direction for improving the clarity and transparency of the paper, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point comments on the paper being incremental compared to another work ([31]) and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the incremental nature of the work, what specific aspects need improvement, or suggestions for enhancing the originality or contribution of the paper. As a result, the comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, making it difficult for the authors to identify the exact section or aspect being referred to. It also lacks specificity, as it does not detail what aspects of the paper are considered incremental or how the adaptation of the existing architecture could be improved. Without clear guidance or references to specific sections or elements of the paper, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"rather incremental\" compared to another work ([31]), stating that the authors adapt an existing architecture for the multiperson case. However, the comment does not provide any specific details or examples to support this claim, nor does it offer a clear explanation of what aspects of the paper are considered incremental. Without additional context or evidence, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is incremental compared to another work ([31]), noting that the authors adapt an existing architecture for the multiperson case. However, it does not provide any specific feedback or suggestions on how the authors could enhance their work or address the incremental nature. Without actionable guidance or detailed critique, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the clarity of the paper. The authors are left without a clear understanding of what changes or additions are needed to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific pages and lines (Page 9, lines 310313, and Page 8, lines 281285), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to external works, which adds to its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to external works, such as [1] Yuri Burda et al, Exploration by Random Network Distillation, ICLR 2019, [2] Deepak Pathak et al, Curiositydriven Exploration by Selfsupervised Prediction, ICML 2017, and [3] Roberta Raileanu et al, RIDE: Rewarding ImpactDriven Exploration for ProcedurallyGenerated Environments, ICLR 2020, which could help support the claims. However, the comment lacks detailed reasoning or examples to fully substantiate the claims, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns and questions about the paper, including the sensitivity of performance and sample efficiency to the \u03bb parameter, the process of calculating \u03bb, and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides specific references to external works, which could help the authors better understand the context and address the issues raised. However, the comment lacks detailed guidance or suggestions on how the authors might improve their explanation or address the concerns. While it identifies areas for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, specifically asking which alternating direction method is employed. However, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable details, such as suggesting which methods should be considered or how to clarify this information in the paper. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the specific alternating direction method used to solve the minmin problem, but it does not specify which part of the paper this information is mentioned in. The authors may need to review the entire paper to identify the relevant section. The comment is specific in its request for clarification but lacks grounding as it does not direct the authors to a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the specific alternating direction method used to solve the minmin problem. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific alternating direction method used to solve the minmin problem, indicating a lack of clarity in the paper. While it identifies a potential area for improvement by pointing out the need for more detailed information, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment is 3 as it prompts the authors to clarify their methods, but it lacks depth and actionable advice, making it incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also notes a potential issue with overestimating the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The authors are left to infer that they need to investigate and address these issues, but without concrete steps or recommendations, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MsPacman of Figure2\" and specific environments like \"WizardOfWor, Zaxxon RoadRunner, and BattleZone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the effectiveness of lower bound double qlearning, including a slight performance decrease in MsPacman and convergence into the same solutions in other environments. Additionally, it points out a potential issue with overestimating the true maximum value. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, citing specific examples from the paper, such as a slight performance decrease in MsPacman and convergence into the same solutions in other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. It also mentions a potential issue with overestimating the true maximum value. While the comment provides some evidence and examples, it lacks detailed reasoning or references to support the claim fully. The authors would need to delve deeper into the paper and possibly external literature to fully understand and address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment raises concerns about the effectiveness of lower bound double qlearning, specifically pointing out a slight performance decrease in MsPacman and convergence into the same solutions in other environments. It also mentions a potential issue with overestimating the true maximum value. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how the authors might address these issues or improve their work. The feedback is 3 as it highlights potential weaknesses, but it does not provide actionable steps for improvement, leaving the authors with a general direction but no specific path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the work or suggestions for alternative approaches that could be explored. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the interpretation of deep neural networks using a linear model. However, it does not specify which part of the paper discusses this novelty or where the authors could improve it. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity as it does not provide detailed guidance on how to enhance the novelty or suggest alternative approaches. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the work, specifically pointing out that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any suggestions or guidance on how the authors might enhance the novelty of their work or explore alternative approaches. Without actionable feedback or constructive suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below, but instead, it becomes worse. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what changes might be necessary to clarify the performance trend. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and it provides an expectation of how the performance should behave. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It suggests that the performance should approach vanilla methods from below but instead becomes worse. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this trend is unexpected or how it relates to the literature. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance trend of DNN+MMA compared to vanilla DNN when lambda becomes small. It points out a discrepancy in the expected behavior, suggesting that the performance should approach vanilla methods from below but instead becomes worse. This feedback is 3 as it identifies a potential issue in the analysis or presentation of results, prompting the authors to reconsider their interpretation or presentation of the data. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional analysis or clarification in the figures. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so in the author response. The comment suggests that the authors have compared their results to earlier systems with worse performances, which is noted as a point of interest. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their comparisons or provide a more comprehensive evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of not comparing results with earlier research work from 2020 and references the authors\" response regarding stateoftheart systems. It also provides a specific example of earlier systems with worse performances (Taghipour and Ng, 2016) that the authors have compared their results to. This allows the authors to accurately identify the part of the paper being addressed and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with earlier research work from 2020, despite the authors providing a reason for not doing so. The comment highlights a potential inconsistency in the comparison, noting that the authors have compared their results to earlier systems with worse performances. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to delve deeper into the paper and the author response to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a specific issue with the paper\"s comparison to earlier research work, noting that the authors have not compared their results with systems from 2020, despite providing a reason for not doing so in the author response. The comment highlights a potential inconsistency in the comparison, as the authors have compared their results to earlier systems with worse performances. This feedback is 3 as it identifies a potential weakness in the paper\"s evaluation and suggests that the authors should reconsider their comparisons. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of relevant studies from 2020 for comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors have reported significance testing but questions the choice of test. It implies that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. While the comment identifies a potential issue with the choice of test, it does not explicitly instruct the authors to use a paired test setting. The action is implicit and somewhat vague, as the authors need to infer that they should consider using a paired test. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the significance testing reported in the paper, questioning the choice of test. It suggests using a paired test setting, such as the Wilcoxon signedrank test, for comparing two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing, making it weakly grounded. The suggestion to use a paired test setting is specific, as it provides a clear alternative approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. The comment provides a logical reasoning for the suggestion, as it explains the context in which a paired test would be more suitable. However, it lacks specific examples or references to support the claim that the current test choice is incorrect. This makes the claim 3, as the authors would need to consider the reasoning and potentially conduct further research to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the rigor and validity of the statistical analysis. However, the comment could be more helpful if it explained why the current test choice is inappropriate or provided additional context or examples to support the suggestion. Overall, the comment is 4 as it directs the authors to a potential improvement in their methodology, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the experiments. The authors are left to infer that they need to expand their experiments and consider larger models or more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limitations of model size and restrictive baselines in both the language modeling and image classification tasks. However, it does not specify which parts of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its critique of the experiments but lacks grounding, as it does not provide a clear reference to the sections or figures where these experiments are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines in both the language modeling and image classification tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the limitations and how to address them. The lack of detailed justification or evidence renders the claim 3, as the authors would need to infer the specific issues and how to improve the experiments based on the general feedback provided.", "helpfulness_rationale": "The review comment identifies a limitation in the comprehensiveness and generality of the experiments, specifically noting that the model size is limited and the baselines are restrictive. This feedback is 3 as it points out an area for improvement, suggesting that the authors should consider expanding their experiments to include more comprehensive and general evaluations. However, the comment lacks specific guidance or suggestions on how to achieve this expansion, such as recommending additional models or baselines to include. While it provides some direction, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. While the comment implies that the authors should consider incorporating this approach, it does not provide explicit instructions on how to do so or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the potential benefits and implementation details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. However, it does not specify which part of Table 1 this suggestion pertains to, nor does it provide detailed guidance on how to incorporate this approach. The authors can infer that it relates to the experimental setup or results section, but the lack of specificity and explicit references make it difficult to pinpoint the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. However, the comment does not provide any reasoning, examples, or references to support why this approach would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML or implicitMAML, to Table 1. While it provides a specific suggestion for improvement, it lacks detailed guidance on how to implement this approach or why it would be beneficial. The comment does not offer a clear rationale for why this addition would enhance the paper or provide examples of how it could be integrated. As a result, the feedback is 3, as it identifies a potential area for improvement but lacks depth and actionable details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This implies that the authors should conduct an ablation study to demonstrate the effectiveness of their prompt choice. While the comment identifies the need for an ablation study, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. This implies that the authors should provide more detailed analysis or experiments to justify their prompt selection. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in suggesting the need for an ablation study, but without explicit references to specific parts of the paper, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of fewshot examples for CoT. The comment suggests that an ablation study could improve performance. However, it does not provide specific examples or detailed reasoning to support why an ablation study is necessary or how it would improve the paper. The claim is 3 as it highlights a potential gap in the paper, but it lacks concrete evidence or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of an ablation study to explain the choice of prompt. It suggests that an ablation study could help clarify why the chosen prompt is effective, particularly in the context of CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s methodology and analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, distinguishing them from \"temporal relationship.\" This feedback is direct and provides a clear action for the authors to take, ensuring that they use these terms accurately in their draft. The comment is explicit and concrete, offering a specific correction that the authors can apply to improve their manuscript. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of using the terms \"causal mechanisms\" and \"causality\" interchangeably with \"temporal relationship,\" providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of terms \"causal mechanisms\" and \"causality,\" suggesting that they should be used carefully to distinguish them from \"temporal relationship.\" This is a factual statement asking for precision in terminology, rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, pointing out a potential confusion in the use of terms related to causality and temporal relationships. By suggesting that the authors use these terms carefully, the comment provides a direct and actionable piece of feedback that can help improve the clarity and accuracy of the manuscript. However, it could be more helpful if it offered examples or further guidance on how to distinguish between these concepts. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the strength of the claim that replacing procedure steps of XAIFOOLER with a random mechanism resulted in better performance than random. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to strengthen the demonstration of capability or what specific changes could be made to improve the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the section being addressed. It is also specific because it questions the strength of the claim that \"better than random\" is a strong demonstration of capability, providing a clear point for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the strength of the claim that replacing procedure steps of XAIFOOLER with a random mechanism resulted in better performance than random. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment questions the strength of a claim made in the paper regarding the performance of XAIFOOLER when compared to a random mechanism. It suggests that \"better than random\" may not be a strong demonstration of capability, implying that the authors should provide more robust evidence or comparisons to substantiate their claims. However, the comment lacks specific guidance or suggestions on how the authors might improve their demonstration of capability or what additional evidence could be included. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels\". While the comment implies that the authors should address this gap, it does not provide explicit instructions on how to integrate this discussion into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the relationship between their results and the referenced work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on the relationship between the results and the referenced work, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this discussion should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" The comment provides a specific reference to a relevant work, which supports the claim by establishing a connection to existing research. However, the comment does not elaborate on why this discussion is important or how it would enhance the paper. While the reference provides some context, the claim could be more 5 with additional explanation or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" This feedback is clear and actionable, as it identifies a specific area where the authors could enhance their paper by providing a connection to existing work. By addressing this suggestion, the authors can provide a more comprehensive understanding of their results and their relevance to the broader field. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion or what aspects of the results should be highlighted. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clear results. The reviewer questions how well the assumptions underlying PCA are met. While the comment implies that the authors should provide more information on the assumptions and their validation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their validation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, questioning the clarity of the results. It provides a logical reasoning by explaining the intuitive nature of PCA and the importance of understanding the assumptions it makes. However, the comment does not specify which part of the paper discusses the use of PCA or the results that are unclear. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its critique of the novelty and significance of the approach, but without explicit references to specific sections or results, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems incremental and lacks clear results. The reviewer provides a logical reasoning by explaining the intuitive nature of PCA and the importance of understanding the assumptions it makes. However, the comment lacks specific examples or references to support the claim that the results are unclear or that the assumptions are not met. While the reference to Dombrowski et al. (2022) is provided, it does not directly relate to the claim being made about the paper. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or specific references to substantiate the critique. This aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty and significance of using PCA to reduce interaction count, suggesting that it may seem incremental and lacks clear results. The reviewer provides a logical explanation of the intuitive nature of PCA and questions how well the assumptions underlying its use are met. This feedback is 3 as it prompts the authors to clarify the novelty and significance of their approach and to provide more information about the assumptions and their validation. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of how to better articulate the results. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the fewshot RC models considered in the paper are not stateoftheart models and questions how their performance compares to relation extraction/generation models in fewshot settings. While the comment raises a concern and asks for a comparison, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the fewshot RC models considered in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison of the models to stateoftheart models and relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, providing references to support this claim. However, the comment lacks detailed analysis or comparison of the models to substantiate the claim fully. While the references are included, the comment could benefit from more explicit reasoning or examples to fully justify the claim. Therefore, the comment is 4, as it provides some support but requires additional details for a more comprehensive understanding.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the fewshot RC models considered are not stateoftheart models. It provides references to support this claim, which is helpful for the authors to understand the context of their work. Additionally, the comment raises a question about how the performance of these models compares to relation extraction/generation models in fewshot settings, prompting the authors to consider this aspect for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of stateoftheart models for comparison. Overall, the comment is 4 as it highlights an area for improvement and encourages the authors to consider a broader context, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the results in Section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors might expand their results to other types of networks or what specific changes they should make to their analysis. Without any guidance or direction, the authors are left without a clear understanding of how to address this limitation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation of the results, which is that they only apply to shallow fullyconnected ReLU networks. This provides clear guidance on what needs to be addressed or expanded upon in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific limitation of the results presented in Section 4, noting that they only apply to shallow fullyconnected ReLU networks. While this feedback identifies a potential area for expansion or generalization of the results, it lacks depth and does not provide suggestions on how the authors might address this limitation or explore broader applicability. The comment highlights an important aspect of the paper but does not offer actionable guidance for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. While the comment implies that these changes should be made, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement these changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, it does not specify which part of the paper is lacking in this regard, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding, as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, the comment lacks specific examples or detailed reasoning to support why these changes are necessary or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the organization of the paper, suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific area for improvement, it lacks detailed guidance or actionable suggestions on how to implement these changes. The feedback is 3 as it points out a general area for improvement but does not provide specific steps or examples to aid the authors in making these changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. While it identifies a gap in the comparison, it does not provide explicit guidance on which models should be included or how to incorporate them into the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to add these models to their comparison but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some other representative panoptic segmentation models,\" which allows the authors to identify the specific part of the paper being addressed, namely the comparison section. It is also specific because it names specific models like PanopticFPN and Mask2Former, indicating what is missing from the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models are not compared, specifically mentioning PanopticFPN and Mask2Former. However, the comment does not provide any reasoning or evidence to support why these models should be included in the comparison or how they would impact the evaluation. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the comparison of panoptic segmentation models, specifically mentioning the absence of PanopticFPN and Mask2Former. This feedback is 3 as it points out a potential area for improvement in the evaluation section of the paper. However, it lacks depth and does not provide specific guidance on how to incorporate these models into the comparison or why they are relevant. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. It explicitly asks the authors to speak about what was observed, implying that the authors should include this information in their discussion. The action is clear and direct, providing a specific request for additional content. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion of using sequential MCB vs a single MCT layers for the decision head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of results and requests that the authors discuss what was observed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for additional information or clarification regarding the results of using sequential MCB vs a single MCT layer for the decision head. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for more information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the discussion by noting that the results for using sequential MCB vs a single MCT layer for the decision head are not presented. It requests that the authors provide some insight into what was observed, which could be valuable for the reader\"s understanding of the methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or what aspects of the results should be discussed. While it points out an area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically suggesting that they should proofread the paper to correct language usage issues. It also provides examples of specific language problems, such as \"we typically considers,\" \"two permutation,\" and \"until converge,\" which need to be corrected. This feedback is clear and concrete, giving the authors a direct path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"the above of (7),\" \"Theorem 1,\" and \"the above of (14),\" allowing the authors to accurately identify the sections that need attention. It is also specific because it points out language usage issues, providing examples of phrases that need correction, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" This level of detail guides the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of minor comments on language usage, providing specific examples of phrases that need correction, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" These suggestions are factual and descriptive, aiming to improve the clarity and accuracy of the paper. Since they do not express opinions, judgments, or suggestions that require verification, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of minor language issues that need to be corrected, such as \"we typically considers,\" \"two permutation,\" and \"until converge.\" While it identifies specific areas for improvement, it lacks depth and does not offer suggestions on how to address these issues or why they are important. The comment is 3 as it points out areas for improvement, but it could be more beneficial if it included explanations or guidance on how to correct these language issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify or address these concerns, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or clarification regarding the choice of distribution sets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the distribution sets are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its questioning of the choice and control of distribution sets, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specificity and does not provide any suggestions or guidance on how the authors might address these questions. The feedback is 3 as it prompts the authors to consider these aspects, but it does not offer actionable advice or detailed insights to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the limited scope of the evaluative framework, specifically mentioning its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or expand the scope of their framework. The action is implicit and vague, as the authors are left to infer that they should consider broader applicability and potential generalization, but without concrete steps or examples, it remains unclear how to implement these suggestions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluative framework, specifically mentioning its limited scope due to the focus on only three QuestionAnswering tasks and two language models. However, it does not explicitly mention which part of the paper discusses this framework, making it weakly grounded. The comment is specific in detailing the limitations and suggesting potential areas for broader applicability, such as considering other reasoning or generation tasks or more advanced models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope due to its focus on only three QuestionAnswering tasks and two language models. It suggests that this restricts the method\"s broader applicability and questions its potential to generalize to other tasks or more advanced models. However, the comment lacks specific examples or references to support the claim about the limitations of the framework or the potential for broader applicability. The reasoning is somewhat vague and does not provide detailed justification or evidence, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. It raises concerns about the method\"s broader applicability and suggests that its potential to generalize to other reasoning or generation tasks or more advanced models is uncertain. This feedback is 3 as it points out a potential weakness in the framework, prompting the authors to consider expanding their evaluation to include a broader range of tasks and models. However, the comment could be more helpful if it provided specific suggestions or examples of additional tasks or models that could be included. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct perplexity experiments using more current language models, specifically transformerbased (masked) language models, to better align their paper with current NLP trends. This is an explicit action with concrete guidance on how to improve the draft by specifying the type of models to use. The authors know exactly what needs to be done to enhance their work, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"perplexity experiments\" and \"obsolete language models (ngram HMM, RNN),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the use of transformerbased (masked) language models to align the paper with current NLP trends. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the perplexity experiments are conducted on outdated language models (ngram HMM and RNN) and recommends using transformerbased models instead. This claim is 3 as it provides a logical reasoning for the suggestion, noting that the current models are rarely used. However, the comment lacks specific examples or references to support the claim that transformerbased models are more appropriate or current in NLP trends. Providing such examples or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on outdated language models (ngram HMM and RNN) that are no longer commonly used. It provides a clear and actionable suggestion for improvement by recommending the use of transformerbased (masked) language models to align the paper with current NLP trends. This feedback is valuable as it directs the authors to update their experiments to reflect more contemporary models, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these new models or addressed potential challenges in doing so. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors need to conduct more empirical experiments or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, suggesting the need for more empirical or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. However, the comment does not specify which experiments are insufficient or where these experiments should be conducted, making it weakly grounded. The authors can infer that it relates to the experimental sections, but the lack of specific references or detailed guidance makes it difficult to pinpoint the exact parts of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests conducting more empirical or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. The comment also mentions the need to cite the result in Kaplan et al. 2020. While the suggestion for additional experiments is logical and provides a clear direction for improvement, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to Kaplan et al. 2020 provides some context but does not fully support the claim about the sufficiency of the current experiments. Therefore, the comment is 3, as it provides a logical basis but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the insufficiency of the experiments. It provides a clear and actionable suggestion by recommending the need for more empirical experiments or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. Additionally, it mentions the importance of citing the result in Kaplan et al. 2020, which adds context to the suggestion. This feedback is 5 as it directs the authors to a specific area for improvement, offering a clear path forward to enhance the validity and robustness of their work. However, it could be more helpful if it provided specific examples or guidance on how to conduct these additional experiments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of \"mu,\" which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion of \"muestimation\" in the paper, implying that it is related to the proportion of missing observations. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of \"mu,\" but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the estimation of \"mu,\" which is described as the proportion of missing observations. The comment highlights a lack of clarity regarding how \"mu\" can be estimated, suggesting that the authors have not provided sufficient information on this aspect. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim of lack of clarity. This makes the claim 3, as it points out an area that needs clarification but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the estimation of \"mu,\" which is described as the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might clarify this issue or improve the discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific action for the authors to take: presenting the performance as a function of the distance of initialization to the groundtruth. It provides a clear and concrete method for implementing this suggestion, including specific steps such as varying the distance c and reporting the performance accordingly. The comment also offers an expectation of the outcome, which further guides the authors on what to expect. This level of detail and explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. It provides a clear and actionable suggestion, but it does not specify which part of the paper this analysis should be included in. While the authors can infer that it relates to the experimental or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific, as it outlines a method for analyzing sensitivity to initialization, but the lack of explicit grounding limits the comment to being 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests an analysis of sensitivity to initialization by proposing a specific method to present performance as a function of the distance of initialization to the groundtruth. The suggestion is supported by logical reasoning, as it is based on the expectation that the mean error and variance would increase as the quality of initialization decreases. However, the comment lacks specific examples or references to existing literature that might support this expectation, making it 3. The authors would need to consider this suggestion and potentially conduct additional analysis to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by analyzing the sensitivity to initialization. It proposes a method to present performance as a function of the distance of initialization to the groundtruth, which could help in understanding how the quality of initialization affects the results. This feedback is clear and offers a concrete way for the authors to enhance their analysis, making it 5 for improving the draft. However, the comment could be more helpful if it included additional context or examples of how this analysis might impact the overall findings or conclusions of the paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of the Frobenius norm, namely the unnecessary use of the absolute value operation due to the real nature of tensor entries. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that since tensor entries are real, taking the absolute value does not add any value to the calculation. The comment provides a clear and straightforward explanation, making it 5. The authors can easily understand and address this point by removing the absolute value operation, as suggested. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm in the paper, specifically pointing out that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can be easily implemented by the authors. However, the comment could be more helpful if it explained why this change is important or how it might impact the overall analysis or results. Despite this, the comment is still valuable as it directs the authors to a precise area for refinement, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should consider providing highprobability bounds, specifically mentioning the use of ensemble methods as performed in the experiments. It also suggests adding a measure of robustness to the experiments, such as error bars or standard deviation, in addition to the mean error. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment suggests providing highprobability bounds and mentions ensemble methods as a possible approach, referencing the experiments. It also suggests adding a measure of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results section. The suggestion to use ensemble methods and add robustness measures is specific, providing clear guidance on how to improve the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and asks if it would be possible to obtain highprobability bounds. It mentions ensemble methods as a potential approach and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that ensemble methods could be used to achieve highprobability bounds. This makes the claim 3, as it provides a direction for improvement but requires further elaboration or evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by noting that only bounds in expectation are provided, and it suggests that highprobability bounds could be beneficial. It offers a specific suggestion to use ensemble methods, as demonstrated in the experiments, to achieve these bounds. Additionally, the comment recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to enhance the robustness and comprehensiveness of their results. However, the comment could be more helpful if it included examples or further explanation of how to implement these suggestions. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the motivation of the paper but expresses skepticism about the results, suggesting that they should be evaluated from more aspects. The reviewer specifically mentions the need to consider actual latency on the target device, memory consumption during inference time, and the actual network size. While the comment implies that the authors should expand their evaluation to include these aspects, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add more evaluation aspects but are not given specific guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation and results of the paper, specifically mentioning that the results seem less impressive. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in suggesting additional aspects to evaluate, such as actual latency on the target device, memory consumption during inference time, and the actual network size. This provides clear guidance on what the authors should consider for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point expresses skepticism about the results, suggesting that they are less impressive and should be evaluated from more aspects. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to evaluate results from additional perspectives, such as actual latency and memory consumption, is a logical step but is not fully substantiated with evidence or detailed reasoning. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the motivation of the paper but expresses skepticism about the results, suggesting that they are less impressive. It provides a constructive suggestion by recommending that the results be evaluated from more aspects, such as actual latency on the target device, memory consumption during inference time, and the actual network size. This feedback is actionable and offers a clear direction for the authors to enhance their evaluation and potentially improve the paper. However, the comment could be more helpful if it provided specific examples or references to support the claim about the results being less impressive. Overall, the comment is 4 as it guides the authors toward a more comprehensive evaluation, but it could be more detailed to fully address the authors\" needs."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the paper\"s motivation for \"diversity\" but notes that the model does not enforce diversity explicitly. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their model to enforce diversity. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the paper\"s motivation for \"diversity\" and the lack of explicit enforcement of diversity in the model. However, it does not specify which part of the paper discusses the motivation for diversity or where the model is described, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the lack of diversity enforcement but lacks grounding, as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the model does not enforce diversity, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for \"diversity\" and the lack of explicit enforcement of diversity in the model. This is a critical observation that could impact the paper\"s validity and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their model to enforce diversity. Without actionable feedback, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it highlights a key area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, as it specifies exactly which experiments are missing and what the authors should add. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically referencing contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are missing from, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the missing experiments but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would enhance the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the significance of these missing experiments. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, such as contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to include these experiments in their draft. However, the comment could be more helpful if it offered additional context or explanation about why these experiments are important or how they might enhance the paper. Despite this, the feedback is 4 as it gives the authors a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons, referencing a specific source \"[C]\". This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The reference to \"[C]\" adds specificity by indicating the source of the suggestion, making the action 5.", "grounding_specificity_rationale": "The comment suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons, referencing a specific source \"[C]\". While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or comparison sections where FIDs are discussed. The comment is specific in suggesting an alternative metric and referencing a source, providing clear guidance on how to improve the evaluation. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using DinoV2 Frechet Distances instead of FIDs for evaluation, citing \"clear flaws\" associated with FIDs and referencing a specific source \"[C]\" for the Inception network. However, the comment does not provide detailed reasoning or examples of these flaws, nor does it specify how DinoV2 Frechet Distances would be more appropriate. This lack of detailed justification or evidence makes the claim 3, as the authors would need to investigate the referenced source to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an alternative evaluation metric, DinoV2 Frechet Distances, in addition to the widely used FID metric. This is a clear and actionable suggestion that can help improve the robustness and comprehensiveness of the evaluation in the paper. By referencing a specific source, \"[C],\" the comment provides a basis for the recommendation, which is helpful for the authors in making an informed decision about their evaluation approach. However, the comment could be more helpful if it provided additional context or explanation about why DinoV2 Frechet Distances are preferred over FIDs, which would enhance its utility for the authors. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the novelty of the paper, questioning whether it offers significant differences from an existing work. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the novelty of their work. The comment implies that the authors should clarify the differences between their work and the referenced paper, but it does not specify how to do so or what aspects to focus on. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper, questioning whether it offers significant differences from an existing work. However, it does not specify which part of the paper this concern relates to, making it weakly grounded. The comment does provide a specific reference to an existing work, which could help the authors understand the context of the concern. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty of the paper, questioning whether it offers significant differences from an existing work. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed comparisons to justify the assertion that the paper\"s novelty is incremental. Without such support, the claim remains 1, as the authors would need to make significant efforts to understand and address the concern. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it offers significant differences from an existing work. It references a specific paper and asks for clarification on how the current paper differs. While the comment identifies a potential issue with the paper\"s originality, it lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the uniqueness of their contribution, but it does not provide actionable steps or detailed advice for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer questions the logic behind this observation, asking \"Why?\" However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what steps they should take to improve their draft. The authors are left without a clear understanding of what needs to be done to resolve the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the ablation studies, noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The comment raises a question about the logic behind this observation, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer asks \"Why?\" without providing any supporting evidence, reasoning, or references to justify the claim. This lack of justification makes the comment 1, as it does not offer any basis for the authors to understand or address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. This observation raises a logical question about the rationale behind these results, prompting the authors to reconsider their approach or provide a clearer explanation. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential problem, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting an experiment where the image is occluded, which would simulate irregularities in neural/behavioral data and allow for the inspection of the model\"s longrange inference capacity. The reviewer emphasizes that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. This feedback is clear and direct, providing the authors with a specific action to take and a clear expectation for the final version of the paper. The action is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which is a specific request for additional experimentation. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what the authors should do, namely conducting an occlusion experiment to simulate irregularities and assess the model\"s longrange inference capacity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data and to assess the model\"s longrange inference capacity. The reviewer provides a logical reasoning for why this experiment would be beneficial, explaining that it would allow for the inspection of the model\"s ability to handle irregularities. However, the comment lacks specific references or examples to support the claim that such experiments are \"reasonably easy\" to run or that they are necessary for a comprehensive evaluation. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by proposing an experiment where the image is occluded. This experiment is designed to simulate the irregularities often present in neural/behavioral data, such as keypoint detection failures in some mice in certain frames. The reviewer explains that this would allow for the assessment of the model\"s longrange inference capacity, which is a valuable addition to the study. The comment is clear and provides a concrete suggestion for enhancing the paper, making it 4. However, it could be more helpful if it offered additional guidance on how to implement this experiment or what specific aspects to focus on. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an action: \"I would suggest using a second yaxis or another visualization which is more physically accurate.\" This provides a clear and concrete direction for the authors to improve their draft by addressing the issue with Figure 6C. The suggestion is specific and actionable, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates when it should not, and suggests using a second yaxis or another visualization to address this issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization to address this issue. However, the comment does not provide any evidence or reasoning to support the claim that the figure implies negative rates. Without specific examples or references, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates when it should not. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a second yaxis or another visualization that is more physically accurate. This feedback is specific and offers a concrete way for the authors to improve their draft, making it 4. However, the comment could be more helpful if it included additional context or examples to further clarify the issue and the suggested solution. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as it might be beneficial. However, the comment does not provide explicit guidance on how to implement this suggestion or which specific models should be tested. The action is implicit and somewhat vague, as the authors would need to infer that they should conduct additional experiments to explore this idea. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as they did not do so in their experiments. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an additional test, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as they did not do so in their experiments. This claim is 3, as it provides a logical suggestion for further experimentation. However, it lacks specific examples or references to other embedding models that could benefit from inverse triples, which would strengthen the justification. The authors would need to infer which models might be relevant and why, making the claim 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as they did not do so in their experiments. This feedback is 3 as it identifies a potential area for further exploration and improvement in the paper. However, it lacks specific guidance on which models to test or how to incorporate these tests into the existing framework. While it provides a direction for expansion, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the statement in the abstract is unclear and suggests that it should be more highlevel, avoiding technicalities. This provides a direct action for the authors to revise the abstract to make it more accessible and less technical. The comment is clear and concrete in its guidance, indicating that the authors should simplify the language used in the abstract. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract\" and the specific statement that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that it should be more highlevel. However, the comment does not provide specific examples or detailed reasoning to support why the statement is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, pointing out that a particular statement is unclear. It suggests that the abstract should be more highlevel and avoid technicalities, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of the technicalities should be avoided. Despite this, the feedback is 4 as it directs the authors to simplify their abstract, making it more accessible to a broader audience. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any explicit guidance or suggestions on how to achieve this improvement. The action is implicit and vague, as the authors are left to infer what specific changes could be made to enhance the complexity of the algorithm. Without concrete details or examples, the authors may struggle to determine how to address this feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that there is room for improvement in the complexity of Algorithm 2, but it does not specify what aspects of the algorithm\"s complexity need improvement or how it could be enhanced. The authors can infer that the comment is related to the algorithmic section of the paper, but without specific guidance, it is difficult to pinpoint the exact part that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that there is room for improvement in the complexity of Algorithm 2, but it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the complexity of Algorithm 2, suggesting that there is still room for enhancement. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable feedback or detailed advice, the authors are left with a general direction but no clear path forward. This makes the comment 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced comment about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. While the comment implies that the authors should expand their results to include other modalities, it does not provide explicit instructions on how to do so or which specific modalities to consider. The suggestion is concrete in terms of the modalities to explore but lacks detailed guidance on implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced comment about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results section, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in suggesting the inclusion of results in other modalities and the consideration of OOD performance, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including results in other modalities, such as languagerelated tasks, would be beneficial. It also notes that for languagerelated tasks, outofdistribution (OOD) performance is important, which might make expected test loss less meaningful. However, the comment lacks specific examples or references to support the claim that including results in other modalities would be valuable or that OOD performance is particularly relevant for language tasks. This makes the claim 3, as it provides a general suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment suggests that the authors should include results in other modalities, specifically mentioning languagerelated tasks. It also provides a nuanced observation about the relevance of expected test loss for languagerelated tasks, noting that outofdistribution (OOD) performance is also important. This feedback is 3 as it identifies a potential area for expansion and provides a specific suggestion for improvement. However, it could be more helpful if it offered guidance on how to incorporate these additional modalities or provided examples of languagerelated tasks that could be explored. Overall, the comment provides some direction but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically in the context of fewshot learning. It highlights the need to explain how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to provide more justification and details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically in the context of fewshot learning for graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the authors should provide this additional justification. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing what needs to be addressed, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically in the context of fewshot learning. It provides a logical reasoning by explaining that the paper defines a fewshot situation for graph link prediction but does not address how to effectively use \"fewshot\" instances or guarantee generalizability to new tasks. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the motivation behind the work. It highlights the importance of explaining how the proposed method effectively uses \"fewshot\" instances and guarantees generalizability to new tasks with limited training steps. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to enhance the justification or provide additional details. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their approach or what specific aspects of their method could be enhanced. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while the comment provides some context about the GP community, it does not specify what aspects of the GP approach are considered naive or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of Gaussian Process (GP) is \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The reference to NIPs 2005 is a general reference and does not provide direct evidence or context for the claim. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Process (GP) as \"kind of straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPs 2005. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their approach or address the perceived naivety in their use of GP. Without detailed feedback or constructive suggestions, the authors are left without a clear path for improvement, making the comment 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014) and suggests that the baseline models may not be properly regularized. The comment raises a specific concern about the application of dropout to both embeddings and hidden states. While the comment identifies a potential issue and provides a reference, it does not explicitly instruct the authors to address the concern or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the regularization methods used in their models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental section D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a particular statement about the necessity of smaller architectures for language models compared to GAN models, and it provides a counterexample from Zaremba et al. (2014) to support the claim. Additionally, the comment raises a question about the application of dropout to both embeddings and hidden states, which further specifies what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions a statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. The comment also raises a question about the application of dropout to both embeddings and hidden states. This provides some justification for the claim, as it references a specific study and raises a potential issue with the regularization methods used. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it offers a solid foundation for the authors to address but lacks complete evidence. This aligns with a score of 4.", "helpfulness_rationale": "The review comment questions a specific statement in the supplemental section D.4 regarding the necessity of smaller architectures for language models (LM) compared to GAN models to avoid overfitting. The reviewer provides a counterexample from Zaremba et al. (2014), which suggests that the baseline models may not be properly regularized. This feedback is 3 as it points out a potential issue with the statement and raises a question about the application of dropout to both embeddings and hidden states. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or suggested specific experiments to conduct. Overall, the feedback is 3 as it identifies a potential weakness and prompts the authors to reconsider their statement, but it lacks depth and actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content. It suggests that the writing could be improved in this part. However, the comment does not provide specific guidance on how to improve the writing or which ablations are particularly problematic. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without clear instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are hard to locate in the following content, indicating a need for improvement in the writing. However, it does not specify which sections or ablations are being referred to, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is specific in its suggestion to improve the writing but lacks grounding as it does not provide clear references to the sections or content being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are hard to locate in the following content. However, it does not provide specific examples or details about which ablations are difficult to find or how the writing could be improved. This lack of detailed information makes it challenging for the authors to understand and address the issue effectively. As a result, the comment is considered 1, as it lacks sufficient evidence or reasoning to support the claim.", "helpfulness_rationale": "The comment identifies a specific issue with the organization of the paper, noting that some ablations mentioned in previous sections are difficult to locate in the subsequent content. This feedback is 3 as it points out a potential problem with the paper\"s structure, suggesting that the writing could be improved to better connect these sections. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or which sections are particularly problematic. While it highlights an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the differential privacy application is not fully developed and encourages the authors to think it through more clearly. It also highlights the novelty of the online algorithm and robustness, and recommends moving the experimental results from the appendix to the main paper. While the comment provides some guidance on areas for improvement, it lacks specific instructions on how to enhance the differential privacy application or what aspects to focus on. The action is implicit and somewhat vague, as the authors are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given 2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the differential privacy application, suggesting that it is \"halfbaked\" and encouraging the authors to think it through more clearly. Additionally, it highlights the novelty of the online algorithm and robustness and recommends moving the experimental results from the appendix to the main paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think it through more clearly. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The mention of the online algorithm and robustness being \"significantly interesting and novel\" is a positive statement but does not contribute to the verifiability of the claim about the differential privacy application. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a mixed assessment of the paper, acknowledging the novelty of the online algorithm and robustness but expressing concerns about the differential privacy application being \"halfbaked.\" It encourages the authors to think through this aspect more clearly. Additionally, it suggests moving the experimental results from the appendix to the main paper, which could enhance the paper\"s clarity and impact. However, the comment lacks specific guidance on how to improve the differential privacy application or what aspects need further development. While it identifies areas for improvement, the feedback is 3 as it provides a general direction but lacks detailed actionable suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, stating that the former is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the comparison or what specific aspects need to be improved. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not specify which part of the paper this comparison is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a comparison between the contribution of multilingual chainofthought and the villa chainofthought, suggesting that the former is incremental. However, it lacks specificity and does not offer any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the comparison or enhance their contribution. As a result, the comment is 1, as it does not provide any actionable insights or constructive feedback for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what changes or clarifications are needed to resolve the ambiguity. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of methodology specificity, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be tailored to bimanual manipulation and that robotic manipulation alone could be more appropriate. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. This is a relevant point that could help the authors clarify the scope and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this issue. It does not offer actionable guidance on how to improve the methodology or clarify its relevance to bimanual manipulation. As a result, while the comment identifies a potential area for improvement, it is incomplete and does not fully support the authors in enhancing their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide METEOR results, which are also reported in recent works. This is a clear and direct action that the authors can take to improve their draft. The comment also provides additional context by mentioning recent works that report METEOR results, which gives the authors a concrete basis for their action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to provide METEOR results, which should be obvious to the authors. It also specifies what needs to be addressed by referencing recent works that report METEOR results. This provides clear guidance on what the authors should include in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include METEOR results, which are also reported in recent works. However, it does not provide specific references to these recent works or explain why METEOR results are important or relevant to the paper. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the importance of METEOR results and find the relevant references on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to include METEOR results, which are also reported in recent works. This feedback is specific and provides a concrete suggestion for improvement, allowing the authors to enhance their draft by addressing a gap in their presentation. However, the comment could be more helpful if it explained why METEOR results are important or how they relate to the broader context of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, as the paper studies each objective in isolation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the comparability of their results. The comment implies that the authors should consider a more comprehensive approach to comparing Geffect values, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across different unlearning objectives and approaches, as the paper studies each objective in isolation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically noting that the study of Geffects for each unlearning objective in isolation may raise concerns about the comparability of Geffect values across different approaches. This is a valid observation that could impact the interpretation of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it highlights a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It questions whether the authors have a theory explaining why the method is less effective in this setting. While the comment raises a specific issue and suggests that the authors should address it, it does not provide explicit guidance on how to develop a theory or improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should explore theoretical explanations for the observed inconsistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the tables\" and \"the 1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting, and asks for a theoretical explanation for this observation. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It supports this claim by referencing the tables, which show that UNIFORM does not always offer a clear advantage. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim. While it provides some evidence, the lack of detailed reasoning or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the advantage of the UNIFORM procedure over other methods is not consistent, particularly in the 1shot setting. It points out that the tables show UNIFORM does not always offer a clear advantage, prompting the authors to consider why this might be the case. The comment also acknowledges that the clarity and design of the experiments and results are well done. However, it could be more helpful if it provided suggestions on how the authors might address the inconsistency or explore theoretical explanations for the observed effect. Despite this, the comment offers a clear direction for the authors to investigate and improve their work, making it 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider the reason behind the information value being a \"stronger predictor\" for dialogue, specifically referencing the complementarity discussed on page 7 or the discussion on page 8. It implies that adding an explanation or reference to an existing linguistic theory could strengthen the paper. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them to add the explanation or reference. The action is mostly implicit, as the authors need to infer that they should include this information. However, the suggestion is concrete, as it specifies the areas to focus on and the potential impact on the paper. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the information value being a \"stronger predictor\" for dialogue and suggests that the authors should consider existing linguistic theories that could explain this phenomenon. By recommending the inclusion of such theories, the comment provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the information value being a \"stronger predictor\" for dialogue could be explained by existing linguistic theories. However, it does not provide specific references or examples of such theories, making the claim 3. The authors would need to conduct additional research to identify relevant theories and incorporate them into their work. While the comment provides a direction for improvement, it lacks detailed justification or evidence, making it 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider the reason behind the information value being a \"stronger predictor\" for dialogue. It references specific pages (7 and 8) where the complementarity is discussed, providing a clear direction for the authors to explore. The comment also implies that incorporating an explanation or reference to existing linguistic theories could strengthen the paper. While the feedback is actionable and provides a specific area for enhancement, it could be more helpful if it offered examples of relevant linguistic theories or suggested how to integrate them into the discussion. Overall, the comment is 4 as it guides the authors toward a meaningful improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived gap in the paper regarding the potential benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. The reviewer suggests that the authors should have spent more time discussing these aspects and provides an example by asking about the biggest takeaways from the found architecture. While the comment implies that the authors should address this gap, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate this discussion into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" discussion on the benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. However, it does not specify which part of the paper this discussion is lacking in, making it weakly grounded. The comment is specific in suggesting that the authors should have spent more time on this aspect and provides an example by asking about the biggest takeaways from the found architecture. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main benefit of using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of supporting evidence or references renders the claim 1, as it does not provide a clear basis for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the discussion of AutoML approaches and their benefits beyond improving raw performance. It suggests that the authors should have spent more time on the aspect of extracting hints for future network architecture design. The comment provides a specific example by asking about the biggest takeaways from the found architecture, which could guide the authors in expanding their discussion. However, the comment could be more helpful if it offered suggestions on how to incorporate this discussion or provided examples of how other papers have addressed similar issues. Overall, the feedback is 3 as it points out an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the definition of \"T_a(t)\" between Section 3.1, where it is used, and Section 4, where it is defined. This comment explicitly identifies the issue and suggests that the authors should ensure consistency in the definition and usage of variables across different sections of the paper. However, it does not provide specific guidance on how to resolve this inconsistency, such as suggesting a reorganization of the sections or a clarification of the definition. While the action is clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of \"T_a(t)\" being used without being defined until Section 4. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the usage and definition of \"T_a(t)\" in the paper. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that \"T_a(t)\" is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency in the paper\"s structure, which could lead to confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a reorganization of the sections or a clarification of the definition. While it points out a weakness, the lack of actionable feedback limits its usefulness. Therefore, the comment is 3, as it provides some insight but lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While the comment implies that the authors should make these changes, it does not provide specific guidance on how to achieve conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors can infer that they need to make these changes but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the paper is being referred to, such as a specific section or chapter, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and that empirical results should be included, but it lacks detailed guidance on how to achieve these improvements. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, the comment lacks specific examples or detailed reasoning to support why the current content is not concise or why empirical results are necessary. Without these details, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies areas for improvement, the comment lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. This makes it 3, as the authors gain some insight into potential improvements but are left without actionable steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two distinct parts. The first part requests clarification on the empirical analysis in Figure 3, specifically asking for additional information on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The second part requests an explanation of why these adjustments are effective in enhancing the model\"s performance. The third part points out the large spacing between Equations (9) and (10) and the preceding text. While the comment identifies areas that need clarification and formatting improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take for each point. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also mentions \"Equations (9) and (10),\" providing further grounding. The comment is specific in its request for clarification on the empirical analysis, specifically asking for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also requests an explanation of why these adjustments are effective. Additionally, it points out the formatting issue with the equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple requests for clarification and additional information regarding the empirical analysis in Figure 3. It asks for details on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy, and why these adjustments are effective. Additionally, it points out a formatting issue with Equations (9) and (10). While the comment identifies areas that need clarification, it does not provide specific evidence or references to support the claims or suggestions. The inclusion of a reference to a related work by Liu et al. does not directly address the issues raised in the comment. Therefore, the comment is 3, as it provides a logical basis for the requests but lacks detailed evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas that require clarification and improvement in the paper. It points out that the empirical analysis in Figure 3 is confusing and requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also asks for an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment highlights a formatting issue with Equations (9) and (10), suggesting that they have large spacing from the preceding text. The inclusion of a reference to a related work by Liu et al. provides some context but does not directly address the issues raised in the comment. While the comment identifies specific areas for improvement, it could be more helpful by providing detailed guidance on how to address these issues. Therefore, the comment is 3, as it offers some direction but lacks comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should compare their work with the recent related work CoCoOp in the experiments. It provides a clear and direct action for the authors to take, which is to include CoCoOp in the experimental comparisons. The comment also explains the rationale behind this suggestion, noting that CoCoOp is an extended version of CoOp and should be considered for comparison. This level of detail provides the authors with a concrete and explicit action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CoCoOp,\" allowing the authors to accurately identify the part of the paper being addressed, which is the experimental section. It also specifies the issue by pointing out the omission of CoCoOp in the experiments, despite it being a relevant work that should be compared. The comment provides a clear direction for the authors to include CoCoOp in the comparisons, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp should be compared in the experiments, despite being published after the NeurIPS deadline. The reviewer provides a logical reasoning by explaining that CoCoOp is an extended version of CoOp, implying that it is relevant and should be included in the comparisons. However, the comment lacks specific examples or references to support the claim that CoCoOp is a significant work that should be included. This makes the claim 3, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the request for comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the experimental comparisons, noting that the recent related work CoCoOp is not included despite being a relevant work. It provides a clear and actionable suggestion for the authors to include CoCoOp in the experiments, explaining that it is an extended version of CoOp and should be considered for comparison. This feedback is valuable as it highlights a gap in the current experimental setup and offers a concrete step for the authors to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or examples of how CoCoOp relates to the current work, which would further support the authors in making the necessary adjustments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring. It also mentions the need to show where model training is used to optimize the selection modules. While the comment implies that the authors should enhance the figure, it does not provide specific guidance on how to achieve this improvement. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed to enhance the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure, suggesting that it should better illustrate the processing pipeline, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as showing where model training is used to optimize the selection modules. This level of detail provides the authors with a clear understanding of what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved by better illustrating the processing pipeline. However, it does not provide any specific reasoning or examples to support why this improvement is necessary or how it would enhance the understanding of the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests an improvement to Figure 1 by proposing a better illustration of the processing pipeline. It provides specific details on what aspects should be included, such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring, as well as the integration of model training to optimize selection modules. This feedback is clear and actionable, offering the authors a concrete way to enhance the visual representation of their work. However, the comment could be more helpful if it explained why these improvements are necessary or how they would impact the reader\"s understanding. Overall, the comment is 4 as it provides specific guidance for improving the figure, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that the author only tested the ReBeL performance on two typical games and suggesting that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment does not provide explicit guidance on how to address this issue or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experimental scope but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental scope by mentioning that the author only conducted experiments on two typical games and suggests exploring the performance on more complex problems, especially those with larger depth. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental scope and the need to explore more complex problems. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and suggests that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment lacks specific examples or references to support the claim about the complexity of the games or the impact of depth on the value and policy functions. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope by noting that the author only conducted experiments on two typical games. It suggests that the performance of ReBeL on more complex problems, especially those with larger depth, should be explored. This feedback is 3 as it points out an area for expansion in the experimental section, which could provide more comprehensive insights into the model\"s capabilities. However, the comment lacks specific guidance on how to conduct these additional experiments or what specific complexities should be explored. To be more helpful, the comment could include suggestions on which games or scenarios to consider or how to adapt the experiments to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to avoid using abbreviations like \"MoCo\" in section headers, as they may be unfamiliar to readers. This feedback provides a clear and direct action for the authors to take, ensuring that their section headers are more accessible to readers. The comment is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number \"(136)\" and the specific issue with the use of the abbreviation \"MoCo\" in the section header. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with using abbreviations in section headers, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. This is a logical claim supported by the reasoning that section headers should be clear and accessible to readers. However, the comment does not provide specific examples or references to substantiate the claim further, which could strengthen the argument. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in section headers, suggesting that they should be avoided as they may be unfamiliar to readers. This feedback is clear and actionable, providing the authors with a direct suggestion to improve the clarity and accessibility of their section headers. By addressing this issue, the authors can enhance the readability of their paper for a broader audience. However, the comment could be more helpful if it provided additional guidance on how to replace the abbreviations with more descriptive text or suggested alternative ways to present the information. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might clarify their technical contribution or improve the analysis. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is unclear or which analyses are considered standard. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not refer to a specific section or part of the paper, and it is not specific in detailing what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the technical contribution is unclear and that most of the analysis is standard. This feedback is important as it highlights a critical area that needs clarification and improvement. However, the comment lacks specificity and does not provide actionable suggestions on how the authors might enhance the clarity of their technical contribution or differentiate their analysis from standard approaches. Without detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a key area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach and that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide explicit guidance on what specific evidence or arguments are lacking or how the authors might address this issue. The action is implicit and vague, leaving the authors to infer that they need to provide more substantial evidence or arguments but without clear direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s primary contribution, specifically mentioning the incremental advancement in efficiency over the TACTiS approach. However, it does not specify which part of the paper discusses this contribution, making it weakly grounded. The comment is specific in its request for more substantial evidence or arguments to establish the significance of this contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific issues or areas where more evidence is needed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, suggesting that it may be an incremental advancement over the TACTiS approach rather than a significant contribution to the field. It highlights the need for more substantial evidence or arguments to establish the significance of the contribution. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. While it points out a potential weakness, it does not offer actionable advice for improvement, making it 3. The authors are left with a general direction but without detailed steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that the work is incremental. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the novelty of their work. The comment lacks actionable details, such as recommending additional experiments, discussing related works in more depth, or suggesting ways to enhance the novelty of the paper. Without explicit or implicit guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, suggesting that the improvements on different datasets are trivial and that the work is incremental. However, it does not specify which datasets or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment also mentions that \"lots of previous works focus on this topic,\" but it does not provide specific references or examples, further limiting its specificity. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that it is incremental. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the paper by stating that the improvements on different datasets are trivial and that the novelty of the paper is limited. It suggests that the work is incremental, as many previous studies have focused on the same topic. However, the comment lacks specific examples or references to support this claim, which makes it difficult for the authors to understand the basis of the critique and how to address it. Without actionable feedback or suggestions for improvement, the comment provides limited value to the authors. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it lacks concrete details on what specific aspects should be covered or how to present the discussion. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a clear and actionable feedback that highlights a gap in the paper\"s content. However, the comment does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the theoretical guarantee should be discussed. While it points out a significant omission, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of quantitative measures to evaluate the generated VCEs, with evaluation primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and vague, as the authors are left to infer that they need to incorporate quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is mainly performed through visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation of generated VCEs lacks quantitative measures, relying mainly on visual inspection. This is a subjective opinion that requires justification, as it implies that the current evaluation method is insufficient. However, the comment does not provide specific examples or references to support why quantitative measures are necessary or how they could be implemented. Without detailed reasoning or evidence, the claim remains 3, as the authors would need to infer the importance of quantitative measures based on general knowledge of evaluation practices. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it relies heavily on visual inspection without quantitative measures. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should incorporate more robust evaluation methods to assess the quality and effectiveness of the generated VCEs. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used for evaluation. Despite this, the feedback is clear and actionable, making it 4 for guiding the authors in enhancing their evaluation process. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper claims to show improvements over baselines, but the actual results are only marginally better and often within the error bar range. This suggests that the performance differences between methods are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The feedback implies that the authors should reconsider their claims or provide more detailed analysis, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim of marginal improvements over baselines, noting that the error range is high, which suggests that the performance differences between methods are not significant. However, it does not specify which part of the paper this claim is based on, such as specific results or sections discussing the baselines and their comparisons. Without explicit references to sections or results, the authors may find it challenging to identify the exact parts that need attention. The comment is specific in detailing the issue with the claimed improvements but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper shows only marginal improvements over baselines, with the performance differences often within the error bar range. This claim is 3 as it provides a logical reasoning based on the data presented. However, the comment lacks specific examples or references to the exact results or sections where these marginal improvements are discussed. Providing more detailed evidence or references would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the paper claims to show improvements over baselines, but the actual results indicate only marginal improvements, often within the error bar range. This suggests that the performance differences between methods may not be significant. While the comment identifies a potential issue with the paper\"s claims, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback is 3 as it highlights a critical area for improvement, but it lacks actionable advice or detailed suggestions, making it incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights significant artifacts in the generated videos, noting that only some beach videos are convincing. It also mentions that the action recognition performance is below the current stateoftheart on the UCF dataset, which uses more complex architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their performance. The questions posed do not offer actionable steps for the authors to take. As a result, the comment lacks concrete details and explicit actions, making it 1.", "grounding_specificity_rationale": "The comment mentions \"significant artifacts\" in the generated videos and notes that only some beach videos are convincing. It also compares the action recognition performance to the current stateoftheart on the UCF dataset, highlighting the use of more complex architectures. However, the comment does not specify which part of the paper discusses the generated videos or the action recognition performance, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it provides some specific information about the artifacts and performance, it lacks detailed guidance on how to address these issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current stateoftheart on the UCF dataset. However, it does not provide specific examples or detailed comparisons to support these claims, nor does it offer any references or logical reasoning to substantiate the assertions. The lack of evidence and detailed justification makes the claims difficult for the authors to address, rendering the comment 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the presence of significant artifacts in the generated videos and the subpar action recognition performance compared to the current stateoftheart on the UCF dataset. It highlights that only some beach videos are convincing, suggesting that the artifacts are a significant concern. Additionally, it points out the gap in action recognition performance, noting that the used architectures are less complex than those employed in the current stateoftheart. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their performance. While it provides some insight into the weaknesses of the paper, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, as well as how to select representative images. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors need to provide more information or clarification on these points, but it does not offer concrete steps or examples to follow. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the diversity and representativeness of the new proposed evaluation set compared to the previous method, specifically questioning how to select representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the issue of diversity and representativeness but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how to select representative images, which is a critical aspect of ensuring the evaluation set is robust and effective. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a background section that introduces the basic RL framework, specifically elements like MDP, trajectories, and policy, to clarify the RL context. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These instructions are clear and provide concrete guidance on what the authors need to do to improve their draft. The feedback is explicit and actionable, as it directly tells the authors what steps to take to enhance their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include a background section to introduce the basic RL framework, specifically elements like MDP, trajectories, and policy, to clarify the RL context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment does not explicitly mention a specific section, it implies that the background section is the area where these additions should be made. This provides some level of grounding, as the authors can infer the relevant part of the paper. However, the comment is specific in detailing what needs to be addressed, such as the introduction of the RL framework and the original DPO algorithm. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a background section to introduce the basic RL framework, which would help clarify the RL context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. The comment logically argues that without this background information, the subsequent sections may be difficult to follow. However, it does not provide specific examples or references to support the claim that the current paper lacks this background information. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, including elements like MDP, trajectories, and policy. This would help clarify the RL context and make the subsequent sections more understandable. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is specific and provides concrete guidance on how the authors can improve the clarity and coherence of their paper. By addressing these suggestions, the authors can significantly enhance the readability and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how to improve the model capacity, whether through adjustments to the model architecture, training data, or other means. Without specific suggestions or directions, the authors are left without a clear understanding of how to address this concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. However, it does not specify which part of the paper discusses the proposed method or the model capacity, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on how to address the limitation or suggest potential solutions. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. This is a relevant observation that could impact the scalability and applicability of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation. Without detailed feedback or recommendations, the authors are left with a general awareness of the issue but without a clear path forward for improvement. Therefore, the comment is 3, as it highlights a potential concern but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the notion described in a specific work by DoshiVelez and Kim. While it implies that the authors should clarify the connection or relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the relevance but are not provided with specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the notion described in a specific work by DoshiVelez and Kim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the notion described in a specific work by DoshiVelez and Kim. However, it does not provide any reasoning or evidence to support why this question is relevant or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" program to the notion described in a specific work by DoshiVelez and Kim. While it identifies a potential area of confusion or relevance, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the connection. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experimental scope. Without guidance on what additional datasets or experiments could be considered, the authors are left without a clear path for improvement. As a result, the comment lacks actionable advice, making it 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide details on what specific issues or improvements could be made regarding the experimental scope. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the experimental scope could be expanded. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the validity of the results. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable suggestions on how the authors might expand their experimental scope or address this limitation. Without guidance on which additional datasets could be considered or how to incorporate them, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the S2D structure, questioning why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that efficiency could be improved but notes that more details are needed regarding parameters. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific details are expected. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of why the number of parameters does not change, even when the kernel height/width stay the same, and suggests that more details are expected regarding parameters. The comment provides a clear direction for the authors to address the lack of clarity in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer provides a logical explanation that if the kernel height/width stay the same, the depth increase would result in more parameters. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by including specific references or examples to support the assertion about the efficiency and parameters. Overall, the claim is 4, as it provides a logical explanation but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It provides a logical explanation that if the kernel height/width remain the same, the depth increase would result in more parameters. The reviewer acknowledges that efficiency could be improved, particularly in terms of FLOP, but emphasizes the need for more details regarding parameters. This feedback is clear and actionable, as it directs the authors to clarify the parameter count and its implications for the S2D structure. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar structures that might be relevant. Overall, the comment is 4, as it effectively points out a critical area for improvement and guides the authors toward a more detailed explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The comment implies that the proposed method may not be novel or innovative, as it seems to be similar to an existing approach. However, the comment does not provide any specific evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the comparison. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the proposed method by pointing out its similarity to an existing approach in reference [10]. It suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data, which implies that the proposed method may not be as novel as claimed. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or differentiate their work from the existing approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no suggestion on how to expand the results, improve the interpretation, or provide additional context. As a result, the authors are left without any guidance on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the limitation of the Atari game results being based on a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, namely that the Atari game results are based on a single game and a single baseline, making it difficult to interpret. This is a clear and actionable feedback that highlights an area for improvement. However, the comment could be more helpful if it provided suggestions on how to expand the results or improve the interpretation, such as recommending additional games or baselines to include. Despite this, the comment still offers valuable insight into a critical aspect of the paper, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The action is implicit and somewhat vague, as the authors can infer that they need to consider adding a sparsity constraint but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s incentivization to use fewer factors, but it lacks grounding as it does not direct the authors to a particular section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increase in the number of factors and computation with more tasks. This claim is 3 as it provides a logical reasoning about the potential impact of the lack of sparsity constraint. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation is relevant and could impact the model\"s efficiency and scalability. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or implement a sparsity constraint. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should reiterate why the GPC (benchmark) is performing better than BPC (their method), specifically highlighting the role of bandit feedback and the lack of information about the form of the cost function. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is explicit and concrete, offering specific guidance on how to improve the presentation of the simulation study. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for why the GPC (benchmark) is performing better than BPC (the authors\" method). The comment suggests that the authors should reiterate that this is due to the use of bandit feedback and not using information about the form of the cost function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not beneficial to the authors and suggests that the authors should reiterate why the GPC (benchmark) is performing better than BPC (their method). The comment provides a specific reason for this claim, stating that it is due to the use of bandit feedback and not using information about the form of the cost function. This reasoning is logical and provides a clear explanation for the observed performance difference, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate the importance of bandit feedback and the lack of information about the form of the cost function in this context. This feedback is clear and actionable, providing the authors with a direct suggestion for improving the clarity and comprehensiveness of their results. By addressing this point, the authors can enhance the understanding and interpretation of their simulation study, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should quantify and clarify the claim about ReLU not working well in deep or convolutional networks. The reviewer provides a specific example from the AlexNet paper, which used ReLU in a deep and convolutional network, challenging the claim. However, the comment does not explicitly instruct the authors to revise their claim or provide guidance on how to quantify and clarify it. The action is implicit and somewhat vague, as the authors need to infer that they should address the claim and provide more detailed evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about the performance of ReLU in deep or convolutional networks. It provides a reference to the AlexNet paper, which used ReLU in a deep and convolutional network, challenging the claim. This reference allows the authors to identify the part of the paper being discussed, making the comment fully grounded. The comment is also specific because it suggests quantifying and clarifying the claim, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"ReLU does not work very well in very deep or in convolutional networks\" by referencing the AlexNet paper, which used ReLU in a deep and convolutional network. This provides a logical counterexample to the claim, making the comment 3. However, the comment could be strengthened by providing more detailed analysis or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions a claim made in the paper regarding the performance of ReLU in deep or convolutional networks. It provides a specific example from the AlexNet paper, which used ReLU in a deep and convolutional network, challenging the claim. This feedback is 3 as it prompts the authors to reconsider their claim and potentially provide more evidence or clarification. However, the comment could be more helpful if it offered suggestions on how to address the claim or provided additional context for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the high perplexity values reported in Figure 1, which seems to contradict better BLEU scores. The reviewer questions how the perplexity was calculated, implying that the authors should clarify or justify their calculation method. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their perplexity calculation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the high perplexity values reported in the figure and questions how they were calculated, suggesting that this might contradict better BLEU scores. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the high perplexity values reported in Figure 1, suggesting that they contradict better BLEU scores. The reviewer questions the calculation of perplexity, implying that there might be an issue with the methodology or interpretation. However, the comment lacks specific examples or references to support the claim that the perplexity values are unusually high or how they relate to BLEU scores. This makes the claim 3, as the authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the high perplexity values reported in Figure 1, which seems to contradict better BLEU scores. It questions the calculation of perplexity, suggesting that the authors should clarify or justify their method. This feedback is 3 as it points out a specific area of concern and prompts the authors to provide more information about their perplexity calculation. However, the comment could be more helpful if it offered suggestions on how to address the discrepancy between perplexity and BLEU scores or provided examples of how to improve the calculation or interpretation of perplexity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. While it explicitly states the need for these experiments, it does not provide specific guidance on how to conduct them or what aspects to focus on. The action is clear but lacks concrete details on implementation, making it 3. The authors know they need to conduct these experiments, but they may not be entirely sure of the exact steps or criteria to follow. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to identify where these changes should be made. Additionally, the comment lacks specificity regarding what aspects of distributed deployment or larger models should be explored. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper, suggesting that experiments on distributed deployment and a larger model should be included. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide a brief discussion on why rooted patterns are important and how they choose the roots. It also offers an alternative suggestion, stating that if nonrooted patterns are sufficient, the discussion could be moved to the supplementary material. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns\" and \"orbit counting in GSN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: an explanation of why rooted patterns are important and how the roots are chosen. The comment suggests either providing a brief discussion or moving the discussion to the supplementary material if nonrooted patterns are sufficient. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately explain the importance of rooted patterns and how they choose the roots. However, it does not provide specific examples or references to support this claim, making it 3. The comment suggests that a brief discussion is expected or that the discussion could be moved to the supplementary material, but it lacks detailed reasoning or evidence to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity and provides actionable feedback. It points out that the authors define rooted patterns but do not explain why they are important or how the roots are chosen. The comment suggests that a brief discussion on this topic is expected or, alternatively, that the discussion could be moved to the supplementary material if nonrooted patterns are sufficient. This feedback is clear and provides the authors with a concrete direction for improving their draft by addressing the lack of explanation and potentially streamlining the content. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide more explanations regarding the consistency between training and inference, which can be easily satisfied due to the smoothness of neural models. While the comment implies that the authors should expand on this aspect, it does not specify what kind of explanations are needed or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to add more detail but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the paper discusses the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests that the authors provide more explanations on this topic, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, suggesting that more explanations are needed. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanations regarding the consistency between training and inference. It points out specific lines in the paper where this topic is discussed, allowing the authors to focus their efforts on enhancing this part of the draft. However, the comment could be more helpful if it offered specific suggestions on what additional explanations or details should be included. Despite this, the feedback is clear and actionable, making it 4 for the authors to improve their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should provide evidence or experiments to support their claim, specifically by testing the proposed model with larger word embedding and LSTM parameters. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for how to address the concern. The action is implicit but concrete, as the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the authors\" claim about achieving superior performance with fewer parameters compared to the baseline. It mentions specific aspects of the model, such as the word embedding size and LSTM size, which are directly related to the claim. The comment also specifies what needs to be addressed by asking for improvements when the proposed model uses larger word embedding and LSTM parameters. This provides clear guidance on what the authors need to consider to strengthen their claim. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. The reviewer asks for evidence or experiments to support the claim, specifically by testing the proposed model with larger word embedding and LSTM parameters. This request for additional evidence or experiments provides a clear direction for the authors to substantiate their claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the baseline model was tested, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving superior performance with fewer parameters compared to the baseline model. It suggests that the baseline model might have been tested with standard parameter settings, which could affect the comparison. The reviewer asks for evidence or experiments to support the claim, specifically by testing the proposed model with larger word embedding and LSTM parameters. This feedback is clear and actionable, as it directs the authors to provide additional evidence or experiments to substantiate their claim. However, it could be more helpful if it offered specific suggestions on how to conduct these experiments or what parameters to test. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two new hyperparameters, k and \u03b7, which require finetuning. It notes that this finetuning depends on the availability of the environment or a good OPE (Online Planning Evaluation) method. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks actionable details, such as recommending specific methods for finetuning or discussing potential alternatives. As a result, the authors are left without a clear understanding of how to proceed with the finetuning process. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two new hyperparameters, k and \u03b7, and their requirement for finetuning. However, it does not specify which part of the paper discusses these hyperparameters, making it weakly grounded. The comment is specific in detailing the issue with the finetuning process, noting its dependence on environmental availability or a good OPE method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two new hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two new hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the environment or a good OPE (Online Planning Evaluation) method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or mitigate its impact. Without specific recommendations or examples, the feedback is 3 as it points out a potential problem but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the application of regularization between the LN model and the GLM presented by pillow et al. It suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. However, the comment does not provide explicit instructions on how to achieve this or what specific features should be replicated. The action is implicit and somewhat vague, as the authors can infer that they need to align their approach with the previous model, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application of regularization to both LN models and GLMs, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the GLM presented by pillow et al., suggesting that the authors should try to reproduce the main features of this model to make the comparison fair. This level of specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should try to reproduce the main features of the previous model presented by pillow et al. to make the comparison fair. The reviewer provides a specific example of how the previous model used L1 regularization for filters and a lowrank approximation to the spatial filter, contrasting it with the current approach of cropping the stimulus. This comparison is based on logical reasoning and provides a clear rationale for the suggestion, making the claim 4. However, the comment could be strengthened by including references to the specific work by pillow et al. or more detailed explanations of the differences in methodology. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM presented by pillow et al. It points out that the authors apply regularization in the form of a cropped stimulus to both models, whereas the previous model used L1 regularization for filters and a lowrank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. This feedback is 3 as it highlights a specific area where the authors might need to adjust their approach to ensure a fair comparison. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific features of the previous model should be replicated. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include some failure cases and related discussion in their paper. While it implies that the authors should add this information, the comment does not provide specific guidance on what constitutes a \"failure case\" or how to structure the discussion. The action is implicit and somewhat vague, as the authors can infer that they need to include additional content but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including \"some failure cases and related discussion,\" but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit guidance, it is difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the inclusion of failure cases and discussion, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including \"some failure cases and related discussion\" would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including failure cases and related discussion would be beneficial for the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what constitutes a \"failure case\" or how to structure the discussion. The authors are left with a general idea of what to address but without detailed instructions on how to implement it. This makes the comment 3, as it points out a potential area for enhancement but does not offer actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting an ablation study to determine the necessity of the base layer GNN encoding in the proposed method. This is a clear and direct action for the authors to take, providing a concrete step to improve their draft. The comment specifies what needs to be done, making it 5. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the necessity of the base layer GNN encoding and suggests conducting an ablation study to address this concern. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to determine its importance. This is a logical suggestion that provides a clear direction for the authors to improve their work. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unclear or unnecessary, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty in the proposed method, namely the necessity of the base layer GNN encoding. It suggests conducting an ablation study to determine whether this component is essential or can be removed without affecting the overall performance. This feedback is clear and actionable, providing the authors with a concrete step to take to improve their draft by clarifying the role of the base layer GNN encoding. However, the comment could be more helpful if it offered additional context or examples of how such an ablation study might be structured or what insights it could provide. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is an explicit suggestion for improvement, as it provides a specific action for the authors to take. The comment is also concrete, as it clearly instructs the authors on how to enhance the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and equations (10) and (11), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests introducing epsilon when discussing equation (11), providing clear guidance on how to improve the clarity of the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point suggests that the introduction of epsilon in equation (11) might be clearer if it were introduced when discussing equation (11). This is a logical suggestion based on the structure of the equations, but it does not provide specific reasoning or examples to support why this change would improve clarity. The comment lacks detailed justification or references, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper, specifically regarding the introduction of epsilon in equations (10) and (11). It suggests that introducing epsilon when discussing equation (11) might improve the clarity of the paper. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can implement to enhance the readability of their draft. However, the comment could be more helpful if it explained why this change would be beneficial or how it would impact the overall understanding of the paper. Overall, the comment is 4, as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"explicitly add the upper bounds of counting\" and potentially elaborate on empirical runtimes. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a clear path forward for the authors. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of inadequate discussion on the computational complexity of counting homomorphisms and suggests adding upper bounds and elaborating on empirical runtimes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, specifically mentioning a brief statement in the paper. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential gap in the discussion, it lacks specific examples or references to support the claim about the inadequacy of the current discussion. The suggestion for improvement is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the discussion of computational complexity in counting homomorphisms. It points out that the current statements are brief and suggests that the authors should explicitly add upper bounds and potentially elaborate on empirical runtimes. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. By addressing this gap, the authors can improve the comprehensiveness and rigor of their paper. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two explicit actions: correcting a typo (\"f\" to \"g\") in line 108 and removing an extra period in line 115. Additionally, it poses a question about the convergence of the baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. The actions are clear and direct, providing specific instructions for the authors to follow. The question also prompts the authors to address a potential issue in their methodology, further enhancing the actionability of the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (\"line 108\" and \"line 115\") where corrections need to be made, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as a typo and an extra period, which need to be corrected. Additionally, it raises a question about the convergence of the baseline MCL with deep learning, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question about the convergence of the baseline MCL with deep learning. The corrections regarding typos and punctuation are factual and do not require verification. The question about convergence is a request for clarification and does not contain a claim that needs verification. Therefore, the comment is factual and does not contain a claim, aligning with the label \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out two errors: a typo in line 108 and an extra period in line 115. It also raises a question about the convergence of the baseline MCL with deep learning, which is a critical aspect of the methodology. This feedback is clear and directs the authors to address these issues, making it 4. However, the comment could be more helpful if it offered suggestions on how to ensure convergence or provided examples of how early cutting of learners might affect ensemble performance. Overall, the comment is 4 as it identifies specific areas for improvement and prompts the authors to address a critical methodological concern."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a study on inference time in the paper, suggesting that it would be valuable to compare the inference speed of the proposed pose estimation method with previous topdown and bottomup methods. While the comment implies that the authors should conduct such a study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include an analysis of inference time and compare it with existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks a study on inference time, particularly in comparison to previous topdown and bottomup pose estimation methods. However, it does not specify which part of the paper this observation is based on, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its suggestion to include a comparison of inference speeds, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is no study on inference time in the paper, suggesting that it would be valuable to compare the inference speed of the proposed pose estimation method with previous topdown and bottomup methods. However, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would impact the paper. Without detailed justification or references to existing literature, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of a study on inference time, which is relevant for a pose estimation method. It suggests that comparing the inference speed of the proposed method with previous topdown and bottomup methods would be valuable. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to enhance their work. However, the comment could be more helpful if it offered guidance on how to conduct such a comparison or what specific aspects of inference time should be considered. Overall, the comment is 4 as it directs the authors to a meaningful area for further analysis and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises two specific issues regarding the proof of Theorem A.3. First, it questions how the input x has two indices, given that it is described as a vector. Second, it suggests a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, proposing that it should be d instead. These explicit questions and suggestions provide clear and concrete actions for the authors to take, ensuring they understand exactly what needs to be addressed and how to make the necessary corrections. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the proof, such as the input x having two indices and a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, questioning the indexing of the input \"x\" and suggesting a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. These are factual observations and questions that do not contain subjective claims or opinions. They are purely descriptive and do not require verification or justification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, questioning the indexing of the input \"x\" and suggesting a correction to the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, providing the authors with precise guidance on how to improve the clarity and accuracy of their proof. By addressing these points, the authors can enhance the rigor and validity of their work. Therefore, the comment is 5, as it offers detailed and constructive feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should address these concerns by providing additional data or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concern about the use of words like \"somewhat\" and \"good generative ability\" in the description, and it questions the reliability of the model when relationships and entities are replaced. The comment further requests specific information on the percentage of correct entities/relationships being plugged in. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of the model, specifically regarding the use of beam search and the accuracy of the results. It questions the reliability of the model when relationships and entities are replaced and suggests that the authors should provide more information on the percentage of correct entities/relationships being plugged in. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the basis of the concern and address it themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the effectiveness of the model, particularly in sections 4.3 and 4.4. It questions the reliability of the model when relationships and entities are replaced, highlighting the need for assurance that the pluggedin entities/relationships are correct. The comment also requests specific information on the percentage of correct entities/relationships being plugged in, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue and guide the authors in addressing it. Overall, the feedback is 4 as it directs the authors to a critical area that requires further analysis and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the limitations of the claim about evolutionary dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some lowvariance units. It also mentions that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be explicitly discussed. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how to discuss these limitations or what specific aspects should be included in the discussion. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the claim about evolutionary dropout,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, noting that it can only increase the variance of some lowvariance units and suggesting that Batch Normalization standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the discussion of evolutionary dropout. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This comparison provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it can only increase the variance of some lowvariance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This feedback is clear and actionable, as it prompts the authors to discuss these limitations explicitly. By addressing this point, the authors can provide a more comprehensive understanding of the strengths and weaknesses of their approach. However, the comment could be more helpful if it offered suggestions on how to discuss these limitations or provided additional context. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the performance of FedPCL is heavily reliant on the selection of pretrained models, which limits its applications. It notes that the model accuracy is sensitive to these pretrained models, as shown in Table 4. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to address this limitation, such as exploring alternative methods for model selection or developing strategies to reduce reliance on pretrained models. Without actionable guidance, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of FedPCL being heavily reliant on the selection of pretrained models and notes the sensitivity of model accuracy to these models. The comment further acknowledges the efforts of the authors in addressing these limitations by developing a lightweight federated learning framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications. It supports this claim by referencing Table 4, which shows the model accuracy is sensitive to pretrained models. The comment also acknowledges the authors\" efforts to address this limitation by developing a lightweight federated learning framework. However, the claim could be strengthened by providing more detailed examples or specific data from Table 4 to substantiate the sensitivity of model accuracy. Overall, the comment is 4, as it provides some evidence but lacks comprehensive details to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment acknowledges the limitations of the performance of FedPCL, specifically its reliance on the selection of pretrained models, which limits its applications. It highlights the sensitivity of model accuracy to these pretrained models, as shown in Table 4. The comment also notes that the authors have addressed this limitation by developing a lightweight federated learning framework that integrates pretrained models for federated aggregation. This feedback is 3 as it identifies a key limitation and acknowledges the authors\" efforts to address it. However, it could be more helpful if it provided suggestions or guidance on how to further improve the framework or reduce its reliance on pretrained models. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should add these elements, it does not provide explicit instructions on how to do so or which figures should be updated. The action is implicit and somewhat vague, as the authors can infer that they need to include additional attention maps but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding \"tentative attention maps\" to the qualitative figures, which implies that it is addressing the figures where attentions are discussed. However, it does not explicitly mention which figures or sections this pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of tentative attention maps, which provides clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include \"tentative attention maps\" in the qualitative figures, alongside the retrieved and final attentions. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the understanding of the results. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that including \"tentative attention maps\" in the qualitative figures would be beneficial. This feedback is 3 as it identifies a potential enhancement to the visual presentation of the results, which could provide additional insights into the attention mechanisms. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these maps or why they would be valuable. While it points out an area for improvement, it does not offer actionable steps or detailed suggestions, limiting its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. While it explicitly states an action, it lacks specific guidance on what aspects of the contribution should be elaborated or how to present them. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description, making it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide specific guidance on what aspects of the contribution should be elaborated. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated or how to present them. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 2, as it provides a general direction but lacks actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the organization and clarity of the paper. It recommends separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections (2.3 and 2.4) where the description of the layerwise attention mechanism is scattered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests organizing the main contributions into a separate section and then describing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. This provides clear guidance on how to improve the organization and clarity of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, specifically regarding the description of the main contributions and the referencing of certain techniques. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the organization and clarity of the paper. It suggests separating the description of the main contributions, specifically the two types of attention for deep VAEs, into a separate section, and then describing the generative and inference models. This recommendation helps the authors to better structure their paper and make it easier for readers to follow. Additionally, the comment suggests referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper\"s comprehensiveness. While the comment is clear and provides valuable guidance, it could be more helpful if it included specific examples or further elaboration on how to implement these suggestions. Overall, the comment is 4, as it offers constructive feedback that can significantly improve the clarity and organization of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about Figure 5, either suggesting that the reviewer does not understand the figure or questioning the accuracy of the labels. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the figure, correct the labels, or improve the figure\"s clarity. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is either the reviewer\"s misunderstanding of the figure or the incorrect labels. This provides clear guidance on what needs to be clarified or corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about Figure 5, either questioning the reviewer\"s understanding of the figure or the accuracy of the labels. However, it does not provide any supporting evidence, reasoning, or examples to clarify the issue. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about Figure 5, either questioning the reviewer\"s understanding of the figure or the accuracy of the labels. While it identifies a potential issue, it lacks specificity and does not provide any actionable guidance or suggestions for improvement. The authors are left without a clear understanding of what needs to be clarified or corrected, making it difficult for them to address the issue effectively. Therefore, the comment is 1, as it does not offer any actionable feedback or insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments. It provides a clear rationale for why this is important, noting that the scale of the datasets (~100k images) suggests that full annotation is likely available, making a supervised baseline informative for comparing selfsupervised methods. The comment also highlights the value of including a fully supervised pretrained network as a baseline. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of supervised baselines in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that including supervised baselines would be informative, especially given the scale of the datasets used. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a missing aspect in the experiments. It provides a logical reasoning by noting that datasets of scale ~100k images likely have full annotation available, making a supervised baseline informative for comparison. However, the comment could be strengthened by providing specific examples or references to studies that have used supervised baselines in similar contexts. While the reasoning is sound, the lack of detailed examples or references makes the claim 4, as it requires the authors to infer the importance of including supervised baselines based on the provided rationale.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why including these baselines is important, especially given the scale of the datasets used, which likely have full annotation available. The comment suggests that including a fully supervised pretrained network as a baseline would be informative for comparing selfsupervised methods. This feedback is actionable and provides a specific direction for the authors to improve their draft by adding a critical comparison point. However, it could be more helpful if it offered suggestions on how to implement these baselines or provided examples of similar studies that have included such comparisons. Overall, the comment is 4 as it effectively guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal, suggesting that the results may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The authors are left to infer that they should consider updating their benchmarks or exploring other methods to improve the significance of their results. While the comment identifies areas for improvement, it lacks concrete steps or suggestions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance differences between methods are minimal across evaluations,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by noting that the performance differences are less than 1 percentage point and may be due to random variation. Additionally, it points out that the benchmarks selected are outdated and likely saturated, providing a specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, citing that the differences are less than 1 percentage point, which may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated, referencing a specific paper, \"LoRA Learns Less and Forgets Less\" [1]. This provides some support for the claim, as the reference to the paper suggests that the benchmarks are indeed outdated. However, the comment could be strengthened by providing more detailed analysis or examples of how the benchmarks are outdated or saturated. Therefore, the claim is 4, as it has some justification but could be further substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal, with variations less than 1 percentage point. It suggests that these differences may be due to random variation and that the benchmarks used are outdated and likely saturated. This feedback is valuable as it highlights a potential flaw in the paper\"s methodology and suggests that the authors should consider updating their benchmarks or exploring other methods to improve the significance of their results. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of more suitable benchmarks. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests that it may not provide significant benefits. It also questions the absence of BEAR from the baselines. While the comment implies that the authors should evaluate their method on domains with nondeterministic dynamics and consider including BEAR in the baselines, it does not explicitly instruct the authors to do so. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests that it may not provide significant benefits. It also questions the absence of BEAR from the baselines. However, the comment does not specify which part of the paper discusses the method\"s application on Hopper or the inclusion of BEAR in the baselines. This lack of explicit references makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its questioning of the method\"s efficacy and the absence of BEAR, but it is 1 as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests that it may not provide significant benefits. It also questions the absence of BEAR from the baselines. The comment provides logical reasoning by pointing out the deterministic nature of Hopper and questioning the method\"s applicability. However, it lacks specific examples or references to support the claim that the method does not have much benefit. The absence of BEAR from the baselines is also noted, but without further context or explanation, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the method\"s effectiveness, particularly in the context of deterministic dynamics, as seen in the Hopper environment. It questions why the method would be beneficial in such a scenario, where the dynamics are deterministic and the method essentially reduces to actionconditional masking. The comment also suggests evaluating the method on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it points out the absence of BEAR from the baselines, which could be a relevant comparison. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should provide this justification or what aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be included in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for a justification but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that these methods are important for performance. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theocratical justification for why cotraining and weight averaging can improve results. While it identifies a potential area for improvement by highlighting the importance of justifying the effectiveness of these methods, the comment lacks specificity and does not offer detailed guidance on how to provide this justification. It does not provide examples or suggest specific aspects to focus on, leaving the authors with a general idea of what is needed but without actionable steps. Therefore, the comment is 3, as it points out a gap in the paper but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific change to the terminology used in section 4, recommending that \"X\" should be a multiset instead of a set. This is an explicit action with clear guidance on how to implement the change, as it specifies the need to include multiplicities of labels in the graph for the histogram to accurately represent it. The authors know exactly what needs to be done to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology used, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of a set in section 4 is inappropriate because it does not account for the multiplicities of labels in a graph. The reviewer provides a logical explanation for why a multiset would be more appropriate, as it can include the multiplicities of the labels. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a potential issue with the terminology used in section 4, suggesting that \"X\" should be a multiset instead of a set to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and provides a concrete way for the authors to enhance the accuracy and clarity of their work. By addressing this suggestion, the authors can improve the precision of their representation and ensure that their histogram accurately reflects the graph\"s characteristics. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds that are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their derivation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation, suggesting that it falls into classical learning theorybased bounds that are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper the derivation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning BayesianPAC based bounds, but without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer supports this claim by mentioning BayesianPAC based bounds as an example of a more realistic approach. However, the comment lacks specific references or detailed explanations of why classical learning theorybased bounds are insufficient. This makes the claim 3, as it provides a general direction for improvement but requires more detailed justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it falls into classical learning theorybased bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback is 3 as it points out a potential limitation in the current approach and suggests an alternative direction, such as BayesianPAC based bounds. However, the comment lacks depth and does not provide detailed guidance on how the authors might address this issue or integrate Bayesian considerations into their work. While it offers a starting point for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without clear grounding, the authors may struggle to identify the exact sections that require expansion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that these details are necessary or missing. Without additional context or justification, the authors may find it challenging to understand the importance of these details or how to address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more details about the proposed method should be presented. It highlights the need for clarification on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides specific guidance on what additional information should be included to enhance the comprehensiveness of the paper. However, the comment could be more helpful if it offered examples or suggestions on how to present these details effectively. Overall, the comment is 4, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the challenge of identifying shared information for consistency checking in responses to prompts like \"introduce a sports celebrity to me.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this challenge or improve their method. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the proposed method\"s ability to detect hallucinations in openended responses, particularly with prompts like \"introduce a sports celebrity to me.\" This provides full grounding as it explicitly mentions the type of prompt and the issue with detecting hallucinations. The comment is also specific because it details the challenge of identifying shared information for consistency checking in such responses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s ability to detect hallucinations in openended responses, specifically with prompts like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by explaining that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. This reasoning is clear and provides a basis for the claim, making the comment 4. However, the comment could be strengthened with specific examples or references to similar challenges in the literature, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, specifically its ability to detect hallucinations in openended responses. It provides a specific example, \"introduce a sports celebrity to me,\" to illustrate the challenge of identifying shared information for consistency checking. This feedback is valuable as it highlights a critical area for improvement and offers a concrete example of the issue, allowing the authors to consider how to address this limitation in their draft. However, the comment could be more helpful if it included suggestions or potential solutions for overcoming this challenge. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional verification, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct further verification but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a particular area for verification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the theoretical findings in relation to realworld deep learning models, specifically questioning the conclusion about label noise and model size on MNIST and CNN. The reviewer suggests verifying these conclusions, which is a logical request for further investigation. However, the comment lacks specific examples or references to support the claim that the findings are unclear or need verification. This makes the claim 3, as it provides a direction for further exploration but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the theoretical findings in relation to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN, which is a specific and actionable piece of feedback. This guidance could help the authors improve the relevance and applicability of their theoretical findings, making the comment 4. However, the comment could be more helpful if it provided additional context or examples of how to conduct this verification, which would enhance its utility for the authors. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point starts by acknowledging the paper\"s organization and writing quality, but then it provides specific feedback on areas that could be improved. It suggests drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action. Additionally, it raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are explicit and provide clear guidance on what the authors need to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the writing quality and the need for a table to compare different CoT prompting methods. It also raises specific questions about the assumption in section 4.2, such as the selection criteria and the reasoning behind it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a positive statement about the paper\"s organization and writing quality, followed by specific feedback and questions. The positive statement is factual and does not require verification. The feedback and questions are also factual and do not contain subjective claims or opinions that need verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment starts by acknowledging the paper\"s organization and writing quality, which is a positive observation. However, it then provides specific feedback on areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across various dimensions. This is a clear and actionable suggestion that could enhance the clarity and comprehensiveness of the paper. Additionally, the comment raises questions about the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, prompting the authors to clarify these points. These questions are specific and provide a clear direction for the authors to address. Overall, the comment is 4 as it offers constructive feedback and guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the distribution p(y|Hf\u00af(tn)) should be chosen as Gaussian, as this is a requirement for Kalman Filtering and Smoothing and CVI. It also mentions that this assumption is later made in the ELBOs. This provides clear and direct guidance on what needs to be done to address the issue. The comment is explicit and concrete, leaving no ambiguity for the authors on how to implement the suggested change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the distribution p(y|Hf\u00af(tn)) and the requirement for it to be chosen as Gaussian for Kalman Filtering and Smoothing and CVI. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue\u2014namely, the necessity of choosing a Gaussian distribution for the mentioned processes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the distribution p(y|Hf\u00af(tn)) must be chosen as Gaussian for Kalman Filtering and Smoothing and CVI to be possible. It further notes that this assumption is later made in the ELBOs. The comment provides a logical explanation for the necessity of this choice, linking it to the requirements of the mentioned processes. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear rationale but could benefit from additional supporting evidence or references.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the choice of distribution for p(y|Hf\u00af(tn)). It points out that this distribution should be chosen as Gaussian, as it is a requirement for Kalman Filtering and Smoothing and CVI. The comment also notes that this assumption is later made in the ELBOs, which helps the authors understand the context and importance of this choice. By highlighting this requirement, the comment offers clear guidance on how to improve the draft, making it 4. However, it could be more helpful if it provided additional context or examples to further clarify the implications of this choice. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The comment implies that the authors should consider reporting cosine similarities for larger weight decay strengths, but it does not specify how to do so or what specific changes are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the application of weight decay to all layers, the expected impact on training loss, and the absence of reported cosine similarities for large weight decay parameters. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that applying weight decay to all layers would lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. It suggests that the absence of reported cosine similarities for such large weight decay strengths is convenient, implying that the authors might be avoiding reporting suboptimal results. However, the comment lacks specific examples or references to support the claim about the expected impact of weight decay on training loss and cosine similarities. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that the authors might be avoiding reporting suboptimal results. This feedback is 3 as it highlights a specific area for improvement and encourages the authors to consider reporting cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional guidance on what specific changes could be made to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant omission in the title, abstract, introduction, and discussion regarding the results being for unsupervised random forests. The reviewer emphasizes that this is a serious issue that needs to be addressed to prevent casual readers from drawing incorrect conclusions. The comment explicitly states that this must be fixed for publication, indicating a clear and direct action for the authors to take. Additionally, the reviewer suggests that it would be straightforward to make these changes. The feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the title, abstract, introduction, and discussion do not adequately explain that the results are for unsupervised random forests, which could lead to incorrect conclusions. The reviewer emphasizes the importance of this clarification, suggesting that it is a \"fairly serious omission.\" However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the exact issues and how to address them based on the reviewer\"s general statement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that the title, abstract, introduction, and discussion do not clearly indicate that the results are for unsupervised random forests. This omission could lead to incorrect conclusions by casual readers. The reviewer emphasizes the importance of addressing this issue for publication, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful by offering specific guidance on how to incorporate this clarification into the paper. Despite this, the feedback is 4 as it highlights a significant weakness and directs the authors to a necessary correction. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests conducting qualitative experiments to demonstrate the validity of the conditional independence model, specifically recommending the use of a toy dataset to show the separability of inlier features and outlier features. This provides a clear and concrete action for the authors to take. The second part suggests providing visualization results or a schematic diagram to help readers understand the proposed test metric and its comparison with other metrics. While the action is explicit, the comment could be more actionable by providing specific guidance on what kind of visualization or diagram would be most helpful. Overall, the comment is 4 as it provides clear directions for improvement, but with some room for further detail.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"qualitative experiments\" and \"conditional independence model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as conducting illustrative experimental results to demonstrate the validity of the model and proposing a new test metric with comparative experiments. Additionally, it suggests providing visualization results or a schematic diagram to aid understanding. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcondi could perform better than minimizing HSIC_HOOD. The comment also points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the need for qualitative experiments or the proposed test metric. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting that illustrative experimental results could be provided to show the effectiveness of minimizing HSICcondi over HSIC_HOOD. This feedback is clear and actionable, guiding the authors on how to enhance the experimental section. Second, the comment notes the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, recommending the inclusion of visualization results or a schematic diagram to aid understanding. While the comment provides valuable insights, it could be more helpful by offering specific suggestions on what kind of visualization or diagram would be most beneficial. Overall, the comment is 4 as it offers actionable feedback for improving the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any specific steps to address the issue. The authors are left without guidance on how to respond to this question or what changes might be necessary to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a comparison of computational complexity, which provides clear guidance on what the authors need to address. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. However, it does not provide any evidence, reasoning, or references to support this claim. The lack of supporting information makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods, suggesting a comparison. While it identifies a potential area for improvement, it lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue. The comment does not offer any detailed feedback or insights that could help the authors improve their draft. Therefore, it is 2, as it points out a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. While the comment implies that this analysis could provide valuable insights, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this analysis further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. The comment also provides a logical explanation of how the roles between \"winners\" and \"cooperators\" might emerge based on the cost to reward the other agent. However, it does not explicitly mention which part of the paper this analysis should be added to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the impact of varying \u03b1 on reward incentives and collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a logical explanation of how the cost affects the roles of \"winners\" and \"cooperators\" and how this might impact the collective return. The comment includes specific examples, such as varying the value of \u03b1, which provides a clear direction for the analysis. However, it lacks detailed references or examples from existing literature to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could be strengthened with additional references or examples.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return, which could provide insights into how the roles between \"winners\" and \"cooperators\" emerge. The comment offers a logical explanation of how the cost affects these roles and suggests that a lower cost might lead to less distinguished roles and a lower collective return. This feedback is clear and actionable, as it identifies a specific area for further analysis and provides a rationale for why it is important. However, it could be more helpful if it included specific suggestions on how to conduct this analysis or what metrics to focus on. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a lack of significance testing to support claims about the differences between certain methods. It provides a specific example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer suggests that without proper testing, including checking the distribution and accounting for multiple comparisons, it is difficult to determine the significance of these claims. This feedback is explicit and provides a clear action for the authors to take, which is to conduct significance testing to support their claims. The suggestion is concrete, as it specifies the need for statistical analysis to validate the differences between methods. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 486,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of significance testing to support claims about the differences between certain methods. The reviewer provides a concrete example from the paper, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between certain methods without providing sufficient evidence, such as significance testing. The reviewer supports this claim by providing specific examples from the paper, including metrics and values, to illustrate the lack of statistical analysis. This detailed example helps substantiate the claim, making it 4. However, the comment could be strengthened by referencing specific statistical methods or standards for significance testing, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between certain methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT4 boosting translation quality and discourse awareness. The reviewer points out that the differences between the methods are minimal and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to determine significance. This feedback is clear and actionable, as it directs the authors to conduct statistical analysis to validate their claims. By addressing this issue, the authors can strengthen the rigor and credibility of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to revise the approach description in \u00a73, indicating that it is partially difficult to follow. It also provides a specific suggestion to use the additional page of the cameraready version to extend the approach description, rather than adding more experiments. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"\u00a7 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach description being partially difficult to follow and suggests revising it. Additionally, it provides a concrete suggestion to use the additional page of the cameraready version to extend the approach description rather than adding more experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in \u00a73 is partially difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support why the description is difficult to follow. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in \u00a73, noting that it is partially difficult to follow. It provides a clear and actionable suggestion to revise the description, recommending the use of the additional page in the cameraready version to extend the approach description rather than adding more experiments. This feedback is direct and offers a concrete way for the authors to improve their draft, making it 4. However, it could be more helpful if it included additional guidance on how to enhance the clarity of the description. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights to explain why the proposed gyrostructures outperform existing methods. Second, it notes that the paper lacks comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance relative to simpler or more commonly used techniques. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific methods to compare or how to incorporate interpretive insights. The actions are implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part\" and the \"related discussion,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the lack of interpretive insights and the omission of comparisons with other stateoftheart methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights to explain why the proposed gyrostructures outperform existing methods. It also notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. The comment provides a logical reasoning for the claim by highlighting the need for interpretive insights and comparisons with other methods. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the experiments section of the paper. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance relative to simpler or more commonly used techniques. This feedback is clear and actionable, as it directs the authors to enhance the interpretability of their results and broaden the scope of their comparisons. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is 4, as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what kind of evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more evidence but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and possible usecases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment identifies a specific area for improvement, it does not provide detailed guidance on what kind of evidence or analysis is needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper lacks evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the specific areas that require more evidence or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS compared to other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be most beneficial or how to present it effectively. Despite this, the comment provides a valuable direction for the authors to enhance their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 5 is difficult to comprehend and requests more details about the two baselines presented. It also points out that the authors only studied CATER for Englishcentric datasets, suggesting that they could extend CATER to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending CATER to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely that it is hard to comprehend, and requests more details about the two baselines presented. Additionally, the comment points out the limitation of the study being confined to Englishcentric datasets and suggests extending CATER to other languages. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented. It also points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests extending CATER to other languages. While the comment identifies a potential issue with the figure and a limitation in the study, it lacks specific examples or detailed reasoning to fully support the claim. The suggestion to extend CATER to other languages is based on common knowledge about text generation APIs, but the comment could be strengthened with more explicit evidence or references. Therefore, the claim is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, stating that it is hard to comprehend. It provides a clear and actionable suggestion by requesting more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study, noting that it only considers Englishcentric datasets, and suggests that the authors could extend their work to other languages in the future. This feedback is valuable as it highlights a potential area for improvement and offers a constructive suggestion for enhancing the comprehensibility and scope of the study. However, the comment could be more helpful if it provided specific guidance on how to enhance the figure or suggested additional languages to consider. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the literature review needs improvement, specifically highlighting the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and provides a direct action for the authors to take, which is to enhance the literature review by making it more explicit and comparative. The suggestion is concrete, as it specifies what needs to be done to improve the literature review. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the literature review section, indicating that it needs improvement. It specifies the issues, such as the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This provides clear guidance on what needs to be addressed in the literature review section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and lacks a comparative analysis of the proposed method with existing work, particularly regarding the utilization of GFlowNet for sequence generation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence renders the claim 3, as it provides a general direction for improvement but lacks concrete guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the literature review. It points out that the current literature review lacks clarity regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment provides a clear and actionable suggestion to enhance the literature review by making it more explicit and comparative. This feedback is valuable as it guides the authors on how to improve the clarity and comprehensiveness of their literature review, which is essential for readers to understand the novelty and significance of their work. However, the comment could be more helpful if it offered specific examples or references to illustrate the improvements needed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests eliminating section 3.2, implying that the content is not necessary for the readers. However, it does not provide any reasoning or explanation for why this section is redundant or how its removal would impact the paper. The action is explicit but lacks concrete details on how to implement the suggestion, making it 3. The authors know they need to consider removing the section, but they are not provided with specific guidance on how to do so or what aspects of the section might be problematic.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the suggestion to eliminate this section, providing a clear direction for improvement. The comment explains that readers are presumed to know about the GumbelSoftmax/Concrete distribution, which justifies the suggestion to remove this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests eliminating section 3.2, claiming that readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment lacks any supporting evidence or reasoning to justify why this assumption is valid or why the section is unnecessary. Without additional context or examples, the claim remains vague and 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests eliminating section 3.2, implying that the content is redundant and that readers are already familiar with the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential area for reduction, it lacks specific reasoning or examples to support why this section is unnecessary or how its removal would improve the paper. The comment does not provide actionable guidance or suggestions for alternative content that could enhance the draft. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects on the improvements observed in the paper, rather than the distillation process itself. It suggests that the finetuning on GLUE without earlystopping could lead to high variances, and proposes that proper ablation studies are needed to verify the claims. While the comment implies that the authors should conduct additional studies to address this concern, it does not provide explicit instructions on how to perform these studies or what specific analyses are needed. The action is implicit and somewhat vague, as the authors can infer the need for additional studies but may not know exactly how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim that distillation improves the teacher\"s performance, suggesting that the improvements could be due to regularization effects rather than distillation. It specifically mentions the finetuning on GLUE without earlystopping, which is a unique aspect of the paper. However, the comment does not explicitly mention which section or part of the paper discusses this claim, making it weakly grounded. The comment is specific in detailing the need for proper ablation studies to verify the claims, but without explicit references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that finetuning on GLUE without earlystopping can lead to high variances, which could mask the true effects of distillation. The comment suggests that proper ablation studies are needed to verify the claims. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the impact of regularization effects. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical point about the potential impact of regularization effects on the observed improvements in the teacher\"s performance, rather than attributing them to distillation as claimed. It suggests that the finetuning process without earlystopping could lead to high variances, which might mask the true effects of distillation. The comment provides a clear and actionable suggestion for the authors to conduct proper ablation studies to verify their claims. This feedback is valuable as it highlights a potential flaw in the paper\"s methodology and offers a specific direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to design these ablation studies or what specific aspects to focus on. Overall, the comment is 4, as it effectively identifies a critical area for improvement and offers a constructive suggestion for further research."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and concrete, providing the authors with specific actions to take to improve their draft. The use of specific examples, such as the MUSE paper, further enhances the actionability of the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as adding performance metrics on word similarity and sentence translation tasks, and including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and detailed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests two improvements for the experiments: (i) adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages. The first suggestion is supported by referencing the MUSE paper, which provides a clear basis for the recommendation. The second suggestion is also logical and aligns with common practices in language evaluation. However, the comment could be strengthened by providing specific examples or references for the second point. Overall, the claim is 4, as it provides a solid basis for the first suggestion and logical reasoning for the second, but lacks detailed examples for the latter. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the experiments in the paper. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. This is a clear and actionable suggestion that can help the authors demonstrate the robustness and effectiveness of their framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This is a minor point but still valuable for expanding the scope of the experiments and providing a more comprehensive evaluation. The comment is 4 as it offers concrete and actionable feedback that can guide the authors in enhancing their experimental setup and results. However, it could be more helpful if it provided additional context or examples to support the suggestions. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the applicability of node importance in a 1shot scenario and another about the absence of a 1shot setting in the experiment section, despite related works like RALE having such a setting. While the comment highlights areas that need clarification or explanation, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to provide more context or explanation regarding the use of node importance in a 1shot scenario and consider including a 1shot setting in their experiments. However, the lack of concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment raises two distinct questions: one about the applicability of node importance in a 1shot scenario and another about the absence of a 1shot setting in the experiment section, despite related works like RALE having such a setting. While the comment does not explicitly mention specific sections of the paper, the authors can infer that the first question pertains to the methodology or results section, and the second question relates to the experiment section. However, the comment does not specify which part of the experiment section is missing the 1shot setting, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the applicability of node importance in a 1shot scenario and the inclusion of a 1shot setting in the experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: one about the applicability of node importance in a 1shot scenario and another about the absence of a 1shot setting in the experiment section, despite related works like RALE having such a setting. The first question is a request for clarification and does not contain a claim that requires verification. The second question is a factual observation about the absence of a 1shot setting in the paper, which is not a claim but rather a statement of fact. Therefore, the comment is factual and does not contain any claims that need verification. It should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two distinct questions that could help the authors improve their draft. First, it questions the applicability of node importance in a 1shot scenario, which could prompt the authors to clarify or expand their methodology. Second, it points out the absence of a 1shot setting in the experiment section, despite related works like RALE having such a setting. This observation could encourage the authors to consider including a 1shot setting in their experiments to enhance the comprehensiveness of their study. While the comment identifies areas for improvement, it lacks specific suggestions or detailed guidance on how to address these issues. Therefore, it is 3, as it provides insight into potential weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the formula, specifically mentioning the need for specific details about the BCE formula, even if it is simple. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. The comment provides a specific example of what needs to be addressed, making it 5. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the formula, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear request for more details about the formula, even if it is simple, and suggests giving specific details about the BCE formula. This level of detail guides the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more details about the formula, specifically mentioning the BCE formula. However, the comment does not provide any reasoning or justification for why these details are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of these details or how to address the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by requesting more details about the formula, specifically mentioning the BCE formula. While the comment is straightforward, it lacks depth and does not offer specific guidance on what aspects of the formula should be detailed or how this would enhance the paper. The feedback is 3 as it identifies an area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these issues. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to conduct these discussions or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but may not know exactly how to approach it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion for additional discussion but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that there should be more discussion about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with finegrained hard constraints and how to address these problems. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional insights and analysis. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach these discussions. Despite this, the feedback provides a valuable direction for the authors to enhance their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why selfsupervised learning is necessary for 360 video data with spatial audio. It implies that the authors should provide more justification or explanation for this choice. However, the comment does not explicitly instruct the authors to add this information or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add an explanation but are not given specific instructions on how to do it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results section, specifically questioning the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more insight into why this approach is valuable. However, the comment does not explicitly mention which part of the experimental results section it is referring to, making it weakly grounded. The comment is specific in its request for additional insight into the necessity of selfsupervised learning on this type of data. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of selfsupervised learning on 360 video data with spatial audio, suggesting that the paper lacks insight into why this approach is valuable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, it lacks insight into why selfsupervised learning is necessary for this type of data. This observation highlights a critical area for improvement, as it prompts the authors to provide a more detailed explanation of the rationale behind their approach. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this gap. Despite this, the feedback is 3 as it directs the authors to a significant area for enhancement, encouraging them to provide a clearer justification for their method. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which gives the authors a clear direction on how to enhance the clarity of their draft. Second, it instructs the authors to include labels for subfigures in Figs 3 and 4, rather than just stating them in the captions. This feedback is concrete and provides specific steps for the authors to follow, ensuring they know exactly what changes to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the link between IP and the terms/equations should be explained more explicitly and prominently, and by instructing the authors to include labels for subfigures in these figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figs 3 and 4, rather than just stating them in the captions. However, the comment does not provide any reasoning or evidence to support why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improving the clarity and presentation of the paper. First, it recommends explaining the link between IP and the terms/equations more explicitly and prominently, which could enhance the reader\"s understanding of the material. Second, it instructs the authors to include labels for subfigures in Figs 3 and 4, rather than just stating them in the captions, which would improve the accessibility and clarity of the figures. These suggestions are clear and actionable, offering the authors concrete steps to enhance the quality and readability of their draft. However, the comment could be more helpful if it provided additional context or examples to support the first suggestion. Overall, the feedback is 4, as it provides valuable guidance for improving the paper\"s clarity and presentation."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, providing them with a specific step to improve their draft. The comment is concrete in its guidance, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests averaging results over multiple runs to determine statistical significance, but it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. Without explicit references to sections or figures, the authors may find it challenging to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the results should be averaged or how this would impact the determination of statistical significance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. This is a common practice in experimental design to ensure the reliability of results. However, the comment does not provide specific examples or references to support why this is necessary or how it would impact the analysis. While the suggestion is based on a logical reasoning, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their findings. By averaging results over multiple runs, the authors can better understand the variability and significance of their results, which is crucial for the validity of their conclusions. However, the comment could be more helpful if it provided additional context or examples of how this should be implemented or why it is important for the specific study. Despite this, the feedback is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis, specifically noting that only the SimCLR case is covered and that the projection head, an important part of the approach, is not analyzed. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include an analysis of the projection head, but it does not specify how this should be done or what aspects of the projection head should be analyzed. This lack of explicit action and detailed guidance makes the comment 3, as the authors can infer the need for additional analysis but may not know exactly how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SimCLR\" and \"projection head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis on an important aspect of the SimCLR approach, namely the projection head, and references recent papers like SimCLRv2 that highlight its significance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is incomplete because it only covers the SimCLR case and neglects the projection head, an important part of the approach. The reviewer supports this claim by referencing SimCLRv2 and other recent papers that highlight the significance of the projection head. This provides a logical reasoning and external references to substantiate the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed references to these recent papers. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis by noting that only the SimCLR case is covered, while the projection head, an important aspect of the approach, is not analyzed. This feedback is clear and actionable, as it directs the authors to include an analysis of the projection head, which could provide valuable insights into the approach. By referencing recent papers like SimCLRv2, the comment also offers a specific direction for the authors to explore. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects of the projection head should be examined. Overall, the comment is 4 as it effectively points out a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should highlight the observations and conclusions made in the experimental section, as this would be beneficial for understanding the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place the highlights or how to present the information. The action is implicit and somewhat vague, as the authors can infer that they need to make the observations more visible but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section these observations and conclusions are located in, making it weakly grounded. The comment is specific in suggesting that the paper should highlight these observations and conclusions, which would be beneficial for understanding the tradeoffs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are important or how they relate to the tradeoffs. Without additional context or evidence, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and accessibility of the paper. However, it could be more helpful if it offered specific guidance on how to present these observations and conclusions, such as suggesting where to place them or how to structure the presentation. Overall, the comment is 4 as it directs the authors to a significant improvement in the clarity and impact of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies what needs to be done, which is to conduct ablation experiments on the modifications mentioned in Section 3.4. This level of detail gives the authors a concrete understanding of how to implement the suggested action, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting ablation experiments on the modifications mentioned in this section to further validate the model\"s performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. This claim is 3 as it provides a logical reasoning for why ablation experiments would be beneficial. However, it lacks specific examples or references to support the necessity of these experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting ablation experiments on the modifications mentioned in Section 3.4 to further validate the model\"s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness of their results by testing the impact of individual modifications. By doing so, the authors can gain a deeper understanding of which modifications are crucial for the model\"s performance. However, the comment could be more helpful if it included examples of specific modifications or suggested how to design the ablation experiments. Overall, the comment is 4 as it offers a constructive suggestion for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It also references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this comparison without specific guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to \"Remark 1,\" which suggests that the authors can identify the specific part of the paper being addressed. However, it does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in suggesting a comparison of performance on datasets with a decision space beyond binary, which could help the authors address a potential limitation of their approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, referencing a specific work by Zhang et al. The comment suggests comparing the performance on datasets with a decision space beyond binary, which is a logical suggestion for further exploration. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to delve deeper into the literature or conduct additional analysis to fully understand the implications of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. This feedback is 3 as it identifies a potential area for improvement and suggests a specific comparison that could be made to enhance the paper. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment offers a clear direction for further exploration but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide explicit or implicit actions for the authors to take. There are no suggestions on how to address these issues, such as conducting additional experiments or analyzing the artifacts. The lack of guidance or specific instructions leaves the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what is meant by \"unexpected artifacts\" or how they relate to the pipelining method. Without clear guidance on where to address these issues, the comment is 1 and lacks specificity. Therefore, this comment is categorized as 1.", "verifiability_rationale": "The review point raises two separate concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two distinct concerns: the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any specific guidance or suggestions on how the authors might address these issues. Without actionable feedback or detailed analysis, the authors are left without a clear understanding of what needs to be improved or how to improve it. This lack of direction makes the comment unhelpful, as it does not offer any meaningful insights or steps for the authors to take to enhance their draft. Therefore, the comment is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans and notes the absence of a \"proof.\" While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should fill in Appendix A and clarify the purpose and proof of Proposition B.1. However, the lack of concrete guidance on how to improve these sections makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with these sections, namely that Appendix A is left blank and the purpose of Proposition B.1 is unclear. The comment further questions whether the \"proof\" is missing and suggests that Proposition B.1 might be an illustration of a wellknown concept in machine learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the content of the appendices, specifically noting that Appendix A is left blank and questioning the purpose of Proposition B.1 in Appendix B. It suggests that the \"proof\" is missing and implies that the concept might be a wellknown principle in machine learning. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the concept is wellknown or that the proof is missing. This makes the claim 3, as it provides a basis for the critique but requires further elaboration or evidence to fully substantiate the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely an illustration of the classic partitioning principle of Kmeans, suggesting that this concept is wellknown in machine learning. The comment also points out the absence of a \"proof,\" which is a critical component of the paper. By highlighting these issues, the comment provides clear and actionable feedback that can help the authors improve their draft by addressing the gaps in their appendices and clarifying the purpose and proof of Proposition B.1. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity of the appendices. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these experiments to enhance the paper. The comment is specific and concrete, as it outlines exactly what experiments are missing and what the authors should focus on. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the parts of the paper that need improvement. The comment is also specific because it clearly specifies what is missing, providing a clear direction for the authors to enhance their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or reasoning to support why these experiments are necessary or how they would enhance the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work to improve its comprehensiveness and robustness. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or provided examples of similar studies that have included such analyses. Despite this, the comment is 4 as it directs the authors to important areas for improvement, making it a valuable feedback for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the approximations introduced in the paper, specifically mentioning lines 107110 where the assumption of attacks being in the feasible set is made. The reviewer suggests that this vulnerability needs to be expanded upon to reassure readers that it is not a real concern. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to expand on the vulnerability. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detail but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) where the assumption of attacks being in the feasible set is made. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential vulnerability related to the approximations introduced and suggests that this issue needs to be expanded upon to reassure readers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approximations introduced in the paper leave \"loose ends\" and suggests that the vulnerability related to the assumption of attacks being in the feasible set needs to be expanded upon. The comment provides a specific reference to lines 107110, which helps to ground the claim. However, it lacks detailed reasoning or examples to fully substantiate the claim about the vulnerability. While the reviewer identifies a potential issue, the comment could be strengthened by providing more explicit evidence or reasoning to support the claim. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the approximations introduced in the paper, specifically highlighting a vulnerability related to the assumption of attacks being in the feasible set. It acknowledges that approximations are necessary for deriving clean results but emphasizes the need to address this vulnerability to reassure readers. The comment provides a clear direction for the authors to expand on this issue, which is a valuable suggestion for improving the paper\"s clarity and robustness. However, it could be more helpful if it offered specific guidance on how to address the vulnerability or suggested potential solutions. Overall, the comment is 4 as it directs the authors\" attention to a critical area that requires further elaboration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution of the paper is limited and the proposed model is incremental in its approach. However, it does not provide any specific guidance or suggestions for the authors to address these concerns. There is no explicit or implicit action for the authors to take, such as revising the contribution section or explaining the novelty of the model. Without any actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution and incremental nature of the proposed model but does not specify which part of the paper this assessment is based on. It lacks grounding as it does not identify a specific section, figure, or aspect of the paper being addressed. Additionally, it is not specific about what aspects of the contribution or model are considered limited or incremental. Without clear references or detailed feedback, the authors cannot effectively address the concerns raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper appears limited and that the proposed model is incremental in its approach. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper appears limited and that the proposed model is incremental in its approach. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived limitations or enhance their work. As a result, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct a more careful analysis, particularly for \"old\" benchmarks where the model may have indirectly seen the data through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional details, it does not specify exactly how to do so or what specific aspects of the evaluation procedures need more detail. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on various benchmarks, setting new stateoftheart (SoTA) scores. It also mentions the need for a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. However, the comment does not specify which benchmarks are being referred to or where in the paper these issues are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in its suggestion for a more detailed analysis and evaluation procedures, but it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new stateoftheart scores, but suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model. The comment implies that the evaluation procedures could be improved by providing more details. However, it does not provide specific examples or references to support the claim about the \"old\" benchmarks or the need for a more detailed analysis. The lack of concrete evidence or detailed reasoning makes the claim 3, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the impressive performance of the proposed model on various benchmarks, noting that it sets new stateoftheart scores. However, it suggests that a more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. This feedback is 3 as it points out a potential issue with the evaluation process and recommends providing more details about the evaluation procedures. While the comment identifies a relevant area for improvement, it lacks specific guidance on how to conduct the more careful analysis or what additional details are needed. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the experimental part, specifically noting that the different methods in the two sets of benchmarks proposed in the article are quite different for different OPE methods. The reviewer requests that the authors provide comments on the differences between the two sets of evaluation methods. While the comment identifies an area for clarification, it does not explicitly instruct the authors to address this issue or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the differences between the two sets of benchmarks proposed in the article for different OPE methods and requests comments on these differences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper verifies different metrics for different OPE methods but notes a discrepancy in the methods used in Figure 4 and Figure 5. However, it does not provide specific examples or detailed reasoning to support the claim of differences between the two sets of benchmarks. The comment lacks sufficient evidence or justification to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different methods in the two sets of benchmarks proposed in the article are quite different for different OPE methods. It requests that the authors provide comments on the differences between the two sets of evaluation methods. This feedback is 3 as it points out a potential area of confusion or inconsistency in the experimental setup, prompting the authors to clarify or address this discrepancy. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method has no advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models learned based on each dataset, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the experimental setup or provide additional context to justify the use of prior knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method has no advantage over the stateoftheart without prior information and that the comparison is unfair due to the added complexity and cost of using two representation models. The comment provides a clear critique of the experimental setup and suggests that the authors should consider these factors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method has no advantage over the stateoftheart (SOTA) without prior information, but shows an advantage when using prior knowledge. The reviewer argues that this comparison is unfair due to the added complexity and cost of using two representation models. While the comment provides a logical reasoning for the unfairness of the comparison, it lacks specific examples or references to support the claim about the SOTA or the proposed method. This makes the claim 3, as the authors would need to delve deeper into the literature or their own results to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method has no advantage over the stateoftheart (SOTA) without prior information. It highlights that the advantage only appears when using prior knowledge, which could be considered unfair due to the added complexity and cost of using two representation models. This feedback is 3 as it points out a critical aspect of the experimental setup that needs attention. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve the comparison. To be more helpful, the comment could provide recommendations on how to adjust the experimental design or analysis to better evaluate the proposed method. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is an explicit suggestion, as it clearly indicates what the authors should do to improve their draft. However, the comment does not provide specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While the action is clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a suggestion for improvement rather than a claim that requires verification. It does not express an opinion, judgment, or subjective statement that needs justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a valuable suggestion as it could provide a more comprehensive understanding of the methods\" performance in different scenarios. However, the comment lacks specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes them difficult to be convincing. However, it does not provide explicit guidance on what specific information should be included in the experimental settings or how the authors should present it. The action is implicit, as the authors need to infer that they should add the missing information, but it is vague because it lacks concrete details on what exactly should be included. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing experimental settings, which makes it difficult for the figures to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes them hard to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing. This is a critical piece of information that is essential for understanding and evaluating the results presented in the figures. By pointing out this omission, the comment highlights a key area that needs attention and improvement. However, it does not provide specific guidance on what information should be included in the experimental settings or how to present it. While the comment is clear about the issue, it lacks actionable suggestions for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the ambiguity in the proposed method\"s ability to avoid impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide explicit guidance on how the authors should clarify this issue or what specific steps they should take to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify the method\"s impact on learning new task knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It mentions the proposed pathway protection method based on sparsity in activation channels and notes that some parameter isolation methods are tailored to leverage this sparsity. However, the comment highlights the ambiguity in how the proposed method avoids impeding the learning of new task knowledge. While the authors can infer that this relates to the methodology or results sections, the comment does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing the issue of ambiguity regarding the method\"s impact on learning new task knowledge. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is unclear regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to delve deeper into the literature or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s rationale, specifically the ambiguity surrounding how the proposed pathway protection method avoids impeding the learning of new task knowledge. It highlights a relevant issue by noting that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\" approach. However, the comment does not provide specific suggestions or examples on how the authors might clarify this ambiguity or address the issue. While it points out a critical area for improvement, the feedback lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that it lacks theoretical support. It implies that the authors should consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. While the comment provides a specific suggestion, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, providing a specific critique about its adhoc nature and lack of theoretical support. It suggests considering alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is specific in detailing what aspect of the regularization needs improvement and provides a concrete suggestion for alternative statistics. However, it does not explicitly mention which part of the paper discusses the regularization term, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, despite the author providing an intuitive explanation. The reviewer suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about the adhoc nature of the regularization term. The suggestion to use the median is a reasonable one, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the adhoc nature of the regularization term and its lack of theoretical support. It suggests that the authors consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is clear and actionable, as it provides a specific suggestion for improvement and encourages the authors to explore theoretical justifications for their regularization approach. However, the comment could be more helpful if it offered additional guidance on how to incorporate these alternative statistics or provided examples of similar approaches in the literature. Overall, the comment is 4, as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by specifying the need to integrate benchmark comparisons against stateoftheart fairness algorithms. This would enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. The comment provides specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking comparisons with existing fairness algorithms and suggests integrating benchmark comparisons against stateoftheart fairness algorithms. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper by providing evidence of the proposed method\"s performance. The comment logically reasons that such comparisons are necessary for positioning the ManyFairHPO framework within the existing FairML research landscape. However, it does not provide specific examples of existing fairness algorithms or detailed reasoning on why these comparisons are crucial. While the claim is 4, it could be strengthened with more detailed justification or references to specific algorithms. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section of the paper, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method\"s performance. This feedback is highly valuable as it guides the authors on how to strengthen their experimental section and position their work within the existing research landscape. The comment is specific and actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they should also include the iteration cost of related methods, including baseline methods. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be added to their draft to address the reviewer\"s concern, and the comment provides concrete guidance on how to implement this action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the \"iteration cost (computational budget)\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors should include the iteration cost of all related methods, including baseline methods. This provides clear guidance on what the authors should add to their discussion, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and related methods, including baseline methods. This is a reasonable request for additional information, as it could help readers understand the efficiency and scalability of the proposed approach. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this discussion based on their own understanding of the paper\"s context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to discuss the iteration cost (computational budget) of the proposed method. It also recommends including the iteration cost of related methods, including baseline methods, which would enhance the paper\"s comprehensiveness. This feedback is specific and offers a concrete way for the authors to improve their draft by providing more detailed information about the computational efficiency of their approach. However, the comment could be more helpful if it offered additional guidance on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take in the experimental section. It suggests reporting the average over multiple runs to better compare the results, as the current results are very close together. Additionally, it recommends discussing the decision boundaries in the toy dataset, as this would be an interesting aspect to explore. Finally, it asks for clarification on the information presented in Fig. 9, specifically the middle and right parts. These suggestions are clear and concrete, providing the authors with specific steps to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and references specific sections (Sec. 3.1 and Sec. 3.3) and a figure (Fig. 9), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear and actionable feedback, such as suggesting the reporting of average results over multiple runs, discussing the decision boundaries in the toy dataset, and seeking clarification on the information presented in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions and requests for clarification regarding the experimental section and specific sections of the paper. It does not contain subjective opinions, judgments, or claims that require verification. It is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback for improving the draft. It suggests reporting the average results over multiple runs to better compare the methods, which is a clear and concrete suggestion. Additionally, it recommends discussing the decision boundaries in the toy dataset, which could enhance the understanding of the results. The comment also requests clarification on the information presented in Fig. 9, which is a direct and helpful request for additional detail. These suggestions are detailed and provide the authors with clear guidance on how to enhance their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the model. There is no guidance on potential modifications, alternative approaches, or further research directions that could help mitigate the issue. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the proposed model, namely that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the issue with the model, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the new proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed model, namely that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a valuable observation that highlights a potential constraint of the model, which could impact its applicability and effectiveness. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore ways to mitigate the curse of dimensionality. While it points out a critical issue, it lacks actionable feedback or constructive advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of the homolumo gap, citing an example from the QM9 dataset where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. The comment suggests that this finding may contradict the paper\"s claim of a \"generalpurpose neural network model.\" While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve their model. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the generalizability of their model and potentially revise their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and references the \"QM9\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of the issue, namely the poor performance of TransformerM on most tasks except those related to homo, lumo, and gap, and suggests that this may contradict the paper\"s claim of a \"generalpurpose neural network model.\" This level of detail provides the authors with clear guidance on what needs to be addressed in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of the homolumo gap may lead to negative transfer, citing an example from the QM9 dataset where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This claim is supported by the specific example from the QM9 dataset, which provides a concrete instance of the potential issue. However, the comment could be strengthened by providing more detailed analysis or references to similar findings in the literature. Overall, the claim is 4, as it offers a clear example but lacks additional supporting evidence or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of the homolumo gap. It provides a specific example from the QM9 dataset, where TransformerM performs poorly on most tasks except those related to homo, lumo, and gap. This observation is relevant to the paper\"s claim of a \"generalpurpose neural network model,\" as it suggests that the model may not be as versatile as claimed. The comment highlights a potential issue that the authors should address, offering a clear direction for further investigation or clarification. However, it could be more helpful if it provided suggestions on how to address this issue or improve the model\"s generalizability. Overall, the comment is 4 as it identifies a critical area for improvement and provides a specific example, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state it is not insightful for discriminating model defenses but then use it in Figure 4 A&B. The reviewer is seeking clarification on why this metric was found useful in this context but not elsewhere. While the comment does not explicitly instruct the authors to revise their draft, it implies that the authors should provide a clearer explanation or justification for their use of the metric. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency and provide a rationale. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082 and figure 4 A&B, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in the authors\" use of the center correlation metric, asking for clarification on why it was found useful in figure 4 but not elsewhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inconsistency in the authors\" use of the center correlation metric, noting that it is initially stated as not insightful for discriminating model defenses but is then used in Figure 4 A&B. The reviewer seeks clarification on why this metric was found useful in this context but not elsewhere. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of inconsistency. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" use of the center correlation metric. It points out that the authors initially state that the metric is not insightful for discriminating model defenses, but then use it in Figure 4 A&B. The reviewer questions the reasoning behind this inconsistency, seeking clarification on why the metric was found useful in this context but not elsewhere. This feedback is 3 as it highlights a specific area of confusion that the authors need to address. However, it lacks depth and does not provide specific suggestions on how to resolve the inconsistency or improve the clarity of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a detailed explanation of why this term might be misleading, noting that it implies the total variation between test and train distributions of the network\"s outputs vanishing to zero, which may not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide specific guidance on how to rephrase it. While the authors can infer that they should reconsider the term, the feedback lacks concrete action steps, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the term, explaining that it might be too strong to capture the empirical phenomenon presented and that it implies a conclusion that may not be supported by the data. The comment provides a clear critique of the terminology used, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented. It provides a logical explanation by noting that the phenomenon represents the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which may not be the case based on a few test functions. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or examples that support the critique, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific critique of the term \"distributional generalization\" used in the paper, suggesting that it might be too strong to accurately describe the empirical phenomenon presented. It offers a detailed explanation of why this term might be misleading, noting that it implies a conclusion about the total variation between test and train distributions that may not be supported by the data. This feedback is clear and actionable, as it prompts the authors to reconsider their terminology and potentially provide a more accurate description of their findings. However, the comment could be more helpful if it suggested alternative terms or provided examples of how to rephrase the description. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a subjective opinion about the theoretical contribution being \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to strengthen the theoretical contribution, improve the bound, or enhance the mathematical novelty of the proof. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on how to improve the theoretical contribution. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the theoretical contribution need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the theoretical contribution being \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s assessment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a subjective assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not offer any specific suggestions or guidance on how the authors might improve their theoretical contribution or address the issues raised. Without actionable feedback or constructive advice, the authors are left without a clear path for enhancing their work. Therefore, the comment is 1, as it does not provide any meaningful insights or directions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues with the experimental evaluation section. First, it notes that the \"picking\" step is not ablated, which is a claim made in the paper but not supported by experimental evidence. Second, it criticizes the comparison on CIFAR, suggesting that the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper, which could make the comparison unfair or incorrect. The comment provides specific suggestions for improvement, such as abating the \"picking\" step and ensuring that the comparison to DEN is fair by using the same setup. These suggestions are explicit and concrete, giving the authors clear guidance on how to address the issues. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the ablation study, specifically the lack of ablation for the \"picking\" step, and the comparison on CIFAR, which is not convincing due to the limited comparison to only one approach (DEN). The comment further specifies that the comparison would be more convincing if the authors used the same setup as in the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s ablation study is incomplete because it does not include the \"picking\" step, and that the comparison on CIFAR is not convincing due to the limited comparison to only one approach (DEN). The comment suggests that using the same setup as in the DEN paper would make the comparison more fair and convincing. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion to use the same setup as in the DEN paper is a logical step, but the comment could be strengthened by providing more context or references to support the critique. Therefore, the claim is 3, as it provides a basis for the critique but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental evaluation section of the paper. It points out that the \"picking\" step is not ablated, which is a claim made in the paper but not supported by experimental evidence. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and does not use the same setup as in the DEN paper, which could make the comparison unfair or incorrect. The comment suggests that using the same setup as in the DEN paper would make the comparison more convincing. This feedback is clear and provides the authors with specific guidance on how to improve their experimental evaluation, making it 4. However, it could be more comprehensive by suggesting additional comparisons or experiments to strengthen the evaluation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" for easier interpretation. This is an explicit suggestion, as it clearly indicates what change should be made to improve the clarity of the plot. However, the comment does not provide detailed guidance on how to implement this change, such as whether to add a thin gray diagonal to the plot or how to label it. While the action is explicit, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment suggests a change in terminology from \"above/below 45 degree\" to \"above/below diagonal\" for easier interpretation. However, it does not specify which part of the paper this suggestion pertains to, such as a figure or table where this terminology is used. Without explicit references or context, the authors may find it challenging to identify the exact sections that need revision. The comment is specific in suggesting a change in terminology but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the term \"above/below 45 degree\" is less intuitive than \"above/below diagonal\" for interpreting a plot. The reviewer provides a logical explanation by comparing the two terms, noting that \"above/below 45 degree\" might be misinterpreted as a local property, whereas \"above/below diagonal\" is more straightforward. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a change in terminology from \"above/below 45 degree\" to \"above/below diagonal\" for easier interpretation of a plot. This is a specific and actionable suggestion that could improve the clarity and accessibility of the paper. By making this change, the authors can enhance the understanding of their results for readers. However, the comment could be more helpful if it provided additional context or examples of how this change would impact the interpretation of the data. Overall, the feedback is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the exact action and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (\"L240 and L428\") in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it questions the phrase \"is sufficient\" and provides a possible interpretation of what the authors might mean by it, suggesting that they should clarify the context. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide any evidence or references to support this interpretation, leaving the authors to infer the necessity of clarification. This makes the claim 3, as it lacks specific examples or references to fully substantiate the suggestion for improvement.", "helpfulness_rationale": "The review comment questions the phrase \"is sufficient\" at specific lines (L240 and L428), suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it identifies a potential ambiguity in the text and offers a possible clarification. However, it could be more helpful if it provided additional guidance on how to rephrase the sentence for clarity. Overall, the comment is 3, as it directs the authors to a specific area needing clarification but lacks depth in suggesting how to improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their work. The feedback lacks actionable details, leaving the authors uncertain about what steps to take to clarify the scientific contribution of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear scientific insight and the need for a clearer explanation of how the model provides further understanding of nonlinear RNN models. The comment provides a detailed critique of the work, making it clear what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 2, as it lacks sufficient evidence or detailed justification to be 5.", "helpfulness_rationale": "The review comment raises a critical point about the lack of clarity regarding the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, suggesting that the work may not offer a new explanation for how these models attain solutions through optimization. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to clarify their contribution. However, it could be more helpful if it provided specific suggestions or examples on how to address this issue, such as proposing alternative explanations or experiments to demonstrate the model\"s unique value. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests that the text in legends and axis labels should be larger, and it specifically mentions that \"Proposition (1)\" should be corrected to \"Proposition 1\" to avoid confusion with Equation 1. Additionally, it recommends increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These instructions are clear and direct, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and provides guidance on correcting \"Proposition (1)\" to \"Proposition 1\" to avoid confusion with Equation 1. It also specifies the need for larger font sizes in Figure 2 and 3. This level of detail allows the authors to accurately identify the parts of the paper that require revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as recommending larger font sizes for legends and axis labels, and correcting the notation \"Proposition (1)\" to avoid confusion with Equation 1. These are descriptive and do not contain subjective opinions, judgments, or claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the formatting and clarity of the paper. It suggests that the text in legends and axis labels should be larger, which is a clear and concrete improvement that can enhance the readability of the figures. Additionally, it points out a potential source of confusion between \"Proposition (1)\" and Equation 1, recommending a correction to avoid this issue. The comment also advises increasing the font size of captions and legends in Figures 2 and 3 to match the text size. These suggestions are detailed and provide the authors with clear guidance on how to improve the presentation and clarity of their work. Therefore, the comment is 5, as it offers specific and actionable feedback that can significantly enhance the quality of the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific comparison for the counterfactual experiments, recommending a comparison against Journey TRAK [1] at a particular step of the sampling trajectory. It also references a specific figure, [1, Figure 2], which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a clear and concrete action for the authors to take, as it specifies both the comparison to be made and the reference to use. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely a comparison against Journey TRAK at a particular step of the sampling trajectory, and references a specific figure ([1, Figure 2]) to support the suggestion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a comparison against Journey TRAK [1] for counterfactual experiments, specifically referencing Figure 2, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This claim is supported by a specific reference to an external work and a figure, providing a clear basis for the suggestion. The mention of a particular figure and the comparison made offer a robust justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments by recommending a comparison against Journey TRAK [1] at a particular step of the sampling trajectory. It references a specific figure, [1, Figure 2], which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and constructive, offering a concrete way for the authors to enhance their analysis and provide a more comprehensive comparison. By suggesting a specific reference and highlighting a relevant figure, the comment empowers the authors to make a meaningful improvement to their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation from the experimental results, noting that replacing normal convolutions with adaptive convolutions may not always be beneficial. It points out a particular instance where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific analysis or comments should be added to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the placement of adaptive convolutions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3\" and \"ACNNv3\" and \"ACNNv2,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the observation that replacing normal convolutions with adaptive convolutions may not always be beneficial, particularly noting the performance difference between ACNNv3 and ACNNv2. The comment further specifies that there is no analysis or comments on the placement of adaptive convolutions, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, citing a specific example from Table3 where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This claim is 3 as it provides a specific example to support the assertion. However, the comment lacks detailed analysis or references to further substantiate the claim, making it difficult for the authors to fully understand the implications or to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation from the experimental results, noting that replacing normal convolutions with adaptive convolutions may not always be beneficial. It highlights a particular instance where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), suggesting that the placement of adaptive convolutions is important. However, the comment lacks depth and does not offer actionable suggestions on how the authors might analyze or address this aspect of the technique. While it identifies a potential area for improvement, the feedback is incomplete and does not provide detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a tradeoff in the proposed method, noting that while it reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, implying that the authors should consider this aspect in their analysis. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should explore this tradeoff further and potentially discuss it in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its comparison to [10], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the tradeoff between computation time and the richness of the search space, noting that the output of ACI has less information compared to the output of [10]. The comment raises a question about the information encoded in ancestral graphs compared to DAGs, which provides a clear direction for the authors to consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the tradeoff between computation time and the richness of the search space in the proposed method. It suggests that the method reduces computation time by limiting the search space to ancestral graphs, but this comes at the cost of less information compared to the output of a method with a richer search space (DAGs). The comment questions how much information of a DAG is encoded in its corresponding ancestral graph, implying that this is a critical aspect to consider. However, the comment does not provide specific evidence, examples, or references to support the claim or the reasoning behind it. This makes the claim 3, as the authors would need to explore the literature or conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a tradeoff in the proposed method, noting that while it significantly reduces computation time by limiting the search space to ancestral graphs, it also results in less information compared to the output of a method with a richer search space (DAGs). The comment raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a critical aspect to consider in the analysis. This feedback is 3 as it points out a potential limitation of the method and encourages the authors to explore this tradeoff further. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the theoretical discussions could be improved, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer expects to see results that provide sufficient training data points for a given confidence level. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific type of results needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical discussions in the paper, specifically mentioning the current theorems and their relation to fair representation. It suggests that the theorems follow directly from the algorithm design and the property of mutual information to \u0394_DP. The reviewer also expresses a desire for sample complexitytype results, such as determining the sufficient amount of training data points that would not return NSF given confidence levels. This provides a clear direction for improvement, making the comment specific. However, it does not explicitly mention which part of the paper the theoretical discussions are located in, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by including sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation for the type of results they would like to see, such as determining the sufficient amount of training data points for a given confidence level. This expectation is based on logical reasoning and provides a clear direction for improvement. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the improvements needed based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could be enhanced by including sample complexitytype results. It provides a clear direction for the authors to consider, such as determining the sufficient amount of training data points that would not return NSF given confidence levels. This feedback is actionable and offers a concrete suggestion for enhancing the theoretical foundation of the paper. However, the comment could be more helpful if it included specific examples or references to guide the authors in implementing these improvements. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their theoretical discussions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the description of VAD (Voice Activity Detection) in the paper, suggesting that it is misleadingly referred to as a VAD. The reviewer argues that the method described is not a true VAD, as it discards TF bins with a magnitude less than epsilon, which is equivalent to discarding bins with zero magnitude to avoid division by zero. The reviewer provides a clear critique of the method and its naming, but does not offer specific guidance or suggestions for improvement. While the comment highlights a potential issue with the paper, it lacks actionable advice on how the authors might address this concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"VAD description\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the VAD description, pointing out that the method described is not a true VAD and that it discards TF bins with zero magnitude, which is not typical for VAD. The comment provides a detailed critique of the method and its naming, offering a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD (Voice Activity Detection) description in the paper is puzzling and suggests that it is not accurately described as a VAD. The reviewer provides a logical explanation by pointing out that the method described discards TF bins with a magnitude less than epsilon, which is equivalent to discarding bins with zero magnitude to avoid division by zero. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by referencing specific literature or common practices in VAD to further substantiate the claim. Overall, the comment is 4, as it provides a logical argument but lacks detailed references or examples to fully support the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of Voice Activity Detection (VAD) in the paper. It points out that the method described, which discards TF bins with a magnitude less than epsilon, is not accurately represented as a VAD. The reviewer explains that a true VAD should look for the presence of speech, not just energy, and is typically defined over time, not frequency. This feedback is clear and provides a specific critique of the paper\"s methodology, allowing the authors to understand and address the issue. However, the comment could be more helpful if it offered suggestions on how to improve the VAD description or provided examples of how to better align it with the definition of VAD. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors include a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This feedback is explicit and provides concrete guidance on what the authors should include in their discussion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, including a brief discussion on the empirical motivation for using timevarying Q^t and S^t, and providing examples of the effects on volatility and predictive intervals. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors include a discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals. This suggestion is based on logical reasoning and provides a clear direction for the authors to improve their discussion. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors include a brief discussion on the empirical motivation for using timevarying Q^t and S^t, as opposed to a fixed one as in Section 4.2. It provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1^t and the average lengths of the predictive intervals when Q^t and S^t vary with time. This feedback is clear and actionable, offering a concrete suggestion for enhancing the discussion section of the paper. By addressing this point, the authors can provide a more comprehensive understanding of their methodology and its implications, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. The comment concludes by asking the authors to clarify this issue, implying that without clarification, the motivations in the paper may not be solid. While the comment identifies a specific area of concern and suggests a need for clarification, it does not provide explicit instructions on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definitions and motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the definitions of anchorbased regression and the regression in RepPoints, and it provides a comparison with other methods like RetinaNet and ATSS. The comment clearly specifies what needs to be clarified, which is the difference between these methods and why one might be preferred over the others. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definitions in Table 1, specifically regarding the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods do not significantly influence the results. This reasoning is based on common knowledge in the field and provides a logical argument for the claim. However, the comment could be strengthened by including specific references or examples to support the claim more thoroughly. Overall, the claim is 4, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific concern about the definitions in Table 1, questioning the differences between anchorbased regression and the regression in RepPoints. The reviewer provides a detailed explanation of the methods, including RetinaNet and ATSS, and suggests that the regression methods may not significantly influence the results. This feedback is clear and actionable, as it prompts the authors to clarify the definitions and motivations in their work. By addressing this point, the authors can improve the clarity and robustness of their paper. However, the comment could be more helpful if it offered suggestions on how to present the information or provided additional context. Overall, the comment is 4, as it identifies a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to. However, the comment does not provide any specific suggestions or actions for the authors to take to improve the clarity or structure of the paper. There is no guidance on how to enhance the presentation or what specific aspects of the experiments need more detail. As a result, the authors are left without a clear understanding of what changes are needed to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to, but it does not specify which parts of the paper are particularly challenging or which experiments are lacking in detail. The authors may infer that the issue lies in the introduction or the experimental sections, but the comment does not provide explicit guidance or references to specific sections. Therefore, the comment is weakly grounded as it does not clearly identify the parts of the paper being addressed, and it is also not specific in detailing what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity and structure, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments have little to hang on to, which suggests a lack of meaningful results or insights. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or structure of the paper. Without actionable feedback or detailed advice, the authors are left without a clear path to address the identified issues. Therefore, the comment is 2, as it highlights a problem but does not offer constructive ways to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should address the fairness of the comparison and provide additional metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed comparisons and metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously, and requests the inclusion of KID/FID metrics for the teacher network. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional metrics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the comparison might not be fair or why the requested metrics are necessary. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It questions whether this simultaneous training affects the performance of the teacher network and suggests that the authors provide KID/FID metrics for the teacher network. This feedback is clear and actionable, as it prompts the authors to consider the implications of their training approach and to provide additional metrics that could help assess the fairness of the comparison. However, the comment could be more helpful if it provided specific guidance on how to address the fairness issue or suggested alternative methods for comparison. Overall, the comment is 4, as it directs the authors to a critical area that requires further exploration and provides a clear action to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the refinement of the region vector, specifically whether the scaling factor of 2 before global pooling is sufficient. It suggests considering the introduction of a scaling variable before the attention weight. While the comment implies that the authors should explore this possibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement or evaluate the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling effect of the attention weight and suggesting the introduction of a scaling variable. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the refinement of the region vector, specifically whether the scaling factor of 2 before global pooling is sufficient. It suggests considering the introduction of a scaling variable before the attention weight. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this scaling factor might be insufficient or how a scaling variable could improve the model. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a specific concern about the refinement of the region vector, questioning whether the scaling factor of 2 before global pooling is sufficient. It suggests considering the introduction of a scaling variable before the attention weight, which could potentially improve the model. This feedback is clear and actionable, as it identifies a potential issue and offers a concrete suggestion for improvement. However, it could be more helpful if it provided additional context or examples to further clarify the impact of the scaling variable. Overall, the comment is 4, as it provides valuable guidance for the authors to consider, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, namely that failures on the ALFRED benchmark are often due to goal misspecification. It explains that the LLM does not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the goal specification or how to handle ambiguities in human language. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of goal misspecification in the context of the ALFRED benchmark, specifically mentioning the LLM\"s inability to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its impact on the LLM\"s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is 3 as it provides a logical explanation of the issue, but it lacks specific examples or references to support the assertion. The comment does not provide detailed evidence or examples of how goal misspecification leads to failures on the ALFRED benchmark, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of goal misspecification in the context of the ALFRED benchmark. It explains that the LLM\"s failure to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language, contributes to the failures on the benchmark. This feedback is 3 as it highlights a critical area for improvement, but it lacks actionable suggestions or guidance on how the authors might address this issue. While it points out a specific problem, it does not provide detailed advice on how to rectify it, leaving the authors with a general understanding of the issue but without a clear path forward. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the improvement of the method over stateoftheart (SOTA) methods like IGEV, suggesting that the effect may not be significantly improved due to the nature of iterative optimization schemes. The reviewer explicitly suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to understand why the improvement is not significant. Additionally, the reviewer questions whether it is difficult for SamplingGaussian to significantly improve SOTA schemes, which are mostly iterative frameworks similar to IGEV. These suggestions provide clear and concrete actions for the authors to take, such as conducting an analysis and addressing the concern about the difficulty of improving SOTA schemes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment raises concerns about the improvement of the method over stateoftheart (SOTA) methods like IGEV and suggests analyzing the distribution of disparities produced by IGEV compared to other baselines. However, it does not explicitly mention which part of the paper this concern relates to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as analyzing the distribution of disparities and questioning the difficulty of improving SOTA schemes. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the limited improvement of the method over stateoftheart (SOTA) methods like IGEV, suggesting that this might indicate the absence of a multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a logical reasoning by suggesting that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to understand the lack of significant improvement. This reasoning is clear and provides a specific direction for the authors to follow. However, the comment could be strengthened by including specific references or examples to further substantiate the claim. Overall, the claim is 4, as it provides a logical basis for the suggestion but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises a concern about the limited improvement of the proposed method over stateoftheart (SOTA) methods like IGEV, suggesting that this might indicate the absence of a multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a clear and actionable suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to understand why the effect is not significantly improved. Additionally, the comment questions whether it is difficult for the SamplingGaussian method to significantly improve SOTA schemes, which are mostly iterative frameworks similar to IGEV. This feedback is valuable as it prompts the authors to investigate the reasons behind the limited improvement and consider the potential challenges in enhancing SOTA schemes. However, the comment could be more helpful if it offered specific guidance on how to conduct the analysis or address the challenges. Overall, the comment is 4, as it provides clear guidance and encourages the authors to explore the limitations of their method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It explicitly recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback provides a clear and concrete action for the authors to take, as it specifies what additional analysis or presentation could be included to enhance the paper. The suggestion is explicit and provides detailed guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, it implies that this analysis could be integrated into the results or discussion sections. The authors can infer that this suggestion pertains to the sections where modelspecific insights or comparisons are discussed. The comment is specific in suggesting a particular analysis to enhance the paper, but it lacks full grounding as it does not explicitly mention the sections where this analysis should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a logical suggestion for enhancing the paper, it lacks specific examples or references to support the claim that such an investigation would add nuance to the conclusions. The suggestion is based on a reasonable assumption, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is actionable and provides a clear direction for the authors to enhance their analysis and presentation, potentially adding nuance to their conclusions. However, the comment could be more helpful if it included specific examples or detailed guidance on how to conduct this analysis. Overall, the comment is 4 as it offers a constructive suggestion for improving the paper, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment is specific and concrete, as it directly instructs the authors to address a particular aspect of their explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed in, such as a particular section or figure. The authors can infer that it relates to the discussion of Fourier modes, but without explicit references, it remains weakly grounded. The comment is specific in its request for clarification, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a logical suggestion to improve clarity in the paper, but it does not contain a claim that requires verification. It is a request for clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their explanation. By addressing this point, the authors can enhance the understanding of their work for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the overall narrative or results. Overall, the feedback is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to supplement the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5. The authors know exactly what to do to address the feedback, which is to include the comparison results in their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests supplementing the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure. However, it does not specify which part of the paper this comparison is currently presented in, making it weakly grounded. The comment is specific in its request for additional information, as it clearly identifies what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, the comment does not provide any reasoning, evidence, or examples to support why this comparison is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to enhance their analysis by including additional comparisons. However, the comment could be more helpful if it provided specific guidance on what aspects of the comparison should be included or how the results should be presented. Despite this, the comment offers a valuable direction for improving the draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks ablations, specifically mentioning the need to include results using the GCPG model without pretrained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what additional results should be included to address the concern. The comment is 5 because it gives the authors a direct and detailed instruction on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ablations\" and \"results using the GCPG model without pretrained initializations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing from the results, namely, the performance gain due to the task formulation versus pretrained language models. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are unclear regarding the performance gain due to the task formulation versus pretrained language models. It suggests including results using the GCPG model without pretrained initializations to clarify this. The comment provides a logical reasoning for the claim by specifying what additional results would help clarify the contribution of the task formulation. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this suggestion based on the context of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of ablations to clarify the performance gain due to the task formulation versus pretrained language models. It provides a clear and actionable suggestion by recommending the inclusion of results using the GCPG model without pretrained initializations. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their results, allowing them to better understand and communicate the contributions of their work. However, the comment could be more helpful if it offered additional context or examples of how these ablations could be conducted or interpreted. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment points out a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for clarification, labeling, or reorganization of the figure to improve its interpretability. Without any actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement describing a difficulty in understanding Figure 1, specifically the axes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with Figure 1, noting that it is hard to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to clarify the axes of the figure to improve its interpretability. However, the comment could be more helpful if it provided suggestions on how to label or describe the axes to enhance clarity. Despite this, the feedback is 4 as it points out a critical area for improvement, guiding the authors toward enhancing the figure\"s readability. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit guidance on how to achieve this or what specific aspects of the results should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should include ImageNet results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\"s convincingness. The authors might infer that it relates to the results section, but the comment lacks specificity and grounding, making it difficult for them to pinpoint the exact area needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning or evidence to support why ImageNet results would be more convincing or how they would enhance the method\"s validity. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate these results or what specific aspects of the method would benefit from them. The feedback is 3 as it points out a potential enhancement, but it does not offer actionable steps or detailed suggestions for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. It also provides a clear reason for this requirement, noting that the proposed approach is based on implicit differentiation, which typically involves additional computational costs. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of \"2 Direct runtime comparisons with existing methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014direct runtime comparisons\u2014and provides a reason for this necessity, noting that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning supports the claim, making it 4. However, the comment could be strengthened by providing specific examples of existing methods or references to similar studies that have conducted such comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It provides a clear rationale for why such comparisons are necessary, noting that the proposed approach is based on implicit differentiation, which typically involves additional computational costs. This feedback is actionable and constructive, as it guides the authors to include direct runtime comparisons to demonstrate the efficiency of their approach. By addressing this gap, the authors can strengthen their paper and provide a more comprehensive evaluation of their method. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning and questions the technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the framework or what specific aspects need improvement. Without actionable suggestions or feedback, the authors are left without a clear path for revision. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework as a simple combination of metalearning and federated learning, questioning its technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the framework are considered simple or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, questioning its technical contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment questions the technical contribution of the proposed framework, suggesting that it is a simple combination of metalearning and federated learning. However, it does not provide any specific feedback or suggestions on how the authors might enhance the framework or address the perceived lack of technical contribution. Without actionable guidance or detailed critique, the comment offers little value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the sufficiency of the contribution, noting that while the paper studies the connection between complementary and model robustness, it lacks further studies on how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and expects more insightful findings or solutions. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or what specific steps they should take to improve the paper. The action is implicit and vague, leaving the authors without clear direction on how to enhance their contribution. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the paper\"s contribution, specifically regarding the connection between complementary and model robustness. However, it does not explicitly mention which part of the paper this concern is based on, such as specific sections or analyses. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique, suggesting that the paper lacks further studies on leveraging these characteristics to improve robustness and expecting more insightful findings or solutions. However, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient because the paper only studies the connection between complementary and model robustness without exploring how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and expects more insightful findings or solutions. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or that the conclusion is easily obtainable. The reasoning is somewhat vague and does not provide detailed evidence or logical reasoning to substantiate the claim. Therefore, the comment is rated as 3, as it provides some justification but lacks key elements to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the paper\"s contribution, noting that while it studies the connection between complementary and model robustness, it lacks further studies on how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and expects more insightful findings or possible solutions. This feedback is 3 as it identifies a potential weakness in the paper and encourages the authors to explore more indepth analysis or solutions. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, it does not provide explicit guidance or suggestions on how the authors should revise their approach or what specific changes they should make to address this concern. The comment lacks actionable details, leaving the authors uncertain about how to implement the suggested change. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. Without explicit references or clear indications of where this issue arises, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the differences in representation should be explored or how this focus should be adjusted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this focus is odd or how it deviates from the paper\"s motivation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the focus of the paper, suggesting that it should emphasize the differences in representation between clusters rather than identifying the \"best\" clusters. This critique highlights a potential gap in the paper\"s approach and encourages the authors to reconsider their focus. However, the comment lacks specific guidance or suggestions on how to address this issue or what alternative approaches might be more suitable. While it identifies a potential weakness, it does not provide actionable feedback to help the authors improve their draft. Therefore, the comment is 3, as it prompts the authors to think about their approach but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that the caption accurately reflects the content of the figure. The feedback is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, indicating that it should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement regarding the incorrect caption for Figure 7. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective elements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, identifying a specific error in the caption of Figure 7. It provides a precise correction, instructing the authors to change \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is actionable and straightforward, allowing the authors to make a simple correction that improves the accuracy and clarity of their work. However, the comment could be more helpful if it explained why the correction is necessary or how it impacts the understanding of the figure. Despite this, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss case studies and error studies to demonstrate the effectiveness of each proposed component. It provides an example of how this could be done by mentioning a specific case study related to graph pretraining for AMR parsing and generation. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of what could be included, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to demonstrate the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of a case study related to graph pretraining for AMR parsing and generation. This feedback is specific as it identifies a particular aspect of the paper that could be improved and provides a concrete example of how to address it. However, it is not fully grounded because it does not explicitly mention the section where this discussion should be included, leaving the authors to infer the relevant part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of a case study related to graph pretraining for AMR parsing and generation, which supports the claim. However, the comment could be strengthened by explaining why case studies are necessary or how they would improve the paper\"s impact. The suggestion is 4 as it provides a concrete example, but it lacks detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper could be strengthened by including case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of how this could be done, referencing a case study related to graph pretraining for AMR parsing and generation. This feedback is actionable and provides a clear direction for the authors to enhance their draft by adding concrete examples. However, the comment could be more helpful if it offered additional guidance on how to conduct these case studies or what specific aspects to focus on. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It questions the need for additional evaluation of these aspects and requests clarification on the motivation for considering them. While the comment implies that the authors should clarify their approach, it does not provide explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification without detailed instructions on how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the evaluation of disentanglement (D) and the potential entanglement between DCI and ES, which helps the authors understand what needs to be clarified. The comment requests clarification on the motivation for considering explicitness (E) and size (S) as extra evaluation, further specifying what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. The reviewer provides examples to support the claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the entanglement between DCI and ES. While the examples provide some support, the lack of comprehensive evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It provides examples to support this claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). The comment also points out the potential entanglement between DCI and ES, which could impact the evaluation. However, it lacks specific suggestions or guidance on how the authors might address these concerns or clarify the motivation for considering explicitness and size as extra evaluation. While the comment identifies important issues, it does not provide actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be addressed in their draft. The comment is specific and concrete, offering a straightforward path for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue of missing standard deviation after multiple experiments and suggests that the author clarify whether certain effects are within the range of standard deviation fluctuations or are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to confusion about the improvements brought by the SoRA method. The reviewer suggests that the author clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This claim is 3 as it highlights a potential issue with the presentation of experimental results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the issue and how to address it, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, namely the lack of standard deviation after multiple experiments. It points out that the improvement brought by SoRA compared to the baseline is limited and may be due to random fluctuations. The comment provides a clear and actionable suggestion for the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is valuable as it directs the authors to a critical area of their paper that requires clarification, potentially enhancing the clarity and robustness of their results. Therefore, the comment is 4, as it offers specific guidance for improvement but could be further enhanced by providing additional context or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the organization and layout of the paper, including the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. It also mentions formatting issues on page 6. While the comment identifies specific problems, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to improve the organization and layout of the paper, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and layout of the paper, including the font size of annotations in Figure 1 and Figure 2, the lack of explicit drawing of these figures, the incorrect placement of Table 2, and formatting issues on page 6. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific as it details what is wrong with each of these elements, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized, citing specific issues such as the font size of annotations in figures, the lack of explicit drawing of figures, and the incorrect placement of Table 2. These are factual observations that can be verified by examining the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of poor organization. While the specific issues mentioned are verifiable, the overall claim could be strengthened with more comprehensive evidence or explanation. Therefore, the comment is 4, as it provides some support but could be more robust with additional details.", "helpfulness_rationale": "The review comment identifies several specific issues with the organization and layout of the paper, including font size problems with annotations in figures, the lack of explicit drawing of figures, and incorrect placement of Table 2. It also mentions formatting issues on page 6. While the comment highlights these problems, it does not provide detailed suggestions or guidance on how to address them. The authors are left with a general understanding of what needs improvement but without actionable steps to take. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider the practicality and safety of the interventions included in the paper for realworld querying. However, it does not provide explicit guidance on how to assess or address these concerns. The action is implicit, as the authors need to infer that they should evaluate the practicality and safety of their interventions. Additionally, the comment lacks concrete details on how to conduct this evaluation or what specific aspects to consider. As a result, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for realworld querying. However, it does not specify which part of the paper discusses these interventions, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider practicality and safety but lacks grounding due to the lack of explicit references to specific sections or elements of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the interventions included in the paper are reasonable computationally, they may not be practical or safe for realworld querying. However, the comment does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important consideration about the practicality and safety of the interventions discussed in the paper. It encourages the authors to think beyond the computational feasibility and consider the realworld implications of their work. However, the comment lacks specificity and does not provide detailed guidance on how to assess or address these concerns. It does not offer actionable suggestions or examples of what specific aspects of practicality and safety should be evaluated. As a result, while the comment identifies a relevant area for consideration, it is 3 due to its lack of depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues that need to be addressed. First, it questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Second, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment suggests moving the definition of \"p\" to make the paper more understandable. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed guidance on how to address these issues. The actions are explicit but somewhat vague, as the authors know what needs to be clarified or defined but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several specific issues that need clarification or improvement. It questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment suggests moving the definition of \"p\" to improve clarity. These specific points provide clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention which sections of the paper these issues are located in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and questions about the paper. The first claim questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. This is 3 as it points out a potential lack of clarity in the paper, but it does not provide specific examples or references to support the claim. The second claim points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. This is a logical observation that highlights a potential issue with the paper\"s clarity. However, the comment lacks specific examples or references to fully substantiate the claim. Overall, the comment is 3, as it provides a logical basis for the claims but lacks detailed evidence or references to fully support them.", "helpfulness_rationale": "The review comment identifies several specific areas that need clarification or improvement in the paper. It questions the meaning of \"upper faces\" of the convex hull, suggesting that the dual subdivision and projection \u03c0 need better explanation. Additionally, it points out that the variable \"p\" is not explicitly defined, which is problematic since it has been used extensively throughout the paper. The comment provides actionable feedback by suggesting that the definition of \"p\" should be moved to improve clarity. While the comment is clear and identifies important issues, it could be more helpful by providing additional guidance on how to explain the concepts or suggesting specific ways to improve the clarity of the paper. Overall, the comment is 4 as it directs the authors to specific areas that require attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors might address this concern or what specific changes could be made to improve the draft. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure where this idea is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the treatment of images and augmentations are unclear or problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the reviewer\"s skepticism. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the concern effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses a lack of conviction regarding the idea that images and their augmentations need to be treated separately. However, it does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might address this concern. Without detailed feedback or guidance, the authors are left without a clear understanding of what aspects of their draft need improvement or how to enhance their argument. As a result, the comment is 1, as it lacks actionable insights or constructive feedback. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance gain of their proposed method by comparing it to baseline detection or parsing techniques separately. This implies an action for the authors to take, which is to conduct additional evaluations to better support their claims. However, the comment does not provide specific guidance on how to conduct these evaluations or which baseline techniques to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: the generative shape model and the word parsing model. It highlights the need for clarity on which component contributes to the performance gain. The reviewer suggests evaluating the approach separately from baseline detection or parsing techniques to better support the claim. This feedback is specific in its request for additional evaluation to clarify the contribution of each component. However, it is not fully grounded as it does not explicitly mention which part of the paper discusses these components, leaving the authors to infer the relevant sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. The reviewer suggests evaluating the approach separately from baseline detection or parsing techniques to better support the claim. This suggestion is based on logical reasoning, as separating the evaluation would help clarify the contribution of each component. However, the comment lacks specific examples or references to support the claim that the current evaluation is unclear or inadequate. Therefore, the claim is 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the proposed method\"s components and their contributions to performance gain. It suggests that the authors should evaluate their approach separately from baseline detection or parsing techniques to better support their claims. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper\"s clarity and rigor. However, the comment could be more helpful if it offered additional guidance on how to conduct these separate evaluations or which specific baseline techniques to use. Overall, the comment is 4, as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific alternatives. The action is implicit and somewhat vague, as the authors are left to infer that they should explore automated disentangling methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically. However, the comment does not specify which part of the paper discusses the disentangling process or the choice of the semantic segmentation network, making it weakly grounded. The comment is specific in detailing the issue with manual disentangling, but without explicit references to sections or modules, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. The reviewer suggests that it would be more interesting if everything were learned automatically. However, the comment lacks specific reasoning or evidence to support why manual disentangling is a problem or why an automated approach would be preferable. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the manual disentangling process, and questions the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore automated disentangling methods. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their work. The comment lacks actionable details, such as recommending specific changes or experiments to demonstrate the enhancement of generalization. As a result, the authors are left without a clear understanding of what steps to take to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not explicitly mention which part of the paper discusses the theoretical analysis or the proposed method, making it weakly grounded. The comment is specific in detailing the issue with the connection between the theoretical analysis and the proposed method, but without explicit references, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the method enhances generalization for distant nodes. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method does not effectively enhance generalization. The reviewer\"s skepticism is based on a perceived lack of clarity, but without further elaboration or evidence, the claim remains somewhat vague. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment raises a concern about the connection between the theoretical analysis and the proposed method, specifically questioning how the method enhances generalization for distant nodes. It points out that the proposed method seems to adopt the selfattention mechanism from transformers without clear explanation of how it improves generalization. This feedback identifies a potential gap in the paper\"s explanation and suggests that the authors should clarify the theoretical basis of their method and its impact on generalization. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending additional experiments, theoretical analysis, or clarification in the text. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing clarification. The comment is specific in its concern but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption is critical or how it affects the method\"s behavior. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the method\"s behavior under different assumptions. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some pieces in the paper are using existing methods, such as equation (12), and that their presentation is vague, requiring the reader to refer to the original paper for understanding. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting ways to clarify the presentation or provide additional context. The action is implicit and vague, leaving the authors to infer that they need to improve the clarity of their presentation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the presentation of existing methods is vague and requires the reader to refer to the original paper for understanding. This provides clear guidance on what needs to be improved in the presentation of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that their presentation is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence renders the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of existing methods in the paper, noting that some pieces are using existing methods, such as equation (12), and that their presentation is vague. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should clarify the presentation of these methods. However, the comment lacks depth and does not provide specific guidance on how to improve the clarity or suggest alternative ways to present the information. While it highlights an important issue, it does not offer actionable steps for the authors to take, making it 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions regarding the experimental setup and the design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While the questions are clear and imply that the authors should provide explanations for these design choices, they do not explicitly instruct the authors to make any changes or additions to their draft. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the main rationales behind two specific design choices: (a) having a separate timbre encoder module and (b) why SADTW takes outputs from the content encoder instead of the timbre encoder. This provides clear guidance on what needs to be addressed in the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the experimental setup and design choices in Figure 1. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and seek clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment consists of a series of questions regarding the experimental setup and design choices in Figure 1. It asks for the main rationales behind having a separate timbre encoder module and why SADTW takes outputs from the content encoder instead of the timbre encoder. While these questions are clear and indicate areas where the authors might need to provide more explanation or justification, they do not offer specific suggestions or guidance on how to address these issues. The feedback is 3 as it prompts the authors to clarify their experimental design, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, ensuring that the table is comprehensive and includes all necessary data. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the results for all four datasets. This provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Table 4 is incomplete\" and suggests that it should include results for all four datasets. However, the comment does not provide any reasoning or evidence to support why the table is incomplete or why the results for all four datasets are necessary. Without additional context or justification, the claim remains 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. By addressing this gap, the authors can enhance the comprehensiveness and usefulness of their results. However, the comment could be more helpful if it explained why including all datasets is important or how it would impact the overall analysis. Despite this, the feedback is 4 as it guides the authors toward a specific improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, such as revising certain sections or clarifying specific points. Without actionable advice or examples, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing/presentation is \"a bit jumbled at times,\" but it does not specify which parts of the paper are affected or provide any details on what aspects are unclear. This makes it difficult for the authors to identify the exact sections that need improvement. Without specific examples or references to particular sections, tables, or figures, the comment lacks grounding and specificity. Therefore, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that the writing/presentation is \"a bit jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references to particular sections of the paper, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges a perceived issue with the writing or presentation of the paper, noting that it can be \"a bit jumbled at times.\" However, it does not provide any specific examples, details, or suggestions on how to improve the clarity or organization of the content. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes are needed to address the issue. This lack of specificity and actionable advice makes the comment 2, as it does not effectively assist the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions. It also speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. While the comment implies that the authors should consider and report on the computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this aspect but are not provided with specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about computational complexity and potential power demand, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of the proposed method compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand when running the Woodbury flow on a mobile device. However, the comment does not provide any specific evidence, examples, or references to support these claims. The lack of detailed reasoning or supporting information makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the computational complexity of the proposed method, particularly in the context of mobile devices. It questions the total computational complexity compared to other methods, such as emerging convolutions, and speculates about the potential impact on power demand. This feedback is 3 as it prompts the authors to consider and address the computational efficiency of their method, which is an important aspect for practical applications. However, the comment could be more helpful if it provided specific suggestions or examples of how to evaluate or improve the computational complexity. Overall, the feedback is 3 as it identifies a relevant area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have made an incorrect statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It specifies that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback provides clear and explicit guidance on what needs to be corrected in the draft, ensuring that the authors know exactly what action to take to improve the accuracy of their statement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement in the paper (\"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\") and references Section 3 of Wang et al., 2023, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the statement, indicating that the heads are active at the S2 token but do not primarily attend to it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Induction, Duplicate Token, and Previous Token heads primarily attending to the S2 token is incorrect, as per Section 3 of Wang et al., 2023. The comment provides a specific reference to external work, which supports the claim by indicating that the heads are active at the S2 token but do not primarily attend to it. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including a direct quote or more detailed explanation from Wang et al., 2023, to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and reliability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the contribution of the work as incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or impressiveness of the pipeline, nor are there suggestions for specific improvements or changes. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the contribution of the work as incremental and lacking novelty, suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the pipeline are considered \"tricks\" or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not novel, suggesting it is merely a collection of tricks to improve defense evaluation. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to other works that have achieved similar results, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the contribution of the work, labeling it as incremental and lacking novelty. It suggests that the proposed pipeline is merely a collection of tricks to improve defense evaluation, implying that the work does not offer significant advancements. However, the comment does not provide specific examples or details on what aspects of the pipeline are considered \"tricks\" or how they could be improved. Without actionable feedback or suggestions for enhancement, the authors are left without a clear path to address the critique. Therefore, the comment is rated as 1, as it does not offer any constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, suggesting that it may not be feasible for large datasets without a distributed version. However, it does not provide explicit guidance on how to address this issue or suggest specific steps for developing a distributed version. The comment implies that the authors should consider scalability, but it lacks concrete details on how to implement this, making it 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the method, suggesting that it may not be feasible for large datasets without a distributed version. However, it does not specify which part of the paper discusses the scalability issue or how it relates to the training data. The authors can infer that it might be related to the experimental setup or results section, but the comment lacks full grounding. It is specific in pointing out the scalability issue, but without explicit references to specific sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable, suggesting that a distributed version would be necessary to handle large datasets. However, the comment lacks specific examples or references to support this claim, such as comparisons with other methods or datasets. The reasoning is somewhat logical, as it points out the potential issue of scalability, but it is not fully substantiated without additional evidence or examples. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, specifically its lack of scalability. It suggests that the method may not be suitable for large datasets without a distributed version. This feedback is 3 as it highlights an area where the method could be improved, but it lacks specific suggestions or guidance on how the authors might address this issue. The comment points out a critical aspect of the method\"s applicability but does not provide actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the noncentral chisquared distribution of the eta_ri term, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify or address this issue in their draft. Without any suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the noncentral chisquared distribution of the eta_ri term, but it does not specify which part of the paper this term is discussed in. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide any details or context about what is unclear or why this distribution is used. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of a noncentral chisquared distribution for the eta_ri term, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of a noncentral chisquared distribution for the eta_ri term, indicating a lack of clarity in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the distribution. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two distinct comments. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks, and references a literature example and a leaderboard. This feedback is explicit and provides a concrete suggestion for improvement by referencing specific literature and resources. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. While the first part is 5, the second part is 3 as it provides a clear critique but lacks detailed guidance on how to improve the analogy. Overall, the comment is 4 due to the explicit and concrete suggestions in the first part, but the second part adds some vagueness. Therefore, it aligns with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 15 and 1618, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the vagueness of the statement at line 15 and suggests that the reinforcement learning/agent analogy is out of place. The comment further specifies that generalization capabilities are better illustrated by examples given later in the paper. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of two parts. The first part critiques the vagueness of a statement at line 15, suggesting that certain RNNs work well for specific natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, providing some support for the claim. However, the reference to the leaderboard is not fully elaborated, and the comment could benefit from more detailed examples or references to substantiate the claim. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated later in the paper. This part lacks specific examples or references to support the claim, making it 3. Overall, the comment is 4, as it provides some justification but could be strengthened with more detailed evidence or examples. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part critiques the vagueness of a statement at line 15, suggesting that it lacks specificity regarding the performance of certain RNNs in natural language reasoning tasks. It references the literature on natural language inference and a leaderboard, offering a concrete example to support the critique. This feedback is clear and actionable, as it directs the authors to provide more specific examples or references to substantiate their claims. The second part critiques the use of a reinforcement learning/agent analogy, suggesting that it is out of place and that generalization capabilities are better illustrated by examples provided later in the paper. While this feedback identifies a potential issue, it lacks specific guidance on how to improve the analogy or what alternative approaches might be more effective. Overall, the comment is 4 as it provides clear and actionable feedback on the first point, but the second point could be more comprehensive. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of significant difference between the proposed sensitivelayer selection and randomized selection in terms of StableDiffusion, and the absence of mathematical or theoretical justification for Algorithm.1. The comment explicitly points out these gaps in the paper, indicating that the authors should address them. However, it does not provide specific guidance on how to improve the discussion or provide mathematical justification. While the actions are clear, the comment lacks concrete details on how to execute them, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. It also points out the lack of mathematical or theoretical justification for Algorithm.1. While the comment highlights these issues, it does not provide specific examples or detailed reasoning to support the claim. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the proposed sensitivelayer selection does not make a significant difference in terms of StableDiffusion, as shown in Fig. 5. This observation highlights a potential weakness in the paper\"s claims or results. Second, it notes the lack of mathematical or theoretical justification for Algorithm.1, which is a critical aspect of the paper\"s methodology. By highlighting these gaps, the comment provides the authors with clear areas for improvement, such as further discussing the results or providing a theoretical foundation for the algorithm. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to enhance the discussion. Overall, the feedback is 4 as it directs the authors to important aspects of their work that require attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change the representation of triples from sets to a tuplelike structure, specifically suggesting that $(e_1, r, e_2)$ would be clearer. This feedback is direct and provides a concrete action for the authors to take, ensuring they know exactly what modification is needed. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the representation of triples, suggesting that they should be represented as tuples instead of sets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the representation of triples as sets is unclear and recommends using a tuplelike structure instead. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve clarity. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if represented as tuples instead of sets, the reviewer offers a concrete way for the authors to enhance the readability and structure of their work. This feedback is clear and directly addresses a particular aspect of the paper, making it 5 for the authors. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of speed analysis in the experiments, noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. This feedback is explicit in its request for additional analysis and comparison, but it lacks specific guidance on how to conduct this analysis or what metrics to use. While the authors know they need to include speed analysis, the comment does not provide detailed instructions on how to implement this, making it 3.", "grounding_specificity_rationale": "The comment highlights a lack of speed analysis in the experiments, noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. This suggests that the authors should include an analysis of inference speed, which would be more interesting than just reducing FLOPs. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of speed analysis and the suggestion to compare inference speed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of speed analysis in the experiments is a significant omission, as it only compares GFLOPs among different segmentation networks without evaluating inference speed. The reviewer suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. While the comment highlights a potential gap in the analysis, it does not provide specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct the speed analysis or what metrics to use. Overall, the feedback is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that optimal quantization is not scalable, even with clustering before it, and that it is costly in terms of both the number of data (N) and the dimension (M). It also mentions that the paper aims to speed up Variational Inference (VI) by achieving fast convergence, which is necessary for big data/big model settings, but that quantization is a bottleneck that undermines this goal. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their method. The action is implicit and vague, as the authors are left to infer that they need to find ways to improve scalability, but without concrete steps or examples, it is difficult for them to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of optimal quantization not being scalable, even with clustering, and how it affects the paper\"s goal of speeding up Variational Inference (VI) for big data/big model settings. It also references the abstract and introduction, providing a clear indication of where these issues are discussed. The comment is specific in detailing the problem with quantization and its impact on the paper\"s objectives. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, even with clustering, and that it is costly in terms of both the number of data (N) and the dimension (M). The reviewer also mentions that the paper aims to speed up Variational Inference (VI) by achieving fast convergence, which is necessary for big data/big model settings, but that quantization is a bottleneck that undermines this goal. The claim is 3 as it provides a logical reasoning about the scalability issue and its impact on the paper\"s objectives. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the scalability of optimal quantization, even with clustering, which is a critical concern for the paper\"s goal of speeding up Variational Inference (VI) in big data/big model settings. It highlights that quantization is a bottleneck that undermines the method\"s effectiveness. However, the comment lacks specific suggestions or guidance on how the authors might address this scalability issue or improve the quantization process. While it points out a crucial weakness, it does not provide actionable feedback or detailed advice for improvement. Therefore, the comment is 3, as it identifies a key area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. It also mentions that issues should be addressed and implies that the work should be considered for a more applicationoriented venue. However, the comment does not provide specific guidance on how to conduct the comparison or address the issues, leaving the authors with a vague understanding of the actions needed. While the suggestion to compare against existing methods is explicit, the lack of concrete details on how to execute this makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"notations issues,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests comparing the effectiveness of the methodology against existing methods, such as contrastive decoding, and implies that the paper should be considered for a more applicationoriented venue if the issues are not addressed. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. However, it does not provide specific examples or references to support why this comparison is necessary or how it would improve the paper. The claim is 3 as it highlights a potential area for improvement but lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding. This is a clear and actionable suggestion that could enhance the paper\"s contribution and relevance. Additionally, the comment mentions \"issues mentioned above\" that should be addressed, implying that there are specific problems or concerns that need to be resolved. However, the comment does not elaborate on what these issues are, which limits its helpfulness. Overall, the feedback is 4 as it provides a clear direction for improvement but could be more comprehensive with specific guidance on the issues to address. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically its requirement for access to the entire training dataset. It questions how the algorithm would operate effectively when the training dataset is not fully perceptible. Additionally, it critiques the comprehensiveness of the related validation experiments, the analysis of time complexity and efficiency, and suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several concerns about the algorithm, including its requirement for access to the entire training dataset, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. It also suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors can make an educated guess about the general areas being addressed, the comment lacks full grounding. It is specific in detailing the issues but 1 in terms of identifying the exact parts of the paper being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several claims about the algorithm, including its requirement for access to the entire training dataset, the comprehensiveness of validation experiments, and the lack of analysis on time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1, as it lacks sufficient support for the claims made.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the algorithm\"s requirement for access to the entire training dataset, the comprehensiveness of validation experiments, and the lack of analysis on time complexity and efficiency. It also suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the comment highlights important issues, it lacks specific guidance or actionable suggestions on how the authors might address these concerns. The feedback is 3 as it points out areas for improvement, but it could be more beneficial with additional detail or concrete advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the representation of kernel functions by neural networks (NNs). It points out that while it is claimed that every kernel can be described by a feature space parameterized by a NN, this is not true for infinitedimensional RKHSs, such as the RBF kernel. The reviewer suggests that this limitation should be made more clear. While the comment identifies a specific issue that needs clarification, it does not provide explicit guidance on how to address this limitation or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors know they need to clarify the limitation but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"104,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that every kernel can be described by a feature space parameterized by a neural network, providing a counterexample with RBF kernels and their infinitedimensional RKHS. The comment suggests that this limitation should be made more clear, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"every kernel can be described by a feature space parameterized by a neural network\" is not true, particularly for RBF kernels. The reviewer provides a logical explanation by noting that the RKHS for RBF kernels is infinitedimensional, requiring an NN with infinite width to represent it. This reasoning is clear and provides a specific example to support the claim, making it 4. However, the comment could be strengthened by referencing specific literature or studies that demonstrate this limitation, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It provides a clear and logical explanation by citing the example of RBF kernels, which have an infinitedimensional RKHS, requiring an NN with infinite width to represent it. This critique highlights a limitation in the paper that should be addressed to ensure the accuracy and clarity of the claims made. The comment is actionable as it suggests that this limitation should be made more clear, offering a specific area for improvement. However, it could be more helpful if it provided additional guidance on how to present this limitation or suggested ways to clarify the claim. Overall, the comment is 4, as it provides valuable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is not wellpositioned in the literature and recommends a thorough literature review to better understand its novelty. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific concept of representing the marginal score as the expectation of scores of distributions conditioned on inputs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that this concept is not novel and has been used in other works, such as denoising score matching and scoreinterpolation. It provides examples and suggests that the authors conduct a thorough literature review to better understand the context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, which use similar concepts. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, suggesting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. It references specific works, such as denoising score matching and scoreinterpolation, to support this claim. The comment also recommends a thorough literature review to better understand the context and potential prior work. This feedback is clear and actionable, as it directs the authors to conduct a more comprehensive literature review to position their work effectively. However, the comment could be more helpful if it provided specific guidance on how to conduct the literature review or what aspects to focus on. Overall, the comment is 4, as it provides valuable insights and suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, particularly in the context of inference. It highlights a potential issue with the limited use of tokens during generation, which could impact the benefits of inference. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should investigate and clarify this aspect of their method. The feedback is vague, as it does not specify what steps the authors should take to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It points out a potential issue with the limited use of tokens, which could impact the benefits of inference. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not clearly identified. The comment is specific in detailing the concern about the autoregressive decoding and the potential impact on inference, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It points out a potential issue with the limited use of tokens, which could impact the benefits of inference. However, the comment does not provide any evidence, reasoning, or references to support the claim that this is a concern. It lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the limited use of tokens, which could impact the benefits of inference. This feedback is 3 as it prompts the authors to consider and address this critical aspect of their method. However, the comment lacks depth and does not provide specific suggestions or guidance on how to resolve the issue. To be more helpful, it could include examples or references to similar approaches that have successfully addressed this challenge. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example to support this claim. The reviewer explicitly states that it is necessary to provide a gradient comparison between KL and PCC, which is a clear and direct action for the authors to take. This feedback is 5 as it specifies exactly what needs to be done to address the concern, providing a concrete step for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, providing a clear explanation and suggesting a necessary comparison of gradients between KL and PCC. This level of detail helps the authors understand what needs to be addressed and how to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence is not convincing. It provides a logical explanation by comparing the gradient distributions of KL divergence and MSE loss, suggesting that the constraint strength of a loss function is defined by its gradient distribution. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a specific assumption made in the paper regarding the Pearson correlation coefficient (PCC) and its comparison to KL divergence. It provides a logical explanation by discussing the gradient distribution of loss functions, such as KL divergence and MSE loss, to challenge the assumption. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by providing a detailed analysis of the gradient distributions. However, it could be more helpful if it included examples or references to further support the reasoning. Overall, the comment is 4 as it provides a constructive critique that can guide the authors in enhancing their argumentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also implies that the authors should discuss the suitability of this approach for modeling pattern separation tasks, for which behavioral data is available. While the comment provides some direction, it lacks explicit instructions or concrete steps on how to address these points. The authors are left to infer that they need to conduct additional analyses or discussions, but the comment does not specify what these analyses should entail or how to structure the discussion. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of GPI with noise added and suggests additional measures to demonstrate its limitations. Furthermore, it provides a specific suggestion to discuss the suitability of the approach for modeling pattern separation tasks, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of GPI with noise added in Fig. 4 and suggests that the authors should consider other measures to demonstrate that GPI cannot achieve a good fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests discussing this further. However, the comment lacks specific examples or references to support the claim that GPI cannot achieve a good fit with behavioral data. The suggestion to discuss the suitability for pattern separation tasks is logical but not fully substantiated. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment raises a question about the performance of GPI with noise added in Fig. 4, suggesting that the authors should consider whether GPI can reproduce the data similarly well or if there are other measures to show that GPI cannot achieve a good fit with behavioral data. It also points out the potential suitability of the approach for modeling pattern separation tasks, for which behavioral data is available, and suggests that the authors should discuss this further. While the comment identifies a potential area for improvement and provides a direction for additional analysis, it lacks specific guidance on how to conduct this analysis or what aspects to focus on. The feedback is 3 as it prompts the authors to consider additional measures and discussions, but it could be more actionable with more detailed suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors consider comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, if resources are available. However, it does not provide explicit instructions or concrete steps on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this comparison and figure out how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this suggestion is based on, making it weakly grounded. The comment is specific in suggesting a particular comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this suggestion should be integrated. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any reasoning, evidence, or references to support why this comparison would be beneficial or how it might impact the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While it highlights an interesting area for exploration, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. It does not offer actionable steps or suggestions for improvement, leaving the authors with a general idea but without clear direction on how to implement it. Therefore, the comment is 2, as it identifies a potential area of interest but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions why the distribution cannot have changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to clarify the matter. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments or provide further clarification, but they are not given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and asking about the disentanglement of changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide specific examples or references to support the claim that the debate was previously left open or that the distribution might have changed. This lack of detailed justification makes the claim 3, as the authors would need to conduct further analysis to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential weakness in the paper\"s argument and encourages the authors to consider alternative explanations. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of experiments that could be conducted to clarify the matter. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the comparison methods using the same setting as the proposed method, specifically with AdamW and cosine learning rate, to ensure a fair comparison. This is a clear and direct action for the authors to take. The comment also provides a rationale for why this is necessary, noting that most recent methods have their code released. The suggestion is concrete and provides a specific step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"AdamW with cosine lr\" and the comparison with \"adam with fixed lr,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unfair comparison and suggests that the authors should reproduce the results using the same setting. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between the proposed method and other methods is unfair due to the use of AdamW with cosine learning rate (lr) versus Adam with fixed lr. The reviewer suggests that reproducing the results using the same setting would be more appropriate. While the comment highlights a potential issue with the comparison, it lacks specific examples or references to support the claim that the current comparison is unfair. The suggestion to reproduce results is logical, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the proposed method and other methods, noting that the use of AdamW with cosine learning rate for training is not consistent with the comparison methods, which use Adam with fixed learning rate. This observation highlights a fairness concern in the comparison and suggests that the authors should reproduce the results using the same setting as the comparison methods. The comment provides a clear and actionable suggestion for improvement, which is valuable for the authors. However, it could be more helpful if it included specific guidance on how to implement this suggestion or why it is important for the comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how to address this curiosity or whether it is relevant to the current draft. As a result, the authors are left without any actionable steps to improve their work based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this question pertains to, nor does it provide any guidance on what specific aspects of performance or the adaptive metric are being questioned. Without explicit references or detailed suggestions, the authors cannot confidently determine which part of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide clear guidance on what needs to be addressed or improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question expressing curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any specific suggestions or guidance on how the authors might address this curiosity or whether it is relevant to the current draft. The comment lacks actionable feedback or insights that could help the authors improve their work. As a result, it is 1, as it does not offer any meaningful direction for enhancing the draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the plots are \"terrible\" due to several issues, including their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are crucial for presenting experimental results and should be clearer. This feedback provides a direct and concrete action for the authors to improve their draft by revising the plots to make them more readable and informative. The comment specifies the issues and suggests that the authors should address these problems to enhance the clarity of their presentation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to several issues, including their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of the problems, such as the difficulty in distinguishing between \"pink vs red\" and the lack of clarity in axis labels. This detailed critique supports the claim, making it 4. However, the comment could be strengthened by suggesting specific improvements or alternatives for enhancing the plots. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, including the small size of the plots, difficulty in distinguishing between colors, poorly labeled axes, and visually similar labels. By highlighting these problems, the comment helps the authors understand what needs to be improved to enhance the clarity and effectiveness of their presentation. The reviewer also emphasizes the importance of these plots as the main presentation of experimental results, underscoring the need for clearer visualizations. This feedback is clear, specific, and actionable, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to improve the performance or what specific changes could be made to enhance the results. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically noting that the differences between the baseline and the best approach are less than 1% for most metrics. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what aspects of the performance gains are being referred to or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. This claim is based on a factual observation, as it describes a specific numerical comparison. However, it does not provide any reasoning or justification for why this level of performance gain is considered low or insufficient. Without additional context or comparison to expected or typical performance gains, the claim remains 3, as it lacks detailed evidence or references to support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the performance gains are not very high, noting that the difference between the baseline and the best approach is less than 1% for most metrics. While this observation highlights a potential issue with the paper\"s results, it does not provide any actionable feedback or suggestions on how the authors might improve the performance or address this concern. Without specific guidance or recommendations, the comment lacks depth and does not offer a clear path for the authors to enhance their work. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It asks for performance metrics without each of these types of information and with just natural language feedback. While the comment implies that the authors should provide these performance metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its inquiry about the performance metrics but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the utility of specific information in the feedback network. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and aim to gather more information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the utility of specific information in the feedback network, such as the incorrect phrase/corrected phrase and the type of mistake. It prompts the authors to consider the impact of these elements on the performance of the feedback network and to provide performance metrics without each of these types of information and with just natural language feedback. This feedback is clear and actionable, as it directs the authors to conduct specific analyses that could significantly enhance their understanding of the feedback network\"s performance. However, the comment could be more helpful if it provided additional guidance on how to conduct these analyses or what specific metrics to focus on. Overall, the comment is 4, as it provides valuable insights and prompts for further investigation, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that Table 1 lacks standard deviations and suggests that the experiments could be more extensive to strengthen the submission. However, it does not provide explicit guidance on how to address the issue of missing standard deviations or how to make the experiments more extensive. The comment implies that the authors should consider adding standard deviations and expanding their experiments, but it does not offer concrete steps or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of standard deviations in the table. Additionally, the comment suggests that the experiments could be more extensive, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 lacks standard deviations and suggests that more extensive experiments would strengthen the submission. However, it does not provide specific examples or references to support the claim that the experiments are insufficient or how the inclusion of standard deviations would improve the submission. The comment lacks detailed reasoning or evidence, making it difficult for the authors to understand and address the feedback. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting the absence of standard deviations, which could be a critical piece of information for readers. It also suggests that the experiments could be more extensive, which would strengthen the submission. However, the comment lacks detailed guidance on how to address the issue of missing standard deviations or how to expand the experiments. While it points out areas for improvement, it does not provide actionable steps or suggestions for the authors to follow. Therefore, the comment is 3, as it highlights important aspects but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. While the comment implies that the authors should consider using a better baseline for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance boost due to additional parameters and suggests a comparison with a different and possibly better neural network, as referenced in [14]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. The comment references an external work ([14]) to support the claim that a different and possibly better neural network was used, which could impact the comparison. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to explore the referenced work and the implications of using a different baseline to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically comparing the performance of LinearTop and NLTop to Unary. It suggests that if a better Unary baseline is used, there might still be a performance boost. This feedback is 3 as it identifies a potential area for improvement by questioning the baseline comparison. However, it lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. The comment could be more helpful if it provided detailed recommendations or examples of how to better evaluate the performance boost. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions to improve the paper: rearranging the structure of the paper (introduction>method>experiments), focusing more on the IEM in Fig 3, and improving the visualization of Figs 7 and 8. While the suggestions are explicit, they lack concrete details on how to implement these changes, such as specific structural rearrangements or visualization enhancements. The authors know what needs to be done but may struggle with the execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improving the structure of the paper, specifically recommending a rearrangement from introduction to method to experiments. It also mentions the need to focus more on the IEM in Fig. 3, which is identified as the main figure in the paper. Additionally, it suggests improving the visualization of Figs. 7 and 8. While the comment provides specific suggestions, it does not explicitly mention which sections need more than one reading pass, making it weakly grounded. However, it is specific in detailing what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is \"a bit hard to follow\" and suggests improvements to the structure and focus on specific figures. However, it does not provide specific examples or detailed reasoning to support these claims. The suggestion to improve the structure and focus on the IEM in Fig. 3 is vague and lacks concrete evidence or references to substantiate the need for these changes. As a result, the comment is considered 1, as it lacks sufficient justification or evidence to support the claims made.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the need to improve the structure and make the paper easier to follow. It suggests rearranging the sections from introduction to method to experiments and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. Additionally, it recommends enhancing the visualization of Figs. 7 and 8. While the comment provides clear suggestions for improvement, it could be more helpful by offering specific examples or detailed guidance on how to enhance the visualization or structure. Overall, the feedback is 4 as it directs the authors toward significant improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only descriptions of the related works but also discussions of the differences to the presented work. This feedback is explicit, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to implement this suggestion, such as which specific related works should be discussed or how to effectively highlight the differences. Therefore, while the action is clear, the guidance on execution is vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the discussion of related work should not only describe the related works but also discuss the differences to the presented work. This provides clear guidance on what needs to be addressed in the related work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including descriptions and discussions of differences with the presented work. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance and importance of a more detailed discussion based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only descriptions of the related works but also discussions of the differences to the presented work. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper by adding depth to the related work section. However, the comment could be more helpful if it included examples of specific works that should be discussed or how to effectively highlight the differences. Despite this, the suggestion is 4 as it guides the authors on how to improve the paper\"s content and structure. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper this suggestion pertains to, such as the experimental section or the results. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The comment is specific in suggesting the need for additional experiments, but without clear grounding, it is challenging for the authors to know exactly where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a subjective opinion or suggestion, as it implies that the current scope of experiments is limited and that exploring other architectures and tasks could provide valuable insights. However, the comment lacks specific reasoning or examples to support why these additional experiments would be beneficial or how they might impact the paper\"s findings. Without detailed justification or references, the claim remains 3, as the authors would need to infer the potential value of these additional experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential limitation in the scope of the experiments and encourages the authors to consider broader applicability. However, the comment lacks specific guidance on which architectures or tasks to explore, which could be beneficial for the authors in planning their next steps. While it provides a direction for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should report the final used learning rates, but it lacks concrete guidance on how to ensure that the optimal learning rate was within the tested interval. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for information about the learning rates but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. However, the comment does not provide specific examples or references to support the claim that the results could be spoiled if the optimal learning rate was outside the tested interval. This lack of detailed justification makes the claim 3, as the authors would need to infer the potential impact themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the learning rates used for the deep models, specifically CIFAR10 and CIFAR100, and questions whether the optimal learning rate for the baseline was within the tested interval. This is a valid point that could impact the validity of the results, as using an optimal learning rate outside the tested interval could indeed affect the outcomes. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or ensure that the optimal learning rate is within the tested interval. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment implies that the authors should address this concern, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. However, it does not specify which part of the paper this concern is related to, such as a particular section or figure discussing the transformer architecture. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment specifies the issue with the transformer\"s nolocality, it does not provide detailed guidance on how the authors might address this concern. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment raises a valid point, it lacks specific examples or references to support the claim that the neighborhood agents should have more impact. The reasoning is somewhat logical but could be strengthened with additional evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer questions the rationale behind this choice and requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. This feedback is 3 as it identifies a potential issue with the methodology and prompts the authors to clarify their reasoning. However, it could be more helpful if it provided specific suggestions or examples on how to address this concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the output from the algorithm depends on the order in which the data are processed and recommends that this should be clarified. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to clarify this dependency or what steps to take to resolve it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data are processed and recommends clarification. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the dependency on data processing order. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or clarify the dependency. Without actionable suggestions or examples, the feedback is 3 as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or evaluate the tradeoffs. The comment implies that the authors should consider the potential impact of these strategies on the model\"s utility, but it lacks concrete steps or recommendations for improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, suggesting a potential tradeoff between reducing a particular behavior and maintaining high performance. However, it does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on the model\"s utility, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting a potential tradeoff between reducing a particular behavior and maintaining high performance. The comment logically reasons that if these strategies significantly impair the model\"s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct additional analysis to fully understand the impact of these strategies. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the potential impact of mitigation strategies on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or evaluate the tradeoffs. While it identifies a relevant area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of using 6fold crossvalidation, suggesting that it is unclear why this method is required for the problem at hand. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the reasoning behind their choice of crossvalidation method, but it does not specify what additional information or explanation should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper and questions the necessity of this method, comparing it to other papers that did not use crossvalidation. However, it does not specify which part of the paper discusses the use of crossvalidation, making it weakly grounded. The comment is specific in questioning the rationale behind the choice of crossvalidation, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, suggesting that it is unclear why this method is required for the problem at hand. The reviewer compares the current work to other papers that did not use crossvalidation, implying that the choice of crossvalidation is not justified. However, the comment lacks specific examples or references to these other papers, making it difficult for the authors to fully understand the basis of the critique. This lack of detailed evidence or references makes the claim 3, as it provides a general rationale but requires more substantiation for full verification.", "helpfulness_rationale": "The review comment raises a valid concern about the use of 6fold crossvalidation in the paper, questioning the necessity of this method given that other papers in the field did not use crossvalidation. This feedback is 3 as it prompts the authors to clarify the reasoning behind their choice of crossvalidation method. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might justify or explain the use of crossvalidation in their work. By offering more detailed guidance, the comment could be more actionable and beneficial for the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The reviewer suggests that additional experiments or a more indepth analysis are needed to better justify the claims made in the paper. While the comment implies that the authors should conduct more experiments or analysis, it does not provide specific guidance on how to achieve this or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment further specifies that additional experiments or a more indepth analysis are necessary to justify the claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three. The reviewer also notes the lack of a consistent trend in the results, making it unclear which proposed method is better. This claim is 3 as it provides a logical reasoning about the inconsistency in the results, but it lacks specific examples or references to support the claim further. The suggestion for additional experiments or analysis is a reasonable next step, but the comment could be strengthened by providing more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three. It also points out the lack of a consistent trend in the results, making it unclear which proposed method is better. This feedback is valuable as it highlights a critical weakness in the paper\"s claims and suggests that additional experiments or a more indepth analysis are necessary to justify the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how to conduct these additional experiments or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors to address a crucial area of improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the impact of these components. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the incorporation of combinatorial and heuristic aspects and suggests that the authors clarify the impact of these components. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. It suggests that the authors clarify the impact of these heuristic components. However, the comment lacks specific examples or detailed reasoning to support the claim about the effectiveness of the method or the impact of the heuristic components. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or references to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to address the issue. Overall, the feedback is 3 as it identifies an area for improvement but lacks depth and actionable suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their method. The comment implies that the authors should clarify or address this issue, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly questions the feasibility of the proposed method without camera information, specifically addressing the issue of ray marching and the knowledge of CAD model correspondences. The comment provides a clear critique of the method\"s reliance on camera information, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how ray marching can be performed without knowing the viewpoint. The comment provides a logical reasoning by pointing out the need for camera information to determine the origin of the ray, which is a critical aspect of the method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It points out the importance of knowing the viewpoint for performing ray marching and highlights a potential issue with the method\"s reliance on CAD model correspondences. This feedback is clear and actionable, as it prompts the authors to address a significant weakness in their approach. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or offered alternative methods for addressing the problem. Overall, the comment is 4, as it identifies a critical area for improvement and guides the authors toward a potential solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that the authors should include a more detailed comparison, it does not provide explicit guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add a more detailed comparison but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its suggestion for improvement but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it included examples of how such a comparison might be structured or suggested specific related works to consider. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern that the presented method, while using ODA as a method for solving the MOIP problem, does not clearly demonstrate how it improves performance and computation speed over just using ODA. However, it does not provide explicit guidance or suggestions on how the authors could address this issue. The comment implies that the authors should provide a clearer explanation of the improvements, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of ODA as a method for solving the MOIP problem and questions how the presented method improves performance and computation speed compared to just using ODA. However, it does not specify which part of the paper discusses ODA or the presented method, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of lacking clarity on improvements over ODA. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presented method, ODA, has not clearly demonstrated how it improves performance and computation speed over just using ODA. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the lack of clarity in the paper regarding how the presented method improves performance and computation speed compared to using ODA alone. It points out that the paper does not provide a clear explanation of the improvements, which is a valid critique. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or provide evidence of the improvements. While it identifies a weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of what needs to be improved but without detailed guidance on how to do so. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Figure 4, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This feedback is explicit, as it directly identifies the problem and suggests that the authors should provide further explanation for these lines. However, it does not specify how the authors should address this issue, such as by adding labels or annotations to the figure. While the action is clear, the lack of detailed guidance on how to implement the suggested changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting that the lines for \"No adapt\" and \"Finetune\" are covered by other lines and lacks additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 as an example. It provides a clear and specific critique by pointing out that the lines for \"No adapt\" and \"Finetune\" are covered by other lines, which could make it difficult for readers to understand the figure. This claim is supported by a logical observation of the figure\"s layout and the potential impact on clarity. However, the comment could be strengthened by suggesting ways to improve the figure\"s clarity, such as adding labels or annotations. Overall, the claim is 4, as it provides a clear rationale but lacks detailed suggestions for improvement.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures in the paper, noting that some are not selfexplanatory. It provides a concrete example by mentioning Figure 4, where the lines for \"No adapt\" and \"Finetune\" are covered by other lines, making it difficult to understand without additional explanation. This feedback is actionable as it directs the authors to improve the clarity of their figures by adding necessary explanations or labels. However, the comment could be more helpful if it suggested specific ways to enhance the figure\"s clarity or provided examples of how to address the issue. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum. It notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. The comment implies that the authors should conduct more comprehensive experiments to evaluate the impact of sampling on convergence. However, it does not provide specific guidance on how to conduct these experiments or what metrics to use, leaving the authors to infer the necessary actions. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum and notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks. The comment specifies the need for more comprehensive evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum, but it is not experimentally evaluated thoroughly on the proposed benchmarks. The comment provides some support by mentioning that this aspect is only compared to sampling from a uniform distribution in Table 1 of the supplementary material. However, the claim lacks detailed reasoning or specific examples of how the sampling affects convergence, making it 3. The authors would need to delve deeper into the experimental evaluation to fully understand the impact of sampling on convergence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights an important aspect of the paper that has not been thoroughly evaluated: the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is only briefly discussed in the supplementary material, specifically in Table 1, where it is compared to sampling from a uniform distribution. This feedback is valuable as it identifies a potential gap in the experimental evaluation and suggests that the authors should conduct more comprehensive experiments to assess the impact of sampling on convergence. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. While the comment highlights areas of confusion and potential inconsistencies, it does not provide explicit instructions or suggestions for how the authors should address these issues. The authors are left to infer that they need to clarify the logic and methodology, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons and the focus on computational cost, suggesting that this aspect is unclear and lacks further discussion. However, the comment does not specify which part of the paper these questions pertain to, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing what is unclear and what needs clarification, but without explicit references to specific sections, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the logic and methodology used in the paper, specifically regarding the comparison between the proposed method and references [9] and [16]. It questions the order of comparisons, the focus on computational cost, and whether this aspect is a significant contribution or issue in practical scenarios. The comment highlights a potential confusion in the paper and suggests that the authors should clarify these points. However, it does not provide specific suggestions or guidance on how to address these issues, leaving the authors with a general understanding of what needs improvement but without detailed steps to take. Therefore, the comment is 3, as it identifies areas for clarification but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to conduct additional experiments on various datasets and to include results from the full dataset. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where experimental results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its suggestion, it is 1, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. However, the comment does not provide any specific reasoning or evidence to support why additional datasets or full dataset experiments are necessary. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also encourages experiments on the full dataset instead of just the lowresource regime. This feedback is clear and actionable, as it provides the authors with a concrete suggestion to enhance the robustness and comprehensiveness of their experimental results. However, the comment could be more helpful if it included specific suggestions on which datasets to use or how to analyze the results. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\" claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their work. The feedback lacks actionable details, such as recommending specific changes to the experimental setup or providing examples of how to clarify the tasks. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\" claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of explicit references to sections, figures, or specific elements of the paper results in weak grounding. While the comment is specific in detailing the issues with the tasks and setup, it does not provide enough context for the authors to identify the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task do not clearly prove the authors\" claims, and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the generic argument task and the random argument task, questioning how they support the authors\" claims. It also describes the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights areas that need improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is 3, as it points out weaknesses but does not provide comprehensive guidance for addressing them."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not provide any explicit or implicit action for the authors to take. The question is phrased as a request for clarification, but it does not guide the authors on how to address the issue or what specific aspects of the comparison should be explored. As a result, the comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not specify which part of the paper this comparison should be made in, nor does it provide guidance on how to address the question. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact area needing attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is relevant or necessary. The comment lacks specific details or references that would help the authors understand the context or significance of the comparison. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the question effectively.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" arXiv:1709.03014. While it identifies a potential area for comparison, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what aspects of the comparison are relevant. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is rated as 2, as it provides minimal value to the authors in terms of improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and direct, providing a specific action for the authors to take. The comment is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely an analysis of the impact of these factors for a fair comparison with the baseline. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis is necessary for a fair comparison with the baseline. However, the comment does not provide specific examples or detailed reasoning to support the claim that this analysis is crucial or how it would impact the comparison. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific direction for the authors to enhance their draft. By addressing this gap, the authors can provide a more comprehensive understanding of their approach and its implications, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is unclear if this trend holds across different model architectures and lacks theoretical evidence. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their analysis. The comment implies that the authors should consider exploring this trend further and providing theoretical evidence, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis of the correlation between dataset size and the Frobenius norm and singular values, suggesting that it is underwhelming and lacks theoretical evidence. However, it does not specify which part of the paper this analysis is presented in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by highlighting the lack of theoretical evidence, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It suggests that the trend may not hold across different model architectures and lacks theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and lacks clarity regarding whether this trend holds across different model architectures. Additionally, the comment notes the absence of theoretical evidence to support this correlation. While the comment highlights important issues that need attention, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is 3 as it directs the authors to areas needing further exploration and justification, but it could be more helpful with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets in terms of being object or scenecentric for linear classification. The reviewer suggests that this could be a setback for selfsupervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the implications of their findings and potentially discuss them in the context of SSL algorithms. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the potential for information leakage in AutoAugment and the implications of the conclusion regarding pretraining and target datasets for selfsupervised learning algorithms. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets for linear classification. The comment suggests that this could be a setback for selfsupervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it provides some logical reasoning, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential for information leakage in the AutoAugment policy, which is obtained through supervised training on ImageNet. It also questions the conclusion in L114 regarding the importance of matching the pretraining and target datasets for linear classification, suggesting that this could be a setback for selfsupervised learning (SSL) algorithms. The comment prompts the authors to consider the implications of their findings and whether combining two datasets could lead to better representations. While the comment identifies a potential issue and raises questions, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for further consideration, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, although it notes that this is not necessary. The comment implies that the authors could consider exploring this aspect, but it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they might need to include an analysis or experiment involving tabular data. However, the comment does not specify how to conduct this analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multimodal data, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, noting that this is not necessary. However, the comment does not provide any reasoning, evidence, or examples to support why exploring tabular data would be beneficial or how it relates to the current work. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. While it acknowledges that this is not necessary, it still provides a direction for potential expansion or analysis. However, the comment lacks depth and does not offer specific guidance on how to approach this exploration or what aspects to focus on. The feedback is 3 as it identifies a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more analysis on the alignment of entity representations, particularly focusing on multilingual alignment and including visualizations or case studies for different language types. It also expresses interest in whether entities from lowresourced languages are well aligned with those from highresourced languages. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the languageagnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting additional analysis on the alignment of entity representations, particularly focusing on multilingual alignment and the inclusion of visualizations or case studies for different language types. Additionally, it expresses interest in the alignment of entities from lowresourced languages with those from highresourced languages. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper has a weak analysis on the alignment of entity representations, particularly for languageagnostic characters. It suggests adding more analysis on multilingual alignment and proposes visualizations or case studies for different language types. The comment also expresses interest in whether entities from lowresourced languages are well aligned with those from highresourced languages. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim of a weak analysis. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of the alignment of entity representations, particularly in the context of languageagnostic characters. It suggests that the authors should add more analysis on multilingual alignment and provide visualizations or case studies for different language types. Additionally, the comment expresses interest in whether entities from lowresourced languages are well aligned with those from highresourced languages. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their analysis and potentially improving the comprehensiveness of their work. However, the comment could be more helpful if it offered examples or specific suggestions for how to conduct these analyses or visualizations. Overall, the comment is 4, as it effectively guides the authors toward improving their draft but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more details on using attention, potentially as an additional appendix. This is an explicit action that the authors can take to enhance their draft. The suggestion is clear and concrete, as it specifies a particular aspect of the paper that needs more detail and provides a potential location for this additional information. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the additional information should be included. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion to include more details is specific, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not provide any reasoning or evidence to support why this additional information is necessary or how it would enhance the paper. Without specific examples or justification, the claim lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more details on the use of attention, which could be beneficial for readers who are interested in understanding this aspect of the methodology. The suggestion to include this information as an extra appendix is clear and actionable, offering a specific way for the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or examples of how the attention mechanism is used, which would give the authors a clearer understanding of what details to include. Overall, the comment is 4 as it identifies a potential area for improvement and offers a concrete suggestion, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not provide explicit instructions on how to address these issues, such as suggesting ways to remove duplicates or indicating how to verify the publication information. The actions are implicit and somewhat vague, as the authors can infer that they need to check and correct the references list but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not specify which part of the paper the references list is located in, making it weakly grounded. The comment is specific in detailing what is wrong with the references, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. This is a factual observation that can be verified by checking the references list. The comment does not require any subjective interpretation or justification, as it is based on verifiable information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. This feedback is clear and actionable, as it provides the authors with concrete areas to address in order to improve the quality and accuracy of their references. By pointing out these issues, the comment helps the authors ensure that their references are properly formatted and complete, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it suggested ways to remove duplicates or provided guidance on how to verify the publication information. Overall, the comment is 4 as it directs the authors to important aspects of their references that need attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It also provides a clear action for the authors to take: \"The authors need to analyze and compare the theoretical results to other comparable methods.\" This feedback is direct and provides a concrete step for the authors to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound, and suggests that the authors should analyze and compare the theoretical results to other comparable methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear and weak. It highlights the lack of clarity regarding the error bound, which is a critical aspect of the theoretical results. The comment provides a clear and actionable suggestion for the authors to analyze and compare the theoretical results to other comparable methods. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete step to enhance the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two distinct issues. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a request for clarification. Second, it points out the absence of the pseudocode for the proposed method, which is a clear and explicit action for the authors to take. The inclusion of specific references to relevant literature, such as [1] and [2], provides concrete guidance on how to address the second issue. However, the first part of the comment is more of a question than a directive, making it less actionable. Overall, the comment is 4 because it provides a clear action for the authors to take regarding the pseudocode, but it could be more actionable if it included specific guidance on how to address the first question. Therefore, this comment aligns with a score of 4.", "grounding_specificity_rationale": "The comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which is a general observation and does not specify where in the paper this is discussed. This part of the comment is 1 as it does not refer to a specific section or part of the paper. Second, it points out the absence of the pseudocode for the proposed method, which is a specific issue that could be addressed by adding the missing code. However, the comment does not specify where the pseudocode should be included, making it somewhat specific. Overall, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two distinct claims. The first claim questions why explicit methods perform better than implicit methods on locomotion tasks, but it does not provide any supporting evidence or reasoning to substantiate this claim. The second claim points out the absence of the pseudocode for the proposed method, which is a factual observation. However, the comment does not provide any justification or explanation for why the pseudocode is missing or how it impacts the understanding of the method. The inclusion of references to external works, such as [1] and [2], is relevant but does not directly support the claims being made. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which could prompt the authors to clarify or justify their experimental results. However, this part of the comment lacks specificity and does not provide actionable guidance. Second, it points out the absence of the pseudocode for the proposed method, which is a clear and actionable suggestion for improvement. The inclusion of references to relevant literature, such as [1] and [2], provides additional context and could help the authors better understand the gap in their work. Overall, the comment is 3 as it identifies a specific area for improvement (the pseudocode) but lacks depth in addressing the first issue. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This comment implies that the authors should provide a justification or explanation for this limitation in their study. However, it does not explicitly instruct the authors to do so or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This implies that the comment is addressing the section where the authors discuss the performance of their model on different types of noise. However, it does not explicitly mention which section this is, making it weakly grounded. The comment is specific in its request for a justification or explanation for the limitation in the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This is a logical observation that prompts the authors to provide a justification or explanation for the limitation in their study. However, the comment does not provide any specific evidence, examples, or references to support the claim that the model should perform well on other types of noise. The lack of detailed reasoning or supporting information makes the claim 3, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why the authors only show results on images corrupted using Gaussian noise, despite claiming that their model can work well for a variety of image noise. This feedback is 3 as it prompts the authors to consider expanding their evaluation to include other types of noise, which could enhance the comprehensiveness and robustness of their study. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending specific types of noise to include or how to present the results. Therefore, while it identifies a potential area for improvement, it could be more helpful with additional detail or direction."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This is a clear and explicit action, as it provides a specific suggestion for improvement. The comment also emphasizes the importance of this visualization, as it relates to the research motivation of the paper. However, it does not provide detailed guidance on how to conduct the visualization, which could be a minor limitation. Overall, the comment is 4, as it gives the authors a clear direction for enhancing their draft.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the performance decline of existing PU learning methods with increasing data dimensionality. It suggests that the authors should visualize this effect, which is crucial for the research motivation of the paper. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. It is specific in suggesting a visualization to support the claim, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors assert the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. The reviewer suggests that visualizing this effect would be beneficial, emphasizing its importance for the research motivation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the existing methods will decline in performance. This lack of evidence makes the claim 3, as the authors would need to provide additional information or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that visualizing this effect would be beneficial, emphasizing its importance for the research motivation of the paper. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the draft by supporting the research motivation with visual evidence. However, the comment could be more helpful if it offered guidance on how to conduct the visualization or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a meaningful improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) should be placed in the supplementary materials. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment is specific and concrete, as it directly instructs the authors on where to relocate the content. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests moving the empirical version of the objective (3) to the supplementary materials. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the empirical section where the objective is discussed. The comment is specific in suggesting a change in the placement of the content, but it lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests moving the empirical version of the objective to the supplementary materials. However, it does not provide any reasoning or justification for this suggestion, such as why this content might be better suited for the supplementary materials or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests moving the empirical version of the objective to the supplementary materials. While this feedback provides a specific suggestion for improving the organization or presentation of the paper, it lacks further context or explanation about why this change might be beneficial or how it could enhance the reader\"s understanding. The comment does not offer any additional insights or suggestions for improving the content or methodology, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a need to simplify the description of results, specifically mentioning an example of convoluted language. It provides suggestions for improvement by referencing related work and suggesting a check on whether useful communication is happening, given the differences in figures seem too small. The comment also references specific papers for further context. While the suggestions are explicit and provide concrete references, the action is 4 because it gives the authors a clear direction on how to improve the clarity of their results section, but it could be more detailed in terms of specific changes to make. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"result description\" and provides specific examples of convoluted language, allowing the authors to accurately identify the parts of the paper being addressed. It also suggests related work and references specific papers, which further grounds the comment. The comment is specific because it details what needs to be addressed, such as simplifying the description of results and checking for useful communication. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the result description is needlessly convoluted and suggests simplifying it. It provides specific examples of convoluted language and references related work ([1] and [2]) to support the suggestion. The references to [1] and [2] offer a basis for the claim that the authors should check for useful communication, as they relate to speakerlistener communication from a teachability perspective. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current description is convoluted. Overall, the claim is 4, as it provides some support but could benefit from more detailed justification. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted description of results, providing an example of overly complex language. It suggests simplifying the description and references related work, such as [1] and [2], which could help the authors improve their presentation. Additionally, the comment questions the significance of the differences in figures, suggesting that the authors should verify whether useful communication is actually happening. This feedback is clear and actionable, offering the authors specific guidance on how to enhance the clarity and effectiveness of their results section. However, the comment could be more helpful if it provided more detailed suggestions on how to simplify the language or further explained the relevance of the referenced works. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the approximation error is defined as the gap between objective values, which is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization to clarify this definition. While the comment implies that the authors should include a mathematical characterization, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit, as the authors need to infer the specific action from the feedback. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the definition of approximation error, suggesting that it is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization. However, the comment does not specify which part of the paper discusses the approximation error, making it weakly grounded. The authors can infer that it relates to a section or table where the error is discussed, but they cannot pinpoint the exact location. The comment is specific in suggesting a way to improve the clarity of the definition, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the definition of approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not offer any specific examples, references, or detailed reasoning to support why the current definition is ambiguous or how a mathematical characterization would improve clarity. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the critique and develop their own understanding of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous without seeing the values in the table. It suggests that providing a mathematical characterization would improve clarity. This feedback is 3 as it points out a specific area for improvement and offers a constructive suggestion for enhancing the paper\"s clarity. However, the comment could be more helpful if it provided additional guidance on how to implement the mathematical characterization or offered examples of similar approaches in the literature. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a specific line in the paper, pointing out that Corollar 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their draft. Without actionable suggestions or guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 180182, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Corollar 10, explaining that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss, and that this does not necessarily mean it is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim made in Corollar 10, suggesting that it only demonstrates that uncertainty sampling moves in descent directions of the expected 01 loss, but this does not necessarily mean it is not minimizing the expected convex surrogate. The comment provides a logical reasoning by questioning the assumption that uncertainty sampling is not minimizing the expected convex surrogate, based on the information provided in Corollar 10. However, it does not provide specific examples or references to support the claim further, which could strengthen the argument. Therefore, the comment is 3, as it provides a logical basis for the critique but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a specific critique of the paper by questioning the interpretation of Corollar 10. It points out that the corollar only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean it is not minimizing the expected convex surrogate. This feedback is 3 as it prompts the authors to reconsider their interpretation and potentially clarify or expand on this aspect in their paper. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the proposed model: first, it notes that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. Second, it points out that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the model. The feedback lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the model\"s complexity or dynamics. As a result, the authors are left without a clear understanding of how to implement the suggested improvements. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"proposed model\" and the \"reassignment probability,\" allowing the authors to accurately identify the parts of the paper being discussed. It is also specific because it clearly specifies the issues with the model, namely that it produces only one node changing cluster per time step due to the reassignment probability and that the evolution model is simplistic. The comment provides detailed feedback on the limitations of the model, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. It also notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment provides a logical explanation for the claim, it lacks specific examples or references to support the assertion about the model\"s limitations. This makes the claim 3, as the authors would need to further investigate the model\"s dynamics and evolution to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model. First, it points out that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, which leads to slow dynamics. Second, it notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. This feedback is clear and highlights areas where the model could be improved, such as enhancing the dynamics or increasing the complexity of the evolution model. However, the comment could be more helpful if it provided suggestions or examples of how the authors might address these issues. Despite this, the feedback is 4 as it directs the authors to areas that require further development and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there are missing details about the division of the dataset into training and test sets, including numbers and the method used for division. It suggests that these details should be added. The comment provides a clear and concrete action for the authors to take, which is to include these details in their draft. This makes the comment 5, as the authors know exactly what needs to be done to improve their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, including numbers and the method used for division. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what is missing and what should be added, such as details about the division method and numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including numbers and the method used for division. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing information. The comment lacks detailed reasoning or evidence, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the division of the dataset into training and test sets. It highlights the importance of including numbers and the method used for division, such as whether it was done randomly or with other considerations. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the transparency and reproducibility of the study. However, the comment could be more helpful if it offered additional guidance on how to present this information or why it is crucial for the study. Overall, the comment is 4, as it directs the authors to a specific area that needs attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the challenges of building text descriptions for each task, which requires human labor, and notes the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these challenges or improve the scalability of the framework. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the challenges of building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights specific challenges, it does not provide detailed guidance on how to address them. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights two main issues: the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with longtext input. While the comment identifies important challenges and limitations, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is 3, as it provides insight into areas needing attention but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the significance of the performance improvement shown in Figure 3, noting that the biggest improvement in the bank dataset was only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed. While the comment implies that the authors should consider presenting their results in a more detailed and intuitive manner, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the presentation of their results but are not given specific guidance on how to achieve this. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the performance improvement of the proposed methods seems not significant, particularly in the bank dataset where the biggest improvement was only ~0.02. Additionally, the comment suggests using tables to show key improvements, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, citing a specific example from Figure 3 where the biggest improvement in the bank dataset is only ~0.02. The comment also suggests using tables to show key improvements, which could enhance the clarity and detail of the results. However, the claim about the lack of significance is based on a single example and lacks broader context or comparison with other datasets or methods. While the suggestion to use tables is logical, the comment could be strengthened by providing more detailed analysis or references to support the claim about the performance improvement. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance improvement of the proposed methods, noting that the biggest improvement in the bank dataset is only ~0.02. It suggests that using tables to directly show key improvements could be more intuitive and detailed, providing a clear and actionable suggestion for enhancing the presentation of results. This feedback is valuable as it highlights a potential weakness in the paper and offers a concrete way for the authors to improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it provided additional context or examples of how to effectively use tables to present the results. Overall, the comment is 4, as it directs the authors to a specific area for improvement while offering a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the experimental validation and related work sections. It points out that only shallow networks are considered, and the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it mentions that the positioning of the work with respect to related works is limited, specifically referencing a paper on layer redundancy. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to expand their experimental validation to include deeper networks, describe their optimization strategy, and better position their work within the context of related studies. However, the lack of explicit guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation and related work sections. It mentions that only shallow networks are considered and that the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it points out a minor issue with the positioning of the work with respect to related works, specifically referencing a paper on layer redundancy. The comment provides specific examples and references, such as the paper by He et al. (2020), which helps the authors understand what needs to be addressed. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the limited consideration of shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically referencing a paper on layer redundancy. The comment provides a specific reference to support the claim about layer redundancy, which enhances the verifiability of the comment. However, the claim about the experimental validation could be further supported by providing more detailed examples or explanations of why the current approach is insufficient. Overall, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and related work sections. It points out that only shallow networks are considered, which limits the experimental validation, and that the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it notes that the positioning of the work with respect to related works is limited, specifically mentioning a paper on layer redundancy. The comment provides a specific reference to support the claim about layer redundancy, which could help the authors better understand the context of their work. However, the comment could be more helpful if it offered suggestions on how to expand the experimental validation or improve the description of the optimization strategy. Overall, the feedback is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of theoretical results or suggestions for potential improvements. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what theoretical results are expected or missing. This makes it difficult for the authors to identify the exact sections that need attention or improvement. The comment lacks both grounding and specificity, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment points out that the work does not provide any new theoretical results, despite the introduction of a new type of loss in the setting. This feedback is 3 as it highlights a potential gap in the paper, suggesting that the authors should focus on developing theoretical contributions to enhance the work. However, the comment lacks specificity and does not provide actionable guidance on how to address this issue or what specific theoretical results could be explored. While it identifies a weakness, it does not offer detailed suggestions for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a hypothesis regarding the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct the analysis or what evidence to provide. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. However, it does not specify which part of the paper this hypothesis is based on, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in detailing the hypothesis and suggesting that human test results might support it, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. However, the comment lacks specific examples or references to support the hypothesis, making it 3. The authors would need to infer the reasoning and provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. This feedback is 3 as it offers a potential explanation for the observed phenomena and prompts the authors to explore this hypothesis further. However, it lacks specific guidance on how to conduct the analysis or what evidence to provide, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. While the comment implies that the authors should expand their testing to include other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should test the model on other tasks but are not provided with specific guidance on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, it does not specify which part of the paper this question pertains to, such as a specific section or results section where the testing results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its inquiry about the scope of testing, but it is 1 because it does not clearly identify the part of the paper being questioned. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. This is a factual inquiry that seeks clarification rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. While this question identifies a potential limitation in the evaluation of the model, it does not provide any specific suggestions or guidance on how the authors might address this issue or expand their testing to include other tasks. The comment lacks actionable feedback, leaving the authors with a general awareness of a potential gap in their evaluation but without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends improving it by providing more illustrations and examples. While the comment implies that the authors should enhance the clarity of this section, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly how to improve the section or what kind of illustrations and examples would be beneficial. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it is hard to follow and suggesting improvements by providing more illustrations and examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.2 is difficult to follow and suggests improving it with more illustrations and examples. However, the comment does not provide any specific reasons or examples of why the section is hard to follow, nor does it offer detailed guidance on what kind of illustrations or examples would be beneficial. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the authors improve the section with more illustrations and examples. This feedback is valuable as it directs the authors to a particular area of their draft that needs enhancement, offering a concrete step to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it specified what kind of illustrations or examples would be most beneficial. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine where to address the feedback. Additionally, the comment lacks specificity regarding what aspects of the technical contribution are limited or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that the technical contribution is limited and lacks significant extension based on a typical model for the crossdomain recommendation setting. This feedback is important as it highlights a critical area where the authors could improve their work. However, the comment does not provide specific suggestions or guidance on how the authors might enhance their technical contribution or what aspects of the model could be improved. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path forward for improvement. Therefore, the comment is 3, as it points out a key area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is an explicit action that provides a clear direction for the authors to enhance their draft. The suggestion is concrete, as it specifies what needs to be added to the table, giving the authors a direct path to implement the recommendation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This provides specific guidance on what needs to be addressed, which is the addition of fullysupervised baselines to Table 1. However, it does not specify which small models are being referred to or why this addition is necessary, making it somewhat vague in terms of the models and the reasoning behind the suggestion. The comment is fully grounded as it explicitly mentions Table 1, allowing the authors to identify the part of the paper being addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. The comment provides a logical reasoning for the suggestion, as it aims to clarify the performance gap between full supervision and SSL for small models. However, it lacks specific examples or references to support the claim that this addition would be useful. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and selfsupervised learning (SSL) for these models. This is a clear and actionable suggestion that could significantly enhance the paper by providing a more comprehensive comparison of the models. By including these baselines, the authors can gain a deeper understanding of the performance differences between full supervision and SSL for small models, which could lead to valuable insights and improvements in their work. The comment is specific and provides a concrete direction for the authors to improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the repeated calculation of the hypervolume for promising region selection. It also suggests that this computation could be timeconsuming for problems with many objectives. While the comment implies that the authors should address the time complexity issue, it does not provide explicit guidance on how to do so. The authors are left to infer that they need to analyze or discuss the time complexity of their algorithm, but without specific instructions or examples, the action remains somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of time complexity and the potential impracticality of the algorithm for problems with many objectives. The comment provides a detailed analysis of the problem, suggesting that the repeated calculation of the hypervolume could be timeconsuming and potentially impractical for certain types of problems. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It suggests that this computation could be timeconsuming, especially for problems with many objectives. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s efficiency, but it lacks specific examples or references to support the claim. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It highlights a potential issue that could impact the practicality of the algorithm for problems with many objectives. This feedback is valuable as it prompts the authors to consider the computational efficiency of their approach and potentially explore optimizations or alternatives to improve performance. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the time complexity issue. Overall, the comment is 4 as it identifies a significant area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be conducted on medium or large datasets, such as ImageNet, to make the results more convincing. However, it labels this as a \"minor issue\" and notes that it will not affect the overall quality of the paper. While the comment implies that the authors should consider using larger datasets, it does not provide explicit guidance on how to implement this suggestion or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the necessity and method of addressing this issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset size used in the experiments, suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting the use of larger datasets, but it lacks detailed guidance on how to implement this suggestion or why it would improve the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the use of small datasets in the experiments makes the results less convincing and recommends using medium or large datasets like ImageNet. However, the comment does not provide specific examples or references to support why larger datasets would be more convincing or how they would impact the results. The suggestion is based on a logical assumption that larger datasets can provide more robust results, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, specifically the use of small datasets in the experiments. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. However, the comment labels this as a \"minor issue\" and notes that it does not affect the overall quality of the paper. While the feedback provides a direction for improvement, it lacks specificity and actionable guidance on how to address the issue or why it would be beneficial to include larger datasets. The comment could be more helpful if it offered detailed suggestions or examples of how to incorporate larger datasets or explained the potential impact on the results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests that they should delve deeper into the limitations of evolutionary methods, specifically regarding leveraging state, reactivity, and learning during an episode. It also advises being honest and direct in their critique, particularly regarding the title, which is deemed too generic and vague. Additionally, the reviewer questions the meaning of \"brittle convergence properties\" and suggests that DeepRL methods are widely adopted, encouraging the authors to consider the landscape 10 years ago. These suggestions are explicit and provide concrete guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for a more precise critique, allowing the authors to identify the relevant parts of the paper. It also addresses the title, suggesting it is too generic and vague, and questions the meaning of \"brittle convergence properties.\" Additionally, the comment provides specific suggestions for improvement, such as exploring state, reactivity, and learning during an episode, and referencing the adoption of DeepRL methods. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, but it lacks specific evidence or references to support these claims. The comment suggests that the authors should delve deeper into the limitations of evolutionary methods, particularly regarding state, reactivity, and learning during an episode. It also critiques the title as too generic and vague, and questions the meaning of \"brittle convergence properties.\" However, without additional context or references, it is difficult for the authors to understand the basis of these claims or how to address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides several points of feedback that could be helpful for the authors. It suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically regarding leveraging state, reactivity, and learning during an episode. This is a valuable suggestion as it could lead to a more comprehensive analysis of the methods. Additionally, the comment advises being honest and direct in the critique, which is a constructive suggestion for improving the tone and clarity of the paper. The comment also questions the meaning of \"brittle convergence properties\" and suggests that the title is too generic and vague, providing specific areas for improvement. However, the comment could be more helpful if it offered more detailed guidance on how to address these issues. Overall, the feedback is 4 as it identifies areas for improvement and provides some actionable suggestions, but it could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these questions. The actions are implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in detailing what needs to be addressed, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the synthesis of the focal stack, the forward model, and the handling of edges with depth discontinuities. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity, such as the synthesis of the focal stack, the forward model using a defocus map and an image, and the handling of edges with depth discontinuities. By asking these questions, the reviewer highlights important aspects of the methodology that need further explanation or elaboration. However, the comment does not provide suggestions or guidance on how the authors might address these gaps in their explanation. While it points out areas for improvement, it lacks actionable feedback, making it 3. The authors are given some insight into what needs clarification, but the comment could be more helpful with additional guidance or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from empirical justification of its claimed contribution regarding the proposed algorithm not requiring as many points or apriori knowledge about dimensions of subspaces. While the comment implies that the authors should provide empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include empirical justification without specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, which is about the proposed algorithm not requiring as many points or apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this contribution is discussed in, making it weakly grounded. The comment is specific in suggesting that empirical justification would be beneficial to support this claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is not adequately justified, specifically regarding the claim that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment does not provide any specific examples, evidence, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the empirical justification of the claimed contribution regarding the proposed algorithm. It suggests that the paper would benefit from empirical evidence to support this claim, which is a valuable insight for the authors. However, the comment could be more helpful if it provided specific guidance on how to conduct or present this empirical justification. Despite this, the feedback is 3 as it directs the authors to a critical area that needs further development. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the novelty of the approach\"s components, specifically mentioning that the weak predictor used (MLP, Regression Tree, or Random Forest) has been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the novelty of the approach. Without actionable suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy (epsilongreedy, similar to BRPNAS), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is lacking in terms of novelty and provides references to previous works that have used similar components. This level of detail helps the authors understand what needs to be addressed in their work. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, citing the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used before for NAS performance prediction. It also notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. The claim is supported by references to previous works [2, 3, 7] and [5], which provides a basis for the critique. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the novelty of the approach, specifically addressing the components used in the weak predictor and the sampling strategy. It points out that the weak predictor is not novel, as it consists of MLP, Regression Tree, or Random Forest, which have been used before for NAS performance prediction. Additionally, it notes that the sampling strategy is similar to epsilongreedy and identical to that in BRPNAS, and that the results of WeakNAS are almost the same as BRPNAS. This feedback is valuable as it highlights areas where the approach lacks originality and suggests that the authors should consider more innovative components. However, the comment could be more helpful if it offered suggestions on how to improve the novelty or provided examples of alternative approaches. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), implying that the novelty of the proposed method is limited. It explicitly states that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a concrete action to take: they should include a detailed discussion comparing their algorithm with RMED. The comment is explicit and provides specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs a sufficient discussion on the comparison with RMED. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of the proposed method is limited. The reviewer supports this claim by referencing RMED, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed comparisons or specific examples of similarities between the two algorithms. This would enhance the verifiability of the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, suggesting that it is too similar to RMED (Komiyama et al. 2015). This is a valuable observation that could help the authors improve their draft by highlighting the need for a more detailed comparison with existing work. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects of the algorithms should be discussed. Despite this, the feedback is 4 as it directs the authors to address a critical area of their paper, making it a valuable contribution to the review process."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the authors lack a comprehensive discussion of previous work on the topic. However, it does not provide specific guidance on what aspects of previous work should be included or how the discussion should be structured. The action is implicit, as the authors need to infer that they should add a comprehensive discussion of previous work, but it is vague because it does not specify what this discussion should entail. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors lack a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as the introduction, literature review, or discussion sections. Without explicit references to these sections, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of previous work are missing or how they could be integrated into the discussion. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, it lacks specific examples or references to support this claim, making it difficult for the authors to understand the scope of the missing discussion or how it could be improved. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation, as it highlights an area where the paper could be strengthened by incorporating a thorough review of existing literature. However, the comment lacks specificity and does not offer guidance on how to address this issue, such as suggesting which specific studies or areas should be included in the discussion. While it identifies a key weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It explicitly asks about the frequency of the OT sample selection process, whether it runs iteratively or only once, and whether the optimization of the loss and solving of OT are conducted by turns iteratively. Additionally, it suggests adding more details and a flow chart to make the process clearer for readers. The comment also requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These explicit questions and suggestions provide clear guidance on what the authors need to address to improve their draft. The feedback is concrete and actionable, as it specifies exactly what information is needed and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the OT sample selection process, such as the frequency of its execution and the relationship with the EP module, and suggests adding more details and a flow chart to clarify the process. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process and whether it runs iteratively or only once, and it asks about the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment identifies areas that need clarification, it does not provide any evidence, reasoning, or references to support these claims. The lack of supporting information makes the claims difficult for the authors to address effectively, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for clarification regarding the OT sample selection process and its relationship with the EP module during training. It questions the frequency of the OT sample selection process, whether it runs iteratively or only once, and whether the optimization of the loss and solving of OT are conducted by turns iteratively. The comment also suggests adding more details and a flow chart to make the process clearer for readers. Additionally, it requests information on the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. However, the comment could be more helpful if it offered additional guidance on how to present the flow chart or what specific details to include. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of experiments with continuous tasks, despite a discussion on how KG handles this setting. It also questions the absence of entropy methods for conditional optimization in the experiments, despite their derivation in Section 7 of the appendix. The comment explicitly asks for a comparison of the empirical performance of these methods with ConBO. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5. The authors know exactly what experiments to conduct and how to compare the performance of the derived methods with ConBO, ensuring they can take concrete steps to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of KG handling continuous tasks and the derivation of entropy methods for conditional optimization in Section 7 of the appendix. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions the absence of experiments with continuous tasks and asks for a comparison of the empirical performance of the derived entropy methods with ConBO. This provides clear guidance on what needs to be addressed and why, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of experiments with continuous tasks, despite a discussion on how KG handles this setting. It also questions the absence of entropy methods for conditional optimization in the experiments, despite their derivation in Section 7 of the appendix. The comment asks for a comparison of the empirical performance of these methods with ConBO. While the comment highlights a potential gap in the experimental section, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of these experiments and their potential impact on the paper. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors discuss how KG handles continuous tasks but do not include experiments with continuous tasks. It also points out the absence of entropy methods for conditional optimization in the experiments, despite their derivation in the appendix. The comment raises a pertinent question about the empirical performance of these methods compared to ConBO, which is a critical aspect of the paper. By highlighting these gaps and suggesting a comparison, the comment provides clear and actionable feedback that can help the authors improve their draft by addressing these omissions. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the feedback is 4, as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include a comparison of their approach, GCG, with other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action, as it clearly instructs the authors on what additional content should be included in the paper. The comment also mentions a minor point about the jailbreaking percentage being low for certain LLMs, which could be a separate action for the authors to address. However, the suggestion to include the comparison is the primary actionable point. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included, namely a comparison of the approach with other LLMs, and mentions a minor point about the jailbreaking percentage. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors showed their approach, GCG, could be transferred to other LLMs and that it could craft adversarial prompts and transfer them to other LLMs. However, the comment does not provide specific examples or references to support this claim, making it 3. The mention of a \"minor point\" about the jailbreaking percentage being low for certain LLMs is also not substantiated with evidence or detailed reasoning. Therefore, the comment is rated as 3, as it lacks sufficient detail and evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include a comparison of their approach, GCG, with other LLMs. This is a clear and actionable piece of feedback that could enhance the paper by demonstrating the versatility and applicability of GCG. Additionally, the comment points out a minor issue regarding the jailbreaking percentage being low for certain LLMs, which could be an area for further exploration or clarification. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or addressed the implications of the low jailbreaking percentage. Overall, the comment is 4 as it offers actionable suggestions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it does not explicitly instruct the authors to provide a detailed explanation, it implies that the authors should clarify this point to improve the understanding of their work. The action is implicit, as the authors need to infer that they should provide more detailed information. However, the comment is 3 because it provides a clear direction for improvement, even if it does not specify exactly how to address the issue. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difference between similarity and exit times, providing a clear direction for the authors to clarify this point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the novelty of the authors\" approach to unsupervised feature selection from a diffusion perspective and expresses confusion about the difference between similarity and exit times. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of novelty or the confusion about the concepts. Without additional context or explanation, the authors may find it challenging to understand the basis of the feedback or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area of confusion in the paper, specifically regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to understand the concepts. This feedback is 3 as it points out a specific area where the authors could improve the clarity and comprehensibility of their work. However, it lacks depth and does not provide specific suggestions on how to address the issue or enhance the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not explicitly instruct them to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these limitations further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not make a claim or provide any evidence to support the need for further exploration of these limitations. The comment is more of a query than a claim, and without any supporting reasoning or examples, it is difficult for the authors to understand the basis of the inquiry. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment is 3 as it prompts the authors to consider the broader applicability of their framework, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should clarify their calculation methods and consider reporting AUC results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about their calculations and consider reporting AUC results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4class classification of breast density\" and \"breast cancer detection,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for clarification on the calculation of precision, recall, and F1score and suggests providing AUC results for comparisons. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the calculation of precision, recall, and F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. The comment is based on common practices in the field of breast cancer detection and classification, which typically involve reporting AUC with sensitivity and specificity at different operating points. This reasoning is logical and aligns with standard practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the suggestion for AUC results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises important questions about the calculation of precision, recall, and F1score for a 4class classification of breast density, which is a specific and relevant aspect of the paper. It also suggests providing AUC results for breast cancer detection, which is a common practice in the field. This feedback is clear and actionable, as it directs the authors to clarify their methodology and consider a more informative way to present their results. By addressing these points, the authors can enhance the clarity and comprehensiveness of their draft. Therefore, the comment is 4, as it provides valuable guidance for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It suggests that the authors could consider using the Kialo dataset instead, which is cleaner and more established. However, the comment does not explicitly instruct the authors to use the Kialo dataset or provide specific guidance on how to integrate it into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using the Kialo dataset but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset and the use of the Kialo dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the dataset creation, noting that the Kialo dataset is wellstudied and cleaner, and suggests that the dataset created in the paper could be used as additional data. This provides clear guidance on what needs to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional because the Kialo dataset already provides the necessary pairs of short claims and their counters. It supports this claim by stating that the Kialo dataset is wellstudied and cleaner than the dataset created in the paper, as it does not rely on automatic processes. This reasoning is logical and provides a clear justification for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance the verifiability of the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the creation of the dataset, suggesting that the Kialo dataset, which is wellstudied and cleaner, could be used instead. This feedback is 3 as it points out an area where the authors might consider simplifying their approach by leveraging an existing dataset. However, the comment could be more helpful if it provided specific guidance on how to integrate the Kialo dataset into the paper or discussed potential benefits or drawbacks of using it. Additionally, it does not address other aspects of the paper, such as the methodology or results, leaving the authors with limited actionable feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the transformer modification and its impact on machine learning insights. It also questions the significance of the improvement brought by the selfcross attention in the ablation study. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concerns about novelty, the impact of the modification, or the interpretation of the ablation study results. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the novelty of the transformer modification and the limited improvement brought by the selfcross attention in the ablation study. The comment provides a clear critique of the significance of the proposed modification and suggests that the main improvements come from using a na\u00efve transformer rather than the proposed modification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the transformer modification is no longer novel and does not bring significant insights in machine learning. It also questions the significance of the improvement brought by the selfcross attention in the ablation study, suggesting that the main improvements come from using a na\u00efve transformer. The comment provides some reasoning by mentioning the limited improvement (<1%) and the lack of novelty in the transformer modification. However, the claim could be strengthened with more detailed analysis or references to specific studies that have achieved similar results without the proposed modification. Overall, the comment is 3 as it provides a logical basis for the claim but lacks comprehensive evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment provides a critical evaluation of the paper, questioning the novelty of the transformer modification and its impact on machine learning insights. It points out that the selfcross attention brings limited improvement (<1%) in the ablation study, suggesting that the main improvements may come from using a na\u00efve transformer rather than the proposed modification. This feedback is 3 as it highlights a potential weakness in the paper\"s claims of innovation and suggests that the authors should reconsider the significance of their contributions. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of how to improve the novelty and impact of the work. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the number of tasks in the experiments is considered limited and suggests that the authors should include several tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. The comment also includes a question for the authors to address their comments on weaknesses. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be done to improve their draft, which is to expand the number of tasks and present results in a different format. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically mentioning the limited number of tasks and the desire to see several tasks and sequential results. However, it does not explicitly mention which part of the experiments section this critique pertains to, such as specific sections or figures. This makes the comment weakly grounded, as the authors can infer the general area but not the exact part. The comment is specific in detailing what the authors should include, such as more tasks and sequential results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of tasks in the experiments is limited and suggests that the authors should include several tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why 10 tasks are considered sufficient or why the current approach is inadequate. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a limitation in the number of tasks considered in the experiments, suggesting that the authors should include more tasks (at least 10) and present results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental section. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or why this change would enhance the paper. Despite this, the comment is 4 as it directs the authors to a significant area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This provides a clear and concrete action for the authors to take, as it specifies the additional tasks they should consider for their experiments. The feedback is explicit and detailed, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments conducted in the paper, specifically mentioning that the evaluation is only on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental section. The suggestion to include additional tasks is specific, providing clear guidance on how to expand the scope of the experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited because they only include sentence similarity tasks and open domain QA tasks, suggesting that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The claim is 3 as it provides a logical reasoning for the limitation of the current experiments and suggests additional tasks that could be included. However, the comment lacks specific examples or references to support the claim that these additional tasks are relevant or necessary. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments conducted in the paper, noting that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving the scope and comprehensiveness of their experiments. By suggesting additional tasks, the comment offers a concrete way for the authors to enhance the validity and applicability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, the comment does not provide explicit guidance on how to include the prompt or where it should be placed within the appendix or supplement. The action is implicit and somewhat vague, as the authors need to infer that they should add the prompt and figure out how to do it. Additionally, the minor comments about the abstract and Figure 2 are not actionable as they lack specific guidance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, it does not specify which part of the paper the prompt is missing from, making it weakly grounded. The comment is specific in its request for the inclusion of the prompt, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, implying that it is currently missing. However, the comment does not provide any reasoning or evidence to support why the prompt is important or how its inclusion would enhance the paper. Without additional context or justification, the claim remains 1, as the authors are left without a clear understanding of the significance of the prompt or how it should be integrated into the paper. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable piece of feedback. This recommendation is helpful as it directs the authors to a specific area where the paper could be improved by providing additional context or information. However, the comment could be more helpful if it explained why the prompt is important or how its inclusion would enhance the paper. Additionally, the minor comments about the abstract and Figure 2 are vague and lack specific guidance, making them less helpful. Overall, the comment provides some useful feedback but could be more comprehensive, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. While it highlights a potential issue with the analysis, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the motivation for their choice of analysis. However, the comment lacks concrete details on how to improve the draft, making it 3. The authors know they need to address the issue but may not be entirely sure how to do so without further guidance.", "grounding_specificity_rationale": "The comment raises a question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. However, it does not specify which part of the paper discusses this analysis, making it weakly grounded. The comment is specific in its questioning of the motivation and the reasoning behind the choice of analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity would not appear in earlier layers. This is a logical question that prompts the authors to clarify their reasoning, but it does not contain a claim that requires verification. It is a request for clarification rather than an opinion or suggestion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer and questions why numerosity would not appear in earlier layers. This prompts the authors to clarify their reasoning and potentially reconsider their approach. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the draft. While it identifies a potential weakness, it lacks depth and actionable feedback, making it 3. The authors are given some insight into a potential area for improvement, but the comment could be more comprehensive to fully assist them in enhancing their work. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not provide any explicit guidance or suggestions on how to address this issue. The comment lacks concrete details or actionable steps for the authors to follow, leaving them without a clear understanding of what needs to be done to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not specify which part of the paper discusses this parameter or where the issue arises. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of setting the parameter S are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the parameter S, stating that its setting remains a problem. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the parameter S, noting that its setting remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the draft. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to resolve the problem. This lack of specificity and guidance makes the comment 2, as it highlights a concern but does not offer any actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a human evaluation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the section discussing caption generation or evaluation metrics. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the human evaluation should be considered or how it would improve the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. This claim is 3 as it provides a logical reasoning for why human evaluation might be more convincing. However, the comment lacks specific examples or references to support the claim that automatic metrics are misleading, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a reasonable basis for the claim but could be improved with more detailed evidence or examples.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it highlights a potential weakness in the evaluation methodology and suggests an alternative approach that could provide more robust insights. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the human evaluation or what aspects should be evaluated. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer argues that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback implies that the authors should clarify or address this point in their introduction, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the introduction but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" where the claim is made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" by pointing out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction is misleading because it states that \"these shape constraints do not require tuning a free parameter,\" while the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. The reviewer provides a logical reasoning by pointing out the distinction between the absence of a free parameter and the need to choose between different types of constraints. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer points out that the choice between convex or concave constraints and increasing or decreasing constraints can be seen as a hyperparameter that needs to be chosen or tuned. This feedback highlights a discrepancy between the claim and the actual complexity of the constraints, which could be misleading to readers. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how the authors might address this issue or clarify the introduction. The feedback is 3 as it prompts the authors to reconsider their claims, but it lacks actionable suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the convergence proof as trivial, suggesting that it lacks substantial novelty and rigor. It implies that the authors should address this issue by providing a more substantial and rigorous proof. However, the comment does not explicitly instruct the authors to revise the proof or provide specific guidance on how to enhance its novelty and rigor. The action is implicit and somewhat vague, as the authors can infer that they need to improve the proof but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Triviality of Convergence Proof,\" indicating that it addresses the theoretical proof for convergence. It also references \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" providing clear references to specific parts of the paper. The comment is specific because it details the issue with the convergence proof, explaining that it appears trivial due to the i.i.d. nature of $X$ and the resulting covariance matrix for $Z$. It also suggests that previous theorems can be adapted with straightforward modifications, highlighting the lack of substantial novelty and rigor in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial, suggesting that the paper\"s claim of noni.i.d. data is contradicted by Assumption 4.1, which indicates that $X$ is i.i.d. The reviewer provides a logical explanation by pointing out that the covariance matrix for $Z$ can be derived straightforwardly from $A^\top A / np$, making the convergence proof seem trivial. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim of triviality. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the convergence proof, suggesting that it appears trivial due to the i.i.d. nature of $X$ and the resulting covariance matrix for $Z$. It points out that the paper claims $Z$ is noni.i.d., but Assumption 4.1 indicates $X$ is i.i.d., leading to a straightforward derivation of the covariance matrix. The comment also references Modification 1 in Appendix C, suggesting that previous theorems can be adapted with minor modifications. This feedback is clear and actionable, as it identifies a specific weakness in the proof and provides a basis for improvement. However, it could be more helpful if it offered suggestions on how to enhance the novelty and rigor of the proof. Overall, the comment is 4, as it directs the authors to a critical area that requires attention and provides a starting point for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental setup should be clarified regarding the semireal nature of the multinode seed cascades, which are artificially created by merging singlenode seed cascades. This provides a direct action for the authors to take, which is to clearly mention this aspect in their draft. The comment is specific and concrete, as it clearly instructs the authors on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the multinode seed cascades are artificially created by merging singlenode seed cascades, which should be clarified. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup might be considered semireal. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the multinode seed cascades are artificially created by merging singlenode seed cascades. It suggests that this should be clearly mentioned in the paper. This feedback is clear and actionable, as it directs the authors to clarify an important aspect of their experimental methodology. By addressing this point, the authors can enhance the transparency and credibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the datasets and models used, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or what specific datasets or models should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include more diverse datasets and models, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in terms of datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, such as assessments of other biases and datasets, and the inclusion of stateoftheart generative models. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper has limited datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights a limitation, it does not provide specific examples or references to support the claim about the absence of other biases or datasets. The lack of detailed justification or evidence makes the claim 3, as the authors would need to conduct further research to fully understand the scope of the limitation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is clear and actionable, as it highlights areas where the authors can expand their analysis to provide a more comprehensive evaluation of biases and models. However, the comment could be more helpful if it suggested specific datasets or models that should be included or provided guidance on how to incorporate these assessments. Despite this, the comment provides valuable insights that can guide the authors in improving their draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a conflict between two statements in the paper regarding the performance of the multienv model compared to the singleenv model. It explicitly requests clarification to resolve this apparent contradiction. The action is direct and clear, as the authors are instructed to clarify the conflicting statements. This provides a concrete and explicit action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conflicting statements regarding the performance of the multienv model compared to the singleenv model. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue of conflicting statements and requests clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between two statements in the paper regarding the performance of the multienv model. It highlights the need for clarification to resolve this apparent contradiction. However, the comment does not provide any additional context, evidence, or reasoning to support why these statements are conflicting or how they should be clarified. Without further explanation or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential conflict between two statements in the paper regarding the performance of the multienv model. It points out that the paper claims both an inevitable performance loss and an outperformance of the singleenv model due to knowledge sharing, which seems contradictory. By highlighting this inconsistency, the comment provides a clear and actionable suggestion for the authors to clarify the issue. This feedback is valuable as it directs the authors to resolve a critical ambiguity in their paper, potentially improving the clarity and coherence of their arguments. However, the comment could be more helpful if it offered specific guidance on how to reconcile the conflicting statements. Overall, the comment is 4, as it effectively identifies a key area for improvement and prompts the authors to clarify their claims."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing the source of the metrics. This feedback is explicit, as it clearly states what needs to be done to improve the draft. However, it lacks concrete details on how to execute these actions, such as which specific metrics require explanation or how to properly cite them. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the description of metrics in the paper, suggesting that it is limited and recommends either providing an explanation of the metrics or citing their source. However, it does not specify which part of the paper discusses the metrics, making it weakly grounded. The comment is specific in its suggestion to provide an explanation or citation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the description of metrics is limited and suggests that an explanation or citation would be beneficial. However, the comment does not provide specific examples of which metrics are lacking in description or how they could be improved. This lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific issues and potential solutions based on the general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the description of the metrics used is limited. It provides a clear and actionable suggestion by recommending that the authors either explain the metrics used or provide a citation to their source. This feedback is valuable as it directs the authors to enhance the clarity and transparency of their work by addressing the metrics used. However, the comment could be more helpful if it specified which metrics are particularly unclear or suggested ways to improve the explanation. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 3, stating that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback provides a clear and direct action for the authors to take: improving the clarity of Figure 3 by enhancing the workflow and captions and clarifying the representation of communication modes. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, including the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be improved in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, and confusion regarding the representation of communication modes. However, the comment does not provide any specific examples or detailed reasoning to support these claims. Without additional context or explanation, the authors may find it difficult to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes. This feedback is clear and actionable, as it provides a direct area for improvement that the authors can address to enhance the clarity and comprehensibility of their figure. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the figure or provided examples of better practices. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. While it identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this point in their draft. The action is implicit, as the authors need to infer that they should provide a clearer explanation of this term. However, the comment lacks concrete details on how to address the issue, making it 3. The authors know they need to clarify the term but may not be entirely sure how to do so without further guidance.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this term is mentioned in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue of unclear terminology but lacks grounding as it does not provide a clear reference to the part of the paper where this term is discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the term \"learned [MASK] embedding\" in the SSL pretraining stage. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it could be clarified. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. By pointing out this ambiguity, the comment provides a clear direction for the authors to clarify their terminology, which is essential for ensuring the paper\"s clarity and accessibility. However, the comment could be more helpful if it offered suggestions on how to clarify this term or provided examples of similar contexts where such embeddings are discussed. Despite this, the feedback is 4 as it directs the authors to a critical area needing clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the reported results appear to be partially derivative, as they extend to hypernetworks results already presented in the literature for standard networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks results already presented in the literature for standard networks. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or results being addressed. The comment lacks specificity as it does not provide details on what aspects of the results are derivative or how they relate to the literature. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the reported results are \"partially derivative,\" suggesting that they extend results already presented in the literature for standard networks to hypernetworks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the reported results are partially derivative, as they extend results already presented in the literature for standard networks to hypernetworks. However, the comment does not provide specific examples or references to support this claim, nor does it offer guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed suggestions, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It suggests that the paper should better motivate the applications where such algorithms are necessary. However, the comment does not provide explicit guidance on how to achieve this motivation or what specific aspects should be included to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective and the lack of motivation for the problem being studied. It points out that the paper does not spend time motivating the applications where fast label aggregation algorithms are needed, and it criticizes the use of static datasets in the empirical analysis. However, the comment does not specify which part of the paper lacks motivation or where the datasets are discussed, making it weakly grounded. The comment is specific in its critique of the lack of motivation and the use of static datasets, but without clear references to specific sections, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It also points out that the empirical analysis uses static datasets, which contradicts the paper\"s objective. The comment provides a logical reasoning by highlighting the discrepancy between the paper\"s objective and the datasets used, suggesting that the problem should be better motivated. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to consider the logical reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks motivation for the problem being addressed, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the empirical analysis uses static datasets, which contradicts the paper\"s objective. This feedback is clear and actionable, as it highlights a critical area for improvement that could enhance the paper\"s relevance and impact. However, the comment could be more helpful if it provided specific suggestions on how to motivate the problem or what aspects of the application should be highlighted. Overall, the comment is 4, as it directs the authors to a key area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It implies that additional relevant CoT baselines for incontext learning of Large Language Models, such as text003 and ChatGPT, are missing in Tables 2 and 3. While the comment identifies the need for clarification and additional information, it does not explicitly instruct the authors to include these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional information but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scope of the study, suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models and that additional relevant CoT baselines for incontext learning of Large Language Models are missing. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also implies that additional relevant CoT baselines for incontext learning of Large Language Models are missing in Tables 2 and 3. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to infer the missing information and potentially conduct additional research to fully understand the scope and the missing baselines. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it is underspecified and suggesting that the work focuses on injecting a CoTbased approach into smallscale Language Models. It also points out the absence of relevant CoT baselines for incontext learning of Large Language Models in Tables 2 and 3. This feedback is clear and actionable, as it directs the authors to clarify the scope of their study and to include additional relevant baselines. However, the comment could be more helpful if it provided specific examples of the missing baselines or suggested how to incorporate them effectively. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment indicates that Figure 3 is difficult to read, but it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might enhance the readability of the figure, such as suggesting changes to the font size, color scheme, or layout. Without actionable advice, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the figure is \"very hard to read,\" which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the figure is difficult to read. Without additional context or explanation, the claim remains unsubstantiated, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable suggestions or guidance on how the authors might improve the figure\"s readability. Without specific advice on font size, color scheme, or layout adjustments, the authors are left without a clear path to address the issue. This feedback is 3 as it points out a problem but does not provide enough detail to be fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this question or what specific steps they should consider to improve their draft. As a result, the authors are left without a clear understanding of what actions to take, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric versus nonsymmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential gap in the introduction, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate comments. The first part, \"The GAT is trained with the whole model?\" is a question that implies the need for clarification or confirmation regarding the training process of the GAT. However, it does not provide explicit guidance on how to address this issue. The second part, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" suggests that the text should be reviewed by a native English speaker and that some sentences need rewriting for clarity. While this provides a general direction, it lacks specific guidance on which sentences need rewriting or how to improve clarity. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement these changes.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper discusses the GAT or where the need for a native English speaker\"s review is mentioned. However, it is specific in suggesting that the GAT is trained with the whole model and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, even if the authors cannot pinpoint the exact sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate claims. The first claim, \"The GAT is trained with the whole model?\" is a question that lacks supporting evidence or justification, making it 1. The second claim, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" is also 1 as it does not provide specific examples or reasoning to support the need for a native speaker\"s review or sentence rewriting. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two separate issues. First, it questions whether the GAT is trained with the whole model, which could be a critical aspect of the methodology that needs clarification. Second, it suggests that the text should be reviewed by a native English speaker to improve clarity, indicating that some sentences may be unclear or poorly phrased. While the comment highlights important areas for improvement, it lacks specific guidance on how to address the first issue or which sentences need rewriting. This makes the feedback 3, as it points out potential weaknesses but does not provide detailed actionable steps for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate observations. The first part suggests replacing a specific mathematical expression with an arbitrary parameter, which implies that the authors should consider using a more general or flexible approach. However, it does not provide explicit guidance on how to make this change or why it would be beneficial. The second part questions the choice of a specific learning rate value, suggesting that the authors should provide a justification for this choice. While the comment identifies areas for improvement, it lacks concrete instructions on how to address these issues. Therefore, the comment is 3, as it provides a direction for improvement but does not fully specify the steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the replacement of a mathematical expression with an arbitrary parameter and questions the choice of a specific learning rate value, suggesting that the authors should provide a justification for this choice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate observations. The first part questions the replacement of a specific mathematical expression with an arbitrary parameter, but it does not provide any reasoning or justification for why this change might be problematic. The second part questions the choice of a specific learning rate value, noting that it differs from the Adam default value, but it does not offer any explanation or evidence to support why this choice is inappropriate. Without additional context or reasoning, the claims are not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, suggesting that this change might not be justified. Second, it questions the choice of a specific learning rate value, noting that it differs from the Adam default value and lacks a clear justification. While the comment highlights areas that need clarification or justification, it does not provide detailed guidance on how the authors might address these issues or why these changes are important. The feedback is 3 as it directs the authors to areas that require further explanation, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in the paper and provide detailed explanations of the model\"s performance under different scenarios. It suggests that this analysis will aid in guiding subsequent improvements and expansions of the ERC research. The comment is clear and direct, providing a specific action for the authors to take. However, it does not offer detailed guidance on how to conduct the error analysis or what specific aspects to focus on. Therefore, while the action is explicit, it is somewhat vague in terms of execution. As a result, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where error analysis could be integrated. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. While the comment is specific in its request for error analysis, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not provide specific examples or references to support the importance of error analysis in the context of the ERC research. While the suggestion is logical and aligns with common practices in evaluating model performance, the lack of detailed justification or examples makes it 3. The authors would need to infer the relevance and importance of error analysis based on general knowledge, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is clear and actionable, as it suggests a specific area for improvement that could enhance the comprehensiveness and rigor of the paper. However, the comment could be more helpful if it provided examples of how error analysis could be integrated or specific aspects of the model that should be analyzed. Despite this, the comment offers valuable guidance that can significantly improve the draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and discussing the differences between datasets. It implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. Additionally, it suggests that if the method can finetune a pretrained model on synthetic data, it would enhance the value of the approach. While the comment provides a clear direction for analysis and discussion, it does not specify how to conduct this analysis or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to analyze the domain gap but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the differences between datasets, which implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discusses the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples or references to support the claim about the domain gap or the benefits of finetuning on synthetic data. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap and discussing the differences between datasets, which is a valuable insight for the authors. It also highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment could be more helpful if it provided specific examples or references to support the claim about the domain gap or the benefits of finetuning on synthetic data. Additionally, it does not offer detailed guidance on how to conduct the analysis or what specific aspects to focus on. While the feedback is 3 in identifying areas for improvement, it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The suggestion to preset the capacity to a small number is concrete, but the question about scaling up without compromising performance is more vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of scalability and suggests that the capacity should be preset to a small number, such as 10, to improve performance. Additionally, it raises a question about scaling up without compromising performance, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance worsens with the growth of the maximum number of identities, as shown in Table 3. It suggests that the capacity should be preset to a small number, such as 10, to improve performance. The comment raises a valid concern about scalability and provides a specific suggestion for improvement. However, it lacks detailed reasoning or references to support the claim that presetting the capacity to a small number would be effective. While the suggestion is logical, the comment could be strengthened with additional evidence or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance worsens with an increase in the maximum number of identities. It suggests that the capacity should be preset to a small number, such as 10, to improve performance. Additionally, the comment raises a practical concern about realworld scenarios where the number of objects can be unpredictable. This feedback is clear and actionable, as it provides a specific suggestion for improvement and highlights a critical aspect of the model\"s performance. However, it could be more helpful if it offered additional guidance on how to address the scalability issue or provided examples of how other models handle similar challenges. Overall, the comment is 4, as it directs the authors to a significant area for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the work is one of the preliminary studies discussing the application of LLP to NLP tasks, as it does not identify any NLPspecific elements in the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific aspects of the work should be revised to better align with the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the claim that the work is one of the preliminary studies discussing the application of LLP to NLP tasks, as it does not identify any NLPspecific elements in the approach. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section being addressed. The comment lacks specificity as it does not provide details on what aspects of the work are not NLPspecific or how the authors could improve this aspect. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the claim that the work is one of the preliminary studies discussing the application of LLP to NLP tasks, as it does not identify any NLPspecific elements in the approach. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the claim that the work is one of the preliminary studies discussing the application of LLP to NLP tasks, as it does not identify any NLPspecific elements in the approach. This feedback highlights a potential inconsistency in the paper\"s claims, prompting the authors to reconsider their assertions and ensure that their work aligns with the claimed scope. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their work. While it identifies a potential weakness, it does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This comment provides a clear and explicit action for the authors to take, which is to include an NCEbased method in their comparison. It also offers a specific reference to support the suggestion, providing concrete guidance on how to implement the action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a study that shows the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion should be made in, nor does it provide detailed guidance on how to incorporate this comparison. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to support the suggestion, but it lacks specific details or examples of how the NCEbased method should be integrated or compared. The authors would need to look up the referenced study to fully understand the context and implications of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include at least one NCEbased method for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing a specific suggestion for enhancing the paper by including a relevant comparison. However, the comment could be more helpful if it offered additional guidance on how to integrate this comparison or why it is important for the paper. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two improvements for the experiment section: conducting a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment explicitly states these actions, it does not provide detailed guidance on how to conduct the significance test or which specific LLMs should be compared. The authors are given a clear direction but lack specific instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements for the \"experiment section,\" which provides some grounding as it indicates a specific part of the paper. However, it does not specify which part of the experiment section needs improvement, such as the methodology, results, or discussion. The comment is specific in suggesting the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). However, the lack of explicit references to sections or specific elements makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests improvements for the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment provides a logical suggestion for enhancing the experiment, it lacks specific examples or references to support why these changes are necessary or beneficial. The claim is 3 as it offers a direction for improvement but lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the experiment section, suggesting that a significance test should be conducted on human evaluation results and that the proposed method should be compared with recent Large Language Models (LLMs). These suggestions are clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experiments. However, the comment could be more helpful if it included specific examples of LLMs to compare with or detailed guidance on conducting the significance test. Overall, the feedback is 4 as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to discuss a specific previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019, and to illustrate the relationship between this work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of research on joint error for UDA and references a specific previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: discussing the relationship between the referenced work and the proposed method, and explaining why the proposed method is better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" in ICML2019. The reviewer provides a specific reference to support the claim, which is a clear and robust form of evidence. This makes the claim 5, as it is wellsupported by a direct reference to existing literature. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that there is no research focusing on the joint error for Unsupervised Domain Adaptation (UDA). It points out that this problem has already been studied in a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. The comment provides a specific reference and suggests that the authors should discuss this work and its relationship to their proposed method, as well as explain why their method is better. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by addressing the gap in their claim and providing a more comprehensive discussion of related work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the use of a newly collected large dataset (209M) compared to the smaller datasets used by existing methods. The reviewer implies that the superior performance of the proposed method could be due to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should consider the impact of dataset size on the results and potentially adjust their analysis or comparisons accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset versus smaller datasets used by existing methods like GEM, which employs only 20M unlabeled data. This provides a clear context for the issue, allowing the authors to identify the part of the paper being discussed as the section comparing the proposed method with SOTA methods. However, the comment does not specify what needs to be addressed or how the authors should adjust their comparison to make it more fair. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a larger dataset. The reviewer provides a specific example, mentioning that GEM uses only 20M unlabeled data, while the proposed method uses a 209M dataset. This comparison highlights the potential impact of dataset size on accuracy, suggesting that the superior performance of the proposed method may be attributed to the larger dataset rather than the method itself. The claim is supported by logical reasoning and specific examples, making it 4. However, the comment could be strengthened by providing more detailed analysis or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods. It points out that the proposed method\"s performance is based on a newly collected 209M dataset, while existing methods use smaller datasets, such as GEM with only 20M unlabeled data. This observation suggests that the superior performance of the proposed method may be due to the larger dataset rather than the method itself. The comment provides a clear and actionable suggestion for the authors to consider the impact of dataset size on their results and potentially adjust their analysis or comparisons to ensure a fair evaluation. However, it could be more helpful if it offered specific guidance on how to address this issue, such as suggesting alternative comparisons or adjustments to the experimental setup. Overall, the comment is 4 as it highlights an important consideration for the authors to address in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of justification for the need to design a new curriculum learning method for text graphs, noting that the research gap and limitations of existing methods are not discussed. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to discuss the limitations of existing methods and justify the need for a new approach, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of justification for designing a new curriculum learning method for text graphs and the absence of discussion on the limitations of existing methods. The comment provides a clear direction for the authors to address by discussing the research gap and why existing methods cannot be applied. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for a new curriculum learning method for text graphs is not justified and that the research gap is not discussed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence leaves the claim 3, as the authors would need to infer the gaps in the justification and research gap themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods are discussed in Section 1, the need for a new curriculum learning method for text graphs is not justified. It points out that the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is clear and actionable, as it prompts the authors to address the lack of justification and discuss the limitations of existing methods. However, the comment could be more helpful if it provided specific suggestions on how to justify the need for a new method or examples of existing methods that could be discussed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that powerful pretrained language models, such as BERT and XLNet, should be used as the base encoder for all methods to overcome the domainshift problem. It implies that the authors should compare the efficacy of the transfer parts rather than using the simplest ngram features. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specific guidance on integrating these models or how to compare the efficacy of the transfer parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods to address the domainshift problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a specific suggestion, it does not specify what aspects of the transfer parts should be compared or how the ngram features are insufficient. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that powerful pretrained language models like BERT and XLNet can help overcome the domainshift problem in NLP. It implies that using these models as the base encoder could improve the efficacy of the transfer parts compared to using ngram features. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The suggestion is based on general knowledge about the capabilities of these models, but without further elaboration, it remains 3. The authors would need to conduct their own research or consult literature to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for improving the approach to domain adaptation in the NLP field. It recommends using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, which could help overcome the domainshift problem. This is a clear and actionable suggestion that could enhance the robustness and effectiveness of the methods being compared. However, the comment could be more helpful if it included specific guidance on how to integrate these models or detailed comparisons with ngram features. Overall, the feedback is 4 as it offers a constructive direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the complexity of the proposed method, noting that it has several complicated modules and more parameters than the baselines. It questions whether the performance gain is due to a specific module or simply because of the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue and implies that the authors should conduct a more comprehensive ablation study to clarify the source of the performance gain, it does not provide explicit guidance on how to conduct this study or what specific modules to focus on. The action is implicit and somewhat vague, as the authors can infer the need for a more detailed ablation study but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed method\" and \"the current version of the ablation study,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of unclear performance gain and the need for a more definitive ablation study to determine whether the improvement is due to a particular module or the increased number of parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed method and questions whether the performance gain is due to a specific module or the increased number of parameters. The comment highlights the lack of clarity in the ablation study, which is a valid observation. However, it does not provide specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. While the comment identifies a potential issue, it lacks the depth of analysis needed to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It raises a question about whether the performance gain is due to a specific module or simply because of the increased number of parameters. The comment also points out that the current ablation study does not provide definitive answers to these questions. This feedback is valuable as it highlights a potential weakness in the paper and suggests that the authors should conduct a more comprehensive ablation study to clarify the source of the performance gain. However, the comment could be more helpful if it provided specific suggestions on how to conduct this study or which modules to focus on. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the explanation of a specific section (lines 196197) and suggests that more detail is needed to understand why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide explicit guidance on how to address this issue or what specific information should be added. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explanation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 196197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for more explanation regarding the difference between the two quantities and how they capture the difference in learning settings. The comment also includes a personal opinion about the acceptance of the paper, but this does not detract from the specificity of the feedback regarding the explanation needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the explanation of a specific section in the paper, specifically lines 196197. It asks for more detail on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this explanation. Without additional context or justification, the authors may find it challenging to understand the basis of the request. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires more explanation, namely the difference between two quantities discussed in lines 196197. It prompts the authors to provide a clearer explanation of why these quantities are different and how they capture the difference in learning settings. While the comment highlights a potential area for improvement, it does not offer specific suggestions or guidance on how to enhance the explanation. Additionally, the comment includes a personal opinion about the paper\"s acceptance, which, while interesting, does not directly contribute to improving the draft. Overall, the comment is 3 as it points out a specific area for clarification but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and direct, providing the authors with a specific action to take. The comment also specifies what needs to be addressed, which is the sensitivity of these parameters. Therefore, the comment is 5, as it gives the authors precise guidance on how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly refers to \"4.]\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed: the sensitivity of fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should address in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information or discussion, rather than a claim or opinion. It does not express a subjective judgment, suggestion, or deduction that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific in its request for the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is actionable and provides a clear direction for the authors to enhance their draft by addressing a specific aspect of their methodology. By highlighting this area, the comment helps the authors to improve the comprehensiveness and robustness of their work. Therefore, the comment is rated as 5, as it offers valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part suggests an interesting direction for further exploration, which is to test the proposed framework with different policy gradient approaches. However, it does not provide explicit guidance on how to conduct this exploration or what specific approaches should be considered. The second part asks a question about the number of random seeds used for learning policies, which is an explicit request for clarification. While the first part is vague, the second part is clear and actionable. Overall, the comment is 4 because it provides a concrete request for clarification but lacks detailed guidance on the first suggestion.", "grounding_specificity_rationale": "The comment suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The second part of the comment asks about the number of random seeds used for learning policies, which is specific but still does not provide clear grounding as it does not specify the exact section or context where this information is discussed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two parts: a suggestion to explore the proposed framework with different policy gradient approaches and a question about the number of random seeds used for learning policies. The first part is a suggestion and does not contain a claim that requires verification. The second part is a factual question seeking clarification, which is not a claim. Therefore, the entire comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two distinct points. The first part suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. This is a valuable suggestion that could enhance the paper\"s scope and applicability. However, it lacks specific guidance on how to conduct this exploration or which approaches to consider, making it 3. The second part is a factual question about the number of random seeds used for learning policies, which is clear and actionable. While the comment offers some useful insights, it could be more helpful if it provided more detailed guidance on the first suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s evaluation is limited to a single dataset and task, and that the results and conclusions would be strengthened by applying the analysis to more datasets and tasks. While the comment implies that the authors should expand their evaluation, it does not provide specific guidance on which additional datasets or tasks to consider or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors can infer that they need to broaden their evaluation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s evaluation is limited to a single dataset and task, implying that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify which additional datasets or tasks should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s evaluation is limited to a single dataset and task, suggesting that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This claim is 3 as it provides a logical reasoning for why the evaluation should be expanded. However, the comment lacks specific examples or references to datasets or tasks that could be used for a more comprehensive evaluation, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, noting that it is based on only one dataset and one task. It suggests that the results and conclusions would be strengthened by applying the analysis to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered examples of additional datasets or tasks that could be considered or provided guidance on how to incorporate them into the analysis. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that there are areas where the writing could be improved, specifically mentioning the definition 2.1 and the interpretation of \"relevant\" auxiliary model weights. However, it does not provide explicit guidance on how to improve the writing or clarify the definition. The comment implies that the authors should revisit the definition and provide more clarity, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that there are areas where the writing could be improved, specifically mentioning \"definition 2.1\" and the interpretation of \"relevant\" auxiliary model weights. This provides full grounding as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it points out a particular issue with the definition, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the writing could be improved in certain places, specifically mentioning the definition 2.1 and the interpretation of \"relevant\" auxiliary model weights. However, it does not provide any specific examples or reasoning to support why the writing is difficult to interpret or how it could be improved. The comment lacks detailed justification or evidence, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, such as the definition 2.1 and the interpretation of \"relevant\" auxiliary model weights. By pointing out these issues, the comment provides the authors with clear guidance on where to focus their efforts to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions or examples of how to improve the definition or provided additional context for better understanding. Despite this, the feedback is 4 as it directs the authors to specific areas needing attention, allowing them to make targeted improvements. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests using ULiRA instead. While the comment implies that the authors should consider alternative methods for privacy guarantees, it does not explicitly instruct them to make this change. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other methods for robustness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing via Ulira as a metric for unlearning effectiveness. It raises a concern about the robustness of MIA testing for privacy guarantees and suggests using ULiRA instead. However, the comment does not specify which part of the paper discusses MIA testing or where the suggestion to use ULiRA should be implemented. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its critique of MIA testing and the suggestion to use ULiRA, but without explicit references to sections or parts of the paper, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA (Membership Inference Attack) testing is not robust for privacy guarantees. It suggests using ULiRA as an alternative. However, the comment lacks specific examples or detailed reasoning to support the claim about the limitations of MIA testing. While it provides a suggestion for improvement, the lack of detailed justification or references makes the claim 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It points out that the effectiveness of MIA testing itself may not be robust for privacy guarantees, which is a critical concern. The comment provides a specific suggestion to use ULiRA instead, which could be a more robust method for evaluating privacy guarantees. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by addressing a significant methodological concern. However, the comment could be more helpful if it provided additional context or examples of how ULiRA might be integrated or compared to MIA testing. Overall, the comment is 4, as it effectively guides the authors toward a potential improvement in their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While the comment implies that the authors should explore this connection, it does not provide explicit instructions or concrete steps on how to incorporate this idea into the paper. The action is implicit and somewhat vague, leaving the authors to infer that they should consider this connection but without clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the paper\"s content. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the considerations should be applicable to kernel regression. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While this comment identifies a potential connection that could enhance the paper\"s relevance and scope, it lacks specific guidance or actionable suggestions on how the authors might explore or incorporate this idea. The feedback is 3 as it prompts the authors to consider a broader application of their work, but it does not provide detailed steps or examples to facilitate this exploration. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quantitive evaluation results in Figure 3, which only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo\"s superiority over competitors. The reviewer explicitly asks if it is possible to perform a quantitative comparison on the final outputs. This comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. The action is explicit and concrete, as it specifies exactly what needs to be done to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs, and suggests that a quantitative comparison on the final outputs is needed. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs, rather than the final outputs, and that Figure 4 illustrates a comparison of final results with a single data sample. The reviewer suggests that this limits the ability to confirm ModelAngelo\"s superiority over competitors. While the comment highlights a potential issue with the evaluation methodology, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed evidence or references makes it 3, as the authors would need to infer the importance of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results presented in the paper, noting that the quantitative evaluation results in Figure 3 only reflect middle outputs rather than the final outputs. It also points out that Figure 4 illustrates a comparison of final results with a single data sample, which may not be sufficient to confirm ModelAngelo\"s superiority over competitors. The comment raises a valid concern about the lack of convincing evidence for ModelAngelo\"s superiority and suggests that a quantitative comparison on the final outputs would be beneficial. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to conduct the quantitative comparison or what specific metrics to use. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including qualitative explanations, minimal descriptions of simulation or experiment procedures, and confusing figures. It suggests adding more details to the paper and/or supplementary information to clarify the work. Additionally, it recommends including error bars and/or pvalues for statistical inferences. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to add more details and statistical analysis, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the explanations, simulation or experiment procedures, and figures, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific details about what is missing, such as more detailed descriptions of procedures, the need for error bars and/or pvalues for statistical inferences, and clarification of figures like \"sample count\" in fig. 2. This level of specificity guides the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and lack detailed descriptions of simulation or experiment procedures. It also points out that some figures are confusing, such as the \"sample count\" in fig. 2. The reviewer suggests that adding more details to the paper and/or supplementary information would improve the clarity of the work. Additionally, the comment recommends including error bars and/or pvalues for statistical inferences. While the comment highlights specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion to include error bars and pvalues is a common practice in scientific writing, but the comment does not provide specific references or detailed explanations of why these are necessary. Therefore, the claim is 3, as it provides a general direction for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the need for more detailed explanations, clearer descriptions of simulation or experiment procedures, and the inclusion of error bars and/or pvalues for statistical inferences. It also points out specific issues with figures, such as the lack of clarity regarding \"sample count\" in fig. 2. By highlighting these weaknesses, the comment provides the authors with actionable feedback on how to enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the clarity of the explanations. Overall, the comment is 4 as it directs the authors to areas that require attention and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. The comment implies that the authors should include references to existing studies that have discussed these factors. While the action is explicit, it lacks concrete guidance on which specific studies to reference or how to integrate them into the paper. The authors know they need to add references but may not be entirely sure how to do so effectively. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that some claims may be inspired by existing studies and suggests adding supportive references. The comment provides an example of the factors discussed in the paper and notes that most of these factors have been discussed in existing studies. This level of detail helps the authors understand what needs to be addressed and why, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. The comment implies that these factors have been discussed in existing studies, but it does not provide specific references or examples to support this claim. While the suggestion to add references is logical, the lack of detailed evidence or references makes the claim 3. The authors would need to conduct additional research to verify the claim, making it a borderline case.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that some claims may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. By pointing out the need for references, the comment offers a clear and actionable suggestion for improving the paper. However, it could be more helpful if it included specific references to existing studies that have discussed these factors, which would provide the authors with more detailed guidance on how to enhance their draft. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional references or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This implies that the authors should include specific settings or comparisons to enhance the paper\"s contribution and relevance to the community. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific settings to include or how to present them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a way to enhance the paper by providing a single review of the various advances in this area, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where this improvement could be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. The claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution by aligning it with existing work. However, the comment lacks specific examples or references to prior work, which would strengthen the justification. The authors would need to infer the exact settings or comparisons to be made, making the claim 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm, similar to prior work such as Dagger and searn. This feedback is 3 as it identifies a potential area for enhancement and provides a clear direction for the authors to consider. However, the comment could be more helpful if it included specific examples or guidance on how to present these settings or comparisons. By providing more detailed suggestions, the authors would have a clearer understanding of what changes to make to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of specific examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their examples. The comment implies that the authors should consider providing more context or analysis to establish the generalizability of these examples, but it does not specify how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity regarding the generalizability of specific examples presented in the paper. The comment highlights the need for more context or analysis to establish the generalizability of these examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases in target statistics and prediction shift of gradient values, but it does not provide a clear explanation of why these examples are unclear or how they could be improved. The comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of examples presented in the paper, specifically those related to biases in target statistics and prediction shift of gradient values. It points out that while the paper provides examples, it is unclear how general these situations are. This feedback is 3 as it highlights a potential area for improvement, encouraging the authors to provide more context or analysis to establish the generalizability of their examples. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of a few more datasets would be beneficial, particularly in the context of crosstask transferability. However, it does not specify which datasets should be included or how they would enhance the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks concrete guidance on which datasets to choose or how to integrate them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including a few more datasets, especially concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections, making it weakly grounded. The comment is specific in suggesting the inclusion of additional datasets for crosstask transferability, but without clear guidance on which datasets to use or how to integrate them, it remains somewhat vague. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that including a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any specific examples, reasoning, or references to support why these additional datasets would be valuable or how they would enhance the study. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1.", "helpfulness_rationale": "The comment suggests that including a few more datasets, particularly those concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they might enhance the study. The feedback is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It explicitly mentions the idea of creating interleaved imagetext tasks, such as Question Answering from images, as an example of how to add variety. This provides a clear and concrete action for the authors to consider, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the tasks presented in the paper, specifically mentioning \"Figure captioning\" and \"matching figures/subfigures to appropriate captions.\" It suggests that the tasks are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the images/plots. The reviewer provides an example of an interleaved imagetext task, such as Question Answering from images. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the task descriptions or methodology sections. The comment is specific in suggesting the addition of unique tasks and provides an example, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the images/plots. The reviewer provides an example of an interleaved imagetext task, such as Question Answering from images, as a potential addition. This suggestion is based on logical reasoning and provides a clear direction for the authors to consider. However, the comment could be strengthened by explaining why these tasks are considered standard or how they could be enhanced. Overall, the claim is 4, as it provides a reasonable suggestion for improvement but lacks detailed justification or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the tasks presented are somewhat standard and could be enhanced by introducing unique tasks that showcase the diversity of the dataset. It suggests considering interleaved imagetext tasks, such as Question Answering from images, as an example of how to add variety. This feedback is clear and actionable, providing the authors with a specific direction for improving their work by diversifying the tasks and showcasing the dataset\"s capabilities. However, the comment could be more helpful if it included additional suggestions or examples of how to implement these unique tasks. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper\"s content and diversity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify whether their work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the concern. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the work in this section includes any novel efforts beyond following the previous work, \"Luciddreamer.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether the work on 3D Gaussians generation in Section 3.1 includes any novel efforts beyond following the previous work, \"Luciddreamer.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the work is not novel. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the work presented in Section 3.1, specifically regarding the generation of 3D Gaussians. It questions whether the work merely follows the previous work, \"Luciddreamer,\" without any additional novel efforts. This feedback prompts the authors to clarify the novelty of their approach, which is an important aspect of academic integrity and originality. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate or highlight any novel contributions. Overall, the comment is 3 as it directs the authors to address a critical aspect of their work, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, suggesting it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors might address these concerns or suggest potential improvements. The feedback is 3 as it points out areas for improvement but lacks concrete steps for the authors to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the upper bound provided in the theorem, such as the crude nature of the bound and the dropping of the nonnegative constraint on the distribution. Additionally, it critiques the assumption that the loss function belongs to the RKHS, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that MMD DRO lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, stating that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. The comment also questions the assumption that the loss function belongs to the RKHS. While the reviewer provides a logical critique of the method, the comment lacks specific references or detailed examples to fully substantiate the claims. The reasoning is 3, as it highlights potential issues with the method, but it could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant drawback of MMD DRO, noting that it lacks a tractable exact equivalent reformulation compared to other methods like phidivergence or Wasserstein uncertainty sets. It critiques the upper bound provided in Theorem 3.1, pointing out that it is crude and drops the nonnegative constraint on the distribution, necessitating further approximation. Additionally, the comment questions the assumption that the loss function belongs to the RKHS, as already pointed out by the authors. This feedback is 4 as it highlights specific weaknesses in the method and provides a clear direction for the authors to address these issues. However, it could be more helpful if it offered suggestions on how to improve the tractability or provided examples of how to address the issues with the upper bound. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to specific problems, such as nonconvex losses and nonnorm type defenses. It also asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant. Additionally, it questions whether the framework could still provide intuitions on the risk upperbound. The comment does not provide explicit instructions or suggestions for the authors to address these questions or concerns. While it implies that the authors should consider these issues, the lack of concrete guidance or actionable steps makes it difficult for the authors to know exactly how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.3\" and \"binary classification,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the relevance of the framework to specific problems, such as nonconvex losses and nonnorm type defenses, and asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant. Additionally, it questions whether the framework could still provide intuitions on the risk upperbound. This level of detail provides clear guidance on what aspects of the paper need further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to specific problems, such as nonconvex losses and nonnorm type defenses. It questions whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant. The comment also asks if the framework could still provide intuitions on the risk upperbound. While the questions are logical and based on the content of the paper, they lack specific evidence or references to support the claims. The reasoning is 3 as it provides a logical framework for questioning the relevance of the framework, but it requires more detailed justification or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework to specific problems, such as nonconvex losses and nonnorm type defenses. It challenges the authors to consider whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant. Additionally, it questions whether the framework could still provide intuitions on the risk upperbound. These questions prompt the authors to critically evaluate the applicability and limitations of their framework, which is a valuable contribution to the paper. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or improve the framework. Overall, the comment is 3 as it identifies areas for further exploration and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an experiment where the trained models are sparsified to reduce the number of selected features and compared to the proposed model in terms of accuracy. This is an explicit action that provides a clear direction for the authors to consider and implement. The suggestion is concrete, as it specifies the exact experiment to conduct and the metric to evaluate. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an experiment where the trained models are sparsified to reduce the number of selected features and compares the accuracy to the proposed model. This provides clear guidance on what the authors could do to enhance their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a suggestion for an additional experiment, asking the authors to consider sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. This suggestion is not a claim or opinion but rather a request for further exploration. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests an additional experiment that could enhance the paper by exploring the effect of sparsifying the trained models on the number of selected features and comparing the accuracy to the proposed model. This feedback is clear and actionable, providing the authors with a specific direction for further analysis that could strengthen their work. However, the comment could be more helpful if it included a rationale for why this experiment would be beneficial or how it might impact the overall understanding of the results. Despite this, the suggestion is valuable and aligns with a score of 4, as it offers a constructive way to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. The reviewer also questions the number of landmarks used, the type of image features, and the fixed radius with different scales. Additionally, they ask about achieving shape invariance. While the comment identifies several areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, specifically the sparsification process, extraction of landmark features, and generation of landmarks on the edge. It also raises questions about the number of landmarks used, the type of image features, and the fixed radius with different scales, as well as achieving shape invariance. This provides clear guidance on what aspects of the paper need more detail and explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, specifically the sparsification process, which makes it difficult to reproduce the results. It raises several questions about the process, such as the extraction of landmark features, generation of landmarks on the edge, and the number of landmarks used. While the comment identifies areas that need clarification, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it challenging for the authors to understand the exact issues and how to address them. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of detail about the techniques used, which makes it difficult to reproduce the results. It raises several specific questions about the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. These questions highlight critical areas where the paper lacks clarity and detail, providing the authors with a clear direction for improvement. By addressing these questions, the authors can enhance the reproducibility and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the clarity of the techniques. Overall, the comment is 4 as it effectively points out areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific guidance or details on how the authors should reorganize the section. The action is implicit, as the authors need to infer that they should make changes to the structure of the appendix, but it is vague because it lacks concrete instructions on what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Appendix H,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the section is difficult to follow, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Appendix H section should be reorganized because it is difficult to follow. However, it does not provide any specific reasons or examples to support this claim, such as explaining which parts are confusing or how the reorganization could improve clarity. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity. However, the comment lacks further guidance or suggestions on how to achieve this reorganization, such as recommending specific changes to the structure or content. While it provides a clear direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. It suggests that more details are needed to reproduce the work, such as specifics about the RNN implementation. While the comment identifies the need for additional details, it does not provide explicit guidance on what specific details should be included or how to present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more technical details but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pseudocode given in the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the paper is not written to be reproducible, and identifies the need for additional details such as specifics about the RNN implementation. The comment provides examples of what is missing, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproducible, despite providing pseudocode in the supplementary material. The reviewer suggests that more details are needed to reproduce the work, such as specifics about the RNN implementation. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the paper is not reproducible. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reproducibility, noting that while pseudocode is provided in the supplementary material, it does not adequately support reproducibility. The reviewer highlights the need for more detailed information, such as specifics about the RNN implementation, to enable actual reproduction of the work. This feedback is clear and actionable, as it provides specific areas where the authors can improve the paper\"s reproducibility. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of what information should be included. Overall, the comment is 4, as it directs the authors to a critical area for improvement, but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. While the comment implies that these additions would improve the figure, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors can infer that they need to add error bars and more trials but are not provided with specific guidance on how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the figure would be stronger with the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This provides clear guidance on what could be improved in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be strengthened by the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This claim is 3 as it provides a logical reasoning for why error bars and more trials would improve the figure. However, the comment lacks specific examples or references to support the claim that these additions would effectively reduce random fluctuations. Providing such examples or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving Figure 1 by recommending the inclusion of error bars and/or more random trials to reduce random fluctuations in the results. This feedback is clear and actionable, as it offers a concrete way for the authors to enhance the figure and potentially improve the clarity and robustness of their findings. However, the comment could be more helpful if it explained why these additions are important or how they would impact the interpretation of the results. Overall, the comment is 4 as it provides a direct and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two explicit actions: providing a brief introduction to energy models in the related work section and clarifying which points in Figure 1 correspond to different learning rates and steps. The first action is clear and concrete, as it specifies what needs to be added to the related work section. The second action is also explicit and concrete, as it instructs the authors to clarify the points in Figure 1. Both actions are direct and provide specific guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for a brief introduction to energy models in the related work section and clarifies the points in Figure 1 that correspond to different learning rates and steps. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate suggestions and a reference to external works. The first suggestion to include a brief introduction to energy models in the related work section is a logical request for context, but it lacks specific examples or references to support why this is necessary. The second suggestion to clarify Figure 1 is factual and does not contain a claim. The references to external works are provided but do not directly support the suggestions. Therefore, the comment is 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides two distinct suggestions for improvement. First, it recommends including a brief introduction to energy models in the related work section, which could help contextualize the paper\"s contributions. Second, it points out a lack of clarity in Figure 1, specifically regarding which points correspond to different learning rates and steps. This feedback is clear and actionable, as it identifies specific areas where the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or examples to support the suggestions. Overall, the comment is 4, as it offers valuable guidance for improving the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or mitigate the potential biases. The action is implicit, as the authors need to infer that they should consider alternative approaches or adjustments to the utilitybased method. The feedback is 3 because it identifies a potential problem but lacks concrete steps for resolution.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach to determining chunk significance in FIITED, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The comment is specific in detailing the potential issue of biases introduced by basing eviction decisions solely on utility scores and provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for recent chunks to gain a temporary high utility, leading to premature evictions of other valuable chunks. This claim is 3 as it provides a logical reasoning about the potential issue with the utilitybased approach. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This feedback is 3 as it highlights a potential weakness in the methodology and encourages the authors to consider alternative approaches or adjustments to mitigate these biases. However, the comment could be more helpful if it offered suggestions or examples of how to address this issue or provided additional context for understanding the potential impact of these biases. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the first paragraph of the Introduction for being too general and not relevant to the paper\"s focus on detecting drift types and magnitude. However, it does not provide explicit guidance on what the authors should do to improve this section. The comment implies that the authors should focus more on the specific aspects of drift detection, but it does not specify how to reorganize or rewrite the introduction to better align with the paper\"s core focus. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this paragraph, namely that it is too general and does not mention drift, which is the core focus of the paper. The comment provides a clear direction for improvement by suggesting that the introduction should be more relevant to the paper\"s focus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is too general and does not mention drift, which is the core focus of the paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why the introduction is not relevant. This lack of evidence and detailed justification makes the claim difficult for the authors to address effectively, rendering it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of the paper, noting that the first paragraph is too general and does not mention drift, which is the core focus of the paper. This feedback is clear and actionable, as it directs the authors to reorient the introduction to better align with the paper\"s central theme. However, the comment could be more helpful if it provided suggestions on how to integrate the relevant information about drift into the introduction or offered examples of how to structure the introduction more effectively. Despite this, the comment provides valuable guidance that can help the authors improve the relevance and focus of their introduction, making it 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms to provide a clearer understanding of the framework\"s performance. The comment also implies the need for more detailed explanations of the presented results. While the action is implicit, it is concrete in suggesting specific improvements, such as conducting quantitative experiments and comparisons. The authors can infer that they need to enhance the experimental section to address the reviewer\"s concerns. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"result section\" and the need for \"quantitative experiments and comparison between selection of algorithms\" or \"a more detailed explanation\" of the presented results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the result section, namely, quantitative experiments and comparisons, and a detailed explanation of the presented results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contributions to the final result are unclear. It suggests that the lack of quantitative experiments and comparisons between algorithms makes it difficult to understand the framework\"s performance. The comment is 3 as it provides a logical reasoning for the claim, noting the absence of quantitative experiments and comparisons. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding how different parts of the framework contribute to the final result. It highlights the need for quantitative experiments and comparisons between algorithms to provide a clearer understanding of the framework\"s performance. The comment also suggests that the authors should include more detailed explanations of the presented results. This feedback is actionable and provides clear guidance on how the authors can improve their draft by enhancing the experimental section. However, the comment could be more helpful if it offered specific suggestions on which experiments or comparisons to conduct. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the paper need to be clarified or improved. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s capabilities are unclear or how they could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is unclear or to guide the authors in addressing the issue. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests presenting a simplified version of Theorem 2 for a general audience, similar to Theorem 1. This implies that the authors should consider making their explanation more accessible to a broader audience. However, the comment does not provide specific guidance on how to simplify the theorem or what aspects to focus on. While the action is implicit, it is somewhat concrete in suggesting a direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, and mentions that Definition 2 and Theorem 2 are hard to digest on their own. This provides specific guidance on what needs to be addressed, which is the clarity and accessibility of these sections. However, it does not explicitly mention which part of the paper these theorems and definitions are located in, making it weakly grounded. The authors can infer that it relates to the theoretical or mathematical sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult for a general audience to understand and proposes simplifying it, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is hard to digest or how it could be simplified. This lack of detailed justification makes the claim 3, as the authors would need to infer the potential issues and solutions based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, to make it more accessible. This is a clear and actionable suggestion that could help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided specific guidance on how to simplify the theorem or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors to a specific area that needs improvement, offering a clear path for enhancement. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting experiments with a larger image resolution to see how it affects performance. While the comment implies that the authors should consider this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what resolution to use. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1, All the experiments are conducted using images under 224*224 resolution,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the interest in seeing how performance would be affected by using a larger resolution. This provides clear guidance on what the authors should consider adding or exploring in their experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be interesting to see how performance changes with a larger image resolution. However, it does not provide any reasoning, evidence, or references to support why this would be beneficial or how it might impact the results. The comment lacks specific examples or logical reasoning to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting direction for further experimentation by proposing the use of larger image resolutions in the experiments. This feedback is 3 as it encourages the authors to explore a potential avenue for improving their results or understanding the robustness of their approach. However, the comment lacks specific guidance on how to conduct these experiments or what specific resolutions to consider, which limits its actionable value. To be more helpful, the comment could include suggestions on how to implement this change or what benefits it might bring. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking for clarification on the keypoint mask averaged feature vector. It implies that the authors should provide more information or explanation regarding this aspect. However, the comment does not explicitly instruct the authors to add or modify content, and it lacks concrete guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"keypoint mask averaged feature vector\" and suggests that it might be a simple multiplication of each feature map elementwise by H_psi. This provides clear guidance on what needs to be addressed in the KeyQN section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the KeyQN section, specifically asking for an explanation of the \"keypoint mask averaged feature vector\" and suggesting that it might be a simple multiplication of each feature map elementwise by H_psi. This is not a claim but rather a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the KeyQN section, specifically asking for clarification on the \"keypoint mask averaged feature vector.\" It suggests that this might be a simple multiplication of each feature map elementwise by H_psi. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the concept in their paper. The feedback is 3 as it points out a need for clarification, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the author should make it easier to distinguish between the different curves in Figure 2. It provides specific and concrete suggestions, such as using styles (e.g., dashed lines) or adding color, to enhance the visual clarity of the figure. This feedback is explicit and provides clear guidance on how to improve the figure, making it 5. The authors know exactly what changes to make to enhance the readability of their figure.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improving the figure, such as using styles (e.g., dashed lines) or adding color to distinguish between the different curves. This level of detail helps the authors understand exactly what needs to be addressed to enhance the figure\"s clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to distinguish between the different curves in Figure 2 and recommends using styles (e.g., dashed lines) or adding color to improve clarity. This is a subjective opinion based on the reviewer\"s experience and does not require specific evidence or references to support the claim. The suggestion is logical and provides a clear path for improvement, making it 3. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides actionable feedback by suggesting the use of styles, such as dashed lines, or adding color to enhance the visual clarity of the figure. This feedback is clear and constructive, offering the authors a direct way to improve the presentation of their data. However, the comment could be more helpful if it included examples of how to effectively use styles or colors to distinguish between the curves. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should \"tonedown the intro\" and not refer to the task as \"language learning,\" as it is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be changed in their draft. The recommendation is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the introduction of the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the claims made in the introduction, pointing out the discrepancy between the task described and the evaluation method used. The comment suggests a change in the introduction to better align with the actual task, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not supported by the tasks and models evaluated. It suggests that the task is more accurately described as \"feedback driven QA in the form of a dialog\" rather than \"language learning.\" However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to consider the context and evidence presented in the paper to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the claims made in the introduction and the actual evaluation methods used in the paper. It points out that the task is described as \"language learning\" but is evaluated through question answering, which is more accurately described as \"feedback driven QA in the form of a dialog.\" This feedback is clear and actionable, as it suggests a specific change to the introduction to better align the description with the actual task. However, the comment could be more helpful if it provided additional context or examples to support the claim and guide the authors in making the necessary adjustments. Overall, the comment is 4, as it directs the authors to a significant improvement in the clarity and accuracy of their introduction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the central contribution of the paper, specifically the use of ODEs for modeling weight evolution, due to concerns about the inaccuracy of neural ODEs when recomputing activations. The reviewer suggests that a previous paper may have first reported this issue, but the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment identifies a potential issue with the paper\"s contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should provide more evidence or analysis to support their claim. However, the comment is 3 because it points out a specific area for improvement, even if it lacks detailed instructions on how to implement the suggested changes. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs for modeling weight evolution, and questions the problem of neural ODEs exhibiting inaccuracy when recomputing activations. It mentions that a previous paper may have first reported this issue, but the current paper lacks a convincing analytical argument or empirical evidence. However, the comment does not specify which part of the paper discusses this issue or where the previous paper is mentioned, making it weakly grounded. The comment is specific in detailing the lack of evidence and analytical argument, but without explicit references to sections or specific parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s central contribution, modeling weight evolution using ODEs, is based on an issue with neural ODEs exhibiting inaccuracy when recomputing activations. The reviewer suggests that this issue was first reported in a previous paper, but the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment identifies a potential issue, it does not provide specific references to the previous paper or detailed reasoning to substantiate the claim. This makes the claim 3, as the authors would need to seek additional information to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the central contribution of the paper, specifically the use of ODEs for modeling weight evolution, due to concerns about the inaccuracy of neural ODEs when recomputing activations. It suggests that a previous paper may have first reported this issue, and the current paper lacks a convincing analytical argument or empirical evidence to support this claim. While the comment identifies a potential weakness in the paper\"s contribution, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their argument. The feedback is 3 as it points out a critical area for improvement but lacks depth and actionable advice, leaving the authors with a general direction for further work. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is an explicit action that provides clear guidance on what the authors should add to their draft. The comment is specific and concrete, as it directly instructs the authors to include this information, leaving no ambiguity about how to implement the suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is a specific and actionable piece of feedback that could enhance the clarity and completeness of the paper. By incorporating this information, the authors can provide a clearer understanding of the methodology and its application. However, the comment could be more helpful if it explained why this detail is important or how it impacts the overall understanding of the paper. Despite this, the feedback is clear and provides a direct suggestion for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes might be necessary to improve the draft. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of lower bounds for round complexity in batched ranking problems, specifically mentioning the exploitation of an easy reduction from collaborative ranking. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue with the lower bound results, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. This observation highlights a potential weakness in the paper\"s contribution, as it suggests that the lower bound results may not be as significant or novel as claimed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). The reviewer implies that more carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not provide explicit guidance on how to improve the prompting technique or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should enhance their prompting strategy but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). However, it does not specify which part of the paper discusses the prompting technique, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the prompting technique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is \"very basic\" and fails to leverage the full potential of Large Language Models (LLMs). However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate the assertion that more carefully curated prompts could lead to better results. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the use of a \"very basic\" prompting technique that fails to fully leverage the potential of Large Language Models (LLMs). It suggests that more carefully curated prompts could lead to better results in generating systematic reviews. This feedback is 3 as it points out an area for improvement and provides a general direction for enhancing the study. However, the comment lacks specificity and does not offer detailed guidance on how to improve the prompting technique or what specific changes should be made. While it provides some insight, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger data sets, acknowledging that compute resources might be a limiting factor. However, it does not provide specific guidance on how to address the potential issue of maintaining probabilities at large batch sizes. The comment implies that this aspect is not critical, but it does not offer concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of batch size on probability maintenance without specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Additional experiments on larger data sets,\" which allows the authors to identify the specific part of the paper being addressed. It also provides specific feedback on the potential issue of maintaining probabilities at large batch sizes, offering a clear direction for improvement. However, the comment does not specify which section of the paper should include these additional experiments or how to address the issue of maintaining probabilities. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger data sets, acknowledging potential compute resource limitations. It also mentions concerns about maintaining probabilities at large batch sizes, but notes that this aspect is not critical. The comment provides a logical reasoning for the suggestion of additional experiments and acknowledges the potential issue with batch size, but it does not offer specific examples or references to support the claim. This makes the comment 3, as it provides a basis for the suggestion but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for additional experiments on larger data sets, acknowledging the potential issue of compute resources. It also addresses a concern about maintaining probabilities at large batch sizes, noting that this aspect is not critical. The comment acknowledges the author\"s response to the initial concern and provides a nuanced perspective on the issue. However, it lacks specific guidance or actionable steps for the authors to address the concerns or suggestions, making it 3. The feedback is clear but incomplete, offering some direction without fully empowering the authors to make significant improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. This feedback is clear and actionable, as it directs the authors to compare their results with those of more recent models and to consider how their performance can be improved. The inclusion of specific references (GLaMM and UNINEXT) and their respective results provides concrete guidance on what the authors need to do to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT, and providing specific results from these models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of models (GLaMM and UNINEXT) that have achieved better results. The inclusion of references to these models and their respective results provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or explanations of why the current performance is considered \"behind\" recent models. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by comparing the performance of the paper on REC and RES with more recent models, such as GLaMM and UNINEXT. It highlights that the current performance is behind these recent models, offering a clear direction for the authors to improve their results. By referencing specific models and their achievements, the comment gives the authors concrete examples to consider for enhancing their draft. This level of detail and specificity makes the comment 5, as it empowers the authors to make targeted improvements. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a change in the wording of a statement regarding evidence, proposing a more nuanced expression. However, it does not provide explicit guidance on how to make this change or what specific wording would be more appropriate. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed without detailed instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a change in the wording from \"evidence\" to a more appropriate term, such as \"Fig.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong and proposes an alternative phrase, \"Fig.\" However, it does not provide any reasoning or justification for why \"evidence\" is too strong or how \"Fig.\" would be more appropriate. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests a change in the wording of a statement, specifically replacing \"evidence\" with a more appropriate term, such as \"Fig.\" This feedback is clear and actionable, as it provides a specific suggestion for improvement. However, it could be more helpful if it explained why the original term might be misleading or if it offered additional context or examples to support the proposed change. Overall, the comment is 4 as it guides the authors toward a more precise and accurate representation of their findings."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory. The comment identifies a specific aspect of the method, namely the use of CLIPseg and OTSU segmentation, as the only notable difference. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or enhance the novelty of their approach. The feedback lacks actionable details, leaving the authors uncertain about how to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning the reliance on framewise SDSA and the use of CLIPseg and OTSU segmentation. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these techniques are discussed. The comment is specific in detailing the limitations of the approach by comparing it to ConsiStory and highlighting the differences in methodology. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, specifically noting that it largely mirrors the approach used in ConsiStory. The comment provides a detailed comparison by highlighting the use of framewise SDSA and the differences in mask sources, such as the use of CLIPseg and OTSU segmentation instead of crossattention. This level of detail provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by referencing specific sections of the paper or providing more detailed comparisons to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory. It highlights the specific differences, such as the use of CLIPseg and OTSU segmentation, which are considered the only notable differences. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide actionable suggestions for enhancing the novelty or originality of the approach. The authors are left with a general understanding of the issue but without specific guidance on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method\"s weakness would be more apparent in images with multiple objects or cluttered scenes. It implies that comparing the approach to previous ones on a dataset with such images would be interesting. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but are not given concrete steps on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method\"s weakness would be more prominent in images with multiple objects or cluttered scenes and proposes a comparison with previous approaches on a fewshot classification dataset. However, it does not specify which part of the paper this suggestion is based on, making it weakly grounded. The comment is specific in suggesting a particular area for comparison, which could help the authors improve their work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method\"s weakness would be more apparent in images with multiple objects or cluttered scenes, and it proposes a comparison with previous approaches on a fewshot classification dataset. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of this suggestion and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method being discussed, suggesting that its effectiveness might be more pronounced in images with multiple objects or cluttered scenes. It proposes a comparison with previous approaches on a fewshot classification dataset, which could provide valuable insights into the method\"s strengths and weaknesses. This feedback is clear and actionable, as it directs the authors to consider a specific scenario that could enhance the understanding and evaluation of their method. However, the comment could be more helpful if it provided specific examples or references to previous works for comparison. Overall, the comment is 4, as it offers a constructive suggestion for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what aspects of the bounds need further explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in suggesting that additional explanation is needed, particularly in the appendix. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, particularly in the appendix. However, it does not provide any specific reasoning or evidence to support why this additional explanation is necessary or how it would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the space limitations in the paper but suggests that the authors could benefit from providing more explanation of the meaning of the bounds, possibly in the appendix. This feedback is 3 as it identifies an area where the paper could be improved by offering additional context or clarification. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the bounds need further explanation or how to present this information effectively. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. This provides a clear and direct action for the authors to take, which is to omit the detailed explanation. The comment is explicit and concrete, as it specifies exactly what action the authors should take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels using OpenAI\"s Triton instead of CUDA, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this implementation is discussed in, making it weakly grounded. The comment is specific in its suggestion to omit the detailed explanation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a fullpage explanation of the implementation of kernels with OpenAI\"s Triton instead of CUDA is unnecessary due to wellknown engineering improvements. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these improvements are wellknown or why a fullpage explanation is unnecessary. This lack of supporting evidence makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment points out that the implementation of kernels using OpenAI\"s Triton instead of CUDA does not require a fullpage explanation, as the engineering improvements are wellknown. This feedback is 3 as it highlights an area where the authors might be overexplaining a point that is already understood in the field. However, the comment could be more helpful if it provided specific guidance on how to condense the explanation or suggested alternative ways to present the information. The authors gain some insight into potential redundancy in their draft, but the feedback could be more actionable and detailed to be fully beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. The reviewer implies that the paper should clarify these points to avoid misleading the reader. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to make these clarifications. The action is implicit and somewhat vague, as the authors need to infer that they should address these points in the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks. However, the comment does not explicitly mention which part of the paper these examples are based on, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the transferability and the difficulty of tasks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support their claim. However, the comment lacks detailed reasoning or references to substantiate the claim fully. While the examples provide some insight, the lack of comprehensive justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiment and the transferability of the policy. It provides specific examples, such as the difference between \"walkerrun\" and \"walkerwalk,\" and the manipulation scenario with 3prong and 4prong tasks, to support the claim that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer suggests that the paper should clarify these points to avoid misleading the reader. This feedback is clear and actionable, as it identifies specific areas that need clarification and provides examples to guide the authors in improving their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed method, noting that it achieves only a 1% gain on a small backbone ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to their smaller receptive fields. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance on larger backbone models like SwinB or SwinL. The action is implicit and vague, as the authors are left to infer that they should investigate the performance on larger models but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvement consistency across different frameworks and tasks, specifically mentioning the relative gains and the use of global pooling in the proposed method. It also raises a concern about the performance on larger backbone models like SwinB or SwinL. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in detailing the issue with the relative gains and the potential impact of global pooling, but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed method are not very strong, particularly when compared to baselines on a small backbone ResNet50. The reviewer provides a specific observation that the proposed method achieves only a 1% gain, which is a factual statement. However, the claim is 3 because it lacks detailed analysis or references to support the assertion that the gains are not strong. The comment also raises a question about the performance on larger backbone models, which is a logical deduction but not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically noting that the improvement achieved by the proposed method is consistent across different frameworks and tasks but is not very strong. It highlights that the method can only achieve a 1% gain on a small backbone ResNet50, suggesting that the improvement might be easier to achieve on smaller models due to their smaller receptive fields. The comment also raises a question about the performance on larger backbone models like SwinB or SwinL, which could be an area for further investigation. While the comment points out a specific issue and raises a relevant question, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their work. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also claims that the work bypasses the core problem of overparametrized neural networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their analysis. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem and that the work bypasses the core problem of overparametrized neural networks. This provides clear guidance on what needs to be addressed in the analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also suggests that the work bypasses the core problem of overparametrized neural networks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the critique. The absence of concrete evidence or references to the NTK theorem or the core problem of overparametrized neural networks limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment critiques the analysis of neural networks, suggesting that it contributes less and that the extension from linear models to wide fullyconnected neural networks is trivial given the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks, only considering easy wide fullyconnected neural networks. While the comment identifies a potential weakness in the analysis, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. Without actionable feedback, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should consider adding more datasets or ensuring that all algorithms can be used on the existing ones, but it does not specify which datasets are problematic or how to resolve the issue. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not specify which datasets are problematic or how they impact the evaluation. The comment also mentions an addendum that provides additional context, but it does not explicitly mention which part of the paper this issue pertains to. The authors can make an educated guess that it relates to the sections discussing datasets and experiments, but the comment lacks full grounding. It is specific in identifying the issue with the datasets but not specific enough in terms of which datasets or experiments are affected. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The addition of an addendum that acknowledges the authors\" response and provides context does not address the initial claim. Without detailed justification or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for certain tasks might not be enough for a thorough evaluation. However, the comment does not provide specific guidance on how the authors might address this issue or suggest alternative datasets that could be used. Additionally, the comment acknowledges the authors\" response, which includes the provision of a repository and online platform for reproducing experiments, as well as the novelty of the datasets and motivations for their choice. While the comment highlights an important consideration, it lacks actionable feedback and depth, making it 3. The authors gain some insight into the need for more comprehensive evaluation but are not provided with detailed guidance on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This comment implies that the authors should include results for these larger models to provide a more comprehensive evaluation of their approach. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The suggestion is concrete in that it specifies which models should be included, but the authors need to infer the action themselves. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment highlights a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This suggests that the authors should include results for these larger models to provide a more comprehensive evaluation. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or table, making it weakly grounded. It is specific in identifying the need for additional results, but without clear grounding, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is good performance on imageNet classification with ResNet50/34/18 but lacks results for larger models like ResNet101/152. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a gap in the results section, noting that while there is good performance on imageNet classification with smaller models like ResNet50/34/18, there are no results provided for larger models like ResNet101/152. This feedback is 3 as it identifies an area where the authors could improve their evaluation by including results for larger models. However, the comment lacks specific suggestions on how to address this gap or what benefits might be gained from including these results. To be more helpful, the comment could provide guidance on why larger models are important or how they might impact the overall evaluation of the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This provides a clear and explicit action for the authors to explore a particular approach. The second part points out a potential inconsistency in the text, noting that \"relatively inexpensive\" is mentioned in the abstract, while \"expensive to evaluate\" is used in the introduction. This feedback is explicit and provides a clear action for the authors to clarify or reconcile these statements. However, the comment could be more actionable by suggesting how to reconcile these statements or providing guidance on how to improve the clarity of the text. Overall, the comment is 4, as it provides a clear direction for the authors to follow, but could be more detailed in its guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the multifidelity framework and sequential design for learning quantities (e.g., probabilities of threshold exceedance)\" and \"Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the text, noting the inconsistency between \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests that the authors consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This claim is 4 as it provides a specific reference to support the suggestion. However, the second part of the comment points out a potential inconsistency in the text regarding the cost of evaluation, but it does not provide detailed reasoning or examples to substantiate this claim. Overall, the comment is 4, as the first part is wellsupported, but the second part lacks detailed justification. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part suggests that the authors consider a multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper by Stroh et al. (2017). This is a valuable suggestion that could enhance the paper\"s methodology and provide a more comprehensive approach to the problem. The second part points out a potential inconsistency in the text, noting that \"relatively inexpensive\" is mentioned in the abstract, while \"expensive to evaluate\" is used in the introduction. This feedback is clear and actionable, guiding the authors to clarify or reconcile these statements. However, the comment could be more helpful if it provided specific suggestions on how to address the inconsistency or improve the clarity of the text. Overall, the comment is 4 as it offers valuable suggestions and identifies a specific area for improvement, but it could be more comprehensive in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit and vague, as the authors are left to infer what needs to be done without clear instructions on how to improve the draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment does not specify which part of the paper discusses the sparse reward problems or the experiments, making it weakly grounded. The comment is specific in its critique of the method\"s ability to address sparse reward problems, but without clear references to specific sections or experiments, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of the proposed method in addressing sparse reward problems, suggesting that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim. The lack of supporting evidence or detailed analysis makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a critical question about the effectiveness of the proposed method in addressing sparse reward problems. It points out that the experiments do not provide sufficient support for this claim and suggests that the method might not be significantly different from existing approaches like Qmix, which could solve sparsereward tasks with a dense reward signal. This feedback is 3 as it identifies a potential weakness in the paper and prompts the authors to consider how their method compares to existing solutions. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the experimental design. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, have access to this data during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide clarification but are not given specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset, specifically whether it is used for training and whether other methods like HMR and SPIN have access to it. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset\"s use and access by other methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the AH36M dataset in the training process and whether other methods, such as HMR and SPIN, have access to this data. The comment does not make a subjective claim or judgment but rather seeks clarification on a specific aspect of the methodology. It is a factual inquiry that requires no verification or justification, as it is a request for information rather than an opinion or suggestion. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the use of the curated AH36M dataset in the training process and whether other methods, such as HMR and SPIN, have access to this data. This is an important point for ensuring a fair comparison among methods. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the use of the dataset. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are left with a clear question to address but without detailed guidance on how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to improve the paper. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes in the proof of the main results,\" which suggests that it is addressing the section where the proof is presented. However, it does not specify which part of the proof is confusing or provide details on the mistakes. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but it does not specify which previous work or how the comparison should be conducted. The comment is weakly grounded as it does not explicitly mention the section, but it is specific in identifying the issues with the proof and the lack of comparison with previous work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence or detailed justification renders the claims 1, as the authors are left without a clear path to improve their work based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to take. Therefore, the comment is 3, as it points out weaknesses but does not provide detailed feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to clarify the motivation, improve the comparison, or address the model size issue. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, while the comment identifies specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several claims, including that the motivation for using an adversarial network is unclear and that the comparison of experimental results is unfair. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the assertion that the comparison is unfair or that the model size is a significant issue. Without additional context or justification, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to compare their final results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. This provides clear and concrete guidance on what action the authors should take to improve their draft. The comment also suggests comparing to specific approaches that have won the challenge, which adds a level of detail to the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"captioning experiment\" and the need to compare results on the official COOC leaderboard for the blind test set, providing a specific link. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely comparing results on the official leaderboard and referencing specific approaches that have been evaluated on this set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should compare its results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been proposed and evaluated on this set. The comment provides a logical reasoning by pointing out the importance of comparing results on the official leaderboard, especially since other approaches have been evaluated and improved upon. However, the comment could be strengthened by providing more specific examples or references to the approaches that have been evaluated on the blind test set. Overall, the claim is 4, as it provides a clear direction for improvement but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out that the paper only compares results on a nonofficial test set or dev set for the captioning experiment. It suggests that the authors should compare their results on the official COOC leaderboard for the blind test set, referencing a specific link and mentioning that other approaches have been evaluated and improved upon. This feedback is clear and constructive, offering a concrete path for the authors to enhance the validity and relevance of their results. By suggesting a comparison to specific approaches that have won the challenge, the comment provides a detailed and actionable suggestion for improvement. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to improve the reliability of the results or what specific changes should be made to the experimental setup or analysis. Without actionable advice or suggestions, the authors are left without a clear path forward to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, specifically the discrepancy between the MSE and MAE, which raises concerns about the validity of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically pointing out the discrepancy between the MSE and MAE in Table 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This feedback is clear and highlights a potential problem that the authors should address. However, the comment does not provide any suggestions or guidance on how to resolve this issue or improve the reliability of the results. While it points out a critical area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that there is not much novelty in the methodology and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their methodology. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that there is not much novelty in the methodology and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this claim is based on, such as a particular section or methodology description. Without explicit references or detailed explanations, the authors cannot confidently determine which aspects of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered extensions of existing methods or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is not much novelty in the methodology, stating that the proposed meta algorithm is a direct extension of existing methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific examples or details about which existing methods are being referenced or how the proposed algorithm could be improved to offer more novelty. Without actionable guidance or suggestions, the comment lacks depth and does not offer the authors a clear path for improvement. As a result, it is 2, as it highlights a potential issue but does not provide sufficient information for the authors to address it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of an adversarial loss to ensure that the perturbed data is similar to the authentic data. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details on what specific adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of the action needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the absence of an adversarial loss to ensure the perturbed data is similar to the authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that there is no adversarial loss to guarantee the perturbed data is similar to the authentic data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure that the perturbed data is similar to the authentic data. This is a clear and actionable feedback that highlights a potential weakness in the methodology or results. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific adversarial loss could be used. While it points out a critical area for improvement, it does not offer detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a need for clarification regarding the terms \"good,\" \"bad,\" and \"wrong\" explanations at line 248. It suggests that the authors should clarify these concepts before using them, which provides a direct and concrete action for the authors to take. The comment is explicit and specific, offering clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248\" and \"L255,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of needing clarification on the terms \"good,\" \"bad,\" and \"wrong\" explanations. The comment provides a clear direction for improvement by suggesting that the authors should clarify these concepts before using them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"wrong\" at line 248 and suggests that the paper should clarify the concepts of \"good,\" \"bad,\" and \"wrong\" explanations before using them. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by clarifying the meaning of \"wrong\" at line 248. It suggests that the authors should provide a clear explanation of what is meant by \"good,\" \"bad,\" and \"wrong\" explanations before using these terms. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and coherence of their draft. However, the comment could be more helpful if it offered additional suggestions on how to present this clarification or provided examples of how similar concepts have been addressed in other works. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the limited comparison of performance with few methods and notes that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of performance with few methods and the inconsistency of the proposed method being better than others. It suggests that analysis should be provided for inferior results that contradict the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing analysis for inferior results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistent performance. Without detailed evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it provides some justification but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s performance evaluation, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. It highlights the need for analysis of inferior results, as they contradict the motivation. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could impact its validity and credibility. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or which aspects to focus on. Overall, the comment is 4, as it effectively points out a key area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The comment implies that the authors should conduct additional experiments to demonstrate the superiority of their method over the baseline and Mid Vision Feedback. However, it does not provide explicit instructions on how to conduct these experiments or what specific comparisons should be made. While the action is implicit, it is concrete in suggesting the need for additional experimental comparisons. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely, a comparison with the image classification result of Mid Vision Feedback (MVF). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This claim is 3 as it provides a logical reasoning for the need of additional comparisons to prove the superiority of the schema searched by ELF over Mid Vision Feedback (MVF). However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of sufficient experimental demonstration of the contribution points. It highlights the absence of a comparison between the author\"s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it directs the authors to conduct additional experiments to demonstrate the superiority of their method over the baseline and Mid Vision Feedback. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use for comparison. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand on this topic, but it lacks concrete details on what specific aspects to cover or how to present them. As a result, the authors are left with a vague understanding of what needs to be done, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. The comment is specific in detailing what is missing, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it points out an area where the authors could provide more depth and analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending additional data or analysis to include. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". This is an explicit action that provides a clear direction for the authors to improve their draft by changing the notation. The comment is specific and concrete, as it directly instructs the authors on how to address the issue of confusion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in suggesting a change to avoid confusion, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the notation \"D\" is used for both dimensionality of points and dilation factor, which could lead to confusion. The reviewer recommends using different notation to avoid this confusion. However, the comment does not provide specific examples or references to support why this confusion is problematic or how it affects the understanding of the paper. The suggestion is logical but lacks detailed justification or evidence, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, where the notation \"D\" is used for both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or suggestions for alternative notations, which would give the authors a more detailed guide on how to address the issue. Despite this, the comment still offers valuable insight into improving the clarity of the paper, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions\" in the paper. It suggests that more elaboration is needed to clarify this concept. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address the issue or what specific details should be elaborated. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the concept of \"state\" but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the concept of \"state\" and asks for further elaboration on whether \"elements\" are equivalent to \"states\" or \"actions.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the concept of \"state\" is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It points out a specific line in the paper (186187) where the term \"elements\" is used, raising a question about whether it refers to \"states\" or \"actions.\" This feedback is 3 as it highlights an area where clarification is needed, prompting the authors to revisit and clarify their terminology. However, the comment could be more helpful if it provided additional guidance on how to address the confusion or suggested specific ways to improve the clarity of the concept. Overall, the comment provides a useful direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include this comparison in their analysis. However, the suggestion is concrete in terms of the specific metric (Jaccard index) to use, which provides some guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this suggestion should be applied to, such as a particular section or analysis. The authors can infer that it relates to the evaluation or results section, but this is not explicitly stated. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests an interesting comparison between the proposed scheme and baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any reasoning or evidence to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests an interesting comparison between the proposed scheme and baseline methods, specifically recommending the use of a Jaccard index. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the evaluation of the proposed solution. By incorporating this comparison, the authors can gain a deeper understanding of their method\"s performance relative to established approaches. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the suggestion is valuable and provides a concrete direction for improvement, making the comment 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should explain the reason behind the proposed module preventing the generator from collapsing, as this is a critical aspect of understanding how the proposed method differs from previous ones. The comment is clear in its request for additional explanation, providing a direct action for the authors to take. However, it does not specify how to present this explanation, leaving some room for interpretation. Overall, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the generator collapsing and requests an explanation for why the proposed module prevents this collapse. The comment provides a clear direction for improvement by suggesting that the authors should include an explanation of the mechanism behind the proposed method\"s effectiveness. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that explaining the reason behind this difference is essential for understanding the proposed method\"s advantages. However, the comment does not provide specific evidence, examples, or references to support the claim about the generator\"s collapse or the proposed module\"s effectiveness. This lack of detailed justification makes the claim 3, as the authors would need to conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the tendency of the generator to collapse when using a standard RGCN as a discriminator, while the proposed module does not. It highlights the importance of understanding the mechanism behind this difference, suggesting that this explanation is crucial for demonstrating the advantages of the proposed method over previous ones. The comment provides a clear direction for improvement by requesting that the authors include an explanation of the proposed module\"s effectiveness in preventing generator collapse. This feedback is actionable and constructive, offering the authors a specific area to focus on for enhancing their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or differentiate their work from the previous study. The comment implies that the authors should consider whether their work is an extension or introduces novel contributions, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not provide actionable feedback, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the article, suggesting similarities with another study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" However, it does not specify which parts of the article are similar or how they relate to the previous study. The authors may infer that the comment pertains to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity regarding what aspects need to be addressed or how the authors should differentiate their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. However, it does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the basis of the concern. The comment lacks concrete evidence or references to the other study, which would be necessary to fully substantiate the claim. As a result, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment raises a concern about the originality of the article, suggesting that its reasoning and writing logic bear similarities to another study. This is a valid point that could prompt the authors to reflect on whether their work introduces novel contributions or is merely an extension of existing research. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from the previous study. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what specific aspects need to be clarified or how the authors might improve the theoretical comparisons. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it lacks details on what needs to be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Theoretical comparisons to adaptive learning of GPRGNN is not clear.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the comparisons are unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN, indicating that they are not clear. However, it does not provide any further guidance or suggestions on how the authors might clarify or improve these comparisons. Without actionable advice or specific examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of using only yes/no responses to measure object hallucination. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what alternative methods could be used to measure object hallucination. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of using yes/no responses to measure object hallucination, specifically noting that a yes response does not necessarily indicate comprehension of the object\"s presence. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in detailing the concern about the measurement method, but without explicit references to specific parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using yes/no responses to measure object hallucination, suggesting that a yes response does not necessarily indicate comprehension of the object\"s presence. The comment provides a logical reasoning by explaining that a yes response could still be associated with incorrect objects in other tasks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this critique and potentially provide additional evidence or clarification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of using yes/no responses to measure object hallucination. It points out that a yes response does not necessarily indicate that the model comprehends the presence of the object, as it may still produce incorrect objects in other tasks. This feedback is 3 as it highlights a potential limitation in the current methodology and prompts the authors to consider alternative or more comprehensive measures for evaluating object hallucination. However, the comment could be more helpful if it provided suggestions or examples of how to address this issue or improve the measurement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the verylongterm forecasting task has limited practical significance and recommends improvements to the discussion. It explicitly suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the verylongterm forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the discussion section is being addressed, so the authors might need to infer the exact location. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task has limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment does not provide any supporting evidence or reasoning to justify why the task is of limited practical significance or how these suggestions would improve the discussion. Without specific examples or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task and suggests improvements to the discussion. It provides specific and actionable feedback by recommending experiments on more datasets and training baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is clear and constructive, offering the authors a clear path to enhance the relevance and impact of their work. However, the comment could be more helpful if it elaborated on why the task is of limited practical significance or how the suggested improvements would address this issue. Overall, the comment is 4 as it provides actionable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should conduct experiments and provide explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also suggests exploring scenarios where only spatial or temporal and summary queries are used. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what experiments and explanations are needed to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. The comment further suggests exploring scenarios where only spatial or temporal and summary queries are used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. It implies that this is a key difference from other works like VideoChatGPT. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these queries and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of experiments and explanations regarding the different queries used in spatiotemporal representation. It highlights the importance of exploring these queries, such as spatial, temporal, and summary, as a key difference from other works like VideoChatGPT. The comment provides a clear and actionable suggestion by asking the authors to consider scenarios where only spatial or temporal and summary queries are used. This feedback is valuable as it directs the authors to conduct additional experiments and provide a more comprehensive analysis of their approach, which could enhance the paper\"s depth and relevance. However, the comment could be more helpful if it offered specific guidance on how to design these experiments or what aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, it does not provide explicit guidance on what specific details should be included or how the authors should present the innovative aspects. The action is implicit and somewhat vague, as the authors can infer that they need to elaborate on the innovative parts but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a specific part of the paper. However, it does not specify which part of the paper discusses the FRM, making it weakly grounded. The comment suggests that the innovative aspects should be detailed, but it does not provide specific guidance on what aspects need more detail or how they should be elaborated. This lack of specificity makes it difficult for the authors to understand what changes are needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is not verifiable, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspects should be detailed. While this feedback identifies a potential area for improvement by highlighting the need for more detailed explanation of the innovative aspects, it lacks specific guidance or suggestions on how the authors might elaborate on these aspects. The comment provides a general direction for improvement but does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could mention the potential social impacts of their work, specifically the risks associated with increased automation and the dual use of their method. While the comment implies that the authors should address this aspect, it does not provide explicit guidance on how to do so or what specific points should be included. The action is implicit and somewhat vague, as the authors need to infer that they should discuss potential social impacts and determine how to address them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the authors\" statement about foreseeing no negative social impacts and suggests that they could discuss the potential risks associated with increased automation and the dual use of their method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" assertion that their work has no negative social impacts, suggesting that the authors could discuss potential risks associated with increased automation and the dual use of their method. However, the comment does not provide specific examples or references to support the claim that these risks are significant or relevant. The reasoning is somewhat vague, making it difficult for the authors to fully understand the basis of the concern. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment addresses the societal impact of the work, specifically the authors\" assertion that they foresee no negative social impacts. The reviewer questions this claim and suggests that the authors could discuss potential risks associated with increased automation and the dual use of their method. While the comment identifies a relevant area for consideration, it lacks specific guidance or examples on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider broader implications, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a potential rearrangement of sections 3 and 4 to reduce redundancy. It explicitly proposes moving the first paragraph of section 4 to section 3 and placing the remainder of section 4 before section 3. This provides a clear and concrete action for the authors to take, allowing them to make a specific change to their draft. The suggestion is direct and provides a clear path for improvement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides a specific suggestion for rearranging the content to reduce redundancy, which is clear and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that sections 3 and 4 are slightly redundant and proposes a rearrangement to improve clarity. However, it does not provide any specific examples or detailed reasoning to support why the sections are redundant or how the suggested rearrangement would improve the paper. Without additional context or evidence, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with redundancy between sections 3 and 4, suggesting a rearrangement to improve clarity. It provides a specific and actionable suggestion by proposing the movement of the first paragraph of section 4 to section 3 and placing the remainder of section 4 before section 3. This feedback is clear and offers a concrete way for the authors to enhance the organization and coherence of their draft. However, the comment could be more helpful if it further explained why the current arrangement is redundant or how the suggested rearrangement would improve the paper. Overall, the comment is 4 as it provides a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not provide specific guidance or suggestions on how the authors might improve this clarity or address the issue. The comment implies that the authors should clarify the relationship between these concepts, but it does not offer concrete steps or details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment provides some specificity by mentioning the lack of clarity, but without grounding, the authors cannot determine where to address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there is a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that this issue is due to poor clarity, which is a valid observation. However, the comment does not provide specific guidance or suggestions on how the authors might improve this clarity or address the issue. Without actionable feedback or detailed recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors. While the comment implies that the authors should conduct these analyses, it does not provide specific guidance on how to approach these analyses or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include theoretical analyses or extensive experiments to understand why certain methods outperform others. It implies that the authors should investigate the reasons behind the performance of simple greedy selection and deterministic MLP predictors compared to more principled acquisition functions and robust probabilistic predictors. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should explore theoretical analyses or extensive experiments to understand why certain methods outperform others. It implies that the current empirical results are strong but lacks a deeper understanding of the underlying reasons. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the simple greedy selection approach outperforms more principled acquisition functions or that deterministic MLP predictors outperform probabilistic predictors. This lack of detailed justification makes the claim 3, as the authors would need to conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that despite the strong empirical results of the proposed method, a more novel and interesting contribution could be made by exploring theoretical analyses or extensive experiments to understand why certain approaches outperform others. It highlights the lack of rigorous analyses in the paper, specifically mentioning the comparison between simple greedy selection and more principled acquisition functions, as well as the performance of deterministic MLP predictors versus probabilistic predictors. This feedback is clear and actionable, as it directs the authors to conduct additional research to enhance the understanding and novelty of their work. However, it could be more helpful if it provided specific guidance on how to conduct these analyses or what aspects to focus on. Overall, the comment is 4, as it offers a valuable direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the discussion of the \"kmax problem\" elsewhere. This request is clear and direct, providing the authors with a specific action to take: to provide a citation. The action is concrete, as it specifies exactly what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment asks for a citation regarding the discussion of the \"kmax problem\" elsewhere, implying that the authors should provide evidence or references to support this claim. However, it does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a citation but lacks grounding, as it does not identify the specific part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the absence of a citation for the \"kmax problem\" and requests a citation for its discussion elsewhere. This is a factual request for clarification or evidence, rather than a claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment requests a citation for the discussion of the \"kmax problem\" elsewhere, indicating that the authors should provide evidence or references to support their claims. While this feedback is clear and actionable, it does not offer any additional insights or suggestions for improvement beyond the request for a citation. The comment is specific in its request but lacks depth and does not provide broader guidance on how to enhance the paper. Therefore, it is 3, as it directs the authors to a specific area for improvement but does not fully address their needs for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or details on what specific information should be included or how the authors should estimate the reliability of the model. As a result, the authors are left with an implicit action that is vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking information on how the function for the optimal sequence length was estimated and questions the reliability of the model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and questions the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the concern or how to address it. As a result, the claim is considered 1, as it does not provide sufficient justification or evidence to support the critique.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and questions the reliability of the model. This feedback is important as it highlights a critical aspect of the methodology that needs clarification. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as recommending specific methods for estimating the optimal sequence length or discussing potential sources of error in the model. Despite this, the comment is 3 as it directs the authors\" attention to a crucial area that requires further explanation and justification. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the applicability of the methods to realworld problems due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to modify the assumptions, improve the applicability, or provide evidence to support the claims. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the limitations due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the applicability. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the issue with the assumptions but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods to realworld problems is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods to realworld problems due to strong assumptions about the availability of camera parameters and object segmentation. This is a relevant observation that could help the authors improve their work by considering how to relax these assumptions or provide evidence for their applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or experiments that could demonstrate the methods\" applicability in more realistic scenarios. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"thousands\" is not accurate in the context of L006 and recommends adding \"on the subword level\" to improve clarity. This feedback is explicit, as it directly instructs the authors to make a specific change to their draft. The suggestion is also concrete, as it provides a clear and actionable step for the authors to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that \"thousands\" is not accurate and suggests adding \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the term \"thousands\" is not accurate in the context of L006 and recommends adding \"on the subword level.\" However, the comment does not provide any reasoning or evidence to support why \"thousands\" is inaccurate or how \"on the subword level\" would improve the clarity. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"thousands\" in L006, suggesting that it may not be accurate and recommending the addition of \"on the subword level\" to improve clarity. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the addition of \"on the subword level\" would enhance the draft. Despite this, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues that need to be addressed. First, it points out that a number of hyperparameters, such as regularization, are not provided. This is an explicit action for the authors to include these missing hyperparameters in their draft. Second, the comment questions the yvalue at x=0 in the latent path figures, suggesting that it might be normalized to zero. This is an implicit action for the authors to clarify this point in their description. Finally, the reviewer suggests conducting further analysis using the interpolations themselves, which is an explicit action with concrete guidance on how to enhance the paper. Overall, the comment provides clear and actionable feedback, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"all the latent path figures (eg Fig 3)\" and \"the y value at x= 0,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the normalization of the yvalue at x=0 and suggests further analysis using interpolations. The comment provides clear guidance on what needs to be clarified or improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the absence of hyperparameters and the behavior of the yvalue at x=0 in the latent path figures. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the feedback, rendering the claims 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas that need clarification or improvement in the paper. It points out the absence of hyperparameters, such as regularization, which is an important detail for reproducibility. Additionally, it questions the behavior of the yvalue at x=0 in the latent path figures, suggesting that it might be normalized to zero, and requests clarification on this point. The comment also suggests conducting further analysis using the interpolations themselves, which could enhance the paper\"s depth and insights. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions on how to address the issues or offered examples of how to conduct the additional analysis. Overall, the comment is 4, as it directs the authors to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues: forward referencing in the paper and the need for clearer explanation of contributions in the introduction. It suggests that the material supporting the main contributions should be included in the main sections rather than the appendix. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to reorganize the content and provide clearer explanations, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as forward referencing and the need for clearer explanations of contributions, particularly in the introduction. Additionally, it points out that material supporting the main contributions is in the appendix rather than the main sections, providing specific examples like \"deeprag algorithm\" or \"discussion on the high concurrency.\" This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in subsequent sections. It also suggests that the main contributions need to be written more clearly in the introduction and that material supporting these contributions is in the appendix rather than the main sections. While the comment identifies specific issues, it lacks detailed examples or references to support these claims. The reasoning is somewhat logical, but the lack of specific examples or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: forward referencing and the need for clearer explanations of contributions in the introduction. It points out that material is introduced without proper explanation and is later explained in subsequent sections, such as Figure 1. The comment also notes that the main contributions are not clearly written in the introduction and that supporting material is relegated to the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper by ensuring that all necessary information is introduced and explained in the appropriate sections. However, the comment could be more helpful if it offered suggestions on how to reorganize the content or provide clearer explanations. Overall, the comment is 4, as it effectively directs the authors to address significant weaknesses in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore or discuss the theoretical impact of rounding on the full tensor error. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"the paper,\" where the issue is discussed. It also specifies the issue, which is the lack of clarity regarding the effect of rounding core tensors on the full tensor error and whether there is an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. The comment does not make a claim or provide an opinion but rather seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical effect of rounding core tensors on the full tensor error. It questions whether there is an error bound in terms of epsilon, which is a critical aspect of understanding the approximation. This feedback is clear and actionable, as it prompts the authors to clarify or discuss the theoretical implications of their method. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested potential approaches for establishing error bounds. Overall, the comment is 4 as it directs the authors to a significant area of improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the results presented in Table 1, specifically noting that it only includes results from the discriminative setting, whereas there are two test settings in visual dialog. The reviewer questions the absence of results for the generative setting, which is known to be more applicable in realworld applications. This comment implies that the authors should include results for the generative setting to provide a more comprehensive understanding of their work. While the action is implicit, it is concrete in suggesting that the authors should include results for the generative setting. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of results for the generative setting, which is known to be more applicable in realworld applications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of results for the generative setting in Table 1, noting that the discriminative setting is not applicable in realworld applications. This claim is 3 as it provides a logical reasoning about the relevance of the generative setting in realworld applications. However, the comment lacks specific examples or references to support the claim that the discriminative setting is not applicable, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the results presented in the paper, noting that Table 1 only includes results from the discriminative setting, while there are two test settings in visual dialog. It questions the absence of results for the generative setting, which is known to be more applicable in realworld applications. This feedback is clear and actionable, as it prompts the authors to include results for the generative setting to provide a more comprehensive understanding of their work. However, the comment could be more helpful if it suggested specific ways to present or analyze the generative setting results. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify what additional information or examples should be included to achieve this. The action is implicit and vague, as the authors are left to infer what specific steps or details are needed to address the concern. Without concrete guidance, the authors may struggle to determine how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to provide more convincing evidence, but without a clear reference to the section or part of the paper where this evidence should be included, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more convincing evidence that a query of the type \"SEARCH\" is feasible in a realistic scenario. This feedback identifies a potential weakness in the paper, specifically the need for more convincing evidence to support the feasibility of the query. However, the comment lacks specificity and does not provide detailed guidance on what additional evidence or examples should be included. While it points out an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, indicating that this aspect remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider to evaluate the approach\"s effectiveness across different language families. Without any actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the discussion or results sections, but without explicit grounding, it is challenging to pinpoint the exact part of the paper being addressed. The comment is specific in identifying the issue of unknown effectiveness across language families, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, suggesting that this aspect remains unknown. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant gap in the paper, noting that the effectiveness of the proposed approach for other language families remains unknown. This is a critical observation that could impact the generalizability and applicability of the work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore the effectiveness across different language families. Without actionable advice or examples, the feedback provides a general direction for improvement but does not fully support the authors in making specific changes to their draft. Therefore, the comment is 3, as it identifies an important area for consideration but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have not analyzed the security (or protection of privacy) of the proposed framework. This is a clear and direct action for the authors to take, as it identifies a specific aspect of the paper that needs further examination. However, the comment does not provide guidance on how to conduct this analysis or what specific aspects of security should be considered. While the action is explicit, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment points out that the authors have not analyzed the security or protection of privacy of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. Without explicit references or clear indications of where this analysis is lacking, the authors may find it challenging to identify the exact areas needing attention. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is not specific because it does not provide detailed guidance on what aspects of security or privacy should be analyzed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security or protection of privacy of the proposed framework. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security and privacy aspects of the proposed framework. This is a critical area that authors should address to ensure the robustness and trustworthiness of their work. However, the comment does not provide specific guidance or suggestions on how the authors might conduct this analysis or what aspects of security and privacy should be considered. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it directs the authors to a critical area but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. This provides a clear and direct action for the authors to take, ensuring that the form of \"p\" is clarified in the draft. The comment is specific and concrete, offering a precise instruction on how to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of the form of \"p.\" The comment provides a clear and actionable suggestion for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the form of \"p\" should be described near line 135, as it is currently not explicitly stated. The reviewer assumes it is a Gaussian distribution but notes that it is not explicitly stated. This comment is a request for clarification and does not contain a subjective claim or opinion that requires verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the form of \"p\" is not explicitly described near line 135, which could lead to confusion. By suggesting that the form of \"p\" should be described, the comment offers a clear direction for the authors to enhance the readability and understanding of their work. However, the comment could be more helpful if it provided additional context or examples of how the form of \"p\" should be described. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about enhancing the clarity. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but are not provided with concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, it does not specify which part of the paper this relates to, such as a particular section or table, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the related work section by describing the differences between the works mentioned. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the mentioned works. However, it does not specify which works are named or what specific differences are lacking, making it difficult for the authors to understand the exact issue or how to address it. This lack of detail and specificity renders the claim 2, as it provides some direction but lacks sufficient evidence or examples to fully support the suggestion for improvement.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the related work section. It points out that some related works are mentioned but not described in sufficient detail, particularly regarding their differences. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their related work discussion. However, the comment could be more helpful if it provided specific examples of works that need more detailed descriptions or suggestions on how to present these differences effectively. Overall, the comment is 4 as it guides the authors toward improving the quality of their related work section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, but the article does not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at the PPP maps. This feedback is explicit, as it clearly instructs the authors to provide a specific explanation. However, it is somewhat vague because it does not specify how the authors should present this explanation or what aspects of the PPP maps should be discussed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It questions the lack of explicit explanation or understanding provided in the article regarding what type of insight is gained from looking at PPP maps. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections discussing PPP metrics and their effects. The comment is specific in its request for an explicit explanation of the understanding gained from PPP maps. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks, noting that the article does not provide an explicit explanation or understanding of this concept. The reviewer asks for clarification on what type of understanding is gained by looking at PPP maps. While the comment raises a valid point about the lack of explanation, it does not provide specific examples or detailed reasoning to support the claim. The authors are left to infer the need for clarification, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of how reliable PPP metrics contribute to understanding PPP effects in different tasks. It points out that while the importance of these metrics is mentioned, the article lacks an explicit explanation or understanding of what insights are gained from looking at PPP maps. This feedback is 3 as it highlights an area where the authors could provide more clarity and depth to their discussion. However, it does not offer specific suggestions or guidance on how to address this gap, leaving the authors with a general direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with stateoftheart methods like SpanBERT for spanrelated tasks, which affects the credibility of the paper. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific methods to compare or how to incorporate these comparisons into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of comparison with stateoftheart methods like SpanBERT for spanrelated tasks, which affects the credibility of the paper. However, it does not specify which part of the paper this issue is addressed in, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in identifying the issue of lacking credibility due to the absence of comparisons, but it lacks grounding as it does not specify where in the paper this comparison should be made. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with stateoftheart methods like SpanBERT for spanrelated tasks. However, the comment does not provide specific examples of these stateoftheart methods or detailed reasoning on why such comparisons are necessary. This lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these comparisons and potentially conduct additional research to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of comparisons with stateoftheart methods like SpanBERT for spanrelated tasks. This is a critical oversight that affects the credibility of the paper. However, the comment does not provide specific suggestions on which stateoftheart methods should be compared or how to incorporate these comparisons into the paper. While it highlights an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a key issue but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the results, specifically regarding the sublinearity of regret. It does not provide any explicit or implicit actions for the authors to take, nor does it suggest any changes or improvements to the draft. The comment is purely a clarification question, leaving the authors without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the interpretation of the results regarding the sublinearity of regret, prompting the authors to clarify their statement. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the interpretation of the results regarding sublinearity of regret. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of the results regarding sublinearity of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. While it identifies a potential misunderstanding or ambiguity in the paper, it does not provide any suggestions or guidance on how to address this issue or clarify the results. The comment is 3 as it prompts the authors to reconsider their interpretation, but it lacks actionable feedback or detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which should be redrawn to better represent the forward prediction model. The comment also mentions that it was difficult to connect the text with the figure and equations. This feedback provides a clear and direct action for the authors to take: redraw Figure 2(b) to improve the clarity of the forwardprediction model representation. The action is explicit and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of clarity in the forwardprediction model, and suggests that the figure should be redrawn to better represent the model. Additionally, it points out the difficulty in connecting the text with the figure and equations. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, specifically mentioning Figure 2(b) as an example. The reviewer suggests that the figure should be redrawn to better represent the model. While the comment identifies a potential issue with the clarity of the model\"s representation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to redraw the figure is a logical step, but without additional context or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, particularly in Figure 2(b), which is described as not providing a schematic representation of the model. The reviewer suggests that the figure should be redrawn to better align with the text and equations. This feedback is clear and actionable, as it provides a direct suggestion for improvement that can enhance the comprehensibility of the paper. However, the comment could be more helpful if it offered additional guidance on how to improve the explanation or provided examples of what a better representation might look like. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their training process. The suggestion to provide a stronger baseline is implicit and lacks concrete details on how to implement it. Therefore, the comment is 3, as it identifies a potential issue but does not provide clear instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of ignoring rewardless actions that could provide useful supervision and suggests that this could be a significant factor in the better performance of FP + RBI compared to RBI alone. The comment further suggests that the authors should provide a stronger baseline to prove the usefulness of FP. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer provides a specific example from Task 3, \"No, the answer is Timothy Dalton,\" which is a rewardless action that could offer valuable feedback. The comment logically infers that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the claim lacks specific references or detailed analysis to fully substantiate the reasoning. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. This is a valuable observation that could help the authors improve their understanding of their model\"s performance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to incorporate rewardless actions into the training process. Additionally, the suggestion to provide a stronger baseline is vague and lacks detail. Overall, the comment is 3 as it points out a potential weakness but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the multiscale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. It implies that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the statement. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the multiscale statement and its benefits. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"multiscale statement\" in the paper, which implies that it is referring to a specific part of the paper where this statement is made. However, it does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in detailing the issue with the statement, explaining that the slow and fast RNNs operate on a logical time scale rather than a physical one, and suggesting that the only benefit is the reduction of the gradient path. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical explanation for this claim, suggesting that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reviewer\"s reasoning and potentially provide additional context or evidence to fully address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement in the paper, suggesting that it might be misleading. It clarifies that the slow and fast RNNs operate on a logical time scale rather than a physical one, which could impact the interpretation of the multiscale statement. The comment also points out that the only benefit of the slow RNN might be the reduction of the gradient path. While the comment highlights a specific area for clarification, it does not provide detailed guidance on how to address the issue or suggest specific changes to improve the draft. The feedback is 3 as it directs the authors to reconsider their explanation of the multiscale statement, but it lacks actionable steps or further elaboration. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the weakness of the baseline methods and the lack of discussion on limitations. It also suggests that the authors should discuss the similarity and difference between their work and reinforcement learning, as well as the generalizability of the results to RL settings. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to strengthen their baseline methods, discuss limitations, and explore the generalizability of their results, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the baseline methods, stating they are weak and not stateoftheart, and notes the absence of a discussion on limitations. It also suggests discussing the similarity and difference between the work and reinforcement learning in the conclusion, along with the generalizability of the results to RL settings. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion or conclusion sections, providing some level of grounding. However, the comment lacks specificity regarding which baseline methods are weak or how the discussion on limitations should be conducted. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and it suggests that the paper lacks a discussion on limitations. It also questions the difference between the work and reinforcement learning, suggesting a discussion on similarity and difference in the conclusion. However, the comment does not provide specific examples or references to support the claim about the baseline methods being weak or outdated. Additionally, it lacks detailed reasoning or evidence to substantiate the suggestion for discussing limitations and the comparison with reinforcement learning. This makes the claim 3, as it provides a general direction for improvement but lacks concrete evidence or detailed justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not stateoftheart, which is a critical issue that needs to be addressed. Additionally, it notes the absence of a discussion on limitations, which is essential for providing a comprehensive understanding of the work. The comment also suggests that the authors should discuss the similarity and difference between their work and reinforcement learning, as well as the generalizability of the results to RL settings. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft. However, the comment could be more helpful if it offered examples or specific suggestions on how to strengthen the baseline methods or discuss limitations. Overall, the comment is 4, as it effectively guides the authors toward improving their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a distinction in the formulation of the paper regarding the decision maker\"s interest in the true objective function versus the stochastic noisy function. It suggests that the authors should make this distinction clearer upfront. While the comment implies that the authors should clarify this point, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed to improve the clarity of the distinction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper\"s formulation regarding the decision maker\"s interest in the true objective function versus the stochastic noisy function. It suggests that the authors should make this distinction clearer upfront. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the formulation or methodology section. The comment is specific in detailing what needs to be clarified, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function, and the noise is assumed to be misleading. It contrasts this with the formulation in the paper, where the decision maker is interested in the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current formulation is misleading. This makes the claim 3, as it requires further elaboration to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential misunderstanding in the paper\"s formulation regarding the decision maker\"s interest in the true objective function versus the stochastic noisy function. It suggests that the authors should clarify this distinction upfront, which is a valuable observation that could improve the clarity and accuracy of the paper. However, the comment could be more helpful if it provided specific suggestions on how to make this distinction clearer, such as proposing alternative formulations or examples. Despite this, the feedback is 4 as it directs the authors\" attention to an important aspect of their work that needs clarification. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two distinct actions. First, it asks if running VGAE with a vamp prior could help match the doubly stochastic construction in the work, which would inform whether the benefits are due to a better generative model or better inference. This is an explicit suggestion with a clear direction for the authors to explore. Second, it recommends keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This is also an explicit suggestion with concrete guidance on how to conduct the comparison. Both suggestions are clear and actionable, providing the authors with specific steps to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improving the figure, such as keeping the generative model fixed and optimizing only the inference part of the model. This level of detail helps the authors understand what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help determine if the benefits are due to a better generative model or better inference. This is a logical suggestion based on the context of the paper, but it lacks specific references or detailed reasoning to fully substantiate the claim. The minor point about Figure 3 suggests a comparison of representations by keeping the generative model fixed, which is a reasonable suggestion but also lacks detailed justification or examples. Therefore, the comment is 3, as it provides a logical basis for the suggestion but requires more detailed evidence or references to be fully substantiated.", "helpfulness_rationale": "The review comment provides two distinct suggestions for improving the draft. First, it questions whether running VGAE with a vamp prior could help match the doubly stochastic construction in the work, which would inform whether the benefits are due to a better generative model or better inference. This is a thoughtful suggestion that could lead to a deeper understanding of the paper\"s contributions. Second, it recommends keeping the generative model fixed and optimizing only the inference part of the model, parameterizing it as either SIGVAE or VGAE to compare representations. This suggestion is clear and actionable, offering a specific way to enhance the analysis and comparison of the models. By addressing these points, the authors can gain valuable insights and improve the comprehensiveness of their work. Therefore, the comment is 4, as it provides actionable feedback that can significantly enhance the draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the method, suggesting that it is somewhat incremental. The comment highlights that the main contribution is a new network design inspired by prior work for sound source localization. However, it does not provide explicit guidance or suggestions on how the authors might enhance the novelty or contribution of their work. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to the performance of the method, specifically mentioning \"Table 2,\" which provides some grounding as it indicates the part of the paper being addressed. However, it does not specify what aspects of the performance are being evaluated or how the novelty/contribution could be improved. The comment lacks specificity regarding what needs to be addressed or how the authors might enhance the novelty of their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the novelty/contribution of the method is somewhat incremental, suggesting that the main contribution is a new network design drawing inspiration from prior work for sound source localization. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, particularly in Table 2, but questions the novelty and contribution of the work. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty of the contribution, it lacks specific guidance or suggestions on how the authors might enhance the novelty or address the incremental nature of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the balance between longrange dependencies and locality, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for a discussion about the importance of learning longrange dependencies versus the role of locality in the graph structure, particularly in relation to image size. The comment provides a clear direction for the authors to consider the balance between these factors and how it affects prediction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the necessity of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The reviewer acknowledges that the paper demonstrates this importance but suggests that the discussion could be more nuanced. The comment implies that the authors should consider the role of locality in the graph structure and its impact on prediction, especially in relation to image size. However, the claim is not fully supported by specific examples, references, or detailed reasoning, making it 3. The authors would need to provide additional evidence or clarification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s discussion on the importance of learning longrange dependencies for powerful predictors. It acknowledges that the paper demonstrates this importance in the context of semantic segmentation but suggests that the discussion could be more nuanced. The reviewer points out a specific concern about the role of locality in the graph structure and its impact on prediction, particularly in relation to image size. This feedback is 3 as it prompts the authors to consider a more balanced discussion of the tradeoffs between longrange dependencies and locality. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the definition of $e_l$ in Eq. (3) and points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also mentions that the performance is getting worse than standard random features, as shown in Figure 1, which may indicate a weakness in the proposed approaches. While the comment identifies areas that need clarification or further investigation, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of $e_l$ and investigate the implications of the exponential dependence on $M$, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3),\" \"Corollaries 1, 2, and 3,\" and \"Theorem 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific details about the issue, such as the exponential dependence on the diameter $M$ of the domain of data and the impact on the required feature size. Additionally, it references Figure 1 to support the claim about the performance. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for clarification of $e_l$ in Eq. (3) and the observation that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also suggests that this dependence affects the constant factor of the required feature size and references Figure 1 to support the claim that the performance is worse than standard random features. While the comment provides some logical reasoning and references a figure, it lacks specific examples or detailed explanations to fully substantiate the claims. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment raises several points that are relevant to the authors\" work. It questions the definition of $e_l$ in Eq. (3), which is a specific and actionable request for clarification. Additionally, it points out that Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data, which could impact the required feature size. The comment also references Figure 1 to illustrate that the performance is worse than standard random features, suggesting a potential weakness in the proposed approaches. While the comment identifies important areas for clarification and improvement, it could be more helpful by providing specific suggestions on how to address these issues or by offering alternative approaches to mitigate the exponential dependence on $M$. Overall, the comment is 4 as it directs the authors\" attention to critical aspects of their work that require further examination and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues in their draft. While it points out areas for consideration, it lacks actionable steps or concrete recommendations for improvement. As a result, the authors are left with a general understanding of the potential problems but without clear direction on how to address them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential issues. It also suggests that oversmoothing could be another factor, referencing a specific paper for further context. However, the comment does not specify which part of the paper discusses DGNs or their modeling abilities, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issues with DGNs, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the poor longrange modeling ability of DGNs could be due to oversquashing and vanishing/exploding gradients, and also mentions oversmoothing as another potential factor. The claim is supported by a reference to a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a basis for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples of how oversmoothing affects DGNs. Overall, the claim is 4 due to the reference, but it could be more robust with additional supporting evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. This feedback is 3 as it points out a specific area for improvement and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on how to incorporate the referenced paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific line (159) where the authors mentioned gradients becoming 0 and collapsing, and asks if this is a commonly encountered issue or observed in experiments. While the comment implies that the authors should provide more information or results on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of model collapse and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the model collapsing and whether it is a commonly encountered issue, and whether it was observed in experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification and additional information regarding the model collapsing issue. It does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, seeking more details about the model\"s behavior. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the demonstration or results related to the model collapsing less than other methods. It references a specific line in the paper where the authors mention gradients becoming 0 and collapsing, and asks if this is a commonly encountered issue or observed in experiments. This feedback is 3 as it prompts the authors to provide more information or results on this topic, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of similar studies that have encountered similar problems. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not provide specific guidance or suggestions on how to clarify the formulation. The authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. Without explicit instructions or concrete examples, the authors cannot effectively address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not specify which specific examples or sections of the paper are problematic, making it difficult for the authors to pinpoint the exact areas that need clarification. The comment lacks grounding as it does not identify a particular part of the paper, and it is also not specific about what aspects of the formulation are unclear. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in both the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 2, as it points out a problem but does not offer any direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides specific models to consider, giving the authors a concrete action to take. The suggestion is direct and actionable, allowing the authors to know exactly what experiments to conduct to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion should be implemented in, making it weakly grounded. The comment is specific in suggesting the types of experiments that could be conducted, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. The claim is based on the assumption that conducting such experiments would provide valuable insights into the method\"s applicability and generalizability. However, the comment does not provide specific examples or references to support why these experiments are necessary or how they would enhance the paper. The reasoning is somewhat logical but lacks detailed justification or evidence, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s applicability and generalizability. By conducting these experiments, the authors can gain valuable insights into the method\"s performance across various LLM families. However, the comment could be more helpful if it offered additional guidance on how to design or interpret these experiments. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or whether it is a problem that needs to be resolved. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment lacks specificity as it does not provide details on why this limitation is a concern or how it could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation of the method, suggesting that it only works for generative models that can be finetuned as in/outpainting models. However, it does not provide any further context, examples, or suggestions on how this limitation could be addressed or whether it is a significant issue. The comment lacks depth and actionable guidance, leaving the authors without a clear understanding of how to improve their work based on this feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer suggests that the connection between these two parts is weak and that their initial expectation of the approach was not met. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen the connection between these parts or clarify their approach. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the connection between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it weakly grounded. The comment is specific in detailing the reviewer\"s initial expectation and how it was not met, providing some guidance on what might be missing or unclear. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE parts of the paper are weak. The reviewer provides a personal interpretation of what they expected the first part to be about, which differs from the actual content. However, the comment lacks specific evidence or detailed reasoning to support the claim that the connections are weak. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer shares their initial expectation of the approach, which was not met, and notes that the connection between these parts is weak. However, the comment does not provide specific suggestions or guidance on how the authors could strengthen this connection or clarify their approach. While it highlights an area for improvement, the feedback lacks actionable details, making it 3. The authors are given some insight into a potential weakness but are not provided with concrete steps to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the results for linear scalarization combined with the SOTA heuristic solver (Concorde) for a better comparison, given that the Pareto front is not highly nonconvex. This is an explicit action with concrete details on how to implement it, as it specifies the exact results that should be included for a more comprehensive comparison. The authors know exactly what needs to be done to enhance their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: including the results for linear scalarization combined with the SOTA heuristic solver (Concorde) for a better comparison. This provides clear guidance on how to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers based on the experimental results, but notes that for the singleobjective TSP, the SOTA heuristic solver (Concorde) usually performs best. The comment suggests including the results for linear scalarization combined with Concorde for a better comparison, given the nonconvexity of the Pareto front. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion about the performance of Concorde. The authors would need to consider this feedback and potentially conduct additional experiments to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation about the experimental results, noting that the learningbased solvers outperform the heuristicbased solvers but that the SOTA heuristic solver (Concorde) is the best for the singleobjective TSP. It suggests that including the results for linear scalarization combined with Concorde would enhance the comparison, given the nonconvexity of the Pareto front. This feedback is clear and actionable, offering a concrete suggestion for improving the draft by providing a more comprehensive comparison. However, it could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4, as it provides valuable guidance for enhancing the paper\"s experimental section."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that while the proposed method is grounded in neuroscience, some of its general ideas are already present in other methods for exploration. It specifically mentions methods that use the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, as well as curiositydriven exploration. The comment suggests that the paper should discuss the proposed method in relation to these existing methods. While the action is implicit, as it does not explicitly instruct the authors to include a discussion, it is concrete in suggesting specific methods to consider. The authors can infer that they need to discuss the novelty and differentiation of their method from existing approaches. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and references specific methods such as the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, which are discussed in the graphbased SLAM appendix section. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: a discussion of the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas in the proposed method are already present in other methods for exploration, such as reasoning topologically using generalized Voronoi graphs or semantic maps, and longterm storage through pose graphs in SLAM. The reviewer provides specific examples and references to existing methods, which supports the claim and makes it 4. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the proposed method, noting that some of its general ideas are already present in other methods for exploration. It specifically mentions methods that use the generalized Voronoi graph, semantic maps, pose graphs in SLAM, and loop closure, as well as curiositydriven exploration. The comment suggests that the paper should discuss the proposed method in relation to these existing methods, which could help clarify its novelty and contributions. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the overlap with existing work. However, it could be more helpful if it offered suggestions on how to differentiate the proposed method or highlighted specific aspects that need further discussion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some experimental setup details back into the main text and relocating some background information from Section 2 to the appendix. This provides a clear and explicit action for the authors to take, as it specifies what needs to be done to improve the clarity and accessibility of the paper. The suggestion is concrete, offering a direct path for the authors to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experimental setup, tasks, and other details being moved to the appendix, which makes it difficult to interpret the paper. It suggests moving some of these details back into the main text and relocating some background information from Section 2 to the appendix instead. This provides specific guidance on what needs to be addressed, but it does not explicitly mention which sections or parts of the paper are being referred to. While the authors can infer that it relates to the experimental setup and Section 2, the comment is not fully grounded as it lacks explicit references to these sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that moving experimental setup, tasks, and other details to the appendix makes it difficult to interpret the paper. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to move some details back into the main text and relocate background information from Section 2 to the appendix is not substantiated with evidence or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup and suggests a way to improve the clarity of the paper. It points out that moving details to the appendix can make it difficult to interpret the paper and suggests moving some of these details back into the main text. Additionally, it recommends relocating some background information from Section 2 to the appendix. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the readability and accessibility of their work. However, the comment could be more helpful if it included specific examples or further elaboration on which details should be moved. Overall, the comment is 4 as it offers a constructive direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide glosses in Figure 2. This is an explicit action that the authors can take to improve their draft. The comment is clear and specific, providing a concrete suggestion on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which allows the authors to identify the specific part of the paper being addressed. However, it does not specify what kind of glosses are needed or why they are necessary, making the comment somewhat vague in terms of what needs to be addressed. Therefore, the comment is fully grounded as it clearly identifies the figure, but it is underspecific in terms of the details of the suggestion. This aligns with a score of 4.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, which is a straightforward request for clarification. However, it does not provide any reasoning or justification for why glosses are necessary or how they would improve the figure. Without additional context or explanation, the authors may find it challenging to understand the importance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests providing glosses in Figure 2, which is a clear and actionable piece of feedback. By offering this suggestion, the reviewer helps the authors improve the clarity and accessibility of their figure, potentially enhancing the reader\"s understanding of the content. However, the comment could be more helpful if it explained why glosses are necessary or how they would benefit the figure. Despite this, the feedback is 4 as it provides a specific and actionable suggestion for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point points out that \"Memb\" is mentioned as the previous stateoftheart but lacks any reference. This implies that the authors should include a reference to support the claim about \"Memb\" being the previous stateoftheart. However, the comment does not explicitly instruct the authors to add a reference, leaving it to be inferred. The action is concrete in terms of what needs to be done (adding a reference), but it is implicit in the instruction. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment mentions \"Memb\" as the previous stateoftheart but notes the absence of any reference. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion or references section where such claims are typically made. However, the comment lacks specificity as it does not detail what kind of reference is missing or why it is important. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"Memb\" is the previous stateoftheart but notes the absence of any reference. This claim is 3 as it points out a potential oversight in the paper, but it lacks specific details or references to support the assertion that \"Memb\" is indeed the previous stateoftheart. The comment does not provide enough information for the authors to fully understand the context or the basis of the claim, making it difficult for them to address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a significant omission in the paper, noting that \"Memb\" is mentioned as the previous stateoftheart but without any reference. This is a critical issue because it undermines the credibility of the claim and the authors\" argument. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific references or ways to integrate them into the paper. While it highlights a crucial weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a problem but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about considering finer grouping for quantization instead of pertensor and perchannel approaches. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what specific actions they should take. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure discussing quantization methods. Without explicit references or context, the authors may find it challenging to determine where this comment should be addressed. The comment is specific in its questioning of the quantization approach but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point is a question asking for justification or explanation regarding the choice of quantization approach. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of quantization approach, specifically asking why a finer grouping is not considered instead of pertensor and perchannel methods. While it identifies a potential area for improvement, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should study the impact of the ratio of unseen classes on the performance of the model. It provides a specific example of how the performance varies with different ratios of unseen classes and unlabeled examples. This feedback is explicit and concrete, as it clearly instructs the authors on what aspect of their work needs further investigation and provides a concrete example of how to approach it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model, specifically mentioning the variation in performance with different ratios of unseen classes and unlabeled examples. However, it does not specify which part of the paper this suggestion should be addressed in, such as a particular section or experiment. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting a particular area for investigation, but without explicit references to specific sections or elements of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the impact of the ratio of unseen classes on the model\"s performance should be studied. It provides a specific example of how the performance varies with different ratios of unseen classes and unlabeled examples. This suggestion is based on logical reasoning and provides a clear direction for further investigation, making it 4. However, the comment could be strengthened by including references to similar studies or experiments that have explored this aspect, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a specific area for further investigation, namely the impact of the ratio of unseen classes on the model\"s performance. It provides a concrete example of how the performance varies with different ratios of unseen classes and unlabeled examples, offering a clear and actionable suggestion for the authors to explore. This feedback is valuable as it directs the authors to a potentially significant aspect of their work that could enhance the understanding and applicability of their results. However, the comment could be more helpful if it included additional guidance on how to approach this investigation or potential implications of the findings. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. While it highlights a potential inconsistency or choice in the methodology, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should clarify or justify their choice of architectures. However, the comment lacks concrete details on how to improve the draft, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. However, it does not specify which part of the paper discusses these architectures or their combination, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its questioning of the methodology choice but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. It does not contain a claim or opinion that requires verification, as it is a request for information rather than a statement that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, and whether the combination of two architectures is the reason for the improvements. This feedback is 3 as it prompts the authors to clarify their methodology and provide a rationale for their architectural choices. However, it lacks depth and does not offer specific suggestions or guidance on how to address this issue or improve the draft. The authors are left with a general question to consider, but without detailed feedback, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in the context of the network\"s sparsity. While it does not explicitly instruct the authors to clarify or define this term, it implies that the authors should provide a clear explanation or definition. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of clarity regarding \"active vertices.\" However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices,\" which is a clear and actionable request for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the definition of \"active vertices\" in the context of the network\"s sparsity. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in the context of the network\"s sparsity, which is mentioned in line 135. This feedback is 3 as it identifies a potential ambiguity in the text that needs clarification. However, it does not provide specific guidance on how to address the issue or suggest alternative ways to define \"active vertices.\" While it points out a weakness, it lacks depth and actionable advice, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the paper\"s theory is not applicable to the used model, which is not explicitly mentioned in the limitations section. It also points out the vagueness of \"structural assumptions\" that are only provided in the appendix, making it difficult to identify the theoretical limitation. The reviewer suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitations and provide additional discussion on societal impact. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the theory\"s inapplicability to the used model is not honestly mentioned and that the vagueness of \"structural assumptions\" makes this limitation hard to find. Additionally, the comment suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks, given their widespread use in industry. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s theory is not applicable to the used model and that this limitation is not honestly mentioned in the limitations section. It also suggests that the authors underestimate the current use of graph neural networks in industry and propose that more elaboration on potential negative societal impacts could be provided. The comment provides some logical reasoning by pointing out the lack of mention of the theory\"s inapplicability and the vagueness of \"structural assumptions.\" However, it lacks specific examples or references to support the claim about the widespread use of graph neural networks or the potential negative societal impacts. This makes the claim 3, as it provides a basis for the argument but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, specifically addressing the applicability of the theory to the used model and the lack of honest mention of this limitation in the limitations section. It also points out the vagueness of \"structural assumptions\" that are only provided in the appendix, making it difficult for readers to understand the theoretical limitations. Additionally, the reviewer suggests that the authors underestimate the current use of graph neural networks in industry and proposes that more elaboration on potential negative societal impacts could be given. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a constructive suggestion for enhancing the paper. However, it could be more helpful if it offered specific examples or references to support the claim about the widespread use of graph neural networks. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide specific guidance or suggestions on how the authors might address these issues. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not specify which part of the paper these weaknesses are discussed in. The authors can make an educated guess that it relates to the sections discussing the FSR metric, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for clearer examples and weaknesses in the FSR metric, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide any specific claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not contain any subjective claims or requests for changes, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide specific details or suggestions on how these weaknesses could be addressed. The comment lacks actionable feedback and does not offer any guidance on how the authors might improve their draft. As a result, it is 2, as it identifies a potential issue but does not provide enough information for the authors to make meaningful improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, it does not provide explicit guidance or suggestions on how the authors should clarify or address this point in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the use of epsilongreedy exploration. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, indicating that the authors should clarify whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, the comment does not provide any supporting evidence, reasoning, or references to clarify this point. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be addressed. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or address the critique, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not detail what aspects of the method are considered \"not new\" or how the authors could improve the novelty of their approach. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the proposed method by stating that it can be viewed as a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not provide any specific feedback or suggestions on how the authors could improve their method or address the critique. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes are needed to enhance their work. As a result, the comment is 1, as it does not offer any meaningful insights or directions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue regarding the impact of the projection head (CNN layers) versus the classification head (FCN layer). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"projection head (CNN layers)\" and \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that only the projection head is affected, not the classification head. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual statement describing the impact of the projection head versus the classification head. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific issue regarding the impact of the projection head (CNN layers) versus the classification head (FCN layer). However, it does not provide any context, explanation, or suggestions for how this observation might affect the overall analysis or results of the paper. Without additional guidance or insight into why this distinction is important or how it might impact the paper, the comment lacks actionable value for the authors. Therefore, it is rated as 2, as it identifies a potential issue but does not offer any meaningful direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide a clear answer or guidance on how to address this issue. The comment implies that the authors should clarify this aspect, but it lacks explicit instructions or concrete steps on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for a clearer discussion on the use of CLIP, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work but does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to related work, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework related to using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary for distinguishing the paper from related work, implying that this aspect could be a key contribution. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the discussion should be clarified. While it identifies a potential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It points out that there are only two \"basis\" (human and object) in the problem context, which limits the analogy, and that the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen the analogy or improve the connection. The feedback is implicit and vague, leaving the authors without a clear understanding of what changes are needed to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, suggesting that the link is weak. It provides specific details by mentioning the limited \"basis\" (human and object) in the problem context and the lack of a close connection between the decomposition/integration steps and Fourier analysis. However, it does not explicitly mention which part of the paper discusses this analogy, making it weakly grounded. The comment is specific in detailing what is wrong with the analogy, so it aligns with the label 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, specifically pointing out the limited \"basis\" (human and object) in the problem context and the lack of a close connection between the decomposition/integration steps and Fourier analysis. While the comment provides some reasoning, it lacks specific examples or references to support the claim fully. The authors might need to delve deeper into the paper to understand the exact nature of the analogy and its limitations. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the strength of the analogy between HOI analysis and Harmonic analysis. It points out that the problem context involves only two \"basis\" (human and object), which limits the analogy, and that the decomposition/integration steps do not have a close connection with Fourier analysis as claimed. This feedback is 3 as it highlights an area where the authors might need to strengthen their argument or provide more detailed connections to support their claims. However, the comment could be more helpful if it offered suggestions on how to improve the analogy or provide additional context to enhance the connection. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether the authors should consider alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the applicability of the proposed methodology, specifically mentioning dynamic precision control during training and its potential limitations on bitserial accelerators. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment provides some insight into the potential implications of the methodology but lacks specificity in terms of what needs to be addressed or how the authors might improve their work. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed methodology, suggesting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. The comment provides a logical reasoning by contrasting the proposed methodology with the more commonly used bitparallel fixedpoint numbers in existing ML accelerators. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this point and potentially conduct further analysis or provide additional context to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the applicability of the proposed methodology, specifically questioning whether dynamic precision control during training would only show meaningful performance gains on bitserial accelerators, which are less common in existing ML accelerators. This observation highlights a potential limitation of the proposed approach and encourages the authors to consider the broader implications of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. While it identifies a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the model by questioning whether it can handle focusing distances other than those present in the training data. It explicitly asks for an evaluation of the model\"s performance on focusing distances not seen during training. This provides a clear and direct action for the authors to take, which is to investigate and report on the model\"s performance on unseen focusing distances. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalizability of the model by asking whether it can handle focusing distances other than those present in the training data. The comment provides a clear direction for the authors to consider and evaluate, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the model by pointing out that the images in Figure 8 are from focusing distances that are also present in the training data. This is a logical observation that prompts the authors to consider whether their model can handle focusing distances not seen during training. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the potential issue and address it themselves, which aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the model by pointing out that the images in Figure 8 are from focusing distances that are also present in the training data. This observation prompts the authors to consider whether their model can handle focusing distances not seen during training, which is an important aspect of model evaluation. The comment provides a clear and actionable suggestion for the authors to investigate and report on the model\"s performance on unseen focusing distances. However, it could be more helpful if it offered specific guidance on how to conduct this evaluation or what metrics to use. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. While the comment implies that the authors should clarify these terms, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms more broadly and address the specific question about \"style.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, leaving the authors to infer that it relates to the sections discussing neural applications or style. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. The comment provides a reference to external work, which supports the claim by offering a framework for understanding content and style. However, the comment could be strengthened by providing more detailed reasoning or examples from the authors\" work to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment suggests that the authors should define \"content\" and \"style\" more broadly in the context of their neural application, referencing a specific example from Gabbay & Hosehn (2018). It questions the meaning of \"style\" in the context of the model, given that it does not capture temporal dynamics. This feedback is 3 as it identifies a potential area for clarification and provides a reference to a relevant work. However, the comment could be more helpful if it offered specific guidance on how to define these terms or how to address the question about \"style\" in the context of the model. The authors gain some insight into the need for clarification but may still struggle to fully understand and address the issue without further elaboration. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. While the comment highlights specific issues with the analysis, it does not provide explicit guidance on how the authors should address these concerns or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation of their analysis and potentially address the issues raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 45\" and \"Fig1(b) v.s. Fig5(b) for Block.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis of vit quantification, including the claim that the proposed approach does not improve the information distortion phenomenon and that the quantization of MHSA introduces a large loss of precision. The comment provides specific examples and references to external works, such as QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, which further supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification is not adequately explained and that the proposed approach does not improve the information distortion phenomenon. It provides specific examples from the paper, such as the comparison of values in Fig1(b) and Fig5(b) for Block.3, to support the claim. Additionally, it references external works in the NLP field, like QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert, to demonstrate that the issue of quantization loss of precision is not unique to the ViT model. This provides a solid foundation for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the claim that a direct quantization method leads to information distortion. It points out that the proposed approach does not improve this phenomenon and provides specific numerical examples to support the claim. Additionally, it notes that the quantization of MHSA introduces a large loss of precision, which is a known issue in transformer quantization. This feedback is valuable as it highlights specific areas where the analysis could be improved and provides concrete examples to support the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues or improve their analysis. Overall, the comment is 4, as it provides clear and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a main weakness in the work, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. The comment also notes the use of a variant of STN in PointNet. While the comment points out the lack of novelty and comparisons, it does not provide explicit guidance on how the authors should address these issues or suggest specific comparisons or analyses to include. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the novelty and include comparisons, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a main weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It provides specific examples of existing works that apply STN in a local pixel neighborhood and mentions PointNet using a variant of STN. However, the comment does not explicitly mention which part of the paper discusses the proposed Xtransformation or the comparisons, making it weakly grounded. The authors can infer that the issue relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the lack of novelty and comparisons, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and that the proposed Xtransformation is similar to STN but applied locally. It also mentions existing works that apply STN in a local pixel neighborhood and the use of a variant of STN in PointNet. While the comment provides some context and references existing works, it lacks specific examples or detailed comparisons to substantiate the claim of limited novelty. The reasoning is 3 as it highlights the similarity to existing works, but it could be strengthened with more detailed comparisons or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN) and the absence of comparisons to STN. It highlights that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes the use of a variant of STN in PointNet, further emphasizing the limited novelty of the work. The comment also points out the absence of empirical or conceptual comparisons to STN, which is an important aspect for evaluating the work. While the comment effectively identifies areas for improvement, it could be more helpful by suggesting specific comparisons or analyses that the authors could include to enhance the novelty and relevance of their work. Overall, the feedback is 4 as it provides clear guidance on areas needing improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. The reviewer also recommends explaining the network model in Section 4.2 with equations to improve clarity. While the comment implies that the authors should clarify the reward source and provide more detailed explanations, it does not explicitly instruct them to do so. The suggestion to explain the network model is concrete, but the action to clarify the reward source is implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12\" and \"Sec. 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Equation 12, questioning the origin of the reward at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. Additionally, the comment provides a suggestion to improve clarity by explaining the network model in Section 4.2 with equations. The inclusion of references to external works further supports the need for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of Equation 12, specifically asking where the reward comes from at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. The reviewer also recommends explaining the network model in Section 4.2 with equations to improve clarity. While the comment raises valid points about the need for clarification, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The inclusion of references to external works is an attempt to support the suggestion for improvement, but it does not directly address the question of the reward\"s origin. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation 12, questioning the origin of the reward at each trial and suggesting that it might be related to one of the r_i terms from Equation 11. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their work. Additionally, the comment recommends explaining the network model in Section 4.2 with equations, which would improve the paper\"s clarity. The inclusion of references to external works provides additional context and support for the suggestion. However, the comment could be more helpful if it provided specific examples or more detailed guidance on how to clarify the network model. Overall, the feedback is 4 as it effectively points out areas for improvement and offers constructive suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two explicit actions: correcting a typographical error (\"Fig.7\" to \"Fig.12\") in the supplementary material and attaching theorems and corollaries in the main paper to their corresponding proof links. These actions are clear and concrete, providing the authors with direct guidance on how to improve their draft. Additionally, the comment suggests addressing concerns related to motivation, methodology soundness, and experiment persuasion, which are also explicit and actionable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the typo (\"Fig.7\" should be \"Fig.12\") and provides a clear suggestion to attach theorems and corollaries to their corresponding proof links. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, providing specific feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and suggestions for improvement, such as correcting a typographical error and attaching theorems and corollaries to their corresponding proof links. It also provides an overall assessment of the paper, noting its novelty, theoretical guarantees, and empirical results. However, the comment does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a typographical error in the supplementary material and suggesting that theorems and corollaries in the main paper should be linked to their corresponding proofs. This feedback is clear and directly guides the authors on how to improve the readability and clarity of their work. Additionally, the comment highlights areas of concern regarding motivation, methodology soundness, and experiment persuasion, which are important aspects of the paper. However, the comment could be more helpful if it provided more detailed suggestions or examples for addressing these concerns. Overall, the feedback is 4 as it offers concrete steps for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about specific parts of the paper, including the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The questions are implicit and lack concrete guidance, leaving the authors to infer what needs to be done. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 3\" and \"Section 3 306ff,\" allowing the authors to accurately identify the parts being addressed. It also raises specific questions about the definitions and concepts presented in these sections, such as the missing determiner in the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" These questions are factual and do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several specific questions about the paper, including the definition of \"Above definition,\" the selection of action verbs, and the concept of \"action frames.\" These questions indicate areas where the authors may need to provide further clarification or explanation to enhance the comprehensibility of their work. However, the comment does not offer suggestions or guidance on how to address these issues, leaving the authors with a clear understanding of what needs to be clarified but without actionable steps to take. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and specific guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a minor issue with a specific line number and page number, indicating that the word \"Empiically\" should be spelled as \"Empirically.\" This provides clear and direct guidance for the authors on what needs to be corrected in their draft. The action is explicit and concrete, leaving no ambiguity about how to implement the suggested change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is a spelling error (\"Empiically\" should be \"Empirically\"). This provides clear guidance on what needs to be corrected. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual statement about a minor issue with a spelling error (\"Empiically\" should be \"Empirically\") on a specific line number and page. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with a spelling error, specifically pointing out that \"Empiically\" should be spelled as \"Empirically\" on Line 32 of Page 1. While this feedback is accurate and actionable, it is limited in scope and does not provide broader insights or suggestions for improving the draft. The comment is clear and direct but lacks depth, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential area for improvement in the proposed invariant learning module, specifically suggesting that the feature selection could be enhanced by considering representation learning. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The comment implies that the authors should consider representation learning, but it lacks concrete details on how to integrate this into their work. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the feature selection in Section 4.2 could be improved by considering representation learning, which is discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions the discussion about representation learning in the appendix but does not elaborate on how this relates to the feature selection in Section 4.2. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the proposed invariant learning module, specifically focusing on the feature selection aspect. It points out that the feature selection is not limited to rawlevel features, as suggested by the framework in Section 4, and suggests that representation learning could be considered to enhance the feature selection. This feedback is 3 as it highlights a specific area for improvement and provides a direction for the authors to consider. However, it lacks detailed guidance or examples on how to integrate representation learning into the feature selection process, which would make the feedback more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some details are missing, specifically mentioning that the design of rewards is not fully understandable. However, it does not provide explicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors to infer that they need to provide more information about the reward design. Since the action is implicit and vague, the authors may struggle to determine exactly what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically referencing the design of rewards, which is not fully understandable. However, it does not specify which part of the paper discusses the reward design, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in identifying the missing details but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any specific details or examples of what is missing or how the design of rewards is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1 as it lacks sufficient evidence or justification to support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where details are missing, namely the design of rewards. It highlights a particular aspect that needs clarification, which is the design of rewards. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. Without detailed guidance, the authors may find it challenging to understand what specific information is missing or how to improve the clarity of the reward design section. Therefore, the comment is 3 as it points out a weakness but does not offer actionable advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the fixed number of entities in the model and questions how it can be generalized to different numbers of entities. While it points out a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details on what steps the authors should take to improve the generalizability of their model. As a result, the authors are left without a clear understanding of how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment refers to \"figure 3 of INs,\" which provides full grounding as it explicitly mentions a specific figure and reference, allowing the authors to accurately identify the part of the paper being addressed. However, the comment is not specific in detailing what needs to be addressed regarding the generalization of the model to different numbers of entities. It highlights a potential issue but does not provide guidance on how to resolve it. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point raises a concern about the fixed number of entities in the model and questions how it can be generalized to different numbers of entities. The comment references \"figure 3 of INs,\" which suggests that the issue is related to a specific figure or example. However, the comment does not provide detailed reasoning or examples to support why this limitation is problematic or how it affects the model\"s performance. Without additional context or evidence, the claim remains 3, as the authors would need to infer the significance of the issue based on the reference to figure 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the model, specifically the fixed number of entities, and questions how it can be generalized to different numbers of entities. It references a figure from another work (INs) to illustrate the issue, which provides some context. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their model. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. It suggests that the experimental design is good but criticizes the lack of code release, which could be a significant issue if not addressed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should consider releasing their code to enhance the paper\"s reproducibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and reproducibility of the paper, specifically mentioning the incremental improvement over a KNN based MT approach and the lack of code release. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique of the lack of novelty and the importance of code release, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. It suggests that the experimental design is good but criticizes the lack of code release, which could be a significant issue if not addressed. The comment provides a logical reasoning for the claim, acknowledging the incremental nature of the work and the importance of code release for reproducibility. However, it lacks specific examples or references to support the claim about the lack of novelty, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper presents an incremental improvement to a KNN based MT approach, noting a lack of novelty but significant engineering and execution effort. It highlights the importance of experimental design and suggests that the lack of code release could be a significant issue if not addressed. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve the novelty of their work. While it identifies areas for improvement, the feedback is somewhat vague and lacks actionable advice, making it 3. The authors gain some insight into the incremental nature of their work and the importance of code release, but the comment could be more comprehensive and detailed to fully support their improvement efforts."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for MLbased emulators. This is an explicit action, as it clearly instructs the authors to include a specific discussion about the runtime. The comment provides a concrete suggestion on what aspect of the paper should be addressed, making it clear to the authors how to implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests discussing the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for MLbased emulators. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of the model\"s performance or limitations. The comment is specific in suggesting that the runtime should be discussed as a limitation, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count, which might be a limitation for applications where computational cheapness is a selling point for MLbased emulators. This claim is 3 as it provides a logical reasoning based on the characteristics of the model. However, it lacks specific examples or references to support the assertion about the runtime being a limitation. Providing more detailed evidence or examples would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the MLbased emulator, Prithvi WxC, by pointing out its large parameter count and suggesting that its runtime should be discussed. This feedback is 3 as it highlights an important aspect that could impact the applicability of the emulator, particularly in contexts where computational cheapness is a key advantage. However, the comment could be more helpful if it provided specific guidance on how to discuss the runtime or suggested ways to address this limitation. The authors are given a direction to consider but lack detailed instructions on how to implement the suggestion, making the feedback 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the idea, improve the metric, or make the method more complex. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the idea and the straightforwardness of both the new metric and method. However, it does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is also not specific about what aspects of the novelty or method need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the novelty of the idea is insufficient and that both the new metric and method are relatively straightforward. However, it does not provide any specific suggestions or guidance on how the authors might enhance the novelty or complexity of their approach. Without actionable feedback or detailed insights, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper \"oversells\" the method, which makes the contribution less clear. However, it does not provide specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to revise their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper \"oversells\" the method, making the contribution less clear. However, it does not specify which part of the paper this issue pertains to, such as a particular section or claim. Without explicit references or detailed examples, the authors cannot confidently determine where in the paper this critique applies. Additionally, the comment lacks specificity regarding what aspects of the contribution are unclear or how the method is being oversold. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper \"oversells\" the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper may be overstating its contributions, which could make the contribution less clear. However, it does not provide specific examples or details on how the paper is overselling the method or what aspects need clarification. Without actionable guidance or detailed feedback, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable advice makes the comment 2, as it does not effectively guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. While the comment implies that these changes would enhance understanding, it does not provide explicit instructions on how to implement these suggestions. The authors can infer that they need to break down the generative process into more detailed steps and simplify the notation, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the model description, specifically mentioning the need to present the generative process in separate steps and reducing the use of symbols and notation tables. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestions for improvement, but without clear grounding, it is challenging for the authors to implement the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps and reducing the use of symbols and notation tables. However, the comment does not provide specific examples or detailed reasoning to support why these changes would enhance understanding. The lack of concrete evidence or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the model description. It suggests that the generative process could be better understood if presented in separate steps and that the use of symbols and notation tables should be minimized. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the clarity and readability of the model description. However, the comment could be more helpful if it included specific examples or guidance on how to present the generative process in a more detailed and accessible manner. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases generated for the training data, specifically questioning how different these paraphrases are from the original sentences. It emphasizes the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment suggests that if the paraphrases are not significantly different from the originals, the quality of the final training data will be low, leading to a limited number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting methods to evaluate or improve the paraphrasing process. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess and potentially improve the paraphrasing process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of paraphrasing for the training data, specifically questioning how different the paraphrases are from the original sentences. It highlights the importance of this aspect for the subsequent steps in the process. However, it does not specify which part of the paper discusses the paraphrasing process, making it weakly grounded. The comment is specific in detailing the concern about the quality of paraphrases and their impact on the final training data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases generated for the training data, suggesting that if the paraphrases are not significantly different from the original sentences, the quality of the final training data will be compromised. The comment logically connects the quality of paraphrases to the impact on the training data, providing a clear rationale for the claim. However, it lacks specific examples or references to support the assertion about the impact of paraphrase quality on the training data. This makes the claim 3, as it requires further evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paraphrasing process for the training data, specifically questioning the difference between the paraphrases and the original sentences. It highlights the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment logically explains that if the paraphrases are not significantly different, the quality of the final training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is clear and actionable, as it prompts the authors to evaluate and potentially improve the paraphrasing process to ensure the quality of their training data. However, it could be more helpful if it provided specific suggestions or examples on how to assess or enhance the paraphrasing quality. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the paper for being wellorganized and easy to follow. However, it provides a specific suggestion regarding Figure 2, recommending the use of a different color or a larger font to improve the visibility of the \"bold\" text highlighting humanidentified rationales. This feedback is explicit and provides concrete guidance on how to enhance the visual presentation of the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the visual presentation of the figure, suggesting alternative ways to highlight the humanidentified rationales, such as using a different color or a larger font. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a complex problem, particularly in NLP tasks like machine translation. It praises the organization and clarity of the paper but provides a specific suggestion regarding Figure 2, recommending changes to improve the visibility of the \"bold\" text. However, the comment does not provide detailed reasoning or examples to support the claim about the complexity of identifying rationales or the specific issues with Figure 2. This makes the claim 3, as it lacks comprehensive evidence or references to fully substantiate the feedback.", "helpfulness_rationale": "The review comment acknowledges the complexity of identifying rationales, particularly in NLP tasks like machine translation, and praises the paper for its organization and clarity. It provides a specific suggestion for improving the visual presentation of Figure 2 by recommending the use of a different color or a larger font to highlight the humanidentified rationales. This feedback is actionable and offers a concrete way for the authors to enhance the readability of their figure, making it 4. However, the comment could be more comprehensive by addressing other aspects of the paper or providing additional suggestions for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the framework\"s applicability beyond LLMbased models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models like HiTeA and InternVideo. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to explore the framework\"s applicability beyond LLMbased models, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the FlippedQA framework should be further verified for its effectiveness and universality beyond LLMbased models, specifically mentioning HiTeA and InternVideo as examples. The comment provides a logical reasoning by pointing out the potential limitation of the framework\"s applicability, which is a valid concern. However, it lacks specific examples or references to support the claim that these models are relevant or that the framework should be tested on them. This makes the claim 3, as it provides a direction for further exploration but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should further verify the effectiveness and universality of the FlippedQA framework by applying it to nonLLMbased models, such as HiTeA and InternVideo. This feedback is clear and actionable, as it identifies a potential limitation in the current application of the framework and provides specific models for further exploration. By suggesting additional experiments or analyses, the comment offers a concrete way for the authors to enhance the robustness and applicability of their work. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the writing could be improved, implying that the authors should make their text more coherent and easier to follow. However, it does not provide specific guidance on how to achieve this improvement, such as suggesting reorganization, clearer explanations, or additional examples. The action is implicit and vague, leaving the authors without clear direction on how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, indicating that it was difficult to understand the main idea and the theoretical analysis. However, it does not specify which parts of the paper are problematic or provide guidance on how to improve the clarity. The authors may infer that the issue lies in the theoretical analysis or the main idea, but without explicit references, it is difficult to pinpoint the exact sections that need attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing could be improved, stating that it took a lot of effort to understand the main idea and the theoretical analysis. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to identify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing could be improved, indicating that it was difficult to follow the main idea and theoretical analysis. However, it does not provide specific guidance or examples of how the writing could be improved, such as suggesting clearer explanations, reorganization, or additional examples. Without actionable feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and specificity to guide the authors effectively."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the proposed method\"s lack of significant theoretical novelty, as it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer expresses willingness to improve their score if the authors address these concerns. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific aspects of the method need improvement. The action is implicit and vague, leaving the authors uncertain about how to respond effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the existing methods it builds upon, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the concern about the lack of significant theoretical novelty and suggests that the authors address this issue to improve the score. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer supports this claim by referencing specific existing methods, such as ClopperPearson intervals and Gaussian elimination, which are cited in the provided references. This provides a clear and logical basis for the claim, making it 5. The inclusion of references adds robustness to the argument, allowing the authors to understand the basis of the critique and address it effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a concern about the lack of theoretical novelty in the proposed method, which primarily builds upon existing methods like ClopperPearson intervals and Gaussian elimination. The reviewer expresses willingness to improve their score if the authors address these concerns. While the comment highlights an important issue, it lacks specific guidance or suggestions on how the authors might enhance the theoretical novelty of their method. Without actionable advice or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is 3, as it points out a weakness but does not provide detailed feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context being addressed. Additionally, the comment lacks specificity regarding what aspects of the text input or object elements are being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text inputs by the four text elements of an object. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review point raises a question about whether the text input can be concatenated by the four text elements of an object. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or clarify their methodology. The lack of actionable feedback or detailed explanation makes it difficult for the authors to understand what needs to be improved or how to improve it. Therefore, the comment is 2, as it highlights a potential issue but does not offer any actionable steps for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer explanation of why the subject matter is important or relevant. However, the comment does not specify how to achieve this motivation or what aspects of the paper need to be revised to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not provided with concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer explanation of why the subject matter is important or relevant. However, it does not specify which part of the paper lacks this motivation or where it should be added. The authors can make an educated guess that it relates to the introduction or background sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting the need for motivation, but without clear guidance on where to address it, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks motivation for why the topic is important or relevant. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that it lacks motivation for why the topic is important or relevant. This is a valid point, as a clear motivation can help readers understand the significance and context of the research. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending additional background information or a clearer explanation of the problem being addressed. While the comment highlights an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific sentence in the abstract (lines 1217) as cumbersome and suggests that it can be made clearer. While the comment implies that the authors should revise this sentence, it does not provide explicit guidance on how to improve it. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the sentence for clarity. However, the comment does point out a specific area that needs attention, which is a step towards actionability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the abstract and lines 1217. It specifies the issue by pointing out that the sentence is cumbersome and suggests that it can be made clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning or examples to support why the sentence is cumbersome or how it could be improved. Without detailed justification or suggestions, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, pointing out that a particular sentence is cumbersome and could be clarified. While it highlights a potential area for improvement, it does not provide specific suggestions or guidance on how to rephrase the sentence for clarity. This limits the helpfulness of the comment, as the authors are left to infer the necessary changes without detailed direction. Therefore, the comment is 3, as it points out a weakness but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the unfairness of comparing the domainspecific model trained on Pix3D to zeroshot singleimage 3D reconstruction models, also tested on Pix3D. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of unfair comparisons or suggestions for alternative experiments or methodologies. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the domainspecific model\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the unfair comparisons to zeroshot singleimage 3D reconstruction models, even though they are also tested on Pix3D. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparisons to zeroshot singleimage 3D reconstruction models are unfair because both the domainspecific model and the models being compared are trained and tested on Pix3D. However, the comment lacks specific reasoning or evidence to support why these comparisons are unfair. It does not provide examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the fairness of comparisons made in the paper, specifically regarding the use of Pix3D for both the domainspecific model and the zeroshot singleimage 3D reconstruction models. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable feedback or specific recommendations, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. The reviewer encourages the authors to continue this line of work for future submission. While the comment identifies areas for improvement, it does not provide explicit instructions on how the authors should address these issues or what specific changes they should make. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the tradeoff for baselines and potentially explore hyperparameter tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance and that the tradeoff between head and tail categories has not been fully investigated for the baselines. The comment provides a specific suggestion to explore the tradeoff for baselines by changing hyperparameters in Decouple [Kang et al.]. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, as shown in Figure 3. It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. The comment provides a logical reasoning by comparing the performance of the proposed approach with Decouple [Kang et al.], which is a wellknown method in the field. However, the comment lacks specific examples or detailed comparisons to fully substantiate the claim. Therefore, the claim is 4, as it provides a clear direction for further investigation but could benefit from more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the tradeoff between head and tail categories has not been fully investigated for the baselines, suggesting that changing hyperparameters in Decouple [Kang et al.] could improve tail accuracy while slightly decreasing head accuracy. This feedback is valuable as it highlights a critical area for improvement and provides a specific direction for further investigation. However, the comment could be more helpful by offering suggestions on how to address these issues or by providing examples of how to explore the tradeoff for baselines. Overall, the comment is 4 as it directs the authors to a key area needing further work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the comment implies that such experiments would be beneficial, it does not explicitly instruct the authors to perform them. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments to strengthen their work. However, the suggestion is concrete in terms of the specific datasets to use, which provides some guidance. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a specific suggestion for improving the paper, it does not specify what aspects of the experiments or results would be improved by using WebVision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any reasoning or evidence to support why these specific datasets would be beneficial or how they would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper\"s support for the C2D method. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D method would benefit from them. While it offers a direction for improvement, it does not fully address the authors\" needs for actionable feedback. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation, noting that it is mostly based on 4 OCR QA datasets and that the authors themselves acknowledge the potential unreliability of this evaluation in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate additional scenarios or datasets. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more diverse scenarios. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is mostly based on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying on only 4 OCR QA datasets, and suggests that this may be unreliable. The comment references Figure 4(5), where the authors acknowledge the potential unreliability of the evaluation. However, it does not provide specific examples or detailed reasoning to support the claim that more scenarios like the LLaVA benchmark are necessary. While the comment highlights a potential issue, it lacks sufficient evidence or detailed justification to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the paper, noting that it is mostly based on 4 OCR QA datasets and that the authors themselves acknowledge the potential unreliability of this evaluation. The comment suggests that more scenarios, such as the LLaVA benchmark, should be included, especially in ablation studies. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a particular benchmark that could enhance the robustness of the evaluation. However, the comment could be more helpful if it offered additional guidance on how to incorporate these additional scenarios or benchmarks. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain as R^m to \u0394^(K+1). Second, it questions the dimensions in the equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L75\" and \"In (2),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the notation and dimensions, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion to clarify the function pi and a question about the dimensions in equation (2). The first part is a suggestion for improvement, which is not a claim requiring verification. The second part questions the dimensions, which is a factual observation. However, the comment does not contain subjective opinions, judgments, or suggestions that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it recommends clarifying the function pi by specifying its domain, which could help readers understand the notation better. Second, it questions the dimensions in equation (2) and suggests assuming the 1st column of X_t is always 0 to resolve the issue. These suggestions are clear and actionable, offering the authors concrete ways to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples to fully address the issues. Overall, the feedback is 4 as it directs the authors toward specific improvements, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or simplify the tasks. The action is implicit and vague, as the authors are left to infer that they should consider alternative approaches but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the reviewer is addressing, such as a particular section or experiment. It also lacks specificity because it does not provide detailed feedback on what aspects of the abstract visual reasoning tasks are confusing or how they could be improved. The authors cannot confidently determine which parts of the paper need revision, making it difficult for them to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment lacks specific examples or references to support the claim that the current formulation is problematic. The absence of detailed reasoning or evidence makes it difficult for the authors to understand and address the concerns. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. The reviewer also expresses confusion about the multiple rows and changing factors between frames, questioning whether these elements are necessary for the models to learn patterns or if they merely exploit artifacts. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or simplify the tasks. While it identifies a potential issue, it does not provide actionable feedback, making it 3. The authors are left with a general understanding of the problem but without detailed steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It highlights two issues: the requirement for \"all of the structured elements for perspectives to be present in the generated tweets,\" which may not be realistic, and the use of \"[author] embeddings initialized by averaging the corresponding artificial tweets,\" which is also not realistic. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific changes. The authors can infer that they need to evaluate the realism of their tweets and consider more realistic approaches, but the feedback lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weak supervision\" and \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the realism of the tweets, particularly the requirement for \"all of the structured elements for perspectives to be present\" and the use of \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" This provides clear guidance on what needs to be addressed in terms of improving the realism of the evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of weak supervision could be improved, specifically questioning the realism of the evaluated tweets. It provides specific examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the use of \"[author] embeddings initialized by averaging the corresponding artificial tweets.\" These examples offer a clear rationale for why the evaluation might not be realistic, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of weak supervision, questioning the realism of the evaluated tweets. It provides concrete examples, such as the requirement for \"all of the structured elements for perspectives to be present in the generated tweets\" and the use of \"[author] embeddings initialized by averaging the corresponding artificial tweets,\" which are not realistic. This feedback is actionable as it directs the authors to reconsider their evaluation methods and suggests a more realistic approach. However, the comment could be more helpful if it offered suggestions on how to enhance the realism of the tweets or provided examples of more realistic methods. Overall, the comment is 4, as it highlights a critical area for improvement and provides some guidance, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of essential visualization of intermediate processes and comparisons, but it does not provide specific guidance on how to address this issue. It does not suggest what kind of visualizations should be included or how the comparisons should be presented. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit mention, it is difficult to pinpoint the exact area needing attention. The comment is specific in identifying the need for visualization and comparisons but lacks grounding due to the lack of specific references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance their draft by including visualizations that could help readers better understand the intermediate steps and comparisons. However, the comment could be more helpful if it provided suggestions on what specific visualizations or comparisons would be most beneficial or how they could be effectively integrated into the paper. Despite this, the comment offers a valuable direction for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The comment lacks explicit instructions or concrete details on how to resolve the problem, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the expected counterfactual violating a condition stated in the definition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. This feedback is clear and actionable, as it points out a potential problem that needs to be addressed in the paper. However, the comment lacks further guidance or suggestions on how the authors might resolve this issue or what implications it might have for the overall analysis. While it highlights a critical area for improvement, the lack of additional context or direction limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to focus on but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the importance of the result and provides a comparison with existing work, specifically [15], which claims that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer suggests that the decentralized algorithm\"s ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the reviewer notes a change in the iteration complexity in Theorem 3, which is no longer dimensionfree. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer what changes might be necessary without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the importance of the result, provides a comparison with existing work ([15]), and notes the change in iteration complexity in Theorem 3. This level of detail helps the authors understand what needs to be addressed in their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the importance of the result presented in the paper, comparing it to existing work ([15]) that claims perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer suggests that the decentralized algorithm\"s ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the comment notes a change in the iteration complexity in Theorem 3, which is no longer dimensionfree. While the comment provides a logical comparison and references existing work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the literature and the specific results to fully understand the critique. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a concern about the importance of the result presented in the paper, suggesting that it is not surprising given existing work on perturbed gradient descent. The reviewer provides a specific reference to [15] and notes a change in the iteration complexity in Theorem 3, which is no longer dimensionfree. While the comment identifies a potential issue with the novelty of the result, it does not offer specific suggestions or guidance on how the authors might address this concern or improve their work. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed analysis to help the authors enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on where the results should be included, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly instructs the authors to include keypoint detection results in the experiments section, allowing them to accurately identify the part of the paper that needs revision. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of keypoint detection results in the experiments section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for inclusion of keypoint detection results in the experiments section. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual statement asking for additional information to be included in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to include keypoint detection results in the experiments section. This feedback is specific and provides a direct suggestion for improvement, which can help the authors enhance the completeness and clarity of their draft. However, it could be more helpful if it explained why these results are important or how they might impact the overall understanding of the paper. Despite this, the comment is 4 as it offers a concrete step for the authors to take, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It explicitly requests a comparison with existing models that use answers as inputs, such as the Revisiting Visual Question Answering Baselines by Jabri et al. (ECCV16). This provides clear and concrete guidance on what action the authors should take to enhance their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific comparison with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not explicitly mention which part of the paper this comparison should be made in, leaving the authors to infer that it should be integrated into the discussion or results section. The suggestion is specific in terms of the comparison, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between the proposed model and existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This suggestion is based on the observation that ternary potential seems to be the main factor in the performance improvement of the proposed model. However, the comment does not provide detailed reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The reference to Jabri et al. is a good starting point, but more context or explanation would be needed to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment suggests a specific comparison that the authors should make to further evaluate the performance of their proposed model. It recommends comparing the model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by exploring the impact of ternary potential in the context of existing models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s overall impact. Despite this, the suggestion is valuable and provides a clear direction for the authors to improve their draft. Therefore, the comment is 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. While it implies that the authors should clarify this aspect, the comment does not provide explicit guidance on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to clarify this point but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential area of confusion, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify this point or address any potential issues related to the grid search. The comment is 3 as it prompts the authors to consider this aspect, but it does not offer actionable advice or detailed feedback to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. However, it does not provide explicit guidance or suggestions for the authors to address this issue. The comment implies that the authors should clarify the nature of these relations, but it lacks concrete steps or actions for them to take. As a result, the comment is vague and does not offer a clear path for the authors to improve their draft. Therefore, it is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. The comment provides a clear direction for the authors to clarify the nature of these relations, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. However, the comment does not provide any evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the question. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the number of discourse relations in Table A2, suggesting that it might be an artifact of colloquial language or a misunderstanding of what constitutes \"discourse\" in other languages. This feedback is 3 as it prompts the authors to clarify the nature of these relations and potentially address any inconsistencies or misunderstandings in their analysis. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address the issue, which limits its usefulness. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to address these issues or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. However, the comment does not provide any evidence, reasoning, or references to support the claim that the sample lacks diversity or that the results may not generalize. Without additional context or justification, the authors may find it challenging to address this concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. This is a critical consideration for ensuring the applicability and relevance of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the diversity of their sample. While it highlights a significant concern, it lacks actionable advice, making it 3. The authors are left with a clear area for improvement but without detailed guidance on how to implement it. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides a critique of the output quality, stating that it is reasonable but not realistic compared to recent GAN works. It suggests that there is room for improvement in result quality, but it does not offer specific guidance or suggestions on how to achieve this improvement. The comment also mentions the limited novelty, low resolution output, and high hardware requirement, which are concerns but not actionable steps for the authors. Overall, the comment lacks explicit or implicit actions that the authors can take to improve their draft, making it 1.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is room for improvement. However, it does not specify which part of the paper discusses the output quality, making it weakly grounded. The comment is specific in detailing the issues with the output quality, such as its lack of realism and the high hardware requirement, but it does not provide guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it unfavorably to recent GAN works. It suggests that the bar has been raised significantly in recent years, implying that the current output quality is inadequate. However, the comment lacks specific examples or references to recent GAN works that demonstrate higher quality, making it difficult for the authors to understand the basis of the claim. This lack of detailed evidence or references renders the claim 3, as it provides a general direction for improvement but lacks concrete support.", "helpfulness_rationale": "The review comment provides a critique of the output quality, noting that it is reasonable but not realistic compared to recent GAN works. It highlights the need for improvement in result quality, particularly in terms of novelty, resolution, and hardware requirements. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these issues. While it identifies areas for improvement, it does not provide detailed guidance or constructive advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the authors\" choice of hyperparameters, implying that they might be subpar. However, the comment does not provide explicit guidance on how to address these concerns or suggest specific actions for improvement. The authors are left to infer that they should explore different hyperparameters or consider extending the curve further, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, making it difficult for the authors to pinpoint the exact area being addressed. However, it is specific in its critique, questioning the use of soft labels in conjunction with CRM and crossentropy, and suggesting that a higher beta value might be more effective. It also expresses concern about the choice of hyperparameters for the leftmost plots. While the authors may infer that this relates to the results section, the lack of explicit grounding makes it challenging to determine the exact part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the choice of hyperparameters, implying that they might be subpar. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels in conjunction with CRM and crossentropy, suggesting that a higher beta value might be more effective. It also questions the choice of hyperparameters for the leftmost plots, implying that they might be subpar. While the comment identifies potential issues, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for improvement but does not provide actionable steps or detailed advice, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should include more evaluations in this direction, specifically on classifying unseen words. Additionally, it suggests adding translations to Figure 6 for readers who do not speak Chinese. While the comment provides a clear direction for improvement, it does not specify exactly how to conduct the additional evaluations or what specific translations should be added to Figure 6. The action is mostly concrete, as it outlines the areas for improvement, but it lacks detailed guidance on execution. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the addition of translations for readers who do not speak Chinese, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the traditional experiment for unseen characters is presented as an afterthought and implies that more evaluation in this direction would be beneficial. However, it does not provide specific examples or detailed reasoning to support why this is an important area for further evaluation. The suggestion to add translations to Figure 6 is a minor point that does not significantly impact the overall claim. Without detailed justification or examples, the claim remains 3, as it lacks the depth needed to fully substantiate the suggestion for additional evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion by noting that the traditional experiment for unseen characters is presented as an afterthought. It implies that the authors should include more evaluations in this direction, specifically on classifying unseen words. Additionally, the comment suggests adding translations to Figure 6 for readers who do not speak Chinese, which could enhance accessibility. While the feedback is clear and actionable, it could be more helpful if it provided specific examples or detailed guidance on how to conduct the additional evaluations or what translations should be included. Overall, the comment is 4 as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the small number of images (20) in the VioT dataset, which the reviewer feels is insufficient to validate the approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should collect more data, how to increase the dataset size, or any other potential solutions. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images (20) in each of the 4 categories, which the reviewer feels is insufficient to validate the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses a concern about the small number of images (20) in the VioT dataset, questioning its sufficiency for validating the approach. However, the comment lacks specific reasoning or evidence to support why 20 images are insufficient or how this impacts the validity of the approach. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset size, specifically noting that only 20 images are provided for each of the 4 categories in the VioT dataset. The reviewer expresses a concern that this small number of images may not be sufficient to validate the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or providing examples of how to improve the dataset. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a specific and concrete action for the authors to take. This feedback provides clear guidance on what additional analysis could be beneficial for the paper, allowing the authors to know exactly what to do to enhance their draft. The comment is explicit and actionable, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the number of layers versus performance, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in its suggestion, as it clearly outlines what additional analysis could be beneficial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a claim requiring justification. However, the comment does not provide any reasoning, examples, or references to support why this study would be interesting or beneficial. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the number of layers versus performance, which could provide valuable insights into the impact of layer depth on the model\"s performance. This is a specific and actionable suggestion that could help the authors improve their draft by offering a more detailed analysis of their results. However, the comment could be more helpful if it provided additional context or reasoning behind why this study would be beneficial or how it might address specific questions or concerns raised in the paper. Overall, the feedback is 4 as it offers a clear direction for further analysis, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the difficulty in following the mathematical derivations, the need for more intuitive explanations, and the lack of figure captions and legends. It specifically mentions that Figure 1 and 2 did not contribute much to the understanding and suggests that the text had to be read multiple times. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more intuitive explanations, add figure captions, and clarify the legends. However, the lack of specific guidance on how to enhance the explanations or improve the figures makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Fig. 1 and Fig. 2) and figure captions, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for more intuitive explanations of mathematical derivations and the lack of figure legends, particularly regarding the colors in Fig. 2. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions and legends, specifically mentioning that Figure 1 and 2 did not contribute much to the understanding. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references to similar works or standards further limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the difficulty in following the mathematical derivations and the need for more intuitive explanations. It also points out the lack of figure captions and legends, specifically mentioning that Figure 1 and 2 did not contribute much to the understanding. The comment provides specific examples, such as the need to explain the colors in Figure 2, which gives the authors clear guidance on how to improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to enhance the explanations or provided examples of how to improve the figure captions and legends. Overall, the feedback is 4 as it highlights important areas for improvement and provides some actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing that incorrect choices could negate any potential improvements from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a sensitivity analysis or provide more information on hyperparameter choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of empirical results to hyperparameter choices, which is an important issue for the paper. However, it does not specify which part of the paper this concern relates to, such as specific sections or results that need to be addressed. The authors can infer that it might relate to the experimental setup or results sections, but this is not explicitly stated. The comment is specific in its request for information on sensitivity to hyperparameter choices, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\"s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The suggestion to investigate this issue is logical, but without further elaboration, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical concern about the sensitivity of empirical results to hyperparameter choices, which is a crucial aspect of evaluating the robustness and reliability of the method. It highlights the potential impact of incorrect hyperparameter choices on the results, emphasizing the need for the authors to address this issue. The comment also expresses a willingness to reconsider the rating if this issue is resolved, providing a clear incentive for the authors to address the concern. However, the comment could be more helpful if it offered specific suggestions or guidance on how to investigate or mitigate the sensitivity of the results to hyperparameter choices. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to address it, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors need to further claim the novelty and contribution of their proposed method, as it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. While the comment implies that the authors should address the lack of novelty, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer justification of their method\"s originality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and contribution of the proposed method, suggesting that it is similar to using the transferability of adversarial examples directly and that the authors need to further claim the novelty of their approach. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the method is described. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that it is similar to using the transferability of adversarial examples directly. The reviewer implies that the authors need to further claim the novelty and contribution of their proposed method. However, the comment lacks specific examples or references to support the claim of similarity or the need for additional novelty claims. This makes the claim 3, as it provides a general critique but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model and is similar to using the transferability of adversarial examples directly. This feedback is 3 as it points out a weakness in the paper\"s originality, prompting the authors to clarify and justify the novelty of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as providing examples of how their method differs from existing approaches or suggesting ways to highlight its unique contributions. Therefore, while the comment raises an important point, it could be more helpful with additional detail or actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point consists of multiple separate issues, each of which is explicit and concrete. The first point explicitly states that the text in Table 1 is too small and hard to read, providing a clear action for the authors to take. The second point identifies a missing gradient symbol in Algorithm 1, line 4, which is also explicit and actionable. The third point references specific papers for further reading, providing a clear action for the authors to consider. Each of these points is explicit and concrete, giving the authors clear guidance on what needs to be addressed. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" \"Algorithm 1,\" and specific references, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text size in Table 1, the missing gradient symbol in Algorithm 1, and provides references for further reading. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple factual statements and references, which are verifiable through the provided references. Each statement is supported by specific references, such as [AFKT21], [BGN21], and [LT18], which provide evidence for the claims made. This level of detail and referencing makes the claims 5, as the authors can easily access and verify the information. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It highlights issues with the text size in Table 1, which is too small and hard to read, and suggests that the authors should address this by making the text larger. Additionally, it points out a missing gradient symbol in Algorithm 1, line 4, which is a critical detail that needs to be corrected. The comment also references relevant literature, such as [AFKT21], [BGN21], and [LT18], which can help the authors in their work. This feedback is clear, specific, and provides concrete suggestions for improvement, making it 5 for the authors to enhance their draft. Therefore, the comment is rated as 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of detailed discussion on computational aspects, particularly in high dimensions, and questions the practical usefulness of the proposed methods. It also points out that the algorithm requires solving several linear programs (LPs) with parameters that are not easily calculable, which is reflected in the smallscale experiments. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or suggest specific steps to enhance the computational aspects or experimental scale. The feedback is 3 as it highlights a critical area for improvement but lacks concrete instructions on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detailed discussion on computational aspects, particularly in high dimensions, and references the appendix for a short discussion. It also points out the issue with the algorithm requiring the solution of several LPs in high dimensions, which is reflected in the smallscale experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods in high dimensions. It highlights the requirement to solve several linear programs (LPs) with parameters that are not easily calculable, which is reflected in the smallscale experiments. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the computational complexity or the limitations of the proposed methods. The lack of detailed evidence or examples makes the claim 3, as the authors would need to delve deeper into the computational aspects to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s discussion of computational aspects, particularly in high dimensions. It points out that the proposed methods require solving several linear programs (LPs) with parameters that are not easily calculable, which is reflected in the smallscale experiments. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors need to provide more detailed computational analysis and potentially explore ways to make their methods more practical for highdimensional applications. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these computational challenges. Overall, the comment is 3 as it directs the authors\" attention to a crucial aspect of their work but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific errors in the equations, providing clear and concrete instructions on how to correct them. It specifies the exact lines where the corrections are needed and what changes should be made, such as replacing \"+\" signs with \"\" signs and adjusting the signs in the definition of B. Additionally, it provides a minor comment about the equation in Line 504. This level of detail and explicit guidance ensures that the authors know exactly what actions to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (Lines 502, 503, and 504), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the errors in the equations, such as the need to replace \"+\" signs with \"\" signs and adjust the signs in the definition of B. Additionally, it provides a minor comment about the equation in Line 504. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections regarding specific mathematical expressions in the paper. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback regarding mathematical errors in the paper. It identifies incorrect signs in equations and suggests corrections, which is crucial for ensuring the accuracy and validity of the mathematical content. By pointing out these errors, the comment empowers the authors to make precise changes that can significantly improve the clarity and correctness of their draft. The inclusion of minor comments further highlights the reviewer\"s attention to detail and commitment to helping the authors improve their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by asking about parameter sharing in the ResNet experiments and suggests a potentially interesting baseline for comparison. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in section 7.1 shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. However, the comment does not provide any evidence, reasoning, or references to support the claim that this comparison would be interesting or equivalent. The suggestion lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet experiments in section 7.1, asking whether the ResNet shares parameters between residual blocks. It also suggests a potentially interesting baseline for comparison, which would involve a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed timestep Euler integrator. This feedback is 3 as it identifies a potential area for exploration and suggests a specific direction for improvement. However, it lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. Therefore, the comment is rated as 3, as it offers some insight but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, stating that it does not \"ignore crossentity comparison\" as claimed. However, it acknowledges that the architecture \"attends to all candidates at once\" to obtain final matching scores. The comment highlights a potential issue with the motivation but does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their motivation, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison.\" However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this claim is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides some specificity by detailing the issue with the motivation, it does not offer detailed guidance on how to address it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture does not \"ignore crossentity comparison\" as stated, but instead \"attends to all candidates at once\" to obtain final matching scores. This claim is 3 as it provides a logical reasoning for the critique, explaining how the architecture functions. However, the comment lacks specific examples or references to support the claim fully, which would make it more robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation behind the crossencoder architecture, pointing out that it does not \"ignore crossentity comparison\" as claimed. Instead, it \"attends to all candidates at once\" to obtain final matching scores. This feedback highlights a potential misrepresentation of the architecture\"s functionality, which could be misleading to readers. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or improve the motivation in their paper. While it identifies an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should reconsider their design choice. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design choice of trimming questions after the first 10 and provides a rationale for this critique, noting that the question model is a bag of words and does not incur significant computational costs for longer sequences. This provides clear guidance on what aspect of the paper needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This claim is 3 as it provides a logical reasoning for questioning the design choice, but it lacks specific examples or references to support the assertion that trimming questions is unnecessary. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that this might be an odd choice, especially since the question model is a bag of words and does not incur significant computational costs for longer sequences. This feedback identifies a potential issue with the experimental design and provides a rationale for why the trimming might not be necessary. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or whether they should reconsider their design choice. While it highlights a potential area for improvement, the feedback could be more actionable and helpful if it included specific recommendations or alternatives. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement, such as recommending more modern alternatives or suggesting ways to update the methods. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an \"antiquated\" GNN model and method, stating that it impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the models or methods are considered antiquated or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an \"antiquated\" GNN model and method, which negatively impacts the performance of the framework. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not offer any constructive feedback or direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be needed to extract shared motifs, implying that the proposed method could simplify this process. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the clarity of the figure. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the explanation process but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, namely the lack of clarity regarding how the proposed method produces the type of explanation shown. The comment suggests that additional adhoc postanalysis might be necessary to extract shared motifs, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Figure 1, specifically regarding how the proposed method produces the type of explanation shown. The reviewer suggests that additional adhoc postanalysis might be necessary to extract shared motifs, implying that the proposed method could simplify this process. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear or that additional analysis is needed. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is unclear how the proposed method produces the type of explanation shown. It suggests that additional adhoc postanalysis might be necessary to extract shared motifs, implying that the proposed method could simplify this process. This feedback is clear and actionable, as it points out a potential weakness in the explanation and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to clarify the explanation or improve the figure. Overall, the comment is 4, as it guides the authors toward enhancing the clarity and comprehensiveness of their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a concern with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the results. The reviewer suggests that the experiment could be strengthened in two ways, but does not specify what these ways are. While the comment implies that the authors should address the issues related to the use of pseudo feature importance and the perturbation value, it lacks explicit guidance on how to do so. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"One experiment to estimate the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of pseudo feature importance and the reliance on Proposition 3.2 and a large enough perturbation value, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is problematic due to its reliance on Proposition 3.2 and the choice of a large enough perturbation value. However, the comment does not provide specific details or examples to support this claim, such as how the pseudo feature importance affects the results or how the perturbation value impacts the experiment. This lack of detailed justification makes the claim 3, as the authors would need to infer the potential issues and address them on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment that estimates the quality of uncertainty estimates, noting that it uses pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the results. The comment suggests that the experiment could be strengthened in two ways, implying that the authors should address these concerns. However, it does not provide detailed guidance on how to improve the experiment or what specific changes could be made. While the comment points out a critical issue, it lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential nonconvexity issue or what properties of function Z should be considered. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182184, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of nonconvexity and suggests that it may not be a problem for the SGD to converge if the function Z has good properties. This provides clear guidance on what needs to be addressed in the specified part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of what \"good properties\" might entail or how they would affect convergence. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. While this observation is relevant and could prompt the authors to consider the properties of function Z, the comment lacks depth and does not provide actionable guidance on how to address this issue or what specific properties of Z should be examined. The feedback is 3 as it identifies a potential area for consideration, but it does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues: the lack of comparison with other models beyond GPT2, confusing sections of the paper, a missing citation/reference in Line 99 of section 3.1, and an unreferenced notation in Line 165 of section 3.4. While the comment identifies these problems, it does not provide explicit instructions or suggestions on how to address them. The authors are left to infer that they need to add comparisons with other models, clarify confusing sections, correct the citation/reference issue, and reference the notation. However, the lack of specific guidance on how to improve these areas makes the comment 3, as the authors know what needs to be done but not exactly how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts being addressed. It specifies the issues with the paper, including the lack of comparison with other models, confusing sections, a missing citation/reference in Line 99 of section 3.1, and an unreferenced notation in Line 165 of section 3.4. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple claims and observations. The first claim about the lack of comparison with other models is not supported by any evidence or reasoning, making it 1. The second claim regarding confusing sections is subjective and lacks specific examples or references to substantiate the claim. The third point about a missing citation/reference in Line 99 of section 3.1 and the unreferenced notation in Line 165 of section 3.4 are factual observations that do not require verification. However, the claim about the authors acknowledging the limitations of their work is a positive statement and does not require verification. Overall, the comment lacks sufficient evidence or reasoning to support the claims, making it 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of comparison with other models beyond GPT2, confusing sections, a missing citation/reference in Line 99 of section 3.1, and an unreferenced notation in Line 165 of section 3.4. It also acknowledges the authors\" effort to acknowledge the limitations of their work. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how to address these issues, such as recommending alternative models for comparison or suggesting ways to clarify the confusing sections. This limits the helpfulness of the feedback, making it 3 as it points out areas for improvement but lacks detailed guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change the color of two lines in the supplementary material from red to green. It also provides specific line numbers and references to the supplementary material, such as SuppMat, L502, L507, and L509, along with the corrections to be made. This level of detail provides clear and concrete guidance on what actions the authors need to take to address the comment. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the supplementary material (SuppMat, L502, L507, and L509) and references to figures or tables (Table 4 and Algorithm 1), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of color changes from red to green for these lines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding specific lines in the supplementary material that should be colored differently. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it identifies a precise issue with the color coding in the supplementary material. It provides clear instructions on which lines should be changed from red to green, along with specific line numbers and references to the supplementary material. This level of detail empowers the authors to make a straightforward correction, ensuring that the feedback is 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but acknowledges that this is not feasible given the paper\"s short length. While the comment implies that the authors should consider a more extensive analysis, it does not provide specific guidance on how to achieve this or what aspects of the analysis should be expanded. The action is implicit and vague, leaving the authors without clear direction on how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper lacks this analysis. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details on what aspects of the analysis are missing or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but acknowledges that this is not feasible given the paper\"s short length. The comment provides a logical reasoning for the suggestion, noting that the current analysis is limited. However, it lacks specific examples or references to support the claim that a more comprehensive analysis would significantly improve the paper. This makes the claim 3, as it provides a rationale but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper is short and suggests that a more comprehensive and dataintensive analysis would significantly improve it. However, it does not provide specific guidance or suggestions on how to achieve this improvement, nor does it offer any actionable steps for the authors to enhance their analysis. The comment lacks depth and does not offer constructive feedback that could help the authors improve their draft. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental settings are not properly mentioned, which is crucial for result reproducibility. It also mentions that the code is not provided. This feedback is clear and direct, providing the authors with specific actions to take: they need to properly document the experimental settings and provide the code. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experimental settings and the lack of code, which are critical for result reproducibility. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the experimental settings and the absence of code, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental settings are not properly mentioned, which is critical for result reproducibility. It also mentions that the code is not provided. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, noting that they are not properly mentioned, which affects result reproducibility. It also points out the absence of code, which is essential for reproducibility. This feedback is clear and actionable, as it highlights specific areas that need improvement. However, the comment could be more helpful if it provided suggestions on how to document the experimental settings or offered guidance on making the code available. Despite this, the comment effectively directs the authors to address a crucial aspect of their work, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations in the evaluation results. It also mentions the absence of a comparison against reinforcement learning (RL) and raises questions about the retraining cost and challenges of including it in the evaluation. The comment provides a clear and concrete action for the authors to take: conduct a comparison with online learning approaches and address the questions raised. This feedback is explicit and provides specific guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the issue of \"online learning formulation overlooking key practical considerations\" is discussed. It also specifies the need for a proper comparison against online learning approaches and reinforcement learning (RL) in the evaluation results. The comment provides clear guidance on what needs to be addressed, such as comparing retraining cost and incremental updates, and why online learning is discarded. This level of detail allows the authors to accurately identify the parts of the paper that require revision and understand the specific issues that need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a proper comparison between the proposed approach and online learning formulations, as well as against reinforcement learning (RL). It raises questions about the retraining cost and challenges of including it in the evaluation. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. The authors would need to provide additional information or examples to fully substantiate the claim, making it a 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a proper comparison between the proposed approach and online learning formulations, as well as against reinforcement learning (RL). It raises important questions about the retraining cost and challenges of including it in the evaluation, which are crucial for understanding the limitations and potential applications of the proposed method. By highlighting these areas, the comment provides clear and actionable feedback that can guide the authors in enhancing the comprehensiveness and rigor of their evaluation. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or address the challenges mentioned. Overall, the feedback is 4 as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should cite works related to metalearning, even though they do not directly target continual learning. It also advises the authors to distinguish between different approaches in metalearning. Additionally, it recommends a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work, as it seems to be an application to continual learning. While the comment provides explicit actions, it lacks detailed guidance on how to implement these suggestions, such as which specific works to cite or how to distinguish the approaches. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and recommends citing works that do not directly target continual learning but are related. It also advises distinguishing between different approaches in metalearning and suggests a more explicit link between the work on RL for architecture search and/or as optimizers for learning and the current work. However, the comment does not specify which parts of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to sections discussing related work or methodology, but the lack of explicit references makes it challenging to pinpoint the exact areas needing revision. The comment is specific in its suggestions, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper connection between the work and metalearning, recommending the citation of related works. It also advises distinguishing between different approaches in metalearning and suggests a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work. While the comment provides a logical reasoning for the connection to metalearning, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to explore the literature to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential connection between the work and metalearning, suggesting that the authors should explore and cite related works. It also advises distinguishing between different approaches in metalearning and highlights the need for a more explicit link between the work on reinforcement learning (RL) for architecture search and/or as optimizers for learning and the current work. This feedback is 3 as it points out an area for expansion and suggests a way to enhance the paper\"s relevance and connections to existing literature. However, the comment could be more helpful if it provided specific examples or references to guide the authors in making these connections. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make it more realistic. While the comment identifies a potential issue and suggests a possible solution, it does not provide explicit instructions on how to implement these suggestions. The action is mostly inferred, and the authors know what needs to be done, but the comment lacks concrete details on execution. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make it more realistic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment where teacher feedback is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with the feedback and suggesting potential improvements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. The reviewer questions whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of lexical and syntactic diversity in teacher feedback, suggesting that it may have been autogenerated. It raises a question about whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make it more realistic. This feedback is 3 as it points out a potential weakness in the methodology and encourages the authors to consider improving the diversity of teacher feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this diversity. Overall, the feedback is clear and actionable, but it could be more comprehensive, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should clarify the existence of additional experiments in the supplement and provide a summary of their results. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a summary of the supplementary experiments. However, the comment provides a clear direction on what needs to be addressed, making it 4.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the existence of additional experiments in the supplement and summarize their results. However, it does not specify which part of the paper this should be addressed in, such as a particular section or figure. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting what needs to be clarified and summarized, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the existence of additional experiments in the supplement and summarize their results. However, it does not provide any specific examples, reasoning, or references to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should clarify the existence of additional experiments in the supplement and provide a summary of their results. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their paper by including this information. However, the comment could be more helpful if it provided specific guidance on how to present these additional experiments or what aspects of the results should be highlighted. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that important references are missing and encourages the authors to conduct a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" It also provides specific references to these works, which are \"Gated Fully Fusion for Semantic Segmentation, AAAI\"20\" and \"EfficientFCN: Holisticallyguided Decoding for Semantic Segmentation, ECCV\"20.\" This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The suggestion to include a comprehensive comparison with these works is explicit and actionable, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, \"GFF[1]\" and \"EfficientFCN[2],\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely a comprehensive comparison with these works, and provides references to the relevant literature. Additionally, it points out the societal impact, which is mentioned on the last page of the manuscript. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important references are missing and suggests a comprehensive comparison with the works \"GFF\" and \"EfficientFCN.\" The reviewer provides specific references to these works, which supports the claim. However, the comment could be strengthened by explaining why these references are important or how they relate to the current work. Despite this, the inclusion of references and the suggestion for comparison provide a solid basis for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references, specifically \"GFF\" and \"EfficientFCN,\" which are relevant to the fast semantic segmentation method in the encodedecoder architecture. The reviewer encourages the authors to conduct a comprehensive comparison with these works, providing specific references to the papers. This feedback is highly valuable as it highlights a critical area for improvement and offers actionable guidance on how to enhance the paper by including relevant comparisons. By suggesting a comparison with these works, the authors can strengthen their contribution and provide a more comprehensive overview of their method. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the validity of the claim regarding the effectiveness of the proposed prompts based on the slight improvement observed in Table 6 and Table 7. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific changes should be made to support the claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of effectiveness, questioning whether the slight improvement supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the claim that \"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why the slight improvement is insufficient to support the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the validity of the claim that the experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. It points out that the slight improvement observed in Table 6 and Table 7 does not adequately support this claim. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their argument. The feedback is 3 as it highlights a concern, but it lacks actionable advice or detailed insights to help the authors improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is explicit and provides clear guidance on what the authors should do to enhance their draft. The comment specifies the exact studies to be considered for comparison, giving the authors a concrete action to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" However, it does not specify which part of the paper this comparison should be made in, nor does it provide guidance on how to incorporate these comparisons into the draft. The authors can infer that it relates to the experimental or results section, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" However, the comment does not provide any reasoning or justification for why these comparisons are necessary or how they would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these suggestions. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is clear and actionable, as it provides the authors with specific references to consider for enhancing their draft. By comparing their work with these studies, the authors can gain insights into how their approach aligns with or differs from existing methods, potentially leading to improvements in their work. However, the comment could be more helpful if it explained why these comparisons are important or how they might impact the paper\"s contributions. Overall, the feedback is 4 as it offers a concrete suggestion for enhancing the paper\"s quality and relevance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"Cycle FC align features\" and suggests that the analysis is insufficient. It implies that there could be various designs for this feature, such as experiments with different sampling intervals and sample sizes. However, the comment does not specify which part of the paper discusses the Cycle FC align features, making it weakly grounded. The suggestion to consider different designs is specific, as it provides a clear direction for potential improvements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analysis of the Cycle FC align features is insufficient and proposes that experiments or analysis with different sampling intervals and sample sizes could be considered. However, the comment lacks specific examples or references to support the claim that the analysis is insufficient or to justify the need for additional experiments. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a potential weakness in the analysis of the Cycle FC align features, suggesting that the current analysis is insufficient. It proposes that the authors consider different designs, such as experiments with various sampling intervals and sample sizes, to enhance the analysis. This feedback is 3 as it points out an area for improvement and provides a specific suggestion for expanding the analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of similar analyses in the literature. Overall, the comment provides some direction for the authors to consider, but it could be more comprehensive and actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. This feedback implies that the authors should include standard deviations to provide a clearer understanding of the results. However, it does not explicitly instruct the authors to add standard deviations or explain how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not know the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the results, which makes it difficult to determine if the best method is indeed the best or if other RF configurations have similar performances. However, it does not specify which part of the paper this issue pertains to, such as a particular table or figure where the results are presented. Without explicit references to specific sections or results, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique of the lack of standard deviations but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations makes it difficult to determine if the best method is truly the best or if other RF configurations have similar performances. This claim is 3 as it logically reasons that standard deviations are necessary for a comprehensive understanding of the results. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a significant omission in the presentation of results, specifically the lack of standard deviations. This is a critical issue because it makes it difficult for the reader to understand the variability and reliability of the results. By highlighting this gap, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to include standard deviations or suggested alternative ways to present the data. Despite this, the comment effectively directs the authors to a crucial aspect of their results that needs attention, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer asks if the approach can be extended to more general settings. While the comment implies that the authors should consider broadening the applicability of their approach, it does not provide explicit guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more general settings but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the setting, but it lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer asks if the approach can be extended to more general settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it could be addressed. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the question and how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer questions whether this approach can be extended to more general settings, which is a relevant and important consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might broaden the applicability of their approach or what general settings they could consider. While it identifies a potential limitation, it does not provide actionable feedback to help the authors improve their draft. Therefore, the comment is 3, as it prompts the authors to consider a broader scope but does not offer detailed guidance on how to achieve this."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dimensionality of each region and the feature extractor used, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on how to address the question or what information should be added to clarify this aspect of the paper. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the dimensionality of each region and the feature extractor used, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is a clear and actionable point for the authors to address. By asking for clarification on this aspect, the comment provides a direct way for the authors to improve their draft by ensuring that the information is accurate and complete. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context. Overall, the comment is 4 as it identifies a specific area for improvement and guides the authors toward enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which aspects of the computation, algorithm, or implementation should be detailed or how these details should be presented. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete guidance on what specific details to include or how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment lacks specificity regarding what specific details should be provided or how they would enhance the paper. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks depth and does not provide a clear justification for the claim, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, the comment lacks specificity and does not offer guidance on what specific details should be included or how they should be presented. This makes it difficult for the authors to understand what changes are needed to enhance their draft. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, implying that the authors should provide an explanation or justification for this selection. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to address the question. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the choice of p, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of how the value of p < 0.4 was chosen, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable point for the authors to address. By asking for an explanation of this choice, the reviewer prompts the authors to provide additional context or justification for their methodological decisions. This feedback is valuable as it directs the authors to clarify an important aspect of their work, potentially enhancing the transparency and comprehensibility of their methodology. However, the comment could be more helpful if it provided additional context or suggestions on how to address the question. Overall, the comment is 4, as it identifies a specific area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It also specifies the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and direct, providing the authors with specific actions to take to improve their draft. The explicit nature of the instructions and the concrete details on what needs to be addressed make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and \"Figures 1, 2, and 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of explanations or analysis for these figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This provides clear guidance on what the authors need to revise. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors failed to provide explanations or analysis for Figures 1, 2, and 3 in Section 5. It specifically points out the need for clarification regarding the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanations or analysis for Figures 1, 2, and 3 in Section 5. It highlights the need for clarification regarding the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by addressing these gaps. However, the comment could be more helpful if it offered suggestions on how to present these explanations or analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what aspects of the motivation need more detail. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the motivation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying CMD in federated learning, suggesting that it could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of the motivation, but without explicit references to specific sections, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that a more explicit demonstration or explanation would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the unclear motivation behind applying CMD in federated learning. It suggests that a more explicit demonstration or explanation would be beneficial. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the explanation or demonstration. Without detailed advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It provides specific references to support the suggestion for comparison, such as [1] and [2]. While the comment implies that the authors should conduct a more comprehensive analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lack of Analysis\" and refers to the insufficient analysis of the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, which provides clear guidance on what needs to be addressed. The comment is specific in detailing the areas that need improvement and provides references for further comparison, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to external works, such as [1] and [2], which supports the suggestion for comparison. However, the claim about the lack of analysis is not fully substantiated with specific examples or detailed reasoning, making it 3. The authors would need to consult the referenced works to fully understand the context and implications of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of evaluation of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would help clarify the unique advantages of the method. The comment provides specific references to external works that could serve as a basis for comparison, offering a clear and actionable path for the authors to enhance their analysis. By addressing these points, the authors can significantly improve the depth and comprehensiveness of their evaluation, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to understand the net effect of each component, particularly in the context of learning with MMD. It provides specific examples of experiments that could be performed, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is explicit and concrete, as it clearly outlines the actions the authors should take to improve their draft. The authors know exactly what experiments to conduct to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the section on \"learning with MMD\" and suggests conducting an ablation study to understand the net effect of each component. It provides specific examples of experiments that could be performed, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This makes the comment fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that an ablation study is necessary to understand the net effect of each component in the learning process with MMD. It provides specific examples of experiments that could be conducted, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is logical and provides a clear rationale for why an ablation study is needed. However, it lacks specific references or detailed explanations of how these experiments would contribute to the understanding of the MMD learning process. Therefore, the comment is 4, as it provides a solid foundation for the claim but could be strengthened with additional details or references.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that an ablation study is necessary to understand the net effect of each component in the learning process with MMD. It provides specific examples of experiments that could be conducted, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is clear and actionable, offering the authors concrete steps to take to improve their draft by providing a more comprehensive understanding of the components involved. However, the comment could be more helpful if it explained why an ablation study is crucial or how it would impact the overall understanding of the paper. Overall, the comment is 4 as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider or investigate this aspect, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this aspect further. However, the question itself is clear, and the authors can deduce that they need to consider this scenario. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper this comment addresses, making it weakly grounded. The comment is specific in its inquiry about the performance of a particular model configuration, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of a specific model configuration. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider an important aspect of their model\"s performance. This inquiry can help the authors evaluate their model\"s robustness and potential vulnerabilities, which is a valuable insight. However, the comment lacks depth and does not offer actionable advice on how to address this issue or improve the model. Therefore, it is 3, as it provides a direction for further exploration but does not fully guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. While the comment identifies an area of concern and raises a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the scalability of RLCD to larger models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that the advantage of RLCD over RLAIF diminishes as the model size increases and raises a question about the scalability of RLCD to larger language models. This provides clear guidance on what needs to be addressed or explored further in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the diminishing advantage of RLCD over RLAIF as the model size increases from 7B to 30B, as observed in Table 2. It also questions whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an observation and raises a question, it lacks specific evidence, examples, or references to support the claim about the scalability of RLCD. The reasoning is somewhat logical but incomplete, making the claim 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a trend observed in the paper, noting that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. It raises a question about whether RLCD (or RLCDRescore) can scale to even larger language models that are better at differentiating responses near the decision boundary. This feedback is 3 as it points out a potential limitation in the paper and encourages the authors to consider the scalability of their approach. However, it lacks specific suggestions or guidance on how to address this issue or improve the scalability of RLCD. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without a solution to this issue. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the scalability problem but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, specifically mentioning its applicability to largescale datasets like ImageNet. However, it does not specify which part of the paper discusses the NC measure or its scalability issues, making it weakly grounded. The comment is specific in identifying the problem of scalability and suggesting that the practical contribution of the paper could be reduced without a solution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, questioning how it can be applied to largescale datasets like ImageNet. The comment suggests that the practical contribution of the paper could be significantly reduced without addressing this issue. However, the comment lacks specific examples or references to support the claim about the scalability problem or potential solutions. This makes the claim 3, as it provides a logical concern but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet, suggesting that the practical contribution of the paper could be significantly reduced without addressing this issue. This feedback is valuable as it highlights a potential limitation of the proposed method and prompts the authors to consider scalability in their approach. However, the comment could be more helpful if it provided suggestions or ideas on how to address the scalability issue, such as proposing alternative methods or techniques that could be used to improve scalability. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of quantitative analysis on computational gains, specifically mentioning the need for specific measurements or comparisons to substantiate the claimed benefits. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements in DQ V2. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, which allows the authors to identify the specific part of the paper being addressed. It also specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. This provides clear guidance on what needs to be addressed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the claimed computational benefits of replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. This claim is 3 as it highlights a gap in the paper\"s analysis but lacks specific examples or references to support the need for such quantitative analysis. The authors would need to consider this feedback and potentially include additional data or comparisons to strengthen their claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of quantitative analysis on computational gains. It highlights the need for specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNNbased data augmentation strategy. The comment provides a clear and actionable suggestion by recommending a quantitative analysis, such as GPU hours, memory usage, or training time, to strengthen the evidence of efficiency improvements in DQ V2. This feedback is valuable as it directs the authors to a critical aspect of their work that requires further development. However, it could be more helpful if it included examples or references to guide the authors in conducting the quantitative analysis. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or comparisons. The action is implicit and somewhat vague, as it lacks specific instructions on how to address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would impact its efficiency for certain scenes. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how to address the issue of efficiency. The authors might infer that it relates to the experimental results or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the method, suggesting that the time for COLMAP and scenebyscene finetuning should be considered. This is a relevant point that could impact the efficiency of the method for certain scenes. However, the comment lacks specificity and does not provide detailed guidance on how the authors should incorporate this consideration into their analysis or comparisons. Without actionable suggestions or examples, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical component of the technique. It asks if the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger input and output channels. These questions imply that the authors should provide more discussion, analysis, or experimental results regarding FMN. While the comment does not explicitly instruct the authors to conduct specific experiments or analyses, it provides a clear direction for what needs to be addressed. The authors can infer that they need to provide more detailed information about FMN, its scalability, and potential experiments. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks specific instructions on how to implement the suggested actions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), which is a specific part of the paper being addressed. This allows the authors to accurately identify the section of the paper that needs attention. The comment is also specific because it raises several questions and concerns about the FMN, such as the lack of discussion or analysis, the use of other architectures, the scaling of adaptive convolutions, and the scalability of FMN with larger input and output channels. These specific questions provide clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical component of the technique. It questions the lack of discussion or analysis on FMN, the use of other architectures for FMN, and the scalability of adaptive convolutions with the number of filter parameters. While the comment highlights areas that need further exploration or clarification, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed justification or examples makes the claims 3, as the authors would need to infer the importance of these aspects based on the questions raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is a crucial component of the technique. It raises several questions, such as whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger input and output channels. These questions highlight important areas that need further exploration and clarification in the paper. By addressing these questions, the authors can provide a more comprehensive understanding of their technique and its potential applications. The comment is 4 as it provides clear and actionable feedback that can guide the authors in improving their draft, but it could be more helpful if it offered specific suggestions on how to address these gaps. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The comment further supports its claim with references to relevant works by Raonic et al. and Gupta et al., providing additional context and justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. The comment provides a logical reasoning by pointing out the potential confusion and the need for comparisons, and it supports this reasoning with specific references to external works. This makes the claim 4, as it provides a clear rationale and relevant references, but could be further strengthened with more detailed examples or analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This feedback is clear and actionable, as it directs the authors to include comparisons to UNets to clarify the source of the performance boost. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment explicitly suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the experiment part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of computation complexity and suggests that a comparison of computation complexity should be included in the experiment part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines. It provides a specific explanation of the computation complexity issue by mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by including specific numerical comparisons or references to existing literature to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It provides a detailed explanation of the computation complexity issue, specifically mentioning the calculation of all flipped previous layer outputs into the current layer in Algorithm 1. The comment also suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, offering the authors a specific area to address and a concrete suggestion for improvement. By highlighting the computational complexity and suggesting a comparison, the comment empowers the authors to enhance the comprehensiveness and rigor of their experimental evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should investigate the individual contributions of two factors: noise and the exponential moving average. It explicitly recommends comparing the performance of the proposed model with and without each factor to understand their separate impacts. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should investigate the individual contributions of two factors: noise and the exponential moving average. It provides a specific suggestion for analysis, which is to compare the performance of the proposed model with and without each factor. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The authors can infer that it relates to the experimental or results sections, but the exact location is not explicitly mentioned. The comment is specific in its suggestion, so it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the proposed model benefits from two factors: noise and the exponential moving average. It recommends analyzing how much each factor contributes individually. The comment provides a logical reasoning by suggesting a specific analysis to understand the impact of each factor, which is a reasonable request for improvement. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to conduct the suggested analysis to fully understand the claim, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies two factors that contribute to the proposed model\"s performance\u2014noise and the exponential moving average\u2014and recommends analyzing how much each factor contributes individually. This feedback is clear and offers a concrete direction for the authors to explore, which could lead to a deeper understanding of the model\"s strengths and weaknesses. By suggesting a comparison of the model\"s performance with and without each factor, the comment empowers the authors to make a more comprehensive evaluation of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as increasing the font size in figures 1 and 2, making the words in the grey box larger, and ensuring that \"V_mem, Th_i, U_i^t\" are not too small. It also suggests adding a \"table\" to compare the number of epochs and parameters with other stateoftheart Transformer designs. These suggestions are concrete and provide clear guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on the font size and clarity of certain elements, such as the words in the grey box and the labels \"V_mem, Th_i, U_i^t.\" Additionally, it suggests improvements for the \"CTRL\" explanation and the font size in figure 2. The comment is specific in detailing what needs to be addressed in each part, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first part is a subjective opinion about the quality of the figures, which is not verifiable as it lacks specific evidence or reasoning. The second part suggests improvements, such as increasing font sizes and adding a table for comparison, which are factual and do not require verification. The third part claims a lack of detail in comparisons with other stateoftheart Transformer designs, which is 3 as it provides a logical suggestion for improvement but lacks specific examples or references. Overall, the comment is a mix of subjective opinions and suggestions, making it difficult to categorize as a whole. However, since it does not contain a single claim that requires verification, it aligns with the label \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the visual presentation of the paper, suggesting improvements to the font size and clarity of certain elements in the figures. It also identifies a lack of detail in comparisons with other stateoftheart Transformer designs, recommending the inclusion of a table to emphasize the data and justify the improved accuracy. This feedback is clear and provides concrete suggestions for enhancing the draft, making it 4 for the authors. However, it could be more comprehensive by offering additional guidance on how to structure the comparisons or what specific details to include. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the timing of the results presentation, suggesting that the authors should also report on the agent\"s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. The comment also wonders if the CNN can perform reasonably well with less data. While the comment identifies areas for potential improvement, it does not provide explicit or concrete actions for the authors to take. The suggestions are vague and lack specific guidance on how to address the issues raised. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the timing of the results presentation and speculates about the performance of the model during the learning process. However, it does not explicitly mention a specific part of the paper, such as a section or figure, where this issue is discussed. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in its suggestion to report on the agent\"s behavior during learning and speculates about the model\"s performance with less data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the timing of the results presentation and speculates about the model\"s performance during the learning process. The reviewer suggests that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. However, the comment is based on speculation and lacks specific evidence or references to support these claims. The reasoning is logical but not fully substantiated, making the claim 3. The authors would need to consider this feedback and potentially conduct additional analysis to address the concerns raised.", "helpfulness_rationale": "The review comment raises a valid concern about the timing of the results presentation, suggesting that the authors should also report on the agent\"s behavior during the learning process. It speculates that the model parameters might be ineffective early in training and that the planning component could potentially harm the performance. This feedback is 3 as it prompts the authors to consider an important aspect of their work that could provide additional insights into the model\"s behavior. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending specific metrics or analyses to include. Therefore, while it identifies a relevant area for improvement, it could be more helpful with additional detail or actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to rewrite a specific sentence that is unclear. It provides a clear action for the authors to take, which is to rephrase the sentence to improve clarity. The feedback is direct and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence that is unclear, \"While a smaller j to simulate more accumulate errors along with the inference steps,\" and references pages 5 and 3, line. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, which is the rewriting of the sentence to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to rewrite a sentence that is unclear. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific sentence that is unclear and requests the authors to rewrite it. This feedback is clear and actionable, as it directly points out a part of the paper that needs improvement and provides a specific task for the authors to complete. By addressing this issue, the authors can enhance the clarity and readability of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors handle concepts in DocRED, specifically whether they consider documents as entire sentences and how they deal with multiple entity mentions referring to the same entity. The comment highlights that this information is currently missing from the manuscript. While the comment implies that the authors should address this gap, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their manuscript. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the authors handle concepts in DocRED, specifically whether they consider documents as entire sentences and how they deal with multiple entity mentions referring to the same entity. However, it does not specify which part of the manuscript this issue is discussed in, making it weakly grounded. The comment is specific in detailing what information is missing, which is the handling of concepts in DocRED. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the handling of concepts in DocRED, specifically whether the documents are considered as entire sentences and how multiple entity mentions referring to the same entity are dealt with. The comment points out that this information is currently missing from the manuscript. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that this information is missing or how it should be addressed. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the handling of concepts in DocRED, particularly whether the documents are considered as entire sentences and how multiple entity mentions referring to the same entity are dealt with. It points out that this information is currently missing from the manuscript, which is a relevant observation that could help the authors clarify their methodology and improve the clarity of their work. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue or what specific aspects of the methodology need further explanation. Overall, the comment is 3 as it identifies a gap in the manuscript but lacks depth in terms of actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a subjective opinion that the contribution is marginal, suggesting that the methods used are welldesigned and demonstrated. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, suggesting that it is marginal because the methods used are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as a particular section or methodology. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment does not provide specific details on what aspects of the contribution are considered marginal or how they could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal, suggesting that the methods used are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the judgment. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. However, it does not provide any specific feedback or suggestions on how the authors might enhance their contribution or address the perceived lack of novelty. Without actionable guidance or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the main contribution and questions the motivation behind the PBSD component, given that the paper is primarily motivated by supervised contrastive learning (DSCL). It suggests that the performance gain is mostly attributed to PBSD, but it does not provide explicit guidance on how the authors should address this issue or clarify the contribution. The comment implies that the authors should provide additional motivation or explanation for the PBSD component, but it does not specify what kind of motivation or explanation is needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It references the ablation study to highlight the performance gain attributed to PBSD. However, the comment does not specify which part of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in its request for additional motivation for PBSD beyond improving discriminative representation on tail classes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It references the ablation study to highlight the performance gain attributed to PBSD, but it does not provide specific examples or detailed reasoning to support the claim that the motivation for PBSD is unclear. The comment lacks sufficient evidence or references to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the main contribution, specifically questioning the motivation behind the PBSD component in the context of a paper primarily motivated by supervised contrastive learning (DSCL). It points out that the performance gain is mostly attributed to PBSD, but the paper does not provide clear motivations for this component beyond improving discriminative representation on tail classes. This feedback is 3 as it identifies a potential area of confusion in the paper and prompts the authors to clarify the role and motivation of PBSD. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered examples of alternative motivations. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. While the comment highlights a potential issue, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or address the issue but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which allows the authors to accurately identify the part of the paper being addressed, likely referring to a specific section or part of the manuscript. It is also specific because it raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. The comment provides a specific example of how the tester might not handle certain pairs, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the tester for the spread parameter and whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This example is a logical deduction based on the information provided, but it does not include specific references or detailed reasoning to fully substantiate the claim. The comment is 3 as it provides a clear example of the issue but lacks comprehensive evidence or references to fully support the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the tester for the spread parameter, specifically whether it immediately yields an (\u03f5, \u03b4)identity tester. It provides an example of how the tester might not handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d50 but dK(\u03c00, \u03c0) is large. This feedback is 3 as it identifies a potential issue with the tester and prompts the authors to clarify or address this concern. However, the comment lacks specific guidance or suggestions on how to resolve the issue, which limits its usefulness. To be more helpful, the comment could include recommendations or examples of how to improve the tester or address the specific scenario mentioned. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment highlights a potential area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the additional experiments should be emphasized or clarified. As a result, the comment lacks actionability, leaving the authors without a clear path for improvement.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. This provides some specificity about the part of the paper that the reviewer did not fully engage with, but it does not specify what aspects of the additional experiments need attention or improvement. The comment is weakly grounded because it does not explicitly mention which section of the paper the additional experiments are located in, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a factual statement expressing appreciation for the comprehensive Appendix and acknowledging the reviewer\"s inability to thoroughly read the additional experiments due to time constraints. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive Appendix as a valuable addition to the paper, providing additional detail about certain aspects. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment appreciates the effort to provide more detail, it lacks actionable feedback or suggestions for improvement. It does not guide the authors on how to address the issue of not fully engaging with the additional experiments or what specific aspects might need further clarification or emphasis. As a result, the comment is 2, as it provides some insight but does not offer actionable advice for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not provide explicit guidance on how to address this issue or clarify the distinction between the two methods. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description and potentially provide more information about the active learning pipeline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. It suggests that if the methods are not the same, the description could be misleading. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in its questioning of the method\"s description, but without clear grounding, the authors may find it challenging to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim of using active learning in step 2 and whether the \"active learning pipeline\" method is the same as traditional active learning. The comment raises a potential issue of misleading description but does not provide specific evidence or examples to support the claim. It lacks detailed reasoning or references to substantiate the concern, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning. This prompts the authors to clarify their description and ensure that it accurately reflects their methodology. By pointing out this potential ambiguity, the comment encourages the authors to provide more detailed and accurate information about their active learning approach. However, the comment could be more helpful if it offered suggestions on how to clarify the description or provided examples of how to differentiate between the two methods. Overall, the comment is 3 as it identifies a potential area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what specific information should be included or how the distribution should be clarified. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the distribution is discussed. Without explicit references or context, the authors may find it challenging to identify the exact area needing clarification. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it lacks any actionable guidance or suggestions on how the authors might clarify this aspect. Without additional context or specific advice, the authors are left without a clear understanding of what changes are needed to improve their draft. This makes the comment 3, as it points out a potential issue but does not provide sufficient direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not explicitly instruct the authors to implement a selfsupervised approach or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors can infer the need for a different approach but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of the current approach. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in its suggestion for improvement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method requires annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples, references, or detailed reasoning to support why a selfsupervised approach would be more appealing or how it could be implemented. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the potential benefits of a selfsupervised approach based on general knowledge. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which requires annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it points out a potential limitation and offers a direction for improvement by suggesting an alternative approach. However, the comment lacks specific guidance on how to implement a selfsupervised pretraining approach or what benefits it might offer. To be more helpful, the comment could include more detailed suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that to fully demonstrate the scalability of LFF, the authors should conduct experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies the type of tasks that should be included, offering concrete guidance on how to enhance the demonstration of LFF\"s scalability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion should be addressed in, making it weakly grounded. The comment is specific in suggesting the types of tasks that should be included to demonstrate scalability, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, which is based on the common practice of evaluating continuous control experiments on simple tasks. However, the comment lacks specific examples or references to existing literature that have successfully applied LFF to such challenging tasks, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It points out that most continuous control experiments are conducted on simple and lowdimensional tasks, such as cartpole or mountain car, and suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, like locomotion of ants or humanoids. This feedback is specific and offers a concrete direction for the authors to enhance the paper\"s scope and impact. By addressing this suggestion, the authors can provide a more comprehensive evaluation of LFF\"s capabilities, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit suggestions for improvement. First, it recommends adding a specific phrase to the abstract to enhance clarity, suggesting a change in wording to include a reference to the change in linear regions in output space. Second, it suggests including learning curves for all experiments, at least in an appendix. These suggestions are clear and concrete, giving the authors specific actions to take to improve their draft. The feedback is explicit and provides detailed guidance on how to implement the changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting a change in the wording of \"attain greater expressivity\" to include a reference to the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments, at least in an appendix. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a change in the abstract to include a specific phrase related to the change in linear regions in output space after a citation. It also recommends including learning curves for all experiments, at least in an appendix. While the suggestion for the abstract is clear, the comment lacks specific reasoning or evidence to support why the current phrasing is inadequate or why the inclusion of learning curves is necessary. The claim is 3 as it provides a logical suggestion but lacks detailed justification or references to substantiate the need for these changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it recommends a more detailed and specific phrase to use in the abstract, suggesting a change in wording to include a reference to the change in linear regions in output space after a citation. This feedback is actionable and helps the authors enhance the clarity and precision of their abstract. Second, it suggests including learning curves for all experiments, at least in an appendix, which would provide additional insights into the performance of the models. This suggestion is clear and actionable, offering a concrete way for the authors to enhance the comprehensiveness of their results. Overall, the comment is 4 as it offers detailed and actionable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and the practical application of the proposed method. It suggests that the paper should demonstrate the methodology\"s use in actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide more context and examples to clarify the paper\"s motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional examples or context to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clarity regarding the paper\"s motivation and the application of the proposed method. It also provides specific examples of how the methodology could be demonstrated, such as adapting a model trained on a synthetic dataset to a real dataset. This allows the authors to accurately identify the parts of the paper that need revision and understand what specific issues need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s motivation is unclear and lacks a clear application of the proposed method. The reviewer questions the need for domain adaptation and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. While the comment provides some logical reasoning by questioning the practical application of the method, it lacks specific examples or references to support the claim. The suggestion to demonstrate the methodology on tasks like adapting a model from a synthetic to a real dataset is a good starting point, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the claim is 3, as it provides a basis for the critique but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation and application, questioning the practical relevance of the proposed method. It highlights the need for clearer demonstration of the methodology\"s use in actual tasks involving domain adaptation, such as adapting a model from a synthetic to a real dataset. This feedback is valuable as it prompts the authors to provide more context and examples to justify the importance and applicability of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of potential applications. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for considering MULT as the only deep learningbased baseline that considers crosssensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or suggest alternative baselines. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed. It mentions specific papers (MISA, M2FNet, MMDFN) but does not indicate where in the paper these references are discussed. Additionally, the comment is not specific as it does not detail what needs to be addressed regarding the consideration of MULT as a baseline. The authors cannot confidently determine which part of the paper is being critiqued, and the comment lacks specificity in terms of what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is \"out of fashion.\" This claim is 3 as it provides a logical reasoning about the relevance of the baseline, but it lacks specific examples or references to support the assertion that MULT is outdated. The comment could be strengthened by including more detailed information or references to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for considering MULT as the only deep learningbased baseline that considers crosssensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" This feedback highlights a potential weakness in the paper\"s choice of baseline, suggesting that the authors may have overlooked more recent or relevant works. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their selection of baselines. Without specific recommendations or examples of alternative baselines, the feedback is 3 as it points out a potential area for improvement but does not provide detailed guidance for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It provides a clear action for the authors to take: they must compare the tensor completion results for all models with the same number of model parameters. The comment also suggests a method for computing the number of model parameters by adding the number of entries of all core tensors for each model. This feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the comparison against other models in the experiments, specifically the omission of value ranks for all models. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: comparing tensor completion results for all models with the same number of model parameters. The suggestion to compute the number of model parameters by adding the number of entries of all core tensors for each model provides concrete guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of value ranks for all models. It suggests that to show the superiority of TW over TT and TR, the authors should compare the tensor completion results for all models with the same number of model parameters. The comment provides a logical reasoning by explaining that the number of model parameters can be computed by adding the number of entries of all core tensors for each model. This reasoning is clear and provides a specific suggestion for improvement, making the claim 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It provides a clear and actionable suggestion for improvement by recommending that the authors compare the tensor completion results for all models with the same number of model parameters. This feedback is highly valuable as it directs the authors to a specific area needing attention and offers a concrete step to enhance the clarity and fairness of their experiments. The comment also includes a suggestion for computing the number of model parameters, which further supports the authors in making the necessary adjustments. Overall, the comment is 5 as it provides detailed and actionable feedback that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include ATA in the comparison in Table 2, as it is better than FP according to the results in Table 1. This is an explicit action with clear guidance on what needs to be done to improve the draft. The comment provides a specific suggestion for enhancing the comparison, making it 5. The authors know exactly what action to take to address the feedback, which is to include ATA in the comparison in Table 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison to \"ATA\" in Table 2, and suggests that including it would make the results more convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in addition to \"+LFP\" in Table 2, as \"ATA\" is better than \"FP\" according to the results in Table 1. This claim is 3 as it provides a logical reasoning based on the results presented in the paper. However, it lacks specific examples or detailed comparisons to fully substantiate the claim, making it 3. The authors would need to consider the additional comparison to strengthen their argument, but the comment provides a clear direction for improvement.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"+LFP\" under the leave one out setting. It suggests that including ATA in the comparison would be more convincing, given that ATA is better than FP according to the results in Table 1. This feedback is clear and actionable, providing the authors with a specific suggestion for enhancing the robustness and credibility of their results. By addressing this point, the authors can improve the comprehensiveness and persuasiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and specific issues with Figure 4. It also mentions minor problems with the text, such as a formatting issue on page 4. While the comment identifies several areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the normalization module, figures, and a particular figure (Fig. 4), allowing the authors to accurately identify the sections being addressed. It also specifies the issues with the normalization module, the need for standardization of pictograms, and the confusion in Figure 4. Additionally, it mentions a minor problem with the text on page 4. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several issues, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and specific issues with Figure 4. However, the comment does not provide detailed reasoning or evidence to support these claims, such as explaining why the normalization module seems different or how the standardization of pictograms would improve the figures. Additionally, it mentions minor problems with the text but does not specify what these issues are. Without sufficient justification or examples, the claims are difficult for the authors to address, making the comment barely verifiable.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including a discrepancy in the normalization module between two versions, the need for standardization of pictograms in figures, and a particular issue with Figure 4 regarding overlapping symbols. It also mentions minor problems with the text, such as a formatting issue on page 4. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific weaknesses, but it lacks depth and actionable advice, leaving the authors with a general understanding of what needs to be improved. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning how the proposed algorithm removes subdivision splines and whether it incurs an extra computation cost. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should provide more detailed information about the algorithm and its computational costs. However, the comment lacks concrete details on how to implement this improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theoretical part\" of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue by questioning the detailed explanation of how the proposed algorithm removes subdivision splines and whether it incurs an extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the removal of subdivision splines and the potential extra computation cost for space partition building. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical part of the paper, questioning the claim that the proposed algorithm removes subdivision splines and the potential extra computation cost for space partition building. This feedback is 3 as it highlights a potential gap in the explanation of the algorithm and its implications. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out an area for improvement, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that certain terms, such as W1, W2, and W, are not defined in the paper. The reviewer suggests that these terms might denote the Encoder and Decoder network, but this is only a guess. The comment does not provide explicit guidance on how to define these terms or where they should be defined in the paper. While it implies that definitions are needed, the action is vague and lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections and equations (p.3, A4, eq.3) where terms like W1, W2, and W are not defined. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what is missing\u2014definitions for these terms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding the absence of definitions for certain terms (W1, W2, and W) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of definitions for certain terms (W1, W2, and W). It provides clear guidance by suggesting that these terms might denote the Encoder and Decoder network, which is a reasonable inference. However, the comment could be more helpful if it offered suggestions on where or how these definitions should be included in the paper. Despite this, the feedback is 3 as it directs the authors\" attention to a critical area that needs clarification. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with certain baselines is unfair because they lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not specify what this better comparison would entail or how the authors should implement it. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without clear guidance on how to make them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison with some baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, it does not specify which baselines are being referred to or where in the paper these comparisons are made. This lack of specificity and grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or any language embedding computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison to certain baselines, suggesting that the lack of prior knowledge of users or language embedding computation makes the comparison unfair. It implies that a better comparison should be considered, which is a valuable insight for the authors. However, the comment lacks specificity and does not provide detailed guidance on what a better comparison might entail or how the authors should implement it. While it highlights an area for improvement, the feedback could be more actionable and helpful with additional details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of limitations and societal impact discussions. While the comment identifies several areas that need clarification or expansion, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about specific parts of the paper, such as the outputside layers, Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2. These references provide full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be clarified or addressed in each of these parts, such as the benefits of outputside layers, the clarity of Figure 4, and the presentation of Pixelshuffle details. Additionally, it points out the absence of discussions on limitations and societal impact. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the potential benefits of outputside layers, the clarity of Figure 4, the presentation of Pixelshuffle details, and the use of pixelshuffle in the superresolution field. It also questions the dimensionality after upsampling in Figure 2 and notes the absence of discussions on limitations and societal impact. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or supporting information renders the claims 1, as the authors are left without a clear path to address the concerns. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the potential benefits of the outputside layers, which could be a significant oversight in the paper. Additionally, it points out that Figure 4 is not clearly illustrated, and the details of Pixelshuffle are not presented clearly. The comment also questions the use of pixelshuffle in the superresolution field and the dimensionality after upsampling in Figure 2. Furthermore, it notes the absence of discussions on limitations and potential negative societal impacts, which is a critical aspect of any research paper. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity of the figures and the presentation of Pixelshuffle details. Overall, the comment identifies important areas for improvement but could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during the training stage. It also inquires whether this process would improve performance. While the comment identifies a potential area of confusion or improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the process and its impact on performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during the training stage. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its inquiry about the process and its potential impact on performance, but it is 1. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of questions seeking clarification about the process of generating negative chips from a lightweight RPN and whether this process affects performance. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking whether they are fixed or updated during the training stage. It also inquires whether this process would help improve performance. While the comment identifies a potential area of confusion or improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore its impact on performance. The feedback is 3 as it prompts the authors to clarify their process, but it does not provide actionable steps or detailed advice for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for this evaluation but may not know exactly how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the experimental or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting a particular evaluation scenario, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients, which is a logical and actionable step to ensure the robustness of the method. However, the comment lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects to focus on. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, limiting its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that most baselines do not use this dataset, which could provide an unfair advantage to the proposed method. The comment implies that the authors should clarify whether 300WLP is used in all experiments or just some, and if so, how this affects the fairness of the comparison. While the comment identifies an issue, it does not explicitly instruct the authors to clarify or address this point. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the experimental methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines. The comment asks if 300WLP is used in all experiments or just some, suggesting that its use could provide an unfair advantage to the proposed method. This issue is related to the experimental setup and methodology, which is discussed in the paper. However, the comment does not explicitly mention a specific section or part of the paper where this issue is addressed, making it weakly grounded. The comment is specific in detailing the concern about the use of 300WLP and its potential impact on fairness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that using 300WLP in all experiments would be unfair. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental methodology, specifically questioning the use of the 300WLP dataset in training the model. It points out that the paper initially states that 300WLP is used for training but later claims the same procedure is used as for the baselines, which most do not use. The comment raises a concern about whether 300WLP is used in all experiments or just some, and if so, how this could provide an unfair advantage to the proposed method. This feedback is 3 as it highlights a potential flaw in the experimental setup and prompts the authors to clarify their methodology. However, it could be more helpful if it provided specific suggestions on how to address this issue or offered guidance on how to ensure fairness in the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their techniques. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on why these techniques are not novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of certain techniques used in the algorithm, such as computation offloading and gradient augmentation. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this concern or enhance the novelty of their work. Without actionable guidance or detailed feedback, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the formulation introduced by the authors, suggesting that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average. It also provides specific examples, like disease incident data being available in counts or rates per number of residents. While the comment identifies a potential limitation and provides examples, it does not explicitly instruct the authors to address this issue or suggest how to modify their formulation. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, pointing out that the observations might be aggregated by methods other than averaging, such as summation or populationweighted average, and provides specific examples like disease incident data. This level of detail helps the authors understand what needs to be addressed in their formulation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation introduced by the authors assumes observations are obtained by averaging over the corresponding support, but this might not be the case. The reviewer suggests that data could be aggregated by other methods, such as summation or populationweighted average, and provides specific examples like disease incident data being available in counts or rates per number of residents. This reasoning is logical and provides a clear explanation of the potential issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the use of alternative aggregation methods. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that this assumption might not hold, as data could be aggregated by other methods, such as summation or populationweighted average. The comment provides specific examples, like disease incident data being available in counts or rates per number of residents, which helps the authors understand the potential limitation of their formulation. This feedback is clear and actionable, as it prompts the authors to consider alternative aggregation methods and potentially revise their formulation to accommodate these variations. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. While the comment implies that the authors should conduct an analysis, it does not specify what aspects of the analysis are missing or how to approach it. The action is implicit and somewhat vague, as the authors can infer that they need to conduct an analysis but are not provided with concrete guidance on what that analysis should entail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics to strengthen the paper. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in suggesting the need for an analysis, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of the inverse scaling phenomenon observed over compute. It suggests that the authors should provide an analysis explaining this training dynamics to strengthen the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis regarding the inverse scaling phenomenon observed over compute. It suggests that the authors provide an analysis explaining this training dynamics, which would enhance the paper\"s solidity. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work by providing a deeper understanding of the observed phenomenon. However, the comment could be more helpful if it offered guidance on how to approach the analysis or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It also questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment explicitly suggests that a formal definition would be beneficial for readers. While the action is clear, the comment could be more actionable by providing specific guidance on how to present the mathematical definitions or clarify the figure. However, the authors know exactly what needs to be addressed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general architecture of the model\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of mathematical definition in architectural details, such as multihead attention, and questions the split arrow in Figure 2. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition in the architectural details of the model, specifically mentioning multihead attention. It questions the split arrow in Figure 2, asking for clarification on whether the same vectors are used for keys and values. The comment suggests that a formal definition would be beneficial for readers. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of mathematical definition in the architectural details of the model, particularly regarding multihead attention. It provides a clear and actionable suggestion by asking for a formal definition of this component, which would enhance the readers\" understanding. Additionally, the comment raises a question about the split arrow in Figure 2, seeking clarification on the inputs for the attention layer. This feedback is detailed and constructive, offering the authors a clear path to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify or address the assumption, but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and \"Theorem 6\" and \"Theorem 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of iid data and how it affects the application of the theorems. The comment provides a detailed critique of the assumption and its implications, offering a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. The comment provides a logical reasoning by pointing out the potential issue with the assumption and its impact on the application of the theorems. However, it lacks specific examples or references to support the claim that the assumption is unjustifiable in practice. Therefore, the comment is 3, as it provides a clear critique but requires additional evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption that each individual\"s data is iid drawn from the same distribution, which is necessary for the proposed algorithm to work. The reviewer questions the justification of this assumption, suggesting that it may not hold in practice due to differences in users\" preferred emojis. This feedback is 3 as it highlights a critical assumption that may impact the validity of the results. However, it lacks specific suggestions or guidance on how the authors might address this issue or provide evidence to support the assumption. To be more helpful, the comment could include recommendations for alternative approaches or additional analysis to justify the assumption. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. This is an explicit action, as it clearly instructs the authors on what to do to improve their draft. The suggestion is also concrete, as it provides a specific direction for the authors to take, such as introducing more complex tasks and comparing with a reinforcement learning baseline. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion should be applied to, nor does it provide detailed guidance on how to implement this change. The authors can infer that it relates to the sections discussing policy and reinforcement learning, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the current setting is a subset of reinforcement learning with a fixed policy and proposes a way to make the policy nonfixed to allow for more complicated tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would enhance the paper. The suggestion lacks specific examples or detailed explanations, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the paper by proposing that the authors consider making the policy nonfixed to allow for more complicated tasks. This could enable a comparison with a reinforcement learning algorithm baseline, which could provide a more comprehensive evaluation of the work. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the policy should be made nonfixed. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide detailed actionable steps. Therefore, the comment is 3, as it offers a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the comprehensiveness of the analyses of the method and experimental outcomes, noting that the experiments primarily focus on presenting results. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comprehensiveness of the analyses of the method and experimental outcomes, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. However, the comment does not specify which sections or experiments are lacking in analysis, making it weakly grounded. The authors can infer that the issue relates to the experimental sections, but the comment lacks specificity regarding what aspects of the analysis are insufficient. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the analyses of the method and experimental outcomes are not comprehensive enough, particularly given that the authors\" method underperforms the baseline in some instances. The comment questions the extent to which the performance improvement can be attributed to the authors\" claim of moving codeswitched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are insufficient or that the performance improvement is questionable. This makes the claim 3, as it provides a general critique but lacks concrete evidence or references to substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the analyses in the paper, specifically noting that the experiments focus more on presenting results rather than providing a thorough analysis of the method and experimental outcomes. It questions the extent to which the performance improvement claimed by the authors can be attributed to their method, given that it underperforms the baseline in some instances. This feedback is valuable as it highlights a critical area for improvement, encouraging the authors to provide more detailed and comprehensive analyses to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to enhance the analysis or provide additional data to substantiate the claims. Overall, the comment is 3, as it directs the authors to a key area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the paper primarily focuses on explaining multitask models, which limits their applicability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for expanding the scope of the paper. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper primarily focuses on explaining multitask models, which limits their applicability. However, it does not specify which part of the paper this focus is discussed in, nor does it provide details on how the limitation affects the applicability. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of applicability are limited or how they could be expanded. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper mainly focuses on explaining multitask models, which limits their applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper primarily focuses on explaining multitask models, which limits their applicability. However, it does not provide any specific suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable feedback or detailed insights, the comment offers little value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the literature review ignores several papers that are seemingly relevant, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not explicitly instruct the authors to include these papers in the literature review or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors can infer that they need to add these papers but are not given explicit instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies specific papers (VRMARINA and DASHAMVR) that are missing from the literature review and suggests that they satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what needs to be addressed in the literature review. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide detailed reasoning or evidence to support why these papers are relevant or how they satisfy Assumption 2. The reference to \"See Question\" implies that the reviewer is seeking clarification, but it does not provide sufficient justification for the claim. Therefore, the comment is considered 2, as it lacks specific examples or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are seemingly relevant, including VRMARINA and DASHAMVR. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to include these papers in the literature review, which could enhance the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these papers or why they are relevant. Overall, the comment is 4, as it provides valuable insights for improving the literature review section."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the presentation of the paper is difficult to follow for the reviewer, but it does not provide any specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer, but it does not specify which part of the paper is causing this issue. The authors cannot confidently determine which sections or aspects of the paper are problematic, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the presentation are unclear or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation of the paper is difficult to follow for the reviewer, which is a valid concern. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might improve the clarity or structure of their paper. Without detailed guidance or examples, the authors are left without a clear understanding of what changes they should make to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions: one about additional insights into modest performance gains on Clothing1M and another about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. While the questions imply that the authors should provide more information or insights, they do not explicitly instruct the authors to do so. The lack of explicit guidance and the vague nature of the questions make it difficult for the authors to know exactly what actions to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the performance of the algorithm on specific datasets, such as Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its request for additional insights and performance data but lacks grounding, as it does not reference specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two questions seeking additional insights into the performance of the algorithm on specific datasets. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises questions about the performance of the algorithm on specific datasets, such as Clothing1M and WebVision, evaluated by DivideMix. While it does not provide specific feedback or suggestions for improvement, it prompts the authors to consider additional insights or data that could enhance their work. This feedback is 3 as it encourages the authors to explore and provide more comprehensive information about their algorithm\"s performance on various datasets. However, it lacks depth and actionable guidance, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors provide a more detailed presentation of the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. It also requests comments on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details and computation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely, a more detailed presentation of the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. Additionally, it requests comments on the computation requirements of the three methods compared in Table 1. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors provide more detailed information about the compared models, specifically highlighting the differences between KVAE and the other models, DMM and DVBF. The reviewer acknowledges a lack of familiarity with the compared models but provides some insight into their differences, such as the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. However, the comment lacks specific examples or references to support the claim that more detailed presentation is needed. This makes the claim 3, as it provides some context but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges a lack of familiarity with the compared models, DMM and DVBF, but provides some insight into their differences with KVAE. It suggests that a more detailed presentation of the compared models would be beneficial, specifically highlighting the simplicity of KVAE due to linear state space transitions and the need for computation of timedependent LGSSM parameters. The comment also requests that the authors comment on the computation requirements of the three methods compared in Table 1. While the feedback identifies a potential area for improvement and provides some guidance, it lacks specific suggestions or examples on how to present the models or address the computation requirements. This limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). While the comment implies that these additional experiments are necessary, it does not provide specific guidance on how to conduct them or which specific aspects of these models should be explored. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the need for more experiments, but it is 1, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). The claim is based on the assumption that these additional experiments would provide a more comprehensive benchmark. However, the comment lacks specific reasoning or evidence to support why these particular LLMs are necessary or how they would enhance the study. The suggestion is 3 as it provides a logical basis for the claim, but it could be strengthened with more detailed justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should conduct additional experiments on different famous LLMs like LLaMA and Falcon, in addition to the ones already mentioned (T5, PaLM, and GPT series). This feedback is clear and actionable, as it provides a specific direction for expanding the experimental scope, which could enhance the comprehensiveness and robustness of the study. However, the comment could be more helpful if it included a rationale for why these specific models are important or how they would contribute to the overall understanding of the topic. Despite this, the suggestion is 4 as it offers a concrete way for the authors to improve their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper lacks information on the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation of defenses would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback provides clear and concrete actions for the authors to take, such as including the hyperparameters used and explaining their derivation, and conducting an evaluation that optimizes hyperparameters against the attack. The comment is explicit and provides detailed guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding hyperparameters used by each defense and how they are derived. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it provides clear guidance on what needs to be addressed, such as describing the hyperparameters and their derivation, and suggests a maximally charitable evaluation of defenses. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. The comment provides a logical reasoning for the claim by suggesting a specific approach that could enhance the evaluation of defenses. However, it does not provide specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 4, as it offers a clear direction for improvement but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their evaluation methodology. By addressing this issue, the authors can improve the comprehensiveness and rigor of their defense evaluation. Therefore, the comment is 5, as it offers detailed and constructive suggestions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications but suggests that the authors could provide more takeaway points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but notes that it is unclear if this is a novel finding in the paper. While the comment provides a concrete suggestion, it lacks guidance on how to present these takeaway points or whether this suggestion is indeed novel. The action is 4 because it offers a specific idea but lacks detailed instructions on how to implement it. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the authors provide more takeaway points for practitioners. It mentions a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. However, the comment does not specify which part of the paper discusses these theoretical results or the suggested takeaway points, making it weakly grounded. The comment is specific in suggesting a particular approach for practitioners but lacks detailed guidance on how to implement it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. However, the reviewer suggests that the main takeaway point is to query a cluster proportionally to the square root of its size, questioning whether this is a novel finding. The comment provides some reasoning by acknowledging the novelty of the work and suggesting a specific takeaway point, but it lacks detailed evidence or references to support the claim that this suggestion is novel or significant. The reasoning is 3, as it provides a logical basis for the claim but requires more substantiation to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and their limited practical implications, which is understandable given the novelty of the work. It suggests that the authors could provide more takeaway points for practitioners, which is a valuable insight. The comment also highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment provides some direction, it lacks depth and does not offer detailed guidance on how to present these takeaway points or whether the suggested approach is indeed novel. This limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the introduction of separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the introduction of separators and asking for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. It is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the introduction of separators in section 4. It questions the rationale behind their inclusion and asks for clarification on what additional information they provide beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to provide a justification for the introduction of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to effectively explain the role of separators. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider alternative approaches to pooling tokens, specifically questioning the choice of mean pooling and asking about the potential benefits of other pooling strategies. While the comment implies that the authors should explore different methods, it does not provide explicit guidance on how to implement these alternatives or which specific strategies to consider. The action is implicit and somewhat vague, as the authors need to infer that they should investigate other pooling methods and determine which ones might be more suitable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling and suggests considering other pooling strategies, providing a clear direction for the authors to explore alternative approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of mean pooling and suggests considering other pooling strategies. However, it does not provide any supporting evidence, reasoning, or references to justify why mean pooling might not be the best choice or to explain the potential benefits of other pooling strategies. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the choice of mean pooling and suggesting that other pooling strategies could be explored. This feedback is clear and actionable, as it prompts the authors to consider alternative approaches that might enhance their analysis. However, the comment could be more helpful if it provided specific examples or references to other pooling strategies that could be beneficial. Despite this, the feedback is 4 as it directs the authors to a potential area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that besides the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is an explicit action that provides a clear direction for the authors to enhance their analysis by including additional metrics. The suggestion is concrete, as it specifies what needs to be added to the table, making it easy for the authors to implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that besides the number of queries, the real search cost (e.g., in terms of GPU days) should be compared in Table 3. This is a suggestion for improvement, but it does not contain a claim that requires verification. It is a request for additional information or analysis, which is factual and does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the analysis presented in Table 3. It recommends comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This feedback is actionable and clear, as it offers a concrete way for the authors to enhance their results by including a more comprehensive metric. However, the comment could be more helpful if it explained why this comparison is important or how it would impact the understanding of the results. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about missing training details, specifically whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but are not given specific guidance on how to present this information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about missing training details, specifically asking if the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections where training details are typically discussed. The comment is specific in its request for clarification on the training process, providing clear guidance on what information is needed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about missing training details, specifically whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. However, it does not provide any supporting evidence, reasoning, or references to justify the need for this information. The comment lacks a claim or opinion that requires verification, as it is primarily a request for clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about missing training details, asking whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This feedback is clear and actionable, as it prompts the authors to provide necessary information about their training process. By addressing this question, the authors can enhance the transparency and comprehensiveness of their methodology section. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include and compare their work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. The comment explicitly states that including these works and discussing the differences with other chatbox research works would be beneficial. This provides a clear and concrete action for the authors to take, as it specifies which works to include and how to frame the comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including and comparing the work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. However, it does not specify which part of the paper this suggestion should be incorporated into, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a conceptual comparison, as well as a general discussion on how the work differs from other chatbox research. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that works such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. are important to include and compare to, at least conceptually. The reviewer provides specific references to external works, which supports the claim by offering a clear basis for comparison. However, the comment could be strengthened by explaining why these works are particularly relevant or how they relate to the current study. Despite this, the inclusion of references provides a solid foundation for the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors should include and compare their work with other relevant studies, such as \"Endtoend taskcompletion neural dialogue systems\" by Li et al. and \"Deep reinforcement learning with a natural language action space\" by He et al. This feedback is clear and actionable, as it provides specific references and a conceptual framework for comparison. Additionally, the comment recommends a general discussion on how the work differs from other chatbox research works, which could help the authors contextualize their contribution within the broader field. By offering these suggestions, the comment is 5 as it guides the authors in enhancing the depth and relevance of their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed methods, DualIS and DualDIS, do not perform well on some crossmodel retrieval tasks, specifically mentioning minor improvements in the MSVD task as shown in Table 3. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the performance of the methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MSVD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, DualIS and DualDIS, by pointing out that their performance shows minor improvements in the MSVD task. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, specifically citing minor improvements in the MSVD task as shown in Table 3. However, the comment lacks specific details or references to support this claim, such as comparisons with other methods or a detailed analysis of the results. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment points out a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, as evidenced by minor improvements in the MSVD task. This feedback is 3 as it identifies a potential weakness in the paper, prompting the authors to consider the limitations of their methods and possibly explore ways to improve their performance. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methods. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, suggesting that running a descent procedure for 40 different networks from the training phase may not be necessary. The reviewer proposes an alternative method, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient, as at least one of these restarts would likely reach the global minimum. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this alternative method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not explicitly mention which part of the paper discusses the experimental setup or the descent procedure, making it weakly grounded. The suggestion is specific, as it provides a clear alternative approach to consider, but the lack of explicit grounding limits the comment\"s effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental strengths of the proposed approach are not convincing, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This claim is 3 as it provides a logical reasoning for the alternative approach, but it lacks specific examples or references to support the claim that this alternative method is more effective or efficient. The comment could be strengthened by providing additional evidence or comparisons to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is 3 as it identifies a potential area for improvement and offers a specific alternative approach to consider. However, the comment could be more helpful if it provided additional context or examples to support the suggestion, such as explaining why the alternative method might be more effective or efficient. Overall, the comment provides some guidance but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship, what additional data or analysis might be needed, or how to present the findings. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, it does not specify which part of the paper this issue pertains to, such as a particular section or analysis. Without explicit references or clear indications of where this issue arises, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the relationship between patches and disease are missing or unclear. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease has not been established. This is a critical observation that highlights a major weakness in the paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or direction, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a problem but does not offer any constructive advice for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the first quotation mark in the phrase \"for \"inbetween\" uncertainty\" should be a forward mark instead of a backward mark. This provides clear and direct guidance on how to correct the error, making the comment 5. The authors know exactly what action to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of quotation marks, and provides the correct notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the correct use of quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable piece of feedback regarding a typographical error in the paper. By pointing out the incorrect use of quotation marks in the phrase \"for \"inbetween\" uncertainty,\" the reviewer offers a clear and direct suggestion for improvement. This feedback is precise and easy to implement, allowing the authors to make a straightforward correction that enhances the clarity and professionalism of their draft. The comment is 5 and provides a tangible way for the authors to improve their work, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy in the performance of FedSP in Tables 1 and 2, noting that it is not the best performer on some datasets. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements to FedSP or how to present the results differently. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to Tables 1 and 2, providing some grounding as it specifies the parts of the paper being addressed. However, it does not specify what needs to be addressed or how the performance of FedSP could be improved. The comment lacks specificity regarding the datasets where FedSP is not the best performer, making it difficult for the authors to understand the exact issue or how to address it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a discrepancy in the performance of FedSP in Tables 1 and 2, noting that it is not the best performer on some datasets. While this observation highlights a potential issue with the paper, it lacks specific guidance or suggestions on how the authors might address this problem or improve the presentation of their results. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several specific questions and suggestions for improvement. It asks for clarification on what Omega is at line 178, suggesting that the authors should be more explicit about this term. Additionally, it points out that OMD is a family of algorithms and recommends being more specific about the link function and the theorem in reference [32] that is being referred to for the regret guarantee. These questions and suggestions provide clear and concrete actions for the authors to take, such as providing definitions or explanations for Omega and OMD, and specifying the link function and theorem. The feedback is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and suggestions for improvement, such as clarifying what Omega is, being more explicit about OMD, specifying the link function, and identifying the relevant theorem in reference [32]. These details provide clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding specific details in the paper, such as the definition of Omega, the link function, and the reference to a theorem in [32]. These questions are factual and seek additional information to better understand the content. Since they do not contain subjective opinions, judgments, or suggestions, they are classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the lack of clarity in the paper. It points out that the term \"Omega\" is not defined at line 178 and suggests that the authors should be more explicit about it. Additionally, it notes that OMD is a family of algorithms and recommends specifying the link function and the theorem in reference [32] that is being referred to for the regret guarantee. These suggestions are clear and direct, offering the authors concrete steps to improve the clarity and comprehensiveness of their draft. By addressing these points, the authors can enhance the readability and accuracy of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the models are learned directly from pixels without a Markovian state, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes might be necessary. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the models are learned directly from pixels without a Markovian state, but it does not specify which part of the paper this observation is based on. The authors may be able to infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is not specific about what implications this has for the paper or how it could be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the models are learned directly from pixels without a Markovian state, which could be a relevant observation for the authors to consider. However, it lacks specificity and does not provide any guidance or suggestions on how this observation might impact the paper or what the authors could do to address it. Without actionable feedback or further explanation, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer suggests that this approach is not commonly seen and requests references to support this claim. While the comment implies that the authors should provide references to substantiate the claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors know they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence, and requests references to support this claim. The authors are provided with clear guidance on what needs to be addressed and how to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this claim, stating that they are only aware of works reporting the Hamming loss defined nodewise. The comment requests references to support the claim, which is a reasonable request for clarification. However, the comment does not provide any specific examples or references to substantiate the claim itself, making it 3. The authors would need to provide additional information or references to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example at different steps of the paper but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically the use of the Hamming distance over entire parts of the sequence. The reviewer questions the validity of this claim, noting that they are only aware of works reporting the Hamming loss defined nodewise. The comment provides a specific area for improvement by requesting references to support the claim, which is a clear and actionable suggestion. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested alternative approaches. Overall, the feedback is 4 as it identifies a potential weakness and provides a concrete step for the authors to take, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" It also implies that the corresponding sections could be removed and the metrics mentioned alongside the datasets or in the captions of the tables, as most metrics are standard practice. This feedback is explicit and provides clear guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and implies that the corresponding sections could be removed or integrated into other parts of the paper. However, it does not specify which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a change in terminology and the potential removal or integration of sections, but without explicit references, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" It also implies that the corresponding sections could be removed and the metrics mentioned alongside the datasets or in the captions of the tables, as most metrics are standard practice. The comment provides a logical reasoning for the change, suggesting that it would improve clarity and align with common practices. However, it lacks specific examples or references to support the claim that most metrics are wellknown and used as standard practice. Therefore, the comment is 4, as it provides a clear rationale but could benefit from additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the clarity and organization of the paper. It recommends changing the name of the \"Evaluation\" element to \"Metrics\" to avoid confusion with the broader meaning of \"evaluation.\" Additionally, it suggests removing the corresponding sections and integrating the metrics into other parts of the paper, such as alongside datasets or in table captions, as most metrics are standard practice. This feedback is specific and offers concrete steps for enhancing the paper\"s structure and clarity, making it 5 for the authors. However, it could be further improved by providing examples of how to integrate the metrics effectively. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit or implicit guidance on how the authors should explore this dataset further. There is no indication of what specific aspects of the dataset should be explored, what additional analysis or discussion could be included, or how the exploration should be conducted. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this relates to, such as a specific section or analysis where the dataset is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs further exploration. Additionally, the comment lacks specificity regarding what aspects of the dataset should be explored or how it could be better integrated into the paper. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on what aspects of the dataset should be explored or how this exploration could enhance the paper. Without detailed suggestions or examples, the authors are left without a clear understanding of how to address this feedback. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer actionable advice. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It also provides a specific suggestion by recommending the use of more descriptive language. Additionally, the comment offers a concrete example by suggesting that the improvement is \"definitely there\" but not necessarily \"remarkable,\" which gives the authors a clear direction on how to rephrase their description. This feedback is explicit and provides concrete guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number, \"[218],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on using more objective terms instead of \"remarkable\" to describe the accuracy improvement. The comment further specifies the issue by suggesting that the improvement is \"definitely there\" but not necessarily remarkable, given the squished axes. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and should be replaced with more objective terms. The reviewer provides a logical reasoning by stating that while the improvement is \"definitely there,\" it might not be considered remarkable due to the squished axes. This reasoning is clear and provides a basis for the suggestion. However, the comment could be strengthened by providing specific examples of more objective terms that could be used. Overall, the claim is 4, as it offers a logical argument but lacks detailed examples or references to fully substantiate the suggestion. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the use of more objective terms instead of \"remarkable\" to describe the accuracy improvement. It also offers a rationale for this suggestion by pointing out that the squished axes might make the improvement appear less significant than it actually is. This feedback is clear and constructive, guiding the authors on how to improve the clarity and objectivity of their description. By addressing this feedback, the authors can enhance the precision and accuracy of their claims, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the synthesized results for UCF101, noting inconsistent motion, changing color, or objects disappearing over time. It suggests that it would be interesting to see videos with a longer duration by running the LSTM over many time steps. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address the issue or specific steps to take. The suggestion is implicit and somewhat vague, as it lacks concrete details on how to implement the idea of longer video sequences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"UCF101,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the synthesized results, such as inconsistent motion, changing color, or objects disappearing over time. The comment suggests exploring videos with longer durations by running the LSTM over many time steps, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the synthesized results for UCF101, noting inconsistencies in motion, color changes, or objects disappearing over time. It suggests that longer video sequences would be beneficial. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the exact issues and how they relate to the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color changes, or objects disappearing over time. It suggests that exploring videos with longer durations by running the LSTM over many time steps could be beneficial. This feedback is clear and actionable, as it points out a particular area for improvement and offers a potential solution. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to implement the suggested longer video sequences. Overall, the comment is 4, as it directs the authors to a specific area for enhancement, but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that, similar to most work on pruning, it is not yet possible to achieve efficiency gains on GPU. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for how the authors might address this issue or improve their work in this context. Without any guidance or direction, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of efficiency gains on GPU in the context of pruning, but it does not specify which part of the paper this claim pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this is not explicitly stated. The comment lacks specificity as it does not provide details on what aspects of the paper are affected by the lack of efficiency gains on GPU or how this could be improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that, similar to most work on pruning, it is not yet possible to realize efficiency gains on GPU. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how it applies to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a common limitation in pruning work, specifically that it is not yet possible to achieve efficiency gains on GPU. However, it does not provide any actionable advice or suggestions for the authors to address this issue or improve their work. Without guidance on how to overcome this limitation or what specific aspects of the paper might be affected, the comment lacks utility for the authors. Therefore, it is rated as 1, as it does not offer any meaningful feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically that it is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should consider using real data or adjusting their comparison, but it does not specify which data or comparison would be more appropriate. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, [5], which is designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison, making it weakly grounded. The comment is specific in pointing out the issue with the comparison and the use of synthetic data, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. The reviewer provides a logical reasoning by pointing out the difference in the complexity of the problems addressed by the two methods, which supports the claim. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that it is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. This feedback is valuable as it highlights a critical weakness in the evaluation process, which could impact the paper\"s credibility. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending the use of real data or alternative comparison methods. Despite this, the comment still offers a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this experiment could strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer that they might need to conduct this experiment but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of numbers of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its suggestion to explore this aspect, but the lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. The reviewer suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this could be an interesting area for exploration. However, the comment does not provide any evidence, reasoning, or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of supporting information or examples renders the claim 1, as the authors are left without a clear path to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors studied the effect of using numbers of bits in logits against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary, implying that this could be an interesting area for exploration. While the comment does not provide specific guidance on how to conduct this experiment or what aspects to focus on, it does offer a potential direction for enhancing the paper. However, the lack of detailed suggestions or actionable steps limits the comment\"s helpfulness. Therefore, it is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the cost implications of the method for men and women, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this question or what specific information should be included in the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of how to respond to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the cost implications of the method for men and women but does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or context about what the authors should consider or how they might address the question. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the cost implications of the method for men and women. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review point raises a question about the cost implications of the method for men and women, which is an important consideration for the practical application of the research. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what information should be included in the paper. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in response to this concern. Therefore, the comment is 2, as it identifies a potential area of interest but does not provide sufficient guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides an example reference, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could serve as a basis for the clarification. While the action is explicit, the comment could be more actionable by providing specific guidance on how to make this clarification, such as suggesting particular aspects to focus on or how to structure the explanation. Nonetheless, the comment provides a clear direction for the authors to follow, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, namely the difference between meta solvers and centralized RL where agents share weights. The reference to \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016\" provides additional context and guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between these and centralized RL where agents share weights. The comment provides a reference to \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which supports the claim by offering a relevant example of a similar concept. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional supporting details.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting that they might be centralized controllers. It provides a specific reference to \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which could serve as a basis for clarifying the difference between meta solvers and centralized RL where agents share weights. This feedback is clear and actionable, as it directs the authors to address a specific area of confusion and provides a relevant reference for further clarification. However, the comment could be more helpful if it offered additional guidance on how to structure the clarification or what specific aspects to focus on. Overall, the comment is 4, as it provides valuable feedback that can lead to a clearer and more comprehensive explanation in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s categorization of papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the availability of papers on arXiv when categorizing them, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of how the paper categorizes papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the issue with the categorization, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s categorization of papers based on their publication years on the ACL anthology is incorrect, as many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This example supports the claim by providing a concrete instance of the issue, making the comment 4. However, the comment could be strengthened by further elaboration or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s categorization of papers based on their publication years on the ACL anthology. It highlights that many papers are available on arXiv earlier than their publication in the ACL anthology, using the BERT paper as an example. This feedback is 3 as it identifies a specific area where the paper\"s categorization might be inaccurate. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their categorization method. To be more helpful, the comment could provide recommendations or examples of how to handle papers that are available on arXiv before their publication in the ACL anthology. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors provide examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and actionable, as it directs the authors to take a specific step to improve the clarity of their draft. The comment provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the notation used for M_T, suggesting that it is not making sense due to its definition over probabilities of atomic events. The comment further provides a clear and specific suggestion to address this issue by recommending the inclusion of examples to explain M_T. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the notation M_T is not clear because it is defined over the probabilities of atomic events. The reviewer requests examples to explain M_T, which is a reasonable request for clarification. However, the comment does not provide any specific reasoning or evidence to support why the notation is problematic or how examples would improve understanding. This lack of detailed justification makes the claim 3, as the authors would need to infer the need for clarification and examples based on the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used for M_T on page 3, suggesting that it is defined over the probabilities of atomic events but is not clearly explained. The reviewer provides a clear and actionable suggestion by recommending the inclusion of examples to clarify this concept. This feedback is valuable as it directs the authors to a specific area where the draft could be improved, offering a concrete step to enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or examples of how the notation could be clarified. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. While the comment implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"QRS and RS,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between QRS and RS in terms of the value of u that would cause them to behave differently. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide any supporting evidence or reasoning to justify why importance sampling should have been used or why the current approach is inferior. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific but still lacks detailed reasoning or examples to fully substantiate the claim. Overall, the comment lacks sufficient evidence and reasoning to be considered 5, making it 2.", "helpfulness_rationale": "The review comment raises two distinct points. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. This feedback is 3 as it prompts the authors to reconsider their approach and potentially improve it. However, it lacks specific guidance on how to address this issue or why importance sampling might be more appropriate. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific and actionable, as it provides a clear direction for the authors to improve their explanation. Overall, the comment is 3 as it identifies areas for improvement but could be more comprehensive and detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on what specific refinements could be made or how the authors might improve the performance enhancements. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the performance enhancements could be refined. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what refinements are needed or how they might be achieved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the observed performance enhancements are \"somewhat modest,\" suggesting that there is room for further refinement. However, the comment lacks specific examples, data, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment notes that the observed performance enhancements are modest, suggesting that there is room for further refinement in the future. While this observation highlights an area for potential improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might enhance the performance or what specific refinements could be made. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of multiple requests for clarification and references. It explicitly instructs the authors to provide references for specific passages in Section 3.2 and to clarify what \"MLP\" refers to in Figure 2. These requests are direct and concrete, providing clear actions for the authors to take. The comment is 5 as it specifies exactly what needs to be addressed and how to address it, leaving no ambiguity for the authors.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely providing references for the mentioned passages and clarifying the term \"MLP\" in Figure 2. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and references, which are not subjective claims or opinions. It asks for specific information to be provided, such as references for certain passages and a description of \"MLP\" in Figure 2. Since it does not contain any claims, suggestions, or judgments, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas in the paper that require improvement. It points out the need for references in Section 3.2, which is a clear and actionable suggestion for enhancing the paper\"s credibility. Additionally, it raises a question about the term \"MLP\" in Figure 2, prompting the authors to clarify this terminology. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate these references or clarify the terminology. Overall, the feedback is clear and actionable, making it 4 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It implies that the performance is similar to IRM, which may be due to the issues mentioned earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to improve the experimental design or analysis to better validate their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically mentioning the last two datasets. However, it does not specify which datasets these are, making it weakly grounded. The comment is specific in its critique, questioning the validity of the results and suggesting a potential cause, but it lacks detailed guidance on how to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of \"problems mentioned above\" suggests that there might be underlying issues, but these are not elaborated upon. As a result, the claim is considered 2, as it lacks sufficient evidence or detailed justification to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically noting that the performance on the last two datasets is similar to IRM, which may indicate a lack of effectiveness in validating the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the experimental results. It lacks actionable feedback, such as recommending additional experiments, modifications to the methodology, or alternative analyses to better validate the proposed method. Without detailed guidance, the authors are left without a clear path for improvement, making the comment 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, questioning the added value of this detection compared to simply knowing the length of the long entity. However, it does not provide any explicit or implicit guidance on how the authors should address this concern or what changes they should make to their draft. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between this detection and simply knowing the length of the long entity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in the example of Figure 2, suggesting that knowing the length of the long entity might be sufficient. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this detection is unnecessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example presented in Figure 2, questioning the added value of this detection compared to simply knowing the length of the long entity. While it identifies a potential area of confusion or unnecessary complexity, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the purpose of detecting both entities. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there is a lack of empirical validation and suggests that experiments should be conducted to validate the bounds. This provides a clear and direct action for the authors to take, which is to include empirical validation through experiments. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment points out the lack of empirical validation and suggests conducting experiments to validate the bounds. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments that are missing. Without explicit references to the paper, the authors may find it challenging to identify the exact areas needing attention. The comment is specific in its request for empirical validation but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of empirical validation, suggesting that experiments should be conducted to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of empirical validation. It suggests that the authors should include experiments to validate the bounds, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on what kind of experiments should be conducted or how the validation should be approached. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, allowing them to enhance the rigor and credibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. While the comment identifies a potential confusion, it does not provide explicit guidance on how to address this issue or clarify the terminology. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the meaning of \"nonsequential information\" and \"chunks\" in their draft. However, the comment does not offer specific suggestions on how to resolve the confusion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"nonsequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the terminology used in the paper, specifically the phrase \"nonsequential information such as chunks.\" It questions whether \"chunk\" is still considered sequential information, indicating a potential confusion in the text. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this confusion exists or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the term \"nonsequential information such as chunks.\" It questions whether \"chunk\" is still considered sequential information, which could be a critical clarification for the authors to make. However, the comment does not provide any suggestions or guidance on how to address this confusion or clarify the terminology. While it highlights an area that needs attention, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Equation 9 and Figure 1, suggesting that the output patches may not be cropped parts of the input image but rather masked versions of the input image with most pixels being black. The reviewer questions whether this is correct and implies that Figure 1 might be misleading. Additionally, the comment suggests that using bilinear sampling to zoom on the region of interest could provide better results. While the comment identifies a potential issue and suggests an alternative approach, it does not provide explicit instructions on how to address the discrepancy or improve Figure 1. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider the suggested alternative. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or masked versions. The comment further suggests an alternative approach using bilinear sampling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that if the latter is correct, Figure 1 might be misleading. Additionally, the comment proposes an alternative approach using bilinear sampling. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the discrepancy or the effectiveness of bilinear sampling. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions of the input image. It suggests that if the latter is correct, Figure 1 might be misleading. Additionally, the comment proposes an alternative approach using bilinear sampling to improve the results. This feedback is clear and actionable, as it points out a potential issue and offers a specific suggestion for improvement. However, it could be more helpful if it provided further details or examples on how to implement the suggested alternative. Overall, the comment is 4, as it directs the authors to a specific area needing clarification and offers a constructive suggestion for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that needs explanation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to address the exception but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the upper bound when there is a separate node with 0 neighbors, which is a clear and specific concern. The comment raises a logical question about the exception and asks for an explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exception is problematic or how it affects the theorem. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the question, rendering the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive, asking for an explanation. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this exception or clarify the theorem. The feedback is 3 as it prompts the authors to consider this specific case, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of technical novelty in the paper, suggesting a comparison with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be improved. The comment implies that the authors should consider the similarities between their work and the previous papers, but it lacks concrete instructions on how to incorporate this comparison or what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited technical novelty by comparing the paper with two mentioned papers (Xing and Tsang, 2022a, b). However, it does not specify which part of the paper this comparison should be made in, such as the introduction, methodology, or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint where the comparison should be included. The comment is specific in identifying the issue of limited novelty and the need for comparison, but it is not fully grounded as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The reviewer provides a logical basis for the claim by noting that the idea, coattention mechanism, and architecture of the current paper are similar to those in the previous papers. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how the current paper lacks novelty. This would enhance the verifiability of the claim. As it stands, the comment is 3, as it provides a basis for the claim but lacks comprehensive evidence. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s technical novelty, suggesting that the idea, coattention mechanism, and architecture are similar to those in previous papers. It provides a basis for this claim by mentioning specific papers (Xing and Tsang, 2022a, b) that focus on graphbased approaches. However, the comment lacks actionable guidance on how the authors might address this concern or differentiate their work from the previous papers. Without specific suggestions or examples, the feedback is 3 as it points out an area for improvement but does not provide detailed direction for the authors to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests deleting the word \"Discussion\" from a specific statement on page 5. This is an explicit action with clear instructions on what the authors should do to improve their draft. The comment is concrete, as it specifies exactly what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5\" and the specific statement about the training time reduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the discussion about the training time reduction has not been revisited in the Discussion section and suggests deleting the word \"Discussion\" from the statement. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the statement about the training time reduction not being as drastic as the parameter reduction is not supported by the Discussion section. The reviewer implies that the statement should be deleted because it is not revisited in the Discussion. However, the comment does not provide any specific reasoning or evidence to support why the statement is incorrect or why it should be deleted. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text on page 5, where it mentions that the training time reduction is less drastic than the parameter reduction. The reviewer points out that this statement is not revisited in the Discussion section, suggesting that the word \"Discussion\" should be deleted. While the comment highlights a potential inconsistency or redundancy in the text, it does not provide any deeper analysis or suggestions for improvement. The feedback is 3 as it directs the authors to a specific area for revision, but it lacks depth and actionable guidance to fully address the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem discussed in the paper applies to other downstream tasks or is specific to binding affinity prediction, and if so, why. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific steps they should consider to clarify this aspect of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem discussed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the problem or its applicability are unclear. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the applicability of the problem discussed in the paper. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem discussed in the paper, specifically whether it is specific to binding affinity prediction or applies to other downstream tasks. While it identifies a potential area for clarification, it lacks depth and does not provide any specific guidance or suggestions on how the authors might address this question or improve their draft. The comment is 3 as it prompts the authors to consider the broader implications of their work, but it does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions could be proposed. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific analysis or solutions should be proposed. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed analysis or solutions but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"The handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the lack of analysis on why GPTgenerated rumors are as difficult to detect as natural rumors, and it questions the experimental results regarding the detection of artificial and natural rumors. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on why GPTgenerated rumors are as difficult to detect as natural rumors. It questions the experimental results that show natural rumors are the easiest to detect, suggesting that artificial rumors, also written by humans, should be similarly difficult to detect. The comment provides a logical reasoning by pointing out the inconsistency in the experimental results and the lack of analysis on this specific issue. However, it does not provide specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it offers a clear rationale but lacks comprehensive evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the analysis of rumors generated by GPT. It points out that the paper highlights the challenges of detecting GPTgenerated rumors but does not provide further analysis or solutions. The comment questions the reasoning behind why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is 3 as it prompts the authors to consider this gap in their analysis and potentially explore additional solutions or explanations. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Section 4, stating that it is more about heuristics than a formal and principled solution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically stating that Section 4 is more about heuristics than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the technical contribution of the paper, noting that Section 4 is more about heuristics than a formal and principled solution. This feedback is 3 as it points out a potential weakness in the paper\"s technical contribution. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the technical contribution. Without specific advice or examples, the authors may find it challenging to know exactly how to enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it instructs the authors to adjust the font size in Figure 6 to make it more readable. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed to improve the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the font size in Figure 6 being too small. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is brief and points out a specific issue with the font size in Figure 6, suggesting that it is too small. While it identifies a potential problem with the figure\"s readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The authors are left with a clear problem to fix but without any actionable advice on how to improve the figure. Therefore, the comment is 3, as it highlights a specific issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses regret that the probability mass function is not fully utilized in the paper, specifically mentioning that it is set to a quasiuniform distribution that depends on only one parameter. The reviewer suggests that considering various probability mass functions could have added depth to the experimental setting. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific alternatives to the quasiuniform distribution. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the quasiuniform distribution being used and suggests that considering various probability mass functions could have added depth to the experimental setting. The comment provides a clear direction for improvement by questioning the choice of the quasiuniform distribution and suggesting an alternative approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not fully utilized in the paper, specifically mentioning that it is set to a quasiuniform distribution. The reviewer suggests that considering various probability mass functions could have added depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that other probability mass functions would be beneficial. The reasoning is somewhat logical, but it is not fully developed, making the claim 3. The authors would need to infer the potential benefits of exploring different probability mass functions, which adds to the complexity of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by noting that the probability mass function is not fully utilized in the paper. It points out that the quasiuniform distribution used in MixBoost depends on only one parameter, suggesting that considering various probability mass functions could have added depth to the experimental setting. The reviewer raises an intuitive point about considering each learner class individually, even in the case of BDTs of different depths. However, the comment lacks specific suggestions or examples of alternative probability mass functions that could be explored. While it highlights a potential area for enhancement, the feedback could be more actionable and detailed to guide the authors effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in comparisons or what specific steps to consider. As a result, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a great percentage of abstention. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspects of the comparison are unfair. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the fairness of the comparison could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. While it identifies a potential issue with the comparison, it lacks depth and does not provide any specific guidance or suggestions on how the authors might address this concern. The comment does not offer actionable advice or insights that could help the authors improve their draft. As a result, it is 2, as it points out a potential issue but does not provide enough information for the authors to make meaningful improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss connections with a specific reference, [a], which is relevant to their topic. It provides a clear action for the authors to take, which is to incorporate a discussion about the connections between their work and the referenced paper. The comment also specifies the relevance of the reference, mentioning that it uses supervised learning in QBF solving, where QBF generalizes SMT. This provides concrete guidance on how to implement the suggested action, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references that are relevant to the topic, allowing the authors to accurately identify the parts of the paper that need attention. It also specifies what needs to be addressed, which is the discussion of connections with the referenced paper, particularly [a], which uses supervised learning in QBF solving. This provides clear guidance on what the authors should focus on in their revisions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that certain references are relevant to the topic and suggests discussing connections with one of them, specifically [a]. However, the comment does not provide a detailed explanation of why these references are relevant or how they relate to the paper. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with missing references and suggests that the authors discuss connections with a particular reference, [a], which is relevant to their topic. It provides a clear and actionable suggestion by specifying the relevance of the reference and the aspect of supervised learning in QBF solving. This feedback is valuable as it directs the authors to incorporate a relevant reference and discuss its implications, potentially enhancing the depth and relevance of their work. However, the comment could be more helpful if it included a brief explanation of why this reference is particularly relevant or how it could impact the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could benefit from additional context or detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration without detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"When training, a mono tonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely whether the monotonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. The reference to a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" adds further specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. The comment references a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" which provides a basis for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve into the referenced work to fully understand the implications and potential alternatives, which adds a layer of complexity to the verification process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the monotonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. It also references a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" which provides a potential direction for exploration. However, the comment could be more helpful if it provided specific examples or detailed suggestions on how to explore alternative relationships or how to incorporate the referenced work into the paper. While it identifies a potential area for improvement, the feedback is somewhat vague and lacks actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost and running time, implying that the authors should consider including this aspect in their analysis. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer that they need to include a comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost and running time, but it does not specify which part of the paper this comparison should be included in. The authors may infer that it relates to the experimental or results sections, but without explicit guidance, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its request for a comparison but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point is a question asking for a comparison in terms of computation cost and running time, which does not contain any claims, opinions, or suggestions that require verification. It is purely factual and does not necessitate a response or further explanation from the authors. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the comparison of computation cost and running time, which is an important aspect of evaluating the efficiency and practicality of the proposed method. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. It does not offer actionable advice or insights that could help the authors improve their draft. As a result, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This is an explicit action with concrete guidance on how to improve the paper by suggesting a specific area of focus. The comment provides a clear direction for the authors to enhance their work by addressing the issue of interprocess communication and providing examples of relevant problems. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clarity in the paper\"s goal and the examples provided, particularly regarding the relevance of samplingbased Bayesian methods. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and to consider ERMbased distributed algorithms like Hogwild provides clear guidance on how to address the identified issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples provided in the paper do not convincingly demonstrate the need for interprocess communication, particularly mentioning the second paragraph where samplingbased Bayesian methods are discussed. The reviewer suggests that the paper\"s results are irrelevant for these methods, which are already embarrassingly parallel. The comment further suggests focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the reviewer provides a logical reasoning for their claim, the comment lacks specific examples or references to support the assertion that the current examples are insufficient. This makes the claim 3, as it requires more detailed evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the examples provided in the introduction do not convincingly demonstrate the need for interprocess communication. It suggests that the authors focus on problems where the loss function does not decompose as the sum of sample losses, such as Hogwild, to better illustrate the relevance of their work. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the clarity and relevance of their paper. However, the comment could be more helpful if it included specific examples or further elaboration on how to apply the suggested focus. Overall, the comment is 4 as it offers a valuable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. While it highlights potential issues, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these concerns or improve their draft. The lack of actionable advice makes the comment 1.", "grounding_specificity_rationale": "The comment raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. It challenges the authors to justify why their approach is more privacypreserving and whether privacy is indeed an issue in this context. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it highlights potential weaknesses, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of the innovative pretraining module design of CPEF. This recommendation is clear and provides a specific action for the authors to take, ensuring that the comparison is fair and highlights the unique features of CPEF. The comment is 5 as it provides a concrete suggestion on how to improve the draft, leaving no ambiguity for the authors on what needs to be done.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between CPEF and PMEF, noting that PMEF lacks a pretraining module and suggesting a comparison with ExpertBert to showcase the advantage of CPEF\"s pretraining module design. This provides clear guidance on what needs to be addressed to ensure fairness in the comparison. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF in Figure 3 is unfair because PMEF lacks a pretraining module. The reviewer suggests comparing CPEF with another pretrained model, such as ExpertBert, to demonstrate the advantage of CPEF\"s pretraining module design. This claim is 3 as it provides a logical reasoning for the unfair comparison and suggests an alternative comparison that could address the issue. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Figure 3, noting that the comparison between CPEF and PMEF is unfair because PMEF lacks a pretraining module. It provides a clear and actionable suggestion to address this issue by recommending a comparison with another pretrained model, such as ExpertBert, to showcase the advantage of CPEF\"s innovative pretraining module design. This feedback is 5 as it not only points out a weakness in the current comparison but also offers a concrete solution to improve the draft. By suggesting an alternative comparison, the reviewer empowers the authors to enhance the validity and fairness of their results, making this comment highly valuable for improving the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. However, it does not provide any guidance or suggestions on how to resolve this issue or what steps the authors should take to fix the problem. The comment lacks explicit or implicit actions, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the functionality of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, indicating that they do not work. While this is a factual observation, it does not provide any guidance or suggestions on how to resolve the issue or improve the draft. The lack of actionable feedback or suggestions makes the comment 2, as it does not offer any direction for the authors to address the problem. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. While the comment implies that these changes are necessary, it does not explicitly instruct the authors to make these revisions. The action is concrete, as it specifies what needs to be addressed, but it is implicit in terms of direct instruction. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The mention of \"section 2\" and \"Label Embeddings\" allows the authors to identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific as it details what needs to be addressed, namely the need for a better formalization of the architecture and clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings. While the comment identifies areas for improvement, it does not provide detailed reasoning or evidence to support the claim that the current discussion is unclear. The suggestion for improvement is logical, but the lack of specific examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples, such as formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out a potential misunderstanding in the figure regarding Label Embeddings, which could be misleading. By offering these detailed suggestions, the comment helps the authors identify areas for improvement and provides actionable feedback to enhance the clarity and accuracy of their work. However, the comment could be more helpful if it included additional guidance on how to formalize the architecture or clarify the Label Embeddings. Overall, the feedback is 4 as it directs the authors to specific parts of the paper that need revision, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph, which clarifies the description. This feedback is explicit and provides a clear action for the authors to take, which is to reorder the section to improve clarity. The suggestion is concrete, as it specifies exactly what the authors should do to enhance the readability of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the difficulty in understanding the description of the neural network, and suggests a solution by recommending that the final paragraph of the section be moved to the beginning. This provides clear guidance on how to improve the clarity of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand but acknowledges that the final paragraph of the section clarifies it. The suggestion to start the section with the final paragraph is based on logical reasoning, as it implies that the clarity of the description improves as the section progresses. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact issues with the initial description and how rearranging the section would improve clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph of the section. It provides a constructive suggestion to improve the clarity by recommending that the section start with the final paragraph, which clarifies the description. This feedback is actionable and offers a clear path for the authors to enhance the readability of their draft. However, it could be more helpful if it included additional suggestions or examples to further clarify the description. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the model is limited to CTC loss and asks if it would be possible to train it towards attentionbased encdec training. While the comment implies that the authors should consider alternative training methods, it does not provide explicit guidance on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors would need to infer that they should explore alternative training methods and figure out how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the model is limited to CTC loss and asks if it could be trained towards attentionbased encdec training. However, it does not specify which part of the paper discusses the model or its limitations, making it weakly grounded. The comment is specific in suggesting an alternative training method, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model is limited to CTC loss and asks if it could be trained towards attentionbased encdec training. However, the comment does not provide any reasoning, evidence, or references to support why the model is limited to CTC loss or why attentionbased encdec training would be beneficial. Without such support, the claim remains 1, as the authors would need to infer the basis of the suggestion themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the model, suggesting that it is currently limited to CTC loss and asks if it could be trained towards attentionbased encdec training. This feedback is 3 as it points out a specific area for improvement and suggests an alternative approach. However, the comment lacks depth and does not provide detailed guidance on how to implement this change or what specific benefits might be expected from such a shift. While it offers a direction for improvement, it does not fully support the authors in making the necessary adjustments. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address the question or what changes might be necessary. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggests that one type (the column header) should suffice. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any supporting evidence, reasoning, or examples to justify why one type should suffice. The comment lacks specific details or references that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). While it identifies a potential area of confusion or redundancy, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the purpose of the different types of tables. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the attack methods used in the paper, labeling them as \"naive\" and suggesting that other classical attack methods in NLP should be considered. The reviewer provides an example of papers that could be referenced for alternative methods. While the comment implies that the authors should consider using more sophisticated attack methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other methods and reference the provided papers. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the attack methods used in the paper, specifically mentioning that they are \"naive\" and suggesting the use of more classical attack methods in NLP. However, it does not specify which part of the paper discusses these attack methods, making it weakly grounded. The comment is specific in suggesting the use of other attack methods and provides an example of papers that could be referenced, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are \"naive\" and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example of papers that could be referenced for alternative methods, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of why the current attack methods are inadequate. Overall, the claim is 4, as it provides some justification but lacks comprehensive evidence or detailed comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by labeling the attack methods as \"naive\" and suggesting that more classical attack methods in NLP should be considered. It provides a specific example of papers that could be referenced for alternative methods, which is a constructive suggestion for improvement. However, the comment could be more helpful if it offered a detailed explanation of why the current attack methods are inadequate or how the suggested methods could be integrated into the paper. Despite this, the feedback provides a clear direction for enhancing the paper, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative mitigation methods or ways to improve image quality. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"mitigation methods\" and their impact on \"image generation capabilities of diffusion models,\" but it does not specify which part of the paper discusses these methods or how they affect image quality. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of image quality are affected or how to improve them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"the mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods used in the paper, suggesting that they may negatively impact the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear path to improve their work. Therefore, the comment is 2, as it highlights a potential problem but does not offer meaningful guidance for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how to address these concerns or suggest specific actions for the authors to take. The action is implicit and vague, as the authors are left to infer that they should consider the potential impact of prior knowledge on fairness and take steps to mitigate it, but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment provides a specific concern about the potential for the pretrained visual model and target dataset to leak additional information, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the potential impact of prior knowledge on fairness and explore ways to mitigate it, but the comment does not provide detailed guidance or evidence to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue with the pretrained visual model and target dataset leaking additional information, which could skew results and lead to unfairness. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or mitigate its impact. While it identifies a critical area for consideration, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, clarification, or further analysis. The comment is purely observational and lacks any actionable guidance, leaving the authors without a clear understanding of what they should do in response. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the observation that function words dominate content words in a Japanese sentence, which is a clear and detailed observation that the authors can address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks depth and does not offer any context or examples to substantiate the observation, making it difficult for the authors to understand the basis of the surprise. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as observed in Figure 1. However, it does not provide any further analysis, explanation, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance for the authors to address the issue or enhance their understanding of the data. As a result, the comment is 1, as it does not provide any meaningful insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a minor change to the baseline used in the paper, recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives. The comment provides specific references to support this suggestion, which gives the authors a clear direction on how to implement the change. However, the comment does not explicitly instruct the authors to make this change, leaving it to be inferred. While the suggestion is concrete, the lack of explicit instruction makes the action 3.", "grounding_specificity_rationale": "The comment suggests a minor change to the baseline used in the paper, specifically recommending the use of the minimal kmeans objective over multiple seeds instead of the average of kmeans objectives. It provides references to support this suggestion, which helps in understanding the context. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results section, but this inference is not direct. The comment is specific in suggesting an alternative baseline, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests an alternative baseline for kmeans objectives, recommending the use of the minimal kmeans objective over multiple seeds instead of the average. It provides references to support this suggestion, specifically citing Jin et al. and Fr\u00e4nti and Sieranoja. These references offer a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the minimal kmeans objective is more reasonable. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a minor suggestion for improvement by recommending the use of the minimal kmeans objective over multiple seeds as a baseline, rather than the average of kmeans objectives. This suggestion is based on references to relevant literature, which adds credibility to the recommendation. However, the comment could be more helpful if it explained why the minimal kmeans objective is more reasonable or provided additional context or examples to support the suggestion. While the feedback is clear and actionable, it lacks depth and detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the task is closer to Argument Mining than Summarization and recommends that the paper clarify the differences against Argument Mining/Discussion Summarization. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so or offer specific guidance on how to make these clarifications. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task is closer to Argument Mining than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in suggesting that the paper should clarify the differences, but it does not provide detailed guidance on how to do so. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the task is closer to Argument Mining than Summarization and recommends clarifying the differences against Argument Mining/Discussion Summarization. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the task is more closely related to Argument Mining than Summarization and recommends that the paper clarify the differences against Argument Mining/Discussion Summarization. This feedback is 3 as it identifies a potential confusion in the categorization of the task and provides a direction for clarification. However, the comment lacks specific guidance on how to make these clarifications or what aspects of the paper need to be addressed. While it points out an area for improvement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training. The reviewer asks the authors to clarify this point. Additionally, the comment suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. The feedback is explicit in asking for clarification and provides a specific issue to address, making it 4. The authors know exactly what needs to be clarified and can take concrete steps to address the confusion and the contradiction in the paper\"s motivation. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the relationship between uncertainty calibration and temperature calibration, particularly with the regularization term H. The comment highlights the inconsistency in the application of these concepts and requests clarification. Additionally, it points out a contradiction in the paper\"s motivation regarding confidence and calibration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the confusion between uncertainty calibration and temperature calibration, specifically regarding the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which seems contradictory. The comment also suggests that reducing entropy makes predictions more confident, which contradicts the paper\"s motivation to calibrate networks that are already overconfident. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the paper to understand the context and address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the relationship between uncertainty calibration and temperature calibration, specifically with the regularization term H. It points out that the training regularization term requires temperature calibration, yet temperature calibration is applied after training, which could be confusing. Additionally, the comment highlights a contradiction in the paper\"s motivation, as reducing entropy makes predictions more confident, which contradicts the goal of calibrating networks that are already overconfident. The reviewer requests clarification on this point, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific suggestions on how to clarify the confusion or reconcile the contradiction. Overall, the feedback is 4 as it directs the authors to a critical area that needs clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies an important reference that is missing from the paper, specifically mentioning the work \"Lista\" by Yann LeCun. It highlights the relevance of this reference to the paper\"s topic and suggests that the authors should discuss the similarities and differences between their work and \"Lista\" to provide appropriate context. This feedback is clear and actionable, as it directs the authors to include a specific reference and to discuss its relevance to their work. The authors know exactly what action to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reference \"Lista\" and its relation to the idea of unrolling, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the discussion of similarities and differences between the proposed work and \"Lista\" to provide appropriate context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. The comment is 4 as it provides a specific reference and a clear suggestion for improvement. However, it lacks detailed reasoning or examples of how the paper could benefit from discussing \"Lista,\" which would strengthen the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the lack of reference to the concept of unrolling, first proposed in \"Lista\" by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista\" to provide context. This feedback is clear and actionable, as it directs the authors to include a specific reference and to discuss its relevance to their work. By doing so, the authors can better situate their contribution within the existing literature and provide a more comprehensive understanding of their research. The comment is 5 as it offers a specific and actionable suggestion that can enhance the paper\"s clarity and relevance. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explain the linear program in Theorem 3 intuitively, specifically asking for clarification on the objective and constraints in equation (3). This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The comment is 5 as it offers concrete guidance on how to enhance the clarity of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining the linear program intuitively, particularly focusing on the objective and constraints in equation (3). This provides clear guidance on how to improve the clarity of the theorem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 should be explained intuitively, specifically asking for clarification on the objective and constraints in equation (3). This is a request for clarification rather than a claim, as it does not express an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for a more intuitive explanation of the linear program in Theorem 3. It highlights the importance of clarifying the objective and constraints in equation (3), which would enhance the reader\"s understanding of the main theorem. This feedback is clear and actionable, providing the authors with a direct suggestion on how to improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present this explanation or suggested specific examples to illustrate the concepts. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by stating that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating that the FLOT cost matrix in Algorithm 1 is not defined. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable piece of feedback that directly points out a gap in the paper\"s presentation. By addressing this issue, the authors can improve the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the FLOT cost matrix or its significance in the algorithm. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), specifically asking if it converges to 0 as T goes to infinity. It provides a comparison with a similar bound in [Grunewalder et al, 2010], Eq. (27), which does converge to 0. The reviewer suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. This feedback is explicit and provides a clear action for the authors to take, which is to address the question of convergence. The comment is 5 as it gives a direct and concrete instruction on what the authors need to do to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27) in [Grunewalder et al, 2010],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of convergence and asks the authors to prove whether the second term in Eq. (30) converges to 0. The comment provides a clear direction for the authors to address the question raised, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of the bound in Theorem 2, Eq. (30), and compares it with a similar bound in [Grunewalder et al, 2010], Eq. (27), which is known to converge to 0. The reviewer notes that the first term in Eq. (30) converges to 0 but questions the convergence of the second term. This is a logical and reasonable inquiry, as it seeks clarification on a specific aspect of the theoretical results. However, the comment does not provide additional evidence or references to support the claim, leaving the authors to infer the necessity of addressing this question. Therefore, the comment is 3, as it provides a logical basis for the inquiry but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a specific question about the convergence of the bound in Theorem 2, Eq. (30), particularly regarding the second term. It provides a comparison with a similar bound in [Grunewalder et al, 2010], Eq. (27), which is known to converge to 0. The reviewer suggests that the authors should prove whether the second term in Eq. (30) also converges to 0. This feedback is clear and actionable, as it identifies a potential gap in the theoretical analysis and encourages the authors to address it. By doing so, the authors can enhance the rigor and clarity of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to approach the proof. Overall, the comment is 4 as it directs the authors to a specific area needing further exploration and justification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the reviewer suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the definition and provide evidence to support the sparsity assumption. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The comment also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the sparsity of the residual term is discussed. The comment is specific in detailing what needs to be addressed, such as clarifying the definition and providing evidence. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The reviewer also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies areas for clarification and improvement, it lacks specific examples or references to support the claim about the sparsity assumption or the advantages of the proposed method. This makes the claim 3, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the sparsity definition of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the reviewer suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify the definition and provide evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to demonstrate the advantages or provided examples of existing methods for comparison. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance or suggestions on how the authors should address this issue or what alternative terminology or explanations could be used. The action is explicit but lacks concrete details on how to implement the change, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the term \"connectivity,\" namely, that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this term is misleading or how it deviates from the intended meaning. Without additional context or explanation, the claim remains 1, as the authors would need more information to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not refer to the structural connections between the brain and body. This feedback is 3 as it points out a specific area where the terminology might be confusing. However, the comment lacks depth and does not provide suggestions on how to address this issue or what alternative terminology could be used. While it highlights a potential problem, it does not offer actionable guidance for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers the authors to another section for more information, but without explicit instructions or concrete suggestions, the authors are left without a clear path forward. This makes the comment vague and 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details or provide specific examples of what is lacking. The comment refers the authors to another section, \"Clarity, Quality, Novelty And Reproducibility,\" for more information, but this does not help the authors identify the exact issues in their current draft. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to determine what needs to be addressed. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, making it difficult for the authors to understand and address the issues. The comment refers to another section for more information, but without detailed justification or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment indicates that the paper lacks polish and details in several areas, including related work, experiments, and writing. However, it does not provide specific examples or suggestions on how to address these issues, leaving the authors without actionable guidance. The comment refers to another section for more information, but this does not help the authors identify the exact weaknesses or improvements needed. As a result, the comment is 1, as it does not offer any meaningful feedback or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights specific steps in the process and suggests that the authors should focus on studying the essentialness of using an orthogonal matrix, particularly in Step 3. It implies that the authors should investigate the impact of orthogonal matrices on the process, which is a concrete action. However, the comment does not provide detailed guidance on how to conduct this investigation or what specific aspects to focus on. While the action is clear, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the study of the essentialness of using an orthogonal matrix, particularly in Step 3. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an orthogonal matrix is essential for a specific step in the process, suggesting that this aspect should be studied further. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or its significance. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific feedback on the process described in the paper, particularly focusing on the use of an orthogonal matrix. It highlights that the token reverse is easily obtained as the transpose of the matrix and that Step 2 can be performed regardless of the weight matrix being orthogonal or not. The comment emphasizes the importance of Step 3, where only an orthogonal matrix weight can perform, and suggests that this aspect should be studied further to validate the necessity of using an orthogonal matrix. This feedback is clear and actionable, offering the authors a specific area to focus on for improving their draft. However, it could be more helpful if it provided additional guidance on how to conduct this study or what specific aspects to investigate. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5, specifically asking if it is due to overfitting. While it prompts the authors to consider the potential cause of the accuracy drop, it does not provide explicit guidance on how to address this issue or what steps to take to investigate further. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the possibility of overfitting and potentially conduct additional analysis or experiments to clarify the reason for the accuracy drop. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the accuracy drop after a certain order and suggests a possible reason, overfitting. This provides the authors with a clear direction on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5, specifically asking if it is due to overfitting. It does not contain a claim or opinion that requires verification. It is a request for information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the accuracy drop in Figure 5, asking if it is due to overfitting. While it prompts the authors to consider a potential explanation for the observed phenomenon, it lacks depth and does not provide any actionable suggestions or guidance on how to address this issue. The comment identifies a potential area of concern but does not offer a clear path for improvement, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the models and datasets used in the paper are too toylike and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to enhance the experiment. The reviewer also asks if there is a foreseeable challenge to experiment on language tasks. While the comment provides explicit suggestions for improvement, it lacks concrete guidance on how to implement these suggestions or address the question about language tasks. The authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the models and datasets used in the paper, suggesting that they are too toylike and proposing specific alternatives like CIFAR100, ResNet 34 or 50, and ViTtiny or small. However, it does not specify which part of the paper discusses these models and datasets, making it weakly grounded. The comment is specific in suggesting alternative models and datasets, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the models and datasets used are \"too toylike\" and suggests using more challenging datasets like CIFAR100 or models like ResNet 34 or 50. The reviewer provides specific examples of alternative models and datasets, which supports the claim. However, the comment lacks detailed reasoning or references to justify why these alternatives are more suitable or challenging. While the suggestion is clear, the lack of detailed explanation or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the models and datasets used in the paper, suggesting that they are too toylike. It provides specific and actionable suggestions for improvement, such as using CIFAR100, ResNet 34 or 50, and ViTtiny or small, which would enhance the experiment. Additionally, the reviewer raises a question about the feasibility of experimenting on language tasks, which could prompt the authors to consider this aspect. The comment is clear and offers concrete guidance, making it 5 for the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This implies that the authors should conduct these ablation studies to provide a more comprehensive understanding of their results. However, the comment does not explicitly instruct the authors to conduct these studies or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for additional studies but may not know exactly how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that some natural ablation studies are missing, specifically asking about the performance of scratchGAN when pretraining is used. This implies that the authors should include these studies to provide a more comprehensive understanding of their results. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. It is specific in suggesting the inclusion of these ablation studies, particularly the one regarding pretraining. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This claim is 3 as it provides a clear suggestion for additional studies that could enhance the paper\"s comprehensiveness. However, the comment lacks specific examples or references to support the importance of these ablation studies, which would strengthen the justification. Therefore, the comment is rated as 3, as it provides a logical suggestion but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This is a valuable observation that could enhance the comprehensiveness of the paper. However, the comment could be more helpful if it provided specific guidance on how to conduct these ablation studies or what aspects of the results should be focused on. Additionally, the mention of a \"central argument against pretraining\" is not fully elaborated, leaving the authors without clear direction on how to address this point. Overall, the comment provides some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify how they handle comparisons between episodes of different lengths in the equation between lines 282 and 283. It also provides specific details about the method used, which is padding the shorter sequence by replicating its last state. Additionally, the comment suggests that the lack of a normalization factor of 1/T can lead to an increase in distance with T, favoring longer trajectories. This feedback is clear and provides concrete guidance on what needs to be addressed and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the equation between lines 282 and 283,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of handling comparisons between episodes of different lengths and suggests that the authors should clarify how they handle this in the equation. Additionally, it provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and points out the lack of a normalization factor of 1/T, which affects the distance calculation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides specific details about the method used, such as padding the shorter sequence by replicating its last state, and notes that the lack of a normalization factor of 1/T can lead to an increase in distance with T, favoring longer trajectories. This reasoning is logical and provides a clear explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific literature or studies that support the claim about the impact of normalization on trajectory comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the handling of comparisons between episodes of different lengths in the equation between lines 282 and 283. It provides detailed feedback by explaining the method used to handle this issue, such as padding the shorter sequence by replicating its last state. Additionally, the comment points out the lack of a normalization factor of 1/T, which can lead to an increase in distance with T and favor longer trajectories. This feedback is actionable and provides clear guidance on how the authors can improve their draft by clarifying these aspects. However, the comment could be more helpful if it suggested alternative methods or provided further context on why this issue is important. Overall, the comment is 4, as it effectively directs the authors to address a critical aspect of their methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the study, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses should be conducted to explore the impact of Vision Transformer or the pruning strategy in selfattention layers. The action is implicit and somewhat vague, as the authors can infer that they need to consider including Vision Transformer and exploring its impact, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of Vision Transformer, an important stateoftheart model in image classification, and questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This provides clear guidance on what needs to be addressed in the experiment section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the absence of Vision Transformer in the experiment, noting its importance as a stateoftheart model in image classification. It also questions whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. While the comment highlights a potential gap in the study, it lacks specific examples or references to support the claim that Vision Transformer is an important model or that its inclusion would significantly impact the results. The reasoning is somewhat logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experiment by pointing out the absence of Vision Transformer, an important stateoftheart model in image classification. It raises a question about whether the pruning strategy would differ in selfattention layers for larger datasets like ImageNet. This feedback is clear and actionable, as it prompts the authors to consider including Vision Transformer in their experiments and to explore its impact on the pruning strategy. By addressing this gap, the authors can enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it provided specific suggestions on how to incorporate Vision Transformer or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against baselines in the paper, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment suggests that this is a common practice in binary analysis applications and that many papers have developed architectureagnostic similarity comparisons or reported similar tasks. While the comment implies that the authors should include baselines for comparison, it does not explicitly instruct them to do so or provide specific guidance on which baselines to use. The action is implicit and somewhat vague, as the authors can infer the need for baselines but may not know exactly which ones to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the lack of baselines in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not comparing against baselines and references a common practice in binary analysis applications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment supports this claim by referencing a \"widelyunderstood binary analysis application\" and mentioning that many papers have developed architectureagnostic similarity comparisons or reported similar tasks. This provides a logical reasoning and common knowledge basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the assertion about the prevalence of baseline comparisons in similar studies. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison against baselines. It highlights that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines, which is a common practice in binary analysis applications. The comment also references the existence of architectureagnostic similarity comparisons or codesearch tasks, suggesting that the authors should include baselines for comparison. This feedback is clear and actionable, providing the authors with a specific area for improvement and a direction for enhancing the validity and relevance of their study. However, the comment could be more helpful if it offered suggestions on which baselines to consider or how to incorporate them into the study. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a specific mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention a specific difference in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This claim is based on a logical observation and does not require external references or detailed reasoning. The suggestion is clear and straightforward, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement. It instructs the authors to include a mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This feedback is clear and direct, offering the authors a concrete way to enhance their draft by clarifying the evaluation process. By addressing this point, the authors can provide a more comprehensive understanding of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies several issues with the figures in the paper, specifically mentioning that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also notes that it is difficult to link the captions to specific parts of the main text. This feedback provides clear and concrete actions for the authors to take, such as increasing the font size of the text in the figures, clarifying the inputs and outputs for each task, and ensuring that the captions are selfcontained and linked to relevant parts of the main text. The explicit nature of the actions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issues with the figures, such as the small text size, unclear inputs and outputs, and nonselfcontained captions. Additionally, it highlights the difficulty in linking the captions to specific parts of the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text size, unclear inputs and outputs, and nonselfcontained captions. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that the text is too small, the inputs and outputs for each task are not clearly explained, and the captions are not selfcontained. It also points out the difficulty in linking the captions to certain parts of the main text. This feedback is clear and actionable, as it provides concrete suggestions for improvement, such as increasing the font size of the text in the figures and clarifying the inputs and outputs for each task. By addressing these issues, the authors can enhance the readability and comprehensibility of their figures, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claims of efficiency advantages over previous work and the lack of metrics in the paper to support these claims. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include metrics to demonstrate the efficiency of their proposed method, but the comment lacks concrete details on what specific metrics should be used or how to present them. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the paper not reporting any metrics to demonstrate the efficiency of the proposed method, despite claims of advantages over previous work. However, it does not specify which part of the paper discusses these advantages or where the metrics should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the lack of metrics but lacks grounding, as it does not provide a clear reference to the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide metrics to support the claim of efficiency advantages over previous work. This is a subjective opinion that requires justification, as it challenges the authors\" assertion of efficiency. However, the comment does not provide specific examples or references to support the claim that the paper lacks necessary metrics. Without detailed evidence or examples, the claim remains 3, as the authors would need to provide additional information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically that it claims advantages over previous work in terms of efficiency but lacks any metrics to support these claims. This is a significant gap in the paper, as it undermines the credibility of the authors\" assertions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which metrics to include or how to present them. While it highlights a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a key weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific suggestions or guidance on how to enhance the contribution or address the perceived limitations. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically mentioning the overfitting problem of training GANs with limited data and the proposal of differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in identifying the issue with the contribution, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the contribution of the paper is not sufficient, specifically addressing the overfitting problem of training GANs with limited data and proposing differentiable augmentation. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the sufficiency of the paper\"s contribution, specifically mentioning the overfitting problem of training GANs with limited data and the proposal of differentiable augmentation. However, it does not provide any specific suggestions or guidance on how the authors might enhance their contribution or address the perceived limitations. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights an issue but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details at line 81, specifically asking about the nature of the statespace (finite or continuous), the actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be better to be precise. This feedback is clear and direct, providing the authors with a concrete action to take to improve their draft. The comment is explicit and actionable, as it specifies exactly what needs to be clarified and why. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing more details about the statespace, actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be better to be precise, which further clarifies the need for detailed information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more details about the statespace, actions, and the space in which theta lies. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors could provide more clarity and detail. By asking about the nature of the statespace, actions, and the space in which theta lies, the reviewer highlights a potential source of confusion that could be addressed. However, the comment does not offer specific suggestions or guidance on how to improve the clarity or provide the requested details. While it points out an area for improvement, it lacks depth and actionable advice, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the effectiveness of the method on general reasoning tasks versus mathematical reasoning, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the method\"s performance on general reasoning tasks. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment compares the effectiveness of the method on general reasoning tasks versus mathematical reasoning, but it does not specify which part of the paper this comparison is based on. The authors cannot confidently determine which sections or results are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the method are ineffective or how they could be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it lacks specific examples, evidence, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential limitation of the method, noting that it does not perform well on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on general reasoning tasks. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the proof technique, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity, and references Section 3 for further context. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged by the authors in Section 3. However, the comment does not provide any additional reasoning, examples, or references to support this claim. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that this is mentioned in Section 3, where the authors discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the proof technique. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are informed of a specific area needing attention but are not provided with a clear path forward for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also mentions recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback provides a clear and explicit action for the authors to take, which is to include GDSS as a baseline in Table 3 and consider the recent work as a potential baseline. The suggestion is concrete and directly actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. Additionally, it provides a suggestion for using recent work as a baseline, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the continuous diffusion model (GDSS) should be compared as a baseline in Table 3, given its performance in Table 2. It also references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. The claim is supported by the mention of specific models and recent work, providing a logical basis for the suggestion. However, the comment could be strengthened by providing more detailed references or examples from the recent work. Overall, the claim is 4, as it offers a clear rationale but lacks comprehensive evidence, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending that the continuous diffusion model (GDSS) be compared as a baseline in Table 3, given its performance in Table 2. It also references recent work that proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft by incorporating additional comparisons and references. However, the comment could be more helpful if it provided further details or examples from the recent work to support the suggestion. Overall, the comment is 4, as it provides valuable guidance for improving the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a personal belief that LiDARbased segmentation is the best choice for the downstream task, contrasting with the authors\" use of object detection. It also provides a rationale for this belief, suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment does not provide explicit guidance or suggestions for the authors to consider alternative methods or address the potential limitations of their current approach. The action is implicit and somewhat vague, as the authors are left to infer that they should consider LiDARbased segmentation but are not given concrete steps on how to implement this change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment discusses the choice of downstream task, specifically object detection, and suggests that LiDARbased segmentation might be a better choice. It provides a rationale for this suggestion, noting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream task or object detection, making it weakly grounded. The comment is specific in detailing the potential issue with the current approach and suggesting an alternative, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion that LiDARbased segmentation is a better choice than object detection for the downstream task. The reviewer provides a rationale by suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment lacks specific examples or references to support the claim that LiDARbased segmentation is superior. The reasoning is somewhat logical but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a subjective opinion that LiDARbased segmentation is a better choice than object detection for the downstream task. It offers a rationale by suggesting that colorizationbased pretraining focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. This feedback is 3 as it highlights a potential limitation of the current approach and suggests an alternative method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or explore LiDARbased segmentation further. To be more helpful, the comment could include detailed advice or examples of how to implement LiDARbased segmentation or discuss its potential benefits. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential contradiction between the objective of Eq (12) and the IPO (Initial Point Optimality), but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for how to resolve the contradiction, what changes might be needed, or even a request for clarification. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (12),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential contradiction with IPO, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the objective of Eq (12) is in contradiction with IPO (Initial Point Optimality). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the objective of Eq (12) in relation to IPO (Initial Point Optimality). However, it does not provide any further explanation or context about what this contradiction entails or how it might impact the paper. Without additional guidance or suggestions on how to address this issue, the comment lacks actionable feedback that could help the authors improve their draft. Therefore, it is rated as 2, as it points out a potential problem but does not offer any meaningful direction for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity, as it does not add any value to allow \"t\" to be arbitrary. This comment explicitly states a specific action that the authors should take to improve their draft, providing clear guidance on what needs to be changed. The suggestion is concrete, as it specifies exactly what needs to be replaced and why, making it easy for the authors to implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of \"T\" for clarity, providing a clear and actionable recommendation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of \"T\" in the histogram intersection kernel for clarity, as it does not add any value to allow \"t\" to be arbitrary. However, the comment does not provide any reasoning or justification for why this change would improve clarity or why \"t\" being arbitrary is problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of \"T.\" This feedback is actionable and clear, as it identifies a potential source of confusion and offers a concrete solution. However, the comment could be more helpful if it explained why this change would enhance clarity or how it might impact the understanding of the kernel. Despite this, the suggestion is valuable and provides the authors with a clear direction for improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, questioning whether the image encoder can produce meaningful embeddings for these concepts. It highlights a potential issue with concepts where the class label is more semantically related than geometrically. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they should investigate or discuss the limitations of their approach in relation to semantic concepts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts. It provides a nuanced analysis by distinguishing between geometrically distinctive concepts and those where class labels are more semantically related. However, it does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in detailing the concern about the adaptation capacity, particularly for concepts with semantic rather than geometric correlations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, questioning whether it can accommodate new concepts, especially those where class labels are more semantically related than geometrically. The reviewer provides a logical reasoning by distinguishing between geometrically distinctive concepts and those with semantic correlations, suggesting that the adaptation capacity might be less effective for the latter. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this critique and potentially provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a thoughtful concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts, particularly those where class labels are more semantically related than geometrically. This is a relevant and insightful observation that could help the authors refine their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the adaptation capacity. While it highlights an important area for consideration, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and direct action for the authors to take, as it specifies the exact comparison that should be added to the paper. The comment is 5 because it gives precise guidance on what needs to be done to enhance the paper, leaving no ambiguity for the authors. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the types of loss functions to be compared, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how these comparisons would enhance the paper. The suggestion is based on common knowledge in the field of biometric verification, but the comment could be strengthened by providing more context or examples of how these comparisons would impact the paper\"s contributions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that could be compared, offering the authors a concrete direction for enhancing their draft. By incorporating this comparison, the authors can better position their work within the current state of the field and provide a more comprehensive evaluation of their approach. However, the comment could be more helpful if it explained why these specific loss functions are relevant or how they might impact the paper\"s contributions. Overall, the comment is 4, as it provides valuable guidance for improving the paper, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take, including correcting grammatical errors, ensuring consistency in terminology, and correcting formatting issues in tables and references. Each of these actions is concrete and directly stated, leaving no ambiguity for the authors on what needs to be done. The comment is 5 as it provides clear and specific instructions for improvement, allowing the authors to make precise changes to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, allowing the authors to accurately identify the parts that need attention. It is also specific because it details the issues, such as grammatical errors, inconsistencies in terminology, and formatting errors in tables and references. The comment provides clear guidance on what needs to be corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and corrections, such as grammatical errors, inconsistencies in terminology, and formatting issues. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a list of specific corrections and improvements that need to be made to the manuscript. It addresses grammatical errors, inconsistencies in terminology, and formatting issues in tables and references. Each point is clear and actionable, allowing the authors to make precise changes to their draft. However, the comment could be more helpful if it offered additional context or explanation for why these corrections are important or how they might impact the overall quality of the paper. Despite this, the feedback is 4 as it provides concrete steps for improvement, making it a valuable resource for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit suggestions for improving the clarity and readability of the paper. It suggests spelling out \"F.L.T.R\" in figure 4, addressing the issue of small text in figure 1, and recommending notation and figure crossreferencing. These suggestions are concrete and provide clear actions for the authors to take, ensuring they know exactly what changes to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"figure 4,\" \"figure 1,\" and the use of \"M and N\" without definition. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details the issues with notation, suggests spelling out \"F.L.T.R\" in figure 4, and recommends improving the visibility of figure 1 text and crossreferencing notation and figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple suggestions for improving the clarity and readability of the paper, including clarifying notation, spelling out \"F.L.T.R\" in figure 4, and addressing the small text in figure 1. These suggestions are factual and descriptive, providing guidance on how to enhance the paper without making subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the clarity and readability of the paper. It points out specific issues, such as the confusion caused by the use of \"M and N\" without definition, and suggests spelling out \"F.L.T.R\" in figure 4. Additionally, it highlights the problem of small text in figure 1 and recommends crossreferencing notation and figures. These suggestions are clear and concrete, offering the authors specific ways to enhance the presentation and accessibility of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the issues. Overall, the feedback is 4 as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. However, it does not provide explicit guidance on how to address this issue or suggest alternative notations. The action is implicit, as the authors need to infer that they should clarify or change the notation to avoid confusion. The comment lacks concrete details on how to implement this change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the potential confusion caused by using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2. This provides clear guidance on what needs to be clarified or addressed in the algorithm. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using $p$ to denote both the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing. However, the comment does not provide any reasoning or evidence to support why this notation is confusing or how it affects the understanding of the algorithm. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and the dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it directs the authors to clarify or change the notation to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending alternative notations or explaining the context in which $p$ is used. Despite this, the comment is 4 as it highlights a specific area for improvement that can enhance the clarity and readability of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit suggestions for improving the paper. It recommends adding a more detailed, mathematical formulation of the approach in the appendix, which would help readers understand the methodology better. Additionally, it suggests enhancing the figure by adding more text labels to clarify its content. The comment also suggests reworking the figure to better align with the main contribution of the paper, which is improvements on the WiC task. These suggestions are concrete and provide clear actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as adding a more detailed mathematical formulation in the appendix and enhancing the figure by adding text labels. Additionally, it suggests reworking the figure to better align with the main contribution of the paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description of the approach is helpful for understanding it intuitively, but it lacks a detailed mathematical formulation, which would be beneficial. It also critiques the figure, stating it is too abstract and does not align well with the main contribution of the paper, suggesting that reworking the figure to depict the WiC task could improve it. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the figure being confusing or the need for a more detailed formulation. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides constructive feedback on two aspects of the paper: the highlevel description and the figure. It suggests that while the highlevel description is helpful for understanding the approach intuitively, a more detailed mathematical formulation would be beneficial, possibly in the appendix. Additionally, the comment critiques the figure, noting that it is too abstract and does not align well with the main contribution of the paper, which is improvements on the WiC task. The reviewer offers specific suggestions for improving the figure, such as adding more text labels and reworking it to better depict the WiC task. These suggestions are actionable and provide clear guidance for the authors to enhance the clarity and relevance of their work. However, the comment could be more helpful if it included examples or further elaboration on how to implement these suggestions. Overall, the feedback is 4 as it identifies areas for improvement and offers concrete steps for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not specify which tasks should be included or how they should be integrated into the paper. The action is implicit and somewhat vague, as the authors are left to infer which tasks might be relevant and how to implement them. While the comment provides a general direction, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where benchmarking results are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding which additional benchmarking tasks should be included or why they are necessary. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would be beneficial. However, it does not provide any reasoning, examples, or references to support why these additional tasks are necessary or how they would enhance the paper. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1.", "helpfulness_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would be beneficial. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on which specific tasks should be included or how they might enhance the paper. This makes it 3, as it points out a potential area for expansion but does not offer actionable advice for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the experiments, specifically asking for the comparison results of YOSO with linformer on iterationwise convergence and seeking an explanation for the difference in performance. While the comment does not explicitly instruct the authors to provide these comparisons or explanations, it implies that these are necessary for a complete understanding of the results. The authors can infer that they need to include these comparisons and analyses in their draft. However, the comment lacks concrete guidance on how to conduct these analyses or present the results, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing from the pretraining experiment part, namely the comparison of steps vs. ppl of linformer with YOSO, and asks for the comparison result of YOSO with linformer on iterationwise convergence. Additionally, it raises a question about the comparison to an explanation that can analyze the difference in performance between YOSO and linformer. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and observations about the experiments, specifically regarding the comparison between YOSO and linformer. It questions the absence of steps vs. ppl of linformer with YOSO in Figure 4 and asks for the comparison result of YOSO with linformer on iterationwise convergence. Additionally, it notes that linformer demonstrates better accuracy in downstream tasks like SST2 and requests an explanation for this difference. While the comment identifies areas for clarification and comparison, it lacks specific evidence or references to support the claims or suggestions. The reasoning is 3 as it provides a logical framework for the questions raised, but it requires more detailed justification or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of experimental results, noting that the pretraining experiment part does not provide a comparison of steps vs. ppl of linformer with YOSO in Figure 4. It also raises questions about the comparison of YOSO with linformer on iterationwise convergence and the difference in performance on downstream tasks like SST2. Additionally, it suggests that an explanation is needed to analyze the difference in performance between YOSO and linformer. This feedback is clear and actionable, as it directs the authors to include specific comparisons and analyses that would enhance the comprehensiveness and clarity of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct these analyses or present the results. Overall, the comment is 4, as it effectively points out areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text, specifically regarding the requirement for the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for correction, clarification, or improvement. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the abstract requires the proposal distribution to upper bound the target everywhere, which is contradicted by the text. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a clear and actionable feedback that highlights a potential error or inconsistency in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it points out a critical area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 1, where the reference to \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer provides a clear suggestion to clarify this by referencing the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reference to \"PointNet\" and provides a suggestion to clarify this by referencing the correct paper. The comment provides a detailed explanation of the confusion and offers a solution, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing due to the absence of this name in the paper and the existence of another paper with the same name. The reviewer supports this claim by providing a specific reference to the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This external reference provides a clear and robust justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reference to \"PointNet\" in Figure 1, pointing out that the name does not appear in the paper and is confused with another paper. It provides a clear suggestion to clarify this by referencing the correct paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. This feedback is actionable and provides a precise way for the authors to improve the clarity and accuracy of their references, making it 5 for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and whether it solves the optimal problem, suggesting that clarification might be needed. It also provides minor corrections, such as removing \"on learning  on\" from Line 78 and correcting the equation in Line 132. While the comment implies that the authors should clarify the policy gradient and make these minor corrections, the actions are not explicitly stated. The feedback is 4 because it provides concrete suggestions for improvement, but the authors need to infer the need for clarification and the specific corrections. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. 6 and Eq. 5) and lines (78 and 132), allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for clarification and minor corrections, such as removing unnecessary text and correcting an equation. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and its relation to solving the optimal problem in Eq. 5. It suggests that clarification might be needed, but it does not provide any specific reasoning, examples, or references to support the claim. The comment is more of a request for clarification rather than a claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Eq. 6, questioning whether it solves the optimal problem and whether the optimal solution to Eq. 5 is obtained after convergence. This is a valid concern that could help the authors clarify their methodology. Additionally, the comment provides minor corrections, such as removing unnecessary text and correcting an equation. While the feedback is 3 in identifying areas for clarification and improvement, it could be more comprehensive by providing detailed guidance on how to address the questions raised. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it is possible to assume a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks for clarification on the difference between the two. While the comment implies that the authors should consider this alternative, it does not provide explicit guidance on how to address the question or what specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and provide a response. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this assumption is discussed. Without explicit references, the authors may find it challenging to determine where to address this question. The comment is specific in its inquiry about the difference between the two distributions, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification on the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on whether it is possible to assume a general Gaussian distribution and what the difference is between the two. While the comment identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or its implications for their work. The feedback is 3 as it prompts the authors to consider an alternative assumption, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a potential issue with the paper, specifically the decision to freeze the partitioning in the first iteration. It suggests that this choice makes strong assumptions about the coverage of the initial data and recommends discussing the limitations of this approach. The comment provides a clear and direct action for the authors to take, which is to address the limitations of this method. This feedback is concrete and actionable, as it specifies exactly what needs to be discussed in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential risk of freezing the partitioning in the first iteration and suggests that the authors should discuss the limitations of this approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a \"risky choice\" that makes strong assumptions about the coverage of the initial data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the decision to freeze the partitioning in the first iteration. It suggests that this choice may make strong assumptions about the coverage of the initial data and recommends that the authors discuss the limitations of this approach. This feedback is clear and actionable, as it points out a specific area that may need further consideration or explanation. However, the comment could be more helpful if it provided additional context or suggestions on how to address the limitations or potential risks associated with this choice. Overall, the comment is 4, as it directs the authors to a critical area that requires attention, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, implying that the authors should clarify or justify the purpose of this section. However, it does not provide any explicit guidance or suggestions on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation about the section\"s intent. Without specific instructions or examples, the authors may find it challenging to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the intent of this section, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2, rather than a claim or opinion that requires verification. It does not contain any subjective opinions, judgments, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, indicating that the authors should clarify the purpose or meaning of this section. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed advice, the authors are left with a vague understanding of what needs to be improved. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the approach, specifically regarding how it integrates knowledge about objects and verbs to overcome reporting bias. It also notes that the paper quickly delves into technical details without adequately explaining the overall approach or its rationale. While the comment identifies areas that need clarification, it does not provide explicit guidance on how to address these issues or suggest specific changes to improve the clarity of the explanation. The action is implicit and somewhat vague, as the authors are left to infer what needs to be clarified and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many aspects of the approach\" that need clarification, implying that the reviewer has specific parts of the paper in mind. It also highlights a particular concern about the interaction between knowledge about objects and verbs and how it relates to overcoming reporting bias. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification, specifically regarding how it integrates knowledge about objects and verbs to overcome reporting bias. The reviewer expresses concern about the lack of clear explanation of the overall approach and its rationale, particularly in the transition to technical details. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issues. The lack of concrete evidence or references leaves the claim 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity, specifically regarding the integration of knowledge about objects and verbs to overcome reporting bias. It highlights that the paper quickly delves into technical details without adequately explaining the overall approach or its rationale. This feedback is valuable as it points out a critical area where the authors need to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue, such as recommending additional explanations or diagrams to illustrate the approach. Despite this, the comment is 4 as it directs the authors\" attention to a key area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors need to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, such as defining the assumed threat model, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically regarding the attacker\"s level of access, capabilities, and the defender\"s available resources. The comment provides a clear and logical reasoning for why this clarification is necessary, particularly in the context of whitebox access to the victim model. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides clear and actionable feedback by suggesting that the authors define the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the decision to use early stopping based solely on link prediction accuracy should be explained. It implies that the authors should provide a rationale for this choice, possibly by considering alternative metrics like type accuracy. While the comment does not explicitly instruct the authors to include this explanation, it provides a clear direction on what aspect of the paper needs clarification. The action is implicit but concrete, as the authors know they need to address the reasoning behind their choice. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the decision to use early stopping only based on link prediction accuracy and suggests considering an average with type accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping based solely on link prediction accuracy, suggesting that it should be explained and potentially considering an average with type accuracy. However, the comment does not provide any reasoning or evidence to support why this decision might be problematic or why an average with type accuracy would be beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, questioning the decision to use early stopping based solely on link prediction accuracy. It suggests that the authors should explain this choice, potentially by considering an average with type accuracy. This feedback is clear and actionable, as it directs the authors to provide a rationale for their methodological choice, which could enhance the clarity and robustness of their approach. However, the comment could be more helpful if it provided additional context or examples of how this explanation could be integrated into the paper. Overall, the comment is 4, as it offers a specific suggestion for improvement that the authors can act upon."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feasibility of setting a classimbalanced task in the fewshot learning setting, where there are only a few examples for each class. It explicitly asks the authors to explain this with concrete details, providing a clear and direct action for the authors to take. The comment is explicit and concrete, as it specifies exactly what the authors need to address and how they should do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the feasibility of setting a classimbalanced task in the fewshot learning setting and asks for concrete details on how to achieve this. The comment provides a clear direction for the authors to address the issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of setting a classimbalanced task in the fewshot learning setting, where there are only a few examples for each class. It asks the authors to explain this with concrete details, which is a request for clarification rather than a claim. Since it does not make a subjective claim or judgment, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the feasibility of setting a classimbalanced task in the context of fewshot learning, where there are only a few examples for each class. It prompts the authors to provide concrete details on how to address this issue, which is a valuable suggestion for improving the clarity and relevance of the paper. However, the comment could be more helpful if it offered specific guidance or examples on how to approach this challenge. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further explanation, making it a useful contribution to the review process. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a critique of the chatGPT baseline, labeling it as \"very rudimentary\" and suggesting that a fewshot approach is not tested. It also offers a potential improvement by suggesting the inclusion of discourse relation information in the prompts, possibly using a ChainofThought style approach. While the comment identifies areas for improvement, it does not provide explicit instructions on how to implement these suggestions or test the fewshot approach. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatGPT baseline, describing it as \"very rudimentary\" and suggesting that a fewshot approach is not tested. It also proposes including discourse relation information in the prompts, possibly using a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatGPT baseline or where the evaluation is presented, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific suggestions for improvement, it lacks grounding, as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the chatGPT baseline is \"very rudimentary\" and suggests that a fewshot approach is not tested. It also proposes including discourse relation information in the prompts, possibly using a ChainofThought style approach, which could yield better results. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the reasoning behind the critique and the potential benefits of the suggested approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by labeling the chatGPT baseline as \"very rudimentary\" and noting that a fewshot approach is not tested. It also provides a constructive suggestion by proposing the inclusion of discourse relation information in the prompts, possibly using a ChainofThought style approach, which could potentially yield better results. This feedback is actionable and offers a clear direction for improvement, as it suggests a specific way to enhance the evaluation of the paper. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is 4, as it provides valuable insights and actionable feedback, but could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explanation regarding the ground truth of sensitivity, specifically noting that the authors only mention \"pruning\" without providing details on how it was done. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide more details on the pruning process. However, the comment lacks concrete instructions on what specific details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail on how the ground truth of sensitivity is achieved, particularly regarding the pruning process. The comment provides a clear direction for the authors to address this gap in their explanation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning the lack of explanation regarding the pruning process. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detailed explanation, namely the process of achieving the ground truth of sensitivity through pruning. It points out that the current explanation is insufficient, as it only mentions \"pruning\" without providing details on how it was done. This feedback is 3 as it directs the authors to a particular section of the paper where they need to provide more detailed information. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the text could be written more clearly, providing explicit examples of what needs clarification. It suggests that the authors should explain what a proper rotation matrix is in line 97 and clarify the meaning of \"solving the problem of the matrix being non positive semidefinite\" in lines 105106. These are direct and concrete actions that the authors can take to improve their draft. The comment provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (97 and 105106) where the text could be clarified. This allows the authors to accurately identify the parts of the paper that need improvement. The comment is also specific because it clearly specifies what needs to be addressed: the explanation of a proper rotation matrix and the meaning of solving the problem of the matrix being non positive semidefinite. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting clarification on specific points in the text. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be improved by suggesting that certain parts need to be written more clearly. It provides explicit examples of what needs clarification, such as the explanation of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being non positive semidefinite in lines 105106. This feedback is actionable and provides clear guidance for the authors to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a potential improvement by recommending a change in terminology from \"g activation function\" to \"a binary operator,\" similar to the approach by Cohen and Shashua (2016). However, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The suggestion is implicit and somewhat vague, as the authors are left to infer the exact steps needed to make this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a change in terminology from \"g activation function\" to \"a binary operator,\" providing a clear direction for improvement. Additionally, it references a specific work by Cohen and Shashua (2016) to support the suggestion, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a change in terminology from \"g activation function\" to \"a binary operator,\" referencing a similar approach by Cohen and Shashua (2016). The comment provides a specific reference to support the suggestion, which is a clear and logical reasoning for the proposed change. This level of detail and reference makes the claim 5, as it provides a solid basis for the authors to consider the suggested change. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the terminology used in the paper, recommending a change from \"g activation function\" to \"a binary operator.\" It references a similar approach by Cohen and Shashua (2016), which adds context and supports the suggestion. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and precision of their work. However, the comment could be more helpful if it explained why this change is beneficial or how it aligns with the broader context of the paper. Overall, the comment is 4 as it provides a valuable suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for the methods or related work sections. This provides a clear and direct action for the authors to take, along with a concrete suggestion on how to implement it. The comment is explicit and provides specific guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they have large overlaps with the content and recommending shrinking them to leave more space for the methods or related work sections. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, implying that this could be improved by shrinking the captions. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to consider shrinking the captions to leave more space for the methods or related work sections. This feedback is valuable as it directly addresses a visual aspect of the paper that could be improved, offering a concrete way for the authors to enhance the presentation of their work. However, the comment could be more helpful if it included examples or further guidance on how to effectively reduce the overlap. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al., 2021, as a benchmark, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this dataset as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of excluding Vidgen et al., 2021, from the table, and questions why this dataset is not used as a potential benchmark for evaluation. The comment provides a clear rationale for why this dataset might be relevant, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the exclusion of Vidgen et al., 2021, from Table 2, suggesting that it might be similar to the dataset presented in the work. The reviewer questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. The comment provides a logical reasoning by pointing out the potential similarity and the absence of this dataset, which could be relevant for the evaluation. However, it lacks specific references or detailed comparisons to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of datasets in Table 2, noting the exclusion of Vidgen et al., 2021, which might be similar to the dataset presented in the work. It questions why this dataset is not used as a potential benchmark for evaluation, particularly for investigating the role of context in detecting hate. This feedback is clear and actionable, as it prompts the authors to consider including this dataset for a more comprehensive evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate Vidgen et al., 2021, into the evaluation framework. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) with errorbars. It also emphasizes the importance of providing statistics due to the small size of the models. This feedback is clear and provides specific guidance on what the authors need to do to improve their draft. The action is explicit and concrete, leaving no ambiguity about how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results comparing standard vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting the results as a mean over many runs (at least 10) with errorbars, and justifying the need for statistics due to the small size of the models. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars to account for potential fluctuations. The reviewer argues that the models are small, making it necessary to provide statistics. This claim is supported by logical reasoning, as it highlights the importance of statistical analysis for small models to ensure reliability. However, the comment could be strengthened by providing specific examples or references to similar practices in the field. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed examples or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback regarding the presentation of results. It suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars to account for potential fluctuations. This is a clear and constructive suggestion that can help the authors improve the robustness and clarity of their results. By emphasizing the importance of statistical analysis, especially for small models, the comment offers a valuable insight that can enhance the credibility and reliability of the findings. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is particularly important for the specific models being studied. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers. However, the comment does not provide explicit guidance or suggestions for the authors to improve their approach or address these limitations. The feedback is implicit and lacks concrete details on how the authors might enhance their work. As a result, the authors are left without a clear understanding of what actions to take to address the concerns raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The authors can make an educated guess about the sections related to the proposed approach and the comparison with operator learning methods, but the comment lacks full grounding. It is specific in detailing the critique of the approach, but the lack of explicit references to specific sections or parts of the paper limits its grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the proposed approach by suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also compares the approach to current operator learning methods, noting their limitations compared to specialized numerical solvers. The comment provides a logical reasoning by highlighting the differences between the proposed approach and existing methods, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to delve deeper into the literature to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical evaluation of the proposed approach, suggesting that it merely learns a surrogate model for solving linear/linearized systems of equations in FEM, without addressing the need for carefully choosing basis functions and meshes, and assembling stiffness matrices. It also highlights the limitations of current operator learning methods compared to specialized numerical solvers, noting that they are more universal but less accurate. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The feedback is 3 as it points out a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this information is important, explaining its potential impact on training and inference speeds. Therefore, the comment is 5, as it provides a specific and concrete action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically referencing the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment and its potential impact on training and inference speeds. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the logical reasoning that different versions of the experimental environment can affect training and inference speeds. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this detail and how it might impact their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for a more detailed description of the experimental environment, including the CUDA and PyTorch versions. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the transparency and reproducibility of the study. By addressing this point, the authors can better inform readers about the conditions under which their experiments were conducted, which is crucial for understanding the results and potential applications. However, the comment could be more helpful if it included additional guidance on how to present this information or why it is particularly important for the specific context of the paper. Overall, the comment is 4 as it directs the authors to a significant improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point consists of two parts: an observation about the challenges of using fully realistic datasets and an agreement with the authors\" judgment regarding societal impact. Neither part provides explicit or implicit actions for the authors to take. The comment does not suggest any changes or improvements to the draft, leaving the authors without guidance on how to address the issues raised. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, leaving the authors uncertain about where to focus their attention. It also lacks specificity, as it does not detail what aspects of the dataset or societal impact are being discussed. Without clear references or detailed feedback, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two separate statements: an observation about the challenges of using fully realistic datasets and an agreement with the authors\" judgment regarding societal impact. The first statement is a factual observation and does not contain a claim. The second statement is a subjective agreement with the authors\" judgment, which is not verifiable as it lacks any supporting evidence or reasoning. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment consists of two separate statements. The first part discusses the challenges of using fully realistic datasets, which could be a relevant point for the authors to consider in their methodology. However, it does not provide any actionable advice or suggestions on how to address these challenges. The second part agrees with the authors\" judgment regarding societal impact, which is a factual statement and does not offer any constructive feedback for improvement. Overall, the comment lacks depth and does not provide any actionable guidance for the authors to enhance their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific paragraph (L156166) where the reviewer struggles to understand the content, despite having a general idea of what the authors are trying to convey. The reviewer also criticizes the figure, stating that the explanation of dashed lines is too vague. While the comment identifies areas of confusion, it does not provide explicit guidance on how to clarify the paragraph or improve the figure. The action is implicit and somewhat vague, as the authors are left to infer what specific changes are needed to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with understanding the paragraph, including the mention of bandit algorithms and the Gittins strategy, and criticizes the figure for being hard to understand due to vague explanations. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paragraph from L156166 is difficult to understand and suggests that the explanation of the figure is vague. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks concrete evidence or references to substantiate the assertion that the paragraph is unclear or that the figure is poorly explained. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) where the reviewer struggles to understand the content, despite having a general idea of what the authors are trying to convey. It also critiques the figure, noting that the explanation of dashed lines is too vague. While the comment highlights areas of confusion, it does not provide detailed suggestions or guidance on how to clarify the paragraph or improve the figure. The feedback is 3 as it points out specific issues, but it lacks actionable advice or examples to help the authors improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. It also references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to provide context. This feedback is explicit and provides a clear action for the authors to take, which is to include the evaluation metric in the specified lines. The reference to a specific expression and the mention of a relevant study provide concrete guidance on how to implement this suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 078079 / Line 08,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. The comment further provides a reference to Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to support the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. It references Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to provide context, which is a specific reference that supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric affects the interpretation of the results. Overall, the claim is 4, as it provides a clear suggestion with some supporting evidence, but it could be more robust with additional details.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the paper by recommending the inclusion of the evaluation metric in the specified lines. This would help readers understand the scale of the improvement and enhance comparability with other studies, such as Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020). The comment is actionable and offers a clear direction for the authors to enhance the comprehensibility of their results. However, it could be more helpful if it provided additional context or examples of how this would impact the interpretation of the results. Overall, the comment is 4, as it offers a constructive suggestion that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the current noise value of 3 is not considered high based on the observations in the plot compared to the true trajectories. This feedback is explicit and provides a clear action for the authors to take, which is to conduct further analysis under higher noise conditions. The suggestion is concrete, as it specifies the direction for additional research. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the simulation study\" and \"the plot compared to the true trajectories,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the stated standard deviation of the noise and the observed behavior in the plot, suggesting that the authors should study the model\"s behavior under higher noise levels. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise is not as high as stated, based on observations in the plot compared to true trajectories. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The suggestion to study the model under higher noise levels is logical but lacks detailed justification or references to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the simulation study, specifically questioning the level of noise used. It points out that the standard deviation of the noise is stated as 3, but based on the observations in the plot compared to the true trajectories, this does not appear to be a high noise value. The comment suggests that the authors should study the behavior of the model under higher noise levels, which could provide more insight into its robustness. This feedback is clear and actionable, offering a specific direction for the authors to explore and potentially improve their work. However, it could be more helpful if it provided additional context or examples of how higher noise levels might impact the model. Overall, the comment is 4, as it directs the authors to a relevant area for further investigation, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their implications for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in detailing the concern about the limitations of the approach but lacks grounding, as the authors cannot confidently determine which section or part of the paper this comment pertains to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support the claim that these bounds would seriously limit the applications. Without additional context or evidence, the authors may find it challenging to understand the full extent of the issue or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide specific guidance or suggestions on how the authors might address this issue or explore alternative applications. The comment highlights a potential limitation but lacks actionable feedback, leaving the authors with a general understanding of the problem but without a clear path for improvement. Therefore, the comment is 2, as it identifies a weakness but does not offer constructive guidance for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises an interesting question about how DVP performs on videos of different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what the authors should do with this observation or how it could be explored further in the paper. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this point. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on videos of different lengths but does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to the methodology, results, or discussion sections, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any guidance on what aspects of DVP\"s performance on videos of varying lengths should be explored or addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of DVP on videos of different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on videos of different lengths. However, it does not provide any context, analysis, or suggestions for how this observation could be explored or improved in the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address this point or its relevance to their work. As a result, the comment is 1, as it does not offer any meaningful insights or directions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify the target in their draft. The comment lacks actionable details, such as suggesting where or how to provide this clarification, making it 1. Therefore, the comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not specify which part of the paper should provide this clarification or what specific aspects need to be addressed. The authors can make an educated guess that the issue might be related to the introduction or methodology sections, but the comment lacks full grounding. It is specific in identifying the need for clarification but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim of confusion. The comment lacks specific examples or detailed explanations of where the confusion arises, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the paper\"s focus on singletoken or multitoken cloze queries. It notes that the clarification is not clear until the conclusion, suggesting that the authors should provide a clearer distinction or explanation earlier in the paper. However, the comment lacks actionable guidance on how to address this issue or where to make the necessary clarifications. While it highlights a potential area for improvement, it does not provide detailed suggestions or examples, making it 3. The authors can infer that they need to clarify their focus, but the feedback could be more comprehensive to be fully actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to address the issue. The comment is 5 as it specifies the steps to be taken, leaving no ambiguity for the authors. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, namely the omission of the KLdivergence term in equation (3), and requests an evaluation of the approximation error by calculating the actual KLdivergence. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the omission of the KLdivergence term in the proposed training objective and suggests evaluating the approximation error by calculating the actual KLdivergence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this omission is significant or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective in Section 3.3, noting the omission of the KLdivergence term in equation (3). It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it indeed approaches zero. This feedback is valuable as it directs the authors to a critical aspect of their methodology that requires further analysis. However, the comment could be more helpful if it offered additional context or examples of how this evaluation might impact the overall results or conclusions. Nonetheless, the suggestion is clear and actionable, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference [1]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology or how to enhance the theoretical analysis. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the limited connection with the methodology section and the simplicity of the theoretical analysis, which is closely related to reference [1]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Section 2 lacks a clear connection with the methodology section and that the theoretical analysis is simplistic and closely related to reference [1]. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the limited connection between Section 2 and the methodology section, and the simplicity of the theoretical analysis, which is closely related to reference [1]. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of what needs improvement but without a clear path forward. Therefore, the comment is 3, as it points out areas for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. However, it does not provide explicit guidance on how to conduct this discussion or what specific aspects should be explored. The action is implicit, as the authors need to infer that they should delve deeper into the application of losses, and it is vague because it lacks concrete details on how to implement this discussion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests further discussion on the situations where the losses are helpful, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in suggesting a particular area of interest, namely the application of losses in specular areas. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that it would be interesting to further discuss the situations in which the losses are helpful, specifically mentioning specular areas. While this feedback identifies a potential area for expansion, it lacks specificity and does not provide actionable guidance on how to conduct this discussion or what aspects to focus on. The comment does not offer detailed suggestions or examples, leaving the authors with a general idea but without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without explicit guidance or actionable steps, the authors are left without a clear understanding of what changes are needed to enhance their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not specify which aspects of the paper are lacking or what specific contributions are insufficient. Without detailed guidance or references to specific sections or elements of the paper, the authors cannot confidently determine which parts need improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the paper\"s strength, specifically questioning whether it is suitable for ICLR. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s doubt. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength in its current state, questioning whether it is suitable for ICLR. However, it does not provide any specific feedback or suggestions on how the authors might strengthen their contribution or improve the paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what changes are needed to enhance their work. This lack of specificity and actionable advice makes the comment unhelpful, as it does not offer any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the major contributions of the paper, suggesting that analyzing previous work does not constitute a contribution. However, it does not provide explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment implies that the authors should focus on identifying and presenting original contributions, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the major contributions of the paper, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the contributions, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that analyzing previous work does not constitute a contribution, which is a subjective opinion. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that analyzing previous work does not constitute a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or enhance their contributions. Without actionable advice or examples, the authors are left with a general understanding of the problem but without a clear path forward for improvement. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of clarity in determining the value of n_t in Algorithm 2 and questions the meaning of \"appropriate number\" in line 225. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to clarify the determination of n_t and the meaning of \"appropriate number,\" but without concrete suggestions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of determining n_t and the meaning of \"appropriate number,\" providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of clarity in determining the value of n_t in Algorithm 2 and questions the meaning of \"appropriate number\" in line 225. The reviewer references [30] as a source for further information, but without providing specific details or examples from the reference, the claim remains 3. The authors would need to consult the referenced work to fully understand the issue and address it in their paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in determining the value of n_t in Algorithm 2 and the meaning of \"appropriate number\" in line 225. This is a clear and actionable feedback that the authors can use to improve their draft by providing more detailed explanations or justifications for these aspects. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar problems have been handled in other papers. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. While the comment implies that the authors should make their code publicly available to facilitate reproducibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for code sharing but are not given specific guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section, making it weakly grounded. The comment is specific in its request for code availability, which is a clear and actionable suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks if the code will be made publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are hard to reproduce or why code availability is necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a critical issue regarding the reproducibility of the results, which is a significant concern in scientific research. By asking if the code will be made publicly available, the reviewer highlights a potential barrier to verification and validation of the findings. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or improve the reproducibility of their results. Without actionable suggestions or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claims made about the mixing time being better in practice, stating that the evidence provided is insufficient. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the support for these claims or what additional evidence might be needed. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific claims made in the paper regarding the mixing time being better in practice. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique, pointing out the lack of sufficient support for these claims through experiments, which limits the evidence provided to practitioners. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evidence supporting the claim that \"in practice the mixing time is even better\" is insufficient. However, it does not provide specific examples or detailed reasoning to substantiate this claim. The comment lacks references or examples of experiments that could support the claim, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the claims made in the paper regarding the mixing time being better in practice. It points out that the evidence provided is insufficient, which limits the usefulness of the claims for practitioners. However, the comment does not offer any suggestions or guidance on how the authors might improve the support for these claims or what additional evidence could be included. While it highlights a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides insight into a weakness but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. This is an explicit suggestion with concrete details on how to implement the action, providing the authors with a clear direction on what to do to improve their draft. The comment is 5 as it gives specific guidance on how to enhance the protected feature, allowing the authors to make a direct and concrete change to their work.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, it does not specify which part of the paper discusses feature A, making it weakly grounded. The comment is specific in suggesting a potential enhancement to the feature, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this suggestion should be implemented. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the protected feature A by proposing its extension to a vector form, which could represent multiple attributes. This is a clear and actionable suggestion that could improve the comprehensiveness and depth of the feature analysis. However, the comment lacks further elaboration or examples of how this extension could be implemented or what benefits it might bring. While it provides a direction for improvement, it could be more helpful with additional guidance or context. Therefore, the comment is rated as 3, as it offers a constructive suggestion but requires more detail to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit suggestions for clarification and additional details regarding the vector representations of words in the equation. It asks the authors to denote the vector representations of \"x\" and \"t\" and to provide information on whether the vectors are L2normalized before the process. Additionally, it requests details on how the \"nearest neighbor\" examples are computed, specifically whether cosine or dotproduct is used. These requests are clear and concrete, giving the authors specific actions to take to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear requests for clarification and additional details, such as denoting the vector representations of \"x\" and \"t,\" whether the vectors are L2normalized, and the method used for computing \"nearest neighbor\" examples. This level of detail guides the authors on what specific aspects need to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for clarification regarding the vector representations and their normalization in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely descriptive and factual. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback to the authors. It identifies a potential area of confusion in the paper, specifically regarding the vector representations of \"x\" and \"t\" in the equation, and suggests denoting these representations. Additionally, it raises questions about the normalization of vectors and the method used for computing \"nearest neighbor\" examples, which are crucial details that could impact the clarity and reproducibility of the work. By addressing these points, the authors can enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that experiments in deep reinforcement learning (RL) should be run multiple times to address the issue of reproducibility and the significance of improvements. It references a community effort towards reproducibility and suggests that this should be considered in the paper. The comment explicitly states the action of running multiple experiments and reporting statistics, providing a clear and concrete direction for the authors to follow. However, it does not specify which experiments should be run multiple times or how to report the statistics, which could be considered a minor limitation. Overall, the comment is 5 as it provides a direct and concrete action for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"deep RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of reproducibility and the need for running multiple experiments and reporting statistics. The reference to a community effort towards reproducibility and the suggestion to consider this in the paper further enhance the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that experiments in deep reinforcement learning should be run multiple times to address issues of reproducibility and the significance of improvements. It references a community effort towards reproducibility and cites a specific paper, \"Deep reinforcement learning that matters\" by Henderson et al. (2018), as evidence. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or specific statistics on how running multiple experiments would improve reproducibility. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a critical issue in deep reinforcement learning (RL) experiments, specifically the lack of reproducibility and the significance of improvements. It suggests that running multiple experiments and reporting statistics is crucial for addressing these concerns. The comment also references a community effort towards reproducibility, providing a specific example from the literature. This feedback is 5 as it identifies a key area for improvement and offers a concrete suggestion for enhancing the paper\"s rigor and credibility. By referencing a relevant paper, the comment provides a clear direction for the authors to follow, making it actionable and valuable for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for consistency in the punctuation of equations. It clearly specifies the actions needed to address the issue, which is to ensure that all equations end with either a period or a comma consistently. This feedback is direct and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, namely \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the sections that need attention. It is also specific because it clearly specifies the issue of inconsistent punctuation in equations, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the punctuation of equations in the paper, specifically mentioning Figure 2, Line 433, and Line 468. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in the paper, suggesting that some end with a period while others end with a comma. It provides clear and actionable feedback by instructing the authors to ensure consistency in the punctuation of equations. This feedback is direct and helps the authors to make a precise correction, which is valuable for improving the clarity and professionalism of their draft. However, the comment could be more helpful if it explained why consistency in punctuation is important or provided examples of how it affects the readability of the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which implies that the technical contribution of the paper is limited. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their contribution. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that $kNNECD$ is very similar to $kNNMT$, implying that the technical contribution of the paper is limited. However, it does not specify which part of the paper this similarity is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the similarity are problematic or how the authors could address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, which implies that the technical contribution of the paper is limited. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the similarity or how it affects the paper\"s contribution. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is limited due to the similarity between $kNNECD$ and $kNNMT$. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this issue or enhance their contribution. Without actionable feedback or guidance, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It also suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is explicit in its request for clarification and provides a clear action for the authors to take, which is to conduct realworld experiments if the figures are artificially generated. The suggestion is concrete, as it specifies what the authors need to do to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: whether the figures are generated from real experiments or artificially, and if artificially, whether the authors can conduct realworld experiments to support the phenomenon observed. This provides clear guidance on what the authors need to clarify or address in their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. However, the comment does not provide any evidence, reasoning, or references to support the claim that conducting realworld experiments is necessary or beneficial. The lack of supporting information makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The review comment raises a critical question about the origin of the figures in Figure 1, asking whether they are generated from real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed. This feedback is valuable as it prompts the authors to clarify the basis of their results and potentially enhance the validity of their claims. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Despite this, the suggestion is clear and actionable, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the author was unclear about the numbers of parameters used in each approach, specifically in Section B.3. This provides a direct action for the authors to take, which is to clarify and provide the specific numbers of parameters used in each approach. The comment is explicit and concrete, as it clearly instructs the authors on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the numbers of parameters used in each approach. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting clarification on the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the numbers of parameters used in each approach, as mentioned in Section B.3. This feedback is clear and actionable, as it directs the authors to clarify and provide the specific numbers of parameters used in each approach. By addressing this point, the authors can improve the clarity and transparency of their paper, making it more understandable for readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. While the comment implies that the authors should add these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional visual or illustrative content but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this explanation is needed. Without explicit references or context, the authors may find it challenging to determine where to incorporate these suggestions. The comment is specific in its suggestion but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why these would be beneficial or how they would improve the clarity of the definition. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and comprehensibility of the paper. By incorporating an example and a figure, the authors can better illustrate the concept, making it easier for readers to understand. However, the comment could be more helpful if it offered guidance on what specific aspects of the definition should be highlighted or how the example and figure should be structured. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper\"s clarity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, specifically mentioning selftraining methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the novelty of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed transductive method, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, specifically mentioning selftraining methods. However, it does not specify which part of the paper discusses this method, making it weakly grounded. The comment is specific in its critique of the method\"s novelty, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, specifically mentioning selftraining methods. However, the comment lacks specific references or detailed explanations to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semisupervised learning, specifically mentioning selftraining methods. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this concern. It does not offer guidance on how the authors might improve the novelty of their method or provide examples of how selftraining methods could be applied differently. Without detailed feedback or constructive suggestions, the comment is not particularly helpful for the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. While the comment identifies a potential issue with the assumption, it does not provide explicit guidance on how to address it or improve the draft. The authors are left to infer that they should focus on the optimization and theoretical aspects, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the assumption among classes, noting that it is not practical and that the formulation or definition is somewhat trivial. However, it highlights the value of the paper in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment does not specify which part of the paper discusses these assumptions or how they relate to the optimization and theoretical aspects. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment provides a logical reasoning by distinguishing between the practicality of the assumption and the potential value of the paper in other areas. While the claim is somewhat supported by the explanation, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is considered 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges that the assumption among classes is not practical but notes that the formulation or definition is somewhat trivial. It highlights the value of the paper in its optimization and theoretical property analysis, suggesting that this aspect provides insights or conclusions. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not guide the authors on how to address the issue with the assumption or how to enhance the optimization and theoretical aspects. As a result, the comment is 3, as it identifies a potential area of improvement but does not offer detailed guidance for the authors to act upon. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation results reported in Table 1, specifically noting that they are based on only three trials for each case. The reviewer suggests that this is statistically insignificant and questions the relevance of reporting deviations. The comment also critiques statements claiming performance superiority over baselines due to the lack of statistical significance. While the comment identifies a potential issue with the evaluation methodology and the interpretation of results, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should either increase the number of trials or rephrase their claims to reflect the limitations of the current evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that they are based on only three trials for each case, which is statistically insignificant. The comment further explains why this affects the interpretation of deviations and the validity of certain performance claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically insignificant. The reviewer argues that this lack of statistical significance makes it nonsensical to report deviations and supports the claim that statements about performance superiority over baselines are not valid. The comment provides a logical reasoning for the claim, explaining why the limited number of trials affects the reliability of the results. However, it could be strengthened by providing specific examples or references to support the assertion about the impact of limited trials on statistical significance. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that they are based on only three trials for each case. This is a critical observation because it highlights a potential flaw in the statistical significance of the results, which could impact the validity of claims about performance superiority over baselines. The comment provides a clear and actionable suggestion by pointing out that the lack of statistical significance makes it nonsensical to report deviations or make claims about performance being better than the next best baseline. This feedback is valuable as it prompts the authors to reconsider their evaluation methodology and potentially revise their claims to reflect the limitations of their data. However, the comment could be more helpful if it offered specific guidance on how to address this issue, such as suggesting additional trials or statistical analyses. Overall, the comment is 4, as it effectively identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not provide explicit guidance on how to address this issue or suggest which papers should be included in the comparison. The action is implicit, as the authors can infer that they need to add a more comprehensive feature comparison, but it lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this issue is located in, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the issue with the feature comparison, but without clear grounding, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison in the paper is shallow and missing two relevant papers. However, it does not provide specific details about which papers are missing or why their inclusion would enhance the feature comparison. This lack of supporting evidence or examples makes the claim difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors\" attention to a particular area that needs improvement. By mentioning the omission of specific papers, the comment provides a concrete suggestion for enhancing the feature comparison, which can help the authors in refining their draft. However, the comment could be more helpful if it included suggestions on how to incorporate these papers or what aspects of the comparison should be expanded upon. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a more cautious usage of the word \"equivalent\" in the paper, particularly when the equivalence is not verified. This is an explicit suggestion for the authors to reconsider their use of the term. However, the comment does not provide specific guidance on how to implement this suggestion, such as recommending alternative phrasing or providing examples of more cautious language. While the action is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (8, 56, 70, 93) where the issue with the word \"equivalent\" is observed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a more cautious usage of the word \"equivalent,\" particularly when the equivalence is not verified. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a more cautious use of the word \"equivalent\" in the paper, particularly when the equivalence is not verified. This is a reasonable suggestion, as it highlights a potential issue with the language used. However, the comment does not provide specific examples or detailed reasoning to support why this caution is necessary. While the suggestion is logical, it lacks concrete evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting a more cautious approach when the equivalence is not verified. This feedback is clear and actionable, as it directs the authors to reconsider their language choice and potentially provide additional verification or clarification. However, the comment could be more helpful if it provided examples of how to implement this suggestion or offered further guidance on what constitutes a more cautious usage of the term. Overall, the comment is 4 as it highlights a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It suggests that without a more detailed analysis of the differences and similarities between these views, it is challenging to draw solid conclusions. The comment implies that the authors should conduct a more comprehensive analysis to better understand the contributions of each view. However, it does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the effectiveness of the multiview clustering approach, questioning the usefulness of views other than the paraphrase similarity view. The comment further specifies the need for a more detailed analysis of differences and similarities between these views to draw solid conclusions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. The reviewer points out that the paraphrase similarity view performs significantly better than other views and their combination, and suggests that without a more detailed analysis of differences and similarities between these views, it is challenging to draw solid conclusions. This claim is 3 as it provides a logical reasoning about the need for further analysis, but it lacks specific examples or references to support the assertion that the other views are not useful. The authors would need to conduct additional analysis to fully address the claim, making it 3.", "helpfulness_rationale": "The review comment raises a critical point about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It highlights that the paraphrase similarity view consistently outperforms other views and their combination, leaving unclear the contribution of the other views. The comment suggests that a more detailed analysis of the differences and similarities between these views is necessary to draw solid conclusions. This feedback is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The comment implies that the authors should provide a clear explanation of the architecture used in their experiments, rather than relying on external references. However, it does not specify how to do this or what details should be included in the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given explicit guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper relies on an external reference (Jiang et al., 2019) for details, making it not selfcontained. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s architecture is not clearly explained, relying on an external reference (Jiang et al., 2019) for details. This claim is 3 as it highlights a potential issue with the paper\"s selfcontainment. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity and selfcontainment. It points out that the architecture used for the experiments is not clearly explained within the paper, instead relying on an external reference (Jiang et al., 2019) for details. This feedback is valuable as it highlights a critical area where the paper lacks transparency and could be improved. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a detailed explanation of the architecture or suggesting alternative ways to present the information. Despite this, the comment is 4 as it directs the authors\" attention to a key area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the typesetting of \"BertScore\" and \"BLEURT\" is inconsistent throughout the paper, suggesting that it would be better to maintain consistency. This provides a clear and direct action for the authors to take, which is to ensure that these terms are consistently typeset throughout the draft. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore and BLEURT,\" allowing the authors to accurately identify the parts of the paper where the inconsistency occurs. It is also specific because it clearly specifies the issue of inconsistent typesetting and suggests maintaining consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistent typesetting of \"BertScore\" and \"BLEURT\" throughout the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, noting that they are inconsistently presented as \"Bertscore\" or \"Bleurt.\" This feedback is clear and actionable, as it provides a straightforward suggestion to maintain consistency in the typesetting of these terms. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it suggested specific guidelines or best practices for maintaining consistency in typesetting. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This implies that the authors should conduct or present additional experiments to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to conduct these experiments or provide specific guidance on how to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed experimental results but are not given explicit instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the preliminary experimental results on Wikipedia about model size,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing detailed results on how model size affects performance, particularly in the context of recent work by Ni et al. that applies the scaling law to dense retrieval models. This provides clear guidance on what the authors need to include in their paper to address the reviewer\"s concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is unreasonable for increasing model size to hurt performance, citing recent work by Ni et al. that shows the scaling law applies to dense retrieval models. The comment suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size. While the reference to Ni et al. provides some basis for the claim, the comment lacks specific details or examples from the paper by Ni et al. to fully substantiate the claim. Additionally, the comment does not provide a clear explanation of why the scaling law would not apply in the context of the authors\" work. Therefore, the claim is 3, as it provides a basis for the reasoning but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that increasing model size can hurt performance. It suggests that this claim is unreasonable, given recent work by Ni et al. that shows the scaling law applies to dense retrieval models. The comment provides a specific reference to support the claim, indicating that the authors should provide preliminary experimental results on Wikipedia regarding model size. This feedback is clear and actionable, as it directs the authors to address a specific concern and provides a basis for their argument. However, the comment could be more helpful if it offered additional guidance on how to present the experimental results or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors to improve their draft by addressing a critical issue and providing a reference for further exploration."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. However, it does not provide explicit guidance or suggestions on how the authors should conduct these experiments or what specific aspects they should focus on. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments but without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"conclusion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the request for related experiments that the information axis tool can help with, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. However, it does not provide any specific claims, opinions, or suggestions that require verification. It is a request for additional information or experiments, which is not a claim that needs justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. While it identifies a potential area for further exploration, it lacks specificity and does not provide actionable guidance on how the authors might conduct these experiments or what specific aspects they should focus on. The comment highlights a potential direction for future work but does not offer detailed suggestions or insights that could help the authors improve their draft. Therefore, the comment is 3, as it provides a general direction but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might address this question or incorporate it into their draft. As a result, the comment lacks actionability and does not offer any direction for the authors to improve their work. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment expresses interest in knowing if other multilingual pretraining setups struggle with Greek, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address this question or what implications it might have for the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking additional information about the paper\"s findings or experiments. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. While it raises a relevant question, it does not provide any specific suggestions or guidance on how the authors might address this inquiry or incorporate it into their draft. The comment lacks actionable feedback or insights that could help the authors improve their work. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific section of the text (lines 293295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer suggests that this makes the point less clear for readers, implying that the authors should clarify or rephrase this section to improve understanding. However, the comment does not provide explicit guidance on how to rephrase or clarify the section, leaving the authors to infer that they need to make the language more precise or detailed. The action is implicit and somewhat vague, as the authors know they need to improve clarity but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point less clear for readers. The comment suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear and could be improved. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point less clear for readers. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the text (lines 293295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer points out that this makes the point less clear for readers, suggesting that it would be difficult for them to understand and evaluate. This feedback is 3 as it highlights a potential area of confusion in the paper and encourages the authors to clarify their explanation. However, the comment could be more helpful if it provided specific suggestions on how to rephrase or improve the clarity of the section. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the organization and clarity of the proof, specifically mentioning that many proofs lack clean logic and are difficult to follow. It also raises a specific question about the applicability of Lemma 3 to any polynomial function. While the comment identifies a problem and poses a question, it does not provide explicit guidance on how to improve the organization or clarity of the proofs. The authors are left to infer that they need to reorganize and clarify their proofs, but without specific instructions on how to do so, the action remains somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proof, noting that it is not wellorganized and lacks clean logic, making it difficult to follow. Additionally, it raises a specific question about the applicability of the result to any polynomial function, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof is \"extremely not well organized\" and lacks clean logic, making it difficult to follow and rigorously check for correctness. It provides a specific example by questioning the applicability of Lemma 3 to any polynomial function. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the organization and clarity of the proofs. While it highlights a potential issue, the lack of specific evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the organization and clarity of the proof, noting that many proofs lack clean logic and are difficult to follow. It highlights the importance of rigorously checking the correctness of the proof, which is crucial for the validity of the results. The comment also raises a specific question about the applicability of Lemma 3 to any polynomial function, which prompts the authors to clarify this aspect. However, the comment could be more helpful if it provided suggestions on how to improve the organization and clarity of the proofs or offered examples of how to address the issue. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This is an explicit action that provides a clear direction for the authors to improve their draft. However, the comment does not specify which realworld datasets should be used or how the experiments should be conducted, leaving some aspects of the action vague. Therefore, the comment is 4, as it gives a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify what aspects of the synthetic datasets are problematic or how realworld datasets would better address the issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This claim is based on the assumption that realworld datasets are more representative of realistic scenarios than synthetic ones. However, the comment lacks specific reasoning or references to support why synthetic datasets are insufficient for the outofdistribution setting. Without detailed justification or examples, the claim remains 3, as it provides a general suggestion but lacks concrete evidence or reasoning to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic ones, particularly for the outofdistribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning the experiments with more realistic scenarios. However, the comment could be more helpful if it included suggestions on which realworld datasets to use or how to adapt the experiments to better reflect realworld conditions. Despite this, the comment offers a valuable insight that could significantly enhance the paper\"s relevance and applicability. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on how to improve the clarity or suggest specific changes. The comment is vague and lacks concrete details on what needs to be clarified or how to address the issue. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a lack of clarity in some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. This provides full grounding as it explicitly mentions the section and lines where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the vagueness of the explanation in that particular section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are \"a little vague,\" specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed explanation or examples renders the claim 1, as the authors are left without clear guidance on how to improve the clarity of their explanations. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the explanations are vague, pointing out the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is 3 as it directs the authors\" attention to a particular section that needs clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the explanation. While it highlights an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, specifically noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical. However, the comment does not provide explicit guidance or suggestions on how to extend the study or what specific steps the authors should take to achieve this. The action is implicit and somewhat vague, as the authors can infer that they need to consider multiple scenarios but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, specifically noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to address this issue. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in suggesting an extension of the study, but it lacks detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the scope of the study by noting that it only considers one truck and one drone, suggesting that extending it to multiple trucks and drones could be more interesting and practical. However, the comment lacks specific reasoning or evidence to support why this extension would be beneficial or how it would impact the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited scope of the study, noting that it only considers one truck and one drone. It suggests that extending the study to multiple trucks and drones could be more interesting and practical, which is a relevant observation. However, the comment lacks specific guidance or suggestions on how the authors might approach this extension or what aspects of the study would need to be revised. While it identifies a potential area for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it largely follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their approach. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, suggesting it largely follows strategies used in ELECTRA. However, it does not specify which part of the paper discusses the pretraining approach or how it relates to ELECTRA, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity regarding what aspects of the approach are not novel or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it largely follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or references to specific aspects of ELECTRA that the proposed approach is based on, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed approach to pretraining lacks novelty as it largely follows the strategies used in ELECTRA. However, it does not provide any specific examples or details on how the approach could be improved or what aspects of ELECTRA it is based on. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issue of novelty. This lack of guidance makes the comment 2, as it identifies a potential weakness but does not offer any constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a perceived lack of motivation for the Newton algorithm in Section 4, suggesting that a bisecting line search would also converge linearly. It implies that the authors should conduct experiments to demonstrate the impact of quadratic convergence on the algorithm\"s runtime, which would help motivate the need for the analysis/algorithm. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should perform experiments to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, explaining that a bisecting line search would also converge linearly and questioning the impact of quadratic convergence on the algorithm\"s runtime. The comment suggests conducting experiments to motivate the need for the analysis/algorithm, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in Section 4 is lacking, suggesting that a bisecting line search would also converge linearly. The reviewer questions the significance of quadratic convergence in terms of runtime impact. While the comment provides a logical reasoning about the convergence rates, it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as it requires further evidence or detailed analysis to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a perceived lack of motivation for the Newton algorithm in Section 4, suggesting that a bisecting line search would also converge linearly. It questions the significance of quadratic convergence in terms of runtime impact and recommends conducting experiments to demonstrate the need for the analysis/algorithm. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a concrete way to address it. By highlighting the need for experiments to motivate the analysis, the comment offers valuable guidance for enhancing the draft. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not significantly differentiate between idiomatic and random data, as indicated by Figure 3. The comment implies that the results do not demonstrate the idiomspecificity of the proposed methods, instead suggesting that better NMT systems are also better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs. random data is similar for most language and score combinations. The comment further specifies that the results do not demonstrate idiomspecificity, suggesting that better NMT systems are also better at idiomatic translations. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not demonstrate idiomspecificity, as the impact on idiomatic vs. random data is similar for most language and score combinations. The comment supports this claim by referencing Figure 3, which provides visual evidence of the similarity in impact. However, the comment could be strengthened by providing more detailed analysis or examples from the figure to fully substantiate the claim. Overall, the claim is 4, as it is supported by a reference to a specific figure, but it lacks additional detailed evidence or reasoning to make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a critical evaluation of the proposed upweighing and KNN methods, suggesting that they do not demonstrate idiomspecificity. It points out that the impact of these methods on idiomatic vs. random data is similar for most language and score combinations, as shown in Figure 3. This observation leads the reviewer to conclude that the results simply indicate that better NMT systems are also better at idiomatic translations. While the comment identifies a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their methods. The feedback is 3 as it highlights a critical area for improvement but does not provide specific steps or recommendations for enhancement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors should have multiple kernels and biases, as indicated by the notation \"C biases.\" It also suggests that the resulting volume should be WxHx1 and the bias should be a scalar. However, the comment does not provide specific guidance on how to implement these changes or where exactly in the paper these adjustments should be made. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, indicating that the authors should have multiple kernels and biases, and that the current notation is confusing. The comment provides a clear suggestion for improvement by recommending a change in the notation to better reflect the presence of multiple biases. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for the resulting volume and bias is confusing, specifically pointing out that the authors should have multiple kernels and biases. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this notation is confusing or how it affects the understanding of the paper. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, particularly regarding the resulting volume and bias. It points out that the authors should have multiple kernels and biases, as indicated by the notation \"C biases,\" but only found this hyperparameter for feedforward models described in section 3.4. The comment highlights the confusion caused by this notation and suggests a correction. However, it does not provide detailed guidance on how to implement the suggested changes or why this notation is problematic. While the comment identifies a clear area for improvement, it lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and make it challenging for the LSTM module to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or suggest specific modifications to Equation 8. The action is implicit, as the authors need to infer that they should reconsider the subtraction of \"s\" from the dynamic information. The feedback lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue with subtracting \"s\" from the dynamic information, which could lead to the loss of dynamic information and make it difficult for the LSTM module to capture complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential loss of dynamic information when subtracting \"s\" from the dynamic information in Equation 8. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The comment lacks concrete evidence or detailed explanation, making it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically the subtraction of \"s\" from the dynamic information, which could lead to the loss of dynamic information and make it difficult for the LSTM module to capture complete dynamic changes. This feedback is 3 as it points out a specific area of concern that the authors should address. However, it lacks depth and does not provide detailed guidance on how to resolve the issue or suggest alternative approaches. While it highlights a potential problem, it does not offer actionable steps for improvement, limiting its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not provide explicit instructions or suggestions for the authors to address these questions. The authors are left to infer that they should investigate or discuss these aspects in their paper, but the comment lacks concrete guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments. Without explicit references or context, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in its inquiry but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point consists of questions seeking clarification on the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this relationship. By asking these questions, the reviewer prompts the authors to consider and potentially investigate these aspects further, which could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or what specific aspects of the network structure or MC samples are most relevant. While it identifies areas for exploration, the feedback is 3 as it provides a direction for further investigation but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is an explicit action with clear guidance on what needs to be done to enhance the clarity of the figures. The suggestion is concrete, as it specifies the exact figures and the type of information to be included, providing the authors with a direct and actionable step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely showing the smoothed GT shapes in these figures to improve the understanding of the reconstruction quality. This provides clear guidance on how to enhance the clarity of the figures, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a suggestion for improvement, but it does not contain any subjective claims, opinions, or judgments that require verification. It is purely descriptive and provides a clear, actionable recommendation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. By recommending the inclusion of smoothed GT shapes in Figures 3 and 5, the reviewer offers a clear way for the authors to enhance the understanding of the reconstruction quality. This feedback is valuable as it directly addresses a potential area for improvement, providing the authors with a concrete step to take in refining their draft. However, the comment could be more helpful if it explained why this suggestion is important or how it would impact the reader\"s understanding. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC in both language and vision tasks. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This feedback implies that the authors should include a direct comparison of test accuracy to demonstrate whether their approach is an improvement over the baseline. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a direct comparison but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of direct comparisons with the prior approach PRANC in terms of test accuracy, despite comparisons of training loss and the rank of possible solutions. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks direct comparisons with the prior approach PRANC in both language and vision tasks, despite modifying it. The reviewer notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. This claim is 3 as it highlights a gap in the evaluation process, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to consider the implications of this gap and potentially address it in their response. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, specifically the lack of direct comparisons with the prior approach PRANC in both language and vision tasks. It highlights that while there are comparisons of training loss and the rank of possible solutions, the absence of a direct comparison of test accuracy makes it unclear whether the proposed approach is an improvement over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to substantiate their claims. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4, as it effectively points out a critical area for improvement in the evaluation process."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of 33 event types in the ACE data. While the comment identifies specific areas of concern, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more information or justification regarding the selection process and coverage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of 33 event types in the ACE data. It specifically mentions \"Section 2 line 262,\" which provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what needs to be addressed, namely the selection process and coverage of event types. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection process of 21 event types from Freebase, as well as the coverage of 33 event types in the ACE data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these concerns. Without additional context or justification, the authors may find it challenging to address these issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection process of 21 event types from Freebase and the coverage of 33 event types in the ACE data. This is a relevant issue that the authors should address to enhance the robustness and applicability of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might improve the generalizability or address these concerns. As it stands, the comment identifies a weakness but lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. This is an explicit action with concrete details on how to implement it, as it specifies the types of experiments that could strengthen the paper\"s claims about the importance of language modeling capability. The authors know exactly what experiments to conduct to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments conducted, namely that they do not adequately reflect the language modeling capability. The comment further suggests including tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s experiments on word similarity and SQuAD in section 5.3 do not adequately reflect the language modeling capability of pretrained models. The reviewer suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that these tasks are more relevant to language modeling. This makes the claim 3, as it requires additional evidence or detailed reasoning to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, noting that the experiments conducted in section 5.3 do not adequately reflect the language modeling capability of pretrained models. It suggests that the authors should consider including tasks like language modeling, machine translation, or text summarization to strengthen this part of the paper. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing a critical aspect of their claims. However, the comment could be more helpful if it offered additional guidance on how to design or conduct these experiments. Overall, the comment is 4, as it effectively guides the authors toward enhancing the relevance and validity of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include important references for domain adaptation and to cite and discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or which parts of the paper should include these references. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its request for additional references but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss them in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are crucial for the paper. This lack of detailed justification or examples makes it difficult for the authors to understand the significance of the missing references and how to address the issue. As a result, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it highlights a critical area for improvement and offers a specific step for the authors to take to enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it specified which references are missing or provided examples of relevant literature. Overall, the comment is 4 as it directs the authors toward a meaningful improvement but could be more detailed in its guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the SCNN model performing well on domain pricing, suggesting that the hyperparameter tuning might be a factor. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. While the comment implies that the authors should investigate the hyperparameter tuning process, it does not provide explicit guidance on how to address this issue. The suggestion to \"Presentation suggestions\" is vague and does not offer concrete actions for improvement. Therefore, the comment is barely actionable, as it identifies an area for investigation but lacks specific guidance on how to proceed.", "grounding_specificity_rationale": "The comment raises a concern about the SCNN model performing well on domain pricing, suggesting that the hyperparameter tuning might be a factor. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about hyperparameter tuning and the distance to the next best model, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN model performing well on domain pricing, suggesting that the hyperparameter tuning might be a factor. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. However, the comment lacks specific evidence or references to support these claims, such as detailed comparisons with other models or explanations of how the hyperparameter tuning process was conducted. Without this additional information, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the SCNN model performing well on domain pricing, suggesting that the hyperparameter tuning might be a factor. It questions whether the chosen hyperparameters are at the end of the searched range and notes a suspiciously large distance to the next best model. This feedback identifies a potential issue with the model\"s performance and suggests that the authors should investigate the hyperparameter tuning process. However, the comment lacks specific guidance on how to address this issue or what steps to take to improve the model. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific guidance on what aspects are unclear or how the authors might clarify them. The comment implies that the authors should address these issues, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or figures. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing clarification. The comment is specific in identifying the issue with the experimental setup but lacks grounding, as it does not provide a clear indication of where in the paper these issues are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific examples or details to support this claim, making it difficult for the authors to understand and address the issues. The lack of concrete evidence or references leaves the claim vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not provide detailed guidance or suggestions on how the authors might clarify or improve these aspects. The comment lacks actionable feedback, such as recommending specific changes or providing examples of how to better motivate the experimental setup. As a result, the authors are left without a clear path for improvement, making the comment 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any specific guidance or suggestions on how the authors could improve their method or address this issue. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what aspects of the improvement are lacking. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the improvement are not impressive. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or comparisons to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the improvement of the proposed method over existing RL methods is not impressive. However, it lacks specificity and does not provide any detailed feedback or suggestions on how the authors could enhance their method or address this issue. Without actionable guidance or examples, the authors are left without a clear understanding of what changes are needed to improve their work. As a result, the comment is 1, as it does not offer any meaningful insights or direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and providing more details about the size of each hourglass module. While the comment does not explicitly instruct the authors to include this information, it implies that the authors should provide a detailed comparison and additional details about the model size. The action is implicit but concrete, as the authors know exactly what information is needed to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking more details about the size of each hourglass module. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the model architecture is described. The comment is specific in its request for additional information about the model size and its comparison to others. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking more details about the size of each hourglass module. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, the label is \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the size of the model, specifically asking for a comparison with competing approaches and seeking more details about the size of each hourglass module. This feedback is valuable as it prompts the authors to provide a clearer understanding of their model\"s architecture and its relation to existing work. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important for the reader. Despite this, the comment provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a claim in the paper as misleading and suggests that the authors should clarify that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. However, the comment does not provide explicit guidance on how to make this clarification or what specific details should be added to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to address the claim but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific claim in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out that the claim is misleading and suggests that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work, such as ClimateBench or ClimateSet, already addresses this gap. The comment provides a specific example of prior work that allegedly supports the claim, which is a clear and logical reasoning to support the critique. However, the comment could be strengthened by providing more detailed references or examples of how these prior works address the gap, which would make the claim 5. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper as misleading, pointing out that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. This feedback is clear and actionable, as it directs the authors to clarify their claim and provide a more accurate representation of their contribution. By addressing this issue, the authors can ensure that their work is accurately positioned within the existing literature, which is crucial for the integrity and credibility of their research. However, the comment could be more helpful if it provided additional guidance on how to effectively address the claim or suggested specific ways to clarify the contribution. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The action is implicit and vague, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not direct. The comment is specific in its critique of the metric learning theory, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It suggests that the metric perspective analysis proposed in the paper does not yield better outcomes. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or comparisons, the claim remains 3, as it provides a general assertion but lacks concrete justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment lacks specific details or suggestions on how the authors might improve this aspect of their work. Without actionable guidance or examples, the feedback is 3 as it identifies a potential weakness but does not provide a clear path for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests moving some visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This feedback is explicit and provides concrete actions for the authors to take, such as moving visual results and condensing figures. The suggestion is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to move visual results from the supplementary material to the main paper, specifically highlighting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This provides clear guidance on what needs to be addressed and where, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is the main experiment. It also suggests condensing the figures illustrating the proposed network architecture. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current visual results are insufficient or that the proposed changes would improve the paper. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that visual results from the supplementary material be moved to the main paper, particularly for the main experiment on crowd density estimation. It also recommends condensing the figures illustrating the proposed network architecture from three to two and using the freed space for visual results. This feedback is clear and constructive, offering the authors a direct way to enhance the visual presentation of their work and improve the reader\"s understanding of the main experiment. By addressing these suggestions, the authors can significantly enhance the clarity and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential source of confusion in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit guidance or suggestions on how to resolve this issue. The comment lacks concrete details on how to address the confusion, such as recommending alternative notation or suggesting a clearer distinction between the two types of risks. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of confusion caused by the dual use of \"r\" and suggests that this notation is problematic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it affects the clarity of the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, where \"r\" is used to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable feedback that highlights a potential source of confusion in the paper. However, the comment does not provide suggestions or guidance on how to resolve this issue, such as recommending alternative notation or suggesting a clearer distinction between the two types of risks. While it points out a problem, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. While the comment implies that the authors should consider this scenario and its implications, it does not provide explicit guidance on how to address it or what specific actions to take. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this scenario and its detection capabilities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. The mention of \"Figure 8\" provides full grounding, as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of detecting crucial differences in test examples and the potential impact of using the wrong corpus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. This question prompts the authors to consider a potential limitation or challenge in their approach and encourages them to explore how their method might handle such scenarios. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the draft. While it highlights an important consideration, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of dataset, specifically suggesting the use of the WebQuestions benchmark set instead of WebQuestionsSP. It provides a rationale for this suggestion, stating that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. While the comment does not explicitly instruct the authors to make a change, it clearly implies that using WebQuestions would be a more appropriate choice. The suggestion is concrete, as it provides a specific alternative dataset and explains the reasoning behind the recommendation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"choice of dataset\" and references \"WebQuestionsSP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the \"most popular WebQuestions (Berant et al., 2013) benchmark set\" instead of WebQuestionsSP, providing a clear rationale for the suggestion. The comment explains that using WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of dataset, suggesting that the authors use the more popular WebQuestions benchmark set instead of WebQuestionsSP. The reviewer provides a logical reasoning for this suggestion, stating that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. This reasoning is based on common knowledge in the field and provides a clear rationale for the suggestion. However, the comment could be strengthened by including specific references or examples to further support the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details.", "helpfulness_rationale": "The review comment raises a valid point about the choice of dataset, suggesting that the authors use the more popular WebQuestions benchmark set instead of WebQuestionsSP. It provides a clear rationale for this suggestion, explaining that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. This feedback is actionable and provides the authors with a specific suggestion for improving their work. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is 4 as it offers a clear and actionable suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits need to be demonstrated. It implies that the authors should provide evidence or examples to support their claims, particularly regarding the impact of sparsity on training speed and cost savings. However, the comment does not explicitly instruct the authors to conduct specific experiments or analyses to address these concerns. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence but are not given clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the necessity of claims about sparsity in training and suggests that any potential benefits need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by mentioning the need to demonstrate benefits and the importance of practical implementation, but it lacks full grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of claims about the desirability of sparsity in training, suggesting that any potential benefits need to be demonstrated. The reviewer provides a logical reasoning by pointing out that a larger network that cannot fit into memory without sparsity may perform better, but this needs to be demonstrated. Additionally, the comment questions the relevance of reduced FLOPs in the age of parallelized computation, suggesting that actual cost savings should be shown. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the necessity of claims about the desirability of sparsity in training, suggesting that these claims are not obvious and need to be substantiated. It provides a logical critique by pointing out that a larger network that cannot fit into memory without sparsity may perform better, and that any hypothetical training speed increases due to reduced FLOPs are meaningless without demonstrating actual cost savings. This feedback is 3 as it prompts the authors to reconsider their claims and provide evidence to support them. However, it could be more helpful if it offered specific suggestions on how to demonstrate these benefits or provided examples of how to address the critique. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the work is limited because the design is not new, as attention for motion learning has been widely used in video understanding. However, the comment does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. There is no explicit or implicit action for the authors to take, leaving them without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning that the design is not new due to the widespread use of attention for motion learning in video understanding. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on how the novelty could be improved or what specific aspects of the design are not novel. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited because the design is not new, citing the widespread use of attention for motion learning in video understanding. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the novelty of the work is limited due to the widespread use of attention for motion learning in video understanding. However, it does not provide any specific suggestions or guidance on how the authors could enhance the novelty of their work or address this critique. Without actionable feedback or detailed insights, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It provides a clear action for the authors to take, which is to verify the effectiveness of the framework on these datasets and present the results in the main paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, such as ImageNet derivatives, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the analysis or results on these datasets, and suggests presenting them in the main paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or results on datasets other than CIFAR derivatives, specifically mentioning ImageNet derivatives. The reviewer suggests that verifying the effectiveness of the framework on ImageNet1k or ImageNet100 is important. This claim is 3 as it provides a logical reasoning for the importance of including results on other datasets. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it only presents improvements on CIFAR derivatives and lacks analysis or results on other datasets, such as ImageNet derivatives. It provides a clear and actionable suggestion to include results on these datasets, specifically mentioning ImageNet1k or ImageNet100, which would enhance the paper\"s comprehensiveness. The comment is specific and offers a concrete direction for improvement, making it 5 for the authors. However, it could be further improved by suggesting how to integrate these results into the main paper or providing examples of how to present them effectively. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors provide a plot of the model illustration, pseudocode table, or code repository to clarify the model design and learning details. It also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2 Unclear model design,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the model architecture and learning details are fragmented or missing, suggesting ways to improve this, such as providing a plot of the model illustration, pseudocode table, or code repository. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details. It suggests providing a plot of the model illustration, pseudocode table, or code repository to facilitate reproducibility, especially since Neurochaos Learning is not a wellknown method. The comment provides a logical reasoning for the need for clarity and suggests specific ways to address the issue, making it 4. However, it could be strengthened by providing examples or references to similar practices in the field, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides specific suggestions for improvement, such as including a plot of the model illustration, pseudocode table, or code repository. This feedback is actionable and constructive, as it offers concrete steps for the authors to enhance the transparency and reproducibility of their work, particularly given the novelty of the Neurochaos Learning method. By addressing these suggestions, the authors can significantly improve the clarity and comprehensibility of their model design, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a discrepancy between how BigFive and MBTI are referred to in the Abstract, Introduction, and Experiments sections. It suggests that these models should be consistently referred to as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is clear and provides a direct action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Abstract, Introduction, and Experiments sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of inconsistent labeling of BigFive and MBTI, suggesting that they should be referred to as datasets throughout the paper unless an extended explanation is provided. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. The reviewer suggests that it would be better to consistently refer to them as datasets throughout the paper, unless the authors provide an extended explanation for their current usage. This claim is 3 as it points out an inconsistency in the paper\"s terminology, but it lacks specific examples or references to support the claim. The authors would need to review their paper to understand the context and make the necessary adjustments, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, where BigFive and MBTI are referred to as models in the Abstract and Introduction but are used as datasets in the Experiments section. It provides a clear and actionable suggestion to address this inconsistency by recommending that these terms be used consistently throughout the paper, unless the authors provide an extended explanation for their current usage. This feedback is valuable as it helps the authors clarify their terminology and ensure consistency, which is crucial for the clarity and credibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present the explanation or suggested potential implications of the inconsistency. Overall, the comment is 4, as it directs the authors to a significant improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include rejection rates in their experiments or to view misclassifications as rejections in the results. This provides a clear and direct action for the authors to take, ensuring they understand exactly what needs to be done to address the comment. The feedback is concrete and actionable, as it specifies both options for how to incorporate rejection rates into the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing rejection rates and suggests including them or viewing misclassifications as rejections in the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests including it or viewing misclassifications as rejections. This claim is 3 as it provides a logical reasoning for why the rejection rate should be included, but it lacks specific examples or references to support the necessity of including this information. The suggestion to view misclassifications as rejections is a reasonable one, but without further elaboration or evidence, the claim remains 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out that the rejection rate is not shown in any experiments. It provides a logical suggestion to either include the rejection rates or view misclassifications as rejections in the results. This feedback is clear and actionable, offering the authors a concrete way to enhance their analysis and presentation of results. However, the comment could be more helpful if it provided additional context or examples of how this information could be integrated into the paper. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for clearer clarification of the generalization to specific TSP instances, particularly in the context of the finetuning step in DIMES. It suggests that the paper should clearly explain how DIMES\"s advantages, such as direct RL training for largescale problems and meta finetuning, help overcome generalization gaps. Additionally, the reviewer suggests comparing DIMES with other methods on TSP100, both with and without metalearning, to further demonstrate its effectiveness. While the comment provides a clear direction for improvement, it does not specify exactly how the authors should present these comparisons or clarify the generalization gaps. The action is 4 because it provides a concrete idea of what needs to be done but lacks detailed guidance on execution. Therefore, this comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generalization to the specific TSP instances (the finetuning step in DIMES),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the advantages of DIMES in overcoming generalization gaps and the need for a comparison with other methods on TSP100. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should clarify the generalization to specific TSP instances, particularly in the context of the finetuning step in DIMES. It acknowledges DIMES\"s advantages in overcoming generalization gaps but emphasizes the need for clearer clarification. Additionally, the reviewer suggests comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment provides a logical reasoning for the need for clarification and comparison, it lacks specific examples or references to support the claim. This makes the claim 3, as it provides a general direction but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for clearer clarification of the generalization to specific TSP instances, particularly in the context of the finetuning step in DIMES. It acknowledges the advantages of DIMES in overcoming generalization gaps but emphasizes the importance of clearly explaining these differences in the paper. Additionally, the comment suggests a comparison of DIMES with other methods on TSP100, both with and without metalearning, to further demonstrate its effectiveness. This feedback is 4 as it provides clear and actionable suggestions for enhancing the clarity and comprehensiveness of the paper. However, it could be more helpful if it offered specific guidance on how to present these comparisons or clarify the generalization gaps. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility. This provides clear and direct actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"final thresholds\" and \"full set of hyperparameters,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the final thresholds used for the results and the sharing of hyperparameters for reproducibility. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the final thresholds used for the results and a suggestion to share the full set of hyperparameters for reproducibility. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by asking for the final thresholds used for the results and suggesting that sharing the full set of hyperparameters would enhance reproducibility. This feedback is clear and actionable, providing the authors with a direct way to improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present these thresholds or hyperparameters, such as suggesting specific formats or locations within the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that the conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment highlights a potential issue with the claim, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of different methods or features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the dataset analysis and the relationship between readability and question difficulty. It also specifies the issue by suggesting that the conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty.\" It suggests that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to consider the methods and features used in their analysis to address this point, but the comment lacks detailed evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that the conclusion may depend on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it points out a potential limitation or assumption in the analysis, prompting the authors to consider the impact of different methods or features on their findings. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue or explore alternative methods. Overall, the feedback is 3 as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific guidance or suggestions on how to achieve this optimization. The action is implicit, as the authors need to infer that they should reduce the whitespace in Figure 1, but it is vague because it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the optimization of Figure 1 to use less whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any reasoning, examples, or references to support why this optimization is necessary or beneficial. The comment lacks specific details or evidence to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that Figure 1 could be optimized by using less whitespace. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this optimization. The authors are left with a vague suggestion without actionable steps to enhance their figure. Therefore, the comment is 2, as it offers minimal value in terms of actionable feedback for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\"  \"look\" + \"walk\" = \"walking\") yield a more meaningful space. While the comment implies that the authors should conduct an analysis to support the claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform an analysis to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\"  \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the morphfitting results in a more meaningful space. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\"  \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the current geometry is not meaningful. This lack of evidence makes the claim 3, as the authors would need to infer the need for such analysis based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry of the space is meaningful, such as demonstrating that certain operations (e.g., \"looking\"  \"look\" + \"walk\" = \"walking\") yield a more meaningful space. This feedback is clear and actionable, as it prompts the authors to conduct an analysis that could significantly enhance the understanding and interpretation of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it identifies a critical area for improvement and offers a direction for further exploration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or which specific aspects of the related work should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the writing and expand the related work section but are not given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper need improvement or where the related work section is lacking. The authors can infer that the writing quality and related work sections are the areas of concern, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space on explaining basic memory networks and the forward model. It also notes a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of concrete evidence or references makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper: the writing quality and the related work section. It suggests that the authors should improve the writing quality by ensuring that the space allocated to explaining basic memory networks and the forward model is utilized more effectively. Additionally, it points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific guidance or examples on how to enhance the writing quality or which reinforcement learning tasks should be included in the related work section. While it highlights important areas for improvement, the feedback is 3 as it provides a general direction but lacks detailed actionable suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or which assumption is more relevant. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the violation of these assumptions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the replacement of the first column of Qo by vo to form P\"o, explaining how this affects the reachability of the first state. The comment further assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated, providing a clear direction for the authors to investigate and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. The reviewer assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to similar issues in the literature. The assumption is based on logical reasoning, but without further elaboration or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the replacement of the first column of Qo by vo to form P\"o, which results in the first state becoming unreachable but from a terminating state. It assumes that either Ass.1 (finite length of an option) or Ass.2 (finite length of a sequence) is violated, providing a clear direction for the authors to investigate and address the issue. However, the comment lacks detailed guidance on how to resolve the problem or which assumption is more relevant, leaving the authors with some insight but incomplete feedback. Therefore, the comment is 3, as it highlights a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is explicit and provides a concrete direction for the authors to explore, making it 5.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks detailed reasoning or evidence to support why the authors should focus on these aspects or how they relate to the improvements in the model. The suggestion is based on logical reasoning but lacks specific examples or references to substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that if the authors did not observe improvements in FLOPs or inference time, they should consider whether there are any improvements in accuracy or specific properties. It provides a specific example related to the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is clear and actionable, offering a direction for the authors to explore and potentially identify additional benefits of their approach. However, the comment could be more helpful if it provided more detailed guidance on how to analyze these aspects or offered specific metrics to consider. Overall, the comment is 4 as it directs the authors to a relevant area for further investigation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should verify this assumption, it does not explicitly instruct them to conduct a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to test the assumption but are not given specific steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about an assumption made in the paper regarding the use of d_e as replacements for entity embeddings. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether this assumption has been tested, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. This is a claim that requires verification, as it implies a lack of evidence or testing to support the assumption. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about an important assumption made in the paper, specifically whether the use of d_e as replacements for entity embeddings has been tested. This is a relevant and timely concern that could significantly impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific tests or evaluations could be conducted to verify the assumption. While it identifies a potential weakness, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the components of the \"scoring function\" and the threshold values/ranges used. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify these aspects, but it does not specify what information should be included or how it should be presented. As a result, the action is implicit and somewhat vague, leaving the authors to infer the necessary steps without clear direction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear: the components of the \"scoring function\" and the threshold values/ranges. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the \"scoring function\" and the threshold values/ranges used. However, it does not provide any specific examples, reasoning, or references to support why this clarity is necessary or how it impacts the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the \"scoring function\" and the threshold values/ranges used. It points out that the authors have not provided sufficient information on how these components were determined, which could be crucial for understanding the methodology and results. However, the comment does not offer any suggestions or guidance on how the authors might address this issue, such as providing additional explanations or examples. While it highlights an important area for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the presentation of factors or what specific changes could enhance the clarity or effectiveness of the information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where factors are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what information is missing or how the presentation could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it lacks specificity and does not offer any suggestions or guidance on how the authors might improve the presentation or conveyance of information. Without actionable feedback or constructive advice, the comment does not provide the authors with a clear path for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their work. As a result, the comment is 1, as it does not offer any direction for improvement or clarification.", "grounding_specificity_rationale": "The comment raises a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of physical interaction are being questioned or how this might impact the simulation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interaction that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interaction that can be included in one simulation. While it highlights an area of interest, it lacks specificity and does not provide any guidance or suggestions for improvement. The authors are left without actionable feedback or insights on how to address this question or its implications for their work. As a result, the comment is 1, as it does not offer any meaningful direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the model comparison section of the paper. It points out that the selection of datasets is inadequate because only one dataset has categorical features, while the others have exclusively numerical features. This is considered a limitation because categorical features are generally more challenging for deep learning models. Additionally, the authors are criticized for not employing onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should consider a more diverse set of datasets and potentially adjust their methodology for handling categorical features. However, the lack of explicit instructions on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model comparison\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, while others have exclusively numerical features. This is a critical point because categorical features are generally considered more challenging for deep learning models. The comment further specifies that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively affect performance for some models. This level of detail provides clear guidance on what needs to be addressed in the model comparison section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison is inadequate due to the selection of datasets, specifically noting that only one dataset has categorical features, while others have numerical features. It suggests that this omission may affect conclusions because categorical features are generally more challenging for deep learning models. The comment also points out that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This reasoning is logical and based on common knowledge about the challenges of deep learning with categorical features. However, the comment could be strengthened by providing specific examples or references to support the claim about the impact of categorical features on model performance. Therefore, the claim is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, highlighting several issues with the dataset selection. It points out that the chosen datasets are inadequate because only one has categorical features, while the others are numerical, which may affect the conclusions drawn. Additionally, it notes that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it identifies specific weaknesses in the dataset selection and methodology, providing the authors with concrete areas to improve their analysis. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending additional datasets or methods for handling categorical features. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by highlighting critical areas for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the choice of IoT datasets (FlatCam Face and Headpose detection) is unusual and may make the benchmarking results difficult to evaluate. It suggests that better options for IoT benchmarking could include wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback provides a clear and concrete action for the authors to consider alternative datasets that might improve the comprehensibility and relevance of their benchmarking results. The comment is explicit and provides specific guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of IoT datasets, specifically mentioning \"FlatCam Face\" and \"Headpose detection,\" and suggests alternative datasets that could be used for benchmarking. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets is unusual and may make the benchmarking results difficult to evaluate. The reviewer provides specific examples of the datasets used, \"FlatCam Face\" and \"Headpose detection,\" and explains why they are considered uncommon choices. The reviewer also suggests alternative datasets that could be used for benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that these datasets are not commonly used. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, namely \"FlatCam Face\" and \"Headpose detection.\" It questions the relevance and popularity of these datasets, suggesting that they may not be the best choices for benchmarking. The reviewer provides a rationale for this concern, noting that the datasets are relatively recent or outdated, which could make the benchmarking results less meaningful. Additionally, the comment offers suggestions for alternative datasets that could be used, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the relevance and comprehensibility of their benchmarking results. However, the comment could be more helpful if it included a detailed explanation of why these alternative datasets are better suited for the purpose. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with pruning in large networks, specifically mentioning the need to consider global top Q values of the metric over the average of gradients. It suggests that this could break acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this aspect further but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning\" and \"large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with pruning in large networks, specifically the need to consider global top Q values of the metric over the average of gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks, which are typically trained in distributed settings, and suggests that the authors should consider the global top Q values of the metric over the average of gradients. This claim is 3 as it provides a logical reasoning about the potential impact of pruning on acceleration techniques like quantization and sparsification. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to explore this issue further to fully understand the implications, which aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of pruning in large networks, specifically highlighting the need to consider global top Q values of the metric over the average of gradients. It suggests that this oversight could impact acceleration techniques like quantization and sparsification. While the comment points out a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or integrate it into their work. Providing more detailed advice or examples would enhance the comment\"s helpfulness. Therefore, the comment is 3, as it offers some insight but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it implies that the authors should verify this, it does not provide explicit instructions on how to check or correct the figures. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially correct the figures. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also clearly specifies the issue by questioning whether some subfigures have been swapped by mistake. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question asking whether some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a factual inquiry seeking clarification. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the potential swapping of subfigures in Figs 1 and 2. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might verify or address this concern. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this potential drawback. While the comment highlights an important consideration, it does not provide explicit guidance on how to incorporate this discussion into the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the tradeoff between sensitivity and false positives, but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the improvement in sensitivity and the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this tradeoff. While the comment highlights a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim about the risk of false positives. This makes the claim 3, as it provides a logical basis but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is valuable as it highlights a potential tradeoff in the methodology and encourages the authors to address this issue in their discussion. While the comment identifies an important consideration, it could be more helpful by providing specific suggestions on how to discuss this tradeoff or potential mitigations. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about the regret bound for the proposed minibatch method, as it could not be found in the supplementary material. While the comment highlights a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to verify the claim and potentially revise their paper to include the missing information. However, the comment lacks concrete details on how to implement this action, making it 3. The authors know they need to verify the claim and possibly add the missing information, but they may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method and its absence in the supplementary material. It also provides a specific reference to a relevant work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which supports the claim. This allows the authors to accurately identify the part of the paper being addressed and understand the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have made a statement about the regret bound for the proposed minibatch method, which is not supported by evidence in the supplementary material. The reviewer references a specific work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which suggests that the claim is based on external knowledge. However, the comment does not provide a detailed explanation or examples from the referenced work to fully substantiate the claim. This makes the claim 3, as it requires the authors to verify the claim and potentially consult the referenced work for further context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a discrepancy between the authors\" claim about the regret bound for the proposed minibatch method and the absence of this information in the supplementary material. It references a relevant work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide context for the claim. However, the comment does not offer specific guidance on how the authors should address this issue or suggest ways to clarify or correct the claim. While it highlights a potential problem, the feedback lacks actionable advice, making it 3. The authors are informed of a potential error but are not provided with detailed steps to rectify it, limiting the comment\"s usefulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper formatting is off and does not follow the NeurIPS formatting style. It specifically mentions issues with the abstract font size and bottom page margins. The reviewer suggests that by fixing these formatting issues, the authors could gain space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as ensuring the paper adheres to the NeurIPS formatting guidelines and adjusting the font size and margins accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper formatting, specifically the abstract font size and the bottom page margins, which are clear indicators of the parts of the paper being addressed. It also provides specific guidance on how to address these issues, such as ensuring the paper follows the NeurIPS formatting style and gaining space to include NLP experiments in the main body. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off and does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the formatting issues. Without detailed evidence or examples, the claim is 3, as it lacks the necessary justification to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out specific problems, such as the abstract font size being too large and the bottom page margins being altered. The comment provides actionable feedback by suggesting that fixing these formatting issues could help the authors gain space and include NLP experiments in the main body of the paper. This feedback is clear and constructive, offering a direct path for the authors to improve their draft. However, it could be more helpful if it included examples or further guidance on how to achieve the suggested improvements. Overall, the comment is 4, as it effectively guides the authors toward improving the formatting and organization of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include a discussion and comparison of these methods, but it lacks concrete details on how to execute this action. The authors can infer that they need to add a section discussing these methods, but the comment does not specify which methods to include or how to compare them. Therefore, the comment is 3, as it provides an implicit action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion and comparison, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim 3, as the authors would need to infer the relevance of these methods and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This is a critical oversight, as it could impact the paper\"s contribution and relevance. However, the comment lacks specific suggestions on how the authors might address this issue, such as recommending which methods to include or how to compare them. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the annotations in Figure 4 should be further enlarged for better visibility. This is a direct and concrete action that the authors can take to improve their draft. The comment clearly instructs the authors on what needs to be done, providing a specific and actionable step. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the enlargement of annotations in Figure 4 for better visibility. This provides clear guidance on how to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 should be enlarged for better visibility. However, it does not provide any reasoning or evidence to support why this is necessary or how it would improve the figure. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. By recommending that the annotations in Figure 4 be enlarged for better visibility, the reviewer offers a clear and concrete way for the authors to enhance the clarity and usability of their figure. This feedback is direct and provides a tangible step for the authors to take, making it 4. However, it could be more helpful if it included additional context or explanation for why this change is necessary or how it would impact the overall understanding of the figure. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion for how to address this issue or what changes should be made to the draft. As a result, the authors are left without any guidance on how to improve their work based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual statement describing the existence of multiple entities in both sentences and documents, which is a general observation in the field of natural language processing. It does not express an opinion, make a claim, or suggest changes, and it does not require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific issue with the text, noting that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This feedback is 3 as it highlights a potential misunderstanding or oversimplification in the paper. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or clarify their text. While it identifies a point for consideration, it does not fully support the authors in improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to change the label on the color bar in Fig. 4 to \"worse\". This is a direct and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done, providing a precise instruction for modification. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, suggesting that one of the labels should be changed to \"worse.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting a change to the label on the color bar in Fig. 4. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it identifies a particular issue with the color bar in Fig. 4 and suggests a correction by recommending that one of the labels should be changed to \"worse.\" This feedback is clear and provides a direct way for the authors to improve their draft by ensuring that the color bar accurately represents the data. However, the comment could be more helpful if it explained why this change is necessary or how it would enhance the clarity of the figure. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific error in the text, indicating that the phrase \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" This provides clear and direct guidance on what needs to be changed in the draft. The action is explicit and concrete, leaving no ambiguity for the authors on how to implement the suggested correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect use of \"\u2026training/validation/test\" instead of \"\u2026training/validation/test sets.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement pointing out a specific error in the text, \"\u2026training/validation/test\" should be corrected to \"\u2026training/validation/test sets.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, providing clear and actionable feedback. By pointing out the incorrect phrase \"\u2026training/validation/test\" and suggesting the correction to \"\u2026training/validation/test sets,\" the reviewer offers a precise and straightforward way for the authors to improve their draft. This level of detail and specificity empowers the authors to make a direct and meaningful change, enhancing the clarity and accuracy of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the clarity and completeness of the paper. It questions whether inference is slowed down and whether there is a way to only do inference, and it asks for the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, it points out the lack of hyperparameter details, which could impact the confidence in the results of the ablation studies. The comment also critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to improve the clarity and completeness of their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the clarity and completeness of the paper, specifically regarding the inference process, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. It also critiques the writing style, stating that it often impedes understanding. While the comment does not explicitly mention specific sections or lines, the authors can infer that it relates to the methodology or results sections, where these issues might be discussed. The comment is specific in detailing what needs to be addressed, such as the coefficient value and the need for hyperparameter details. However, it lacks full grounding because it does not explicitly mention the sections or lines where these issues are discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and concerns about the clarity and completeness of the paper, including the impact of inference on the model, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. While the comment identifies potential issues, it does not provide specific evidence or references to support these claims. The questions posed are logical and reasonable, but without additional context or examples, the claims remain 3. The comment lacks detailed reasoning or references to substantiate the concerns, making it difficult for the authors to fully address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could help the authors improve their draft. It questions the impact of inference on the model, specifically whether it is slowed down and if there is a way to only do inference. It also asks for clarification on the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, the comment points out the lack of hyperparameter details, which could affect the confidence in the results of the ablation studies. Furthermore, it critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas for improvement, it could be more helpful by providing specific suggestions on how to address these issues or by offering examples of how to improve the clarity of the writing. Overall, the comment is 3 as it highlights important areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and proposes two potential solutions: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. While the comment provides explicit suggestions for improvement, it does not specify which part of the paper the definition is located in, making it somewhat vague in terms of execution. The authors know what needs to be done but may need to search the paper to identify the exact location of the definition. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as adding an extra pair of brackets or defining the bracketed term separately, which clearly specifies what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and proposes two potential solutions: adding extra brackets or defining the bracketed term separately. However, the comment does not provide any reasoning or evidence to support why the current definition is confusing or how the suggested changes would improve clarity. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the quantile, suggesting that it is confusing. It provides two actionable suggestions for improvement: adding an extra pair of brackets around the term or defining the bracketed term separately if space allows. These suggestions are clear and offer concrete ways for the authors to enhance the clarity of their definition. However, the comment could be more helpful if it explained why the current definition is confusing or provided additional context about the quantile definition. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests replacing the term \"stateoftheart\" with \"very high performing model\" in line 152, citing the model by Dozat and Manning (2016) as no longer stateoftheart. This feedback is explicit, as it clearly instructs the authors to make a specific change to their draft. The suggestion is also concrete, as it provides a direct action and a possible alternative phrase to use. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the term \"stateoftheart\" with \"very high performing model,\" providing a clear action for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the term \"stateoftheart\" with \"very high performing model\" due to the model by Dozat and Manning (2016) no longer being considered stateoftheart. However, the comment does not provide any evidence or reasoning to support why the model is no longer considered stateoftheart, nor does it reference any recent studies or updates that might justify this claim. Without additional context or references, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, suggesting that the term \"stateoftheart\" might not be accurate due to the model by Dozat and Manning (2016) no longer being considered stateoftheart. The reviewer provides a clear and actionable suggestion to replace this term with \"very high performing model,\" which is a practical and constructive feedback. However, the comment could be more helpful if it included additional context or references to support why the model is no longer considered stateoftheart, or if it suggested alternative models that could be used as a reference. Overall, the comment is 4 as it directs the authors to a specific improvement in their draft, but it could be more comprehensive with additional context or references."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this weakness or improve their method. Without guidance on potential solutions or areas for further investigation, the authors are left without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where this issue is discussed. Additionally, the comment lacks specificity in terms of what needs to be addressed or how the authors might improve the method. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as a main weakness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a clear and actionable piece of feedback that highlights a critical area for improvement. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their method. While it points out a significant weakness, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several issues with the paper, including the need for objective statements and references to support subjective claims. It also highlights the challenges in designing an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it suggests that the authors should provide a detailed explanation to verify the statements made. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The actions are inferred and somewhat vague, as the authors are left to determine the specific steps needed to address each point. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the need for objective statements and references to support subjective claims. It also discusses the challenges in designing an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it mentions the use of multiscale architecture design and the need for a detailed explanation. However, the comment does not specify which parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique, it lacks grounding as it does not clearly identify the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some subjective statements are inappropriate and suggests that proofs and references are needed to support them. It also highlights the challenges in designing an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, it mentions the use of multiscale architecture design and the need for a detailed explanation. While the comment provides some logical reasoning and references to specific aspects of the paper, it lacks detailed examples or specific references to support the claims fully. The suggestion to provide a detailed explanation is also not elaborated upon. Therefore, the comment is 3, as it provides a general direction but lacks specific evidence or detailed reasoning to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the need for objective statements and references to support subjective claims. It also highlights the challenges in designing an effective architecture and the sensitivity of image recovery performance to neural architecture choices. Additionally, the comment points out the need for a detailed explanation of multiscale architecture design, particularly regarding when to fuse multiscale features. The suggestion to consider models with skip connections as using multiscale information in an implicit way is a valuable insight. However, the comment could be more helpful if it provided specific examples or references to support the claims and suggestions. Overall, the feedback is 4 as it directs the authors to address critical areas of their paper, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method compares to prior art, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of the comparison should be addressed or how the authors might conduct this comparison. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or additions are needed to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed method with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the introduction or results sections, but without explicit mention, it is weakly grounded. The comment is specific in its request for a comparison with prior art, but it lacks detailed guidance on how to conduct this comparison or what aspects to focus on. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question asking for a comparison with prior art, which does not contain any claims, opinions, or suggestions that require verification. It is purely factual and does not necessitate a response or further explanation from the authors. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the comparison of the proposed method with prior art. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or what aspects of the comparison are most relevant. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft in response to this critique. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data (~20 different types) and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. While the comment implies that the authors should explore these analyses further, it does not provide explicit guidance on how to conduct these analyses or what specific observations to look for. The action is implicit and somewhat vague, as the authors can infer that they need to delve deeper into the analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"language/nationality\" and provides specific examples of languages/nationalities included in the data, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the potential for interesting observations by comparing biases towards different languages/nationalities. This level of detail provides clear guidance on what the authors should focus on to improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data and expresses curiosity about potential interesting observations by comparing biases towards different languages/nationalities. However, the comment lacks specific examples or references to support the claim that these analyses could be more detailed or that biases vary significantly. The suggestion is 3 as it provides a general direction for further analysis, but it requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically highlighting the \"language/nationality\" aspect. It points out that the data includes a diverse range of languages/nationalities and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. This feedback is 3 as it identifies a specific area for further analysis and suggests a potential direction for exploration. However, it lacks detailed guidance on how to conduct these analyses or what specific observations to look for, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, and suggests that it is necessary and helpful for the approach design. However, it does not provide explicit guidance or suggestions on how the authors should explore or utilize these properties. The action is implicit, as the authors need to infer that they should investigate other properties, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific properties or aspects of the approach design are being questioned. This makes it difficult for the authors to identify the exact section or aspect of the paper being addressed, resulting in weak grounding. The comment is also not specific as it lacks detailed guidance on what properties to consider or how to incorporate them. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used besides norm, suggesting it is necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would be beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used besides norm, suggesting that it is necessary and helpful for the approach design. While the comment identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or utilize these properties. Without actionable advice or examples, the authors are left with a vague direction for improvement. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be fully beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d could be a simpler network. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they should reconsider the network architecture and simplify the d network, but the comment lacks specific guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" indicating that it addresses a specific part of the paper, likely a section or subsection. It is also specific because it details the weaknesses in the method, such as its reliance on previous methods and the lack of network changes or losses. The comment further questions the use of two SIRENs for f and d, suggesting that d could be a simpler network. This provides clear guidance on what aspects of the method need improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims about the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d could be a simpler network. While the comment identifies potential weaknesses, it lacks specific examples or detailed reasoning to support these claims. The lack of detailed justification or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed evidence or explanation to be 5.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including its reliance on previous methods and the lack of network changes or losses. It also questions the use of two SIRENs for f and d, suggesting that d could be a simpler network. This feedback is clear and actionable, as it points out specific areas where the method could be improved and provides a rationale for why these changes might be beneficial. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of simpler networks that could be used for d. Overall, the comment is 4 as it directs the authors to areas that need improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a redundancy in RQ1, suggesting that it does not add any new information for the audience. It implies that the authors should consider analyzing the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3. While the comment suggests an interesting point to analyze, it does not provide explicit instructions on how to implement this analysis or which specific sections of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with RQ1, stating that it adds no extra information for the audience and suggests an alternative analysis point regarding the effect of explicit hate information on implicit hate speech detection performance. The reference to a specific paper (\"https://aclanthology.org/2023.findingseacl.9/\") provides additional context and supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and does not add new information. It suggests an alternative analysis point regarding the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3. The comment provides a reference to a specific paper, which could support the suggestion for further analysis. However, the claim about RQ1 being redundant is not fully substantiated with detailed reasoning or examples, making it 3. The suggestion for additional analysis is more specific and could be helpful for the authors, but the lack of detailed justification for the redundancy claim limits the overall verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a redundancy in RQ1, suggesting that it does not provide any additional information for the audience. It implies that the performance variation across multiple HS datasets in a crossdata setting is expected and therefore not novel. The comment also suggests an interesting point for analysis: how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. This feedback is 3 as it points out a potential area for improvement and suggests a new direction for analysis. However, it lacks specific guidance on how to implement this analysis or which sections of the paper should be revised. To be more helpful, the comment could provide more detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an expectation for the paper to include a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how the authors should address this expectation. There is no suggestion of specific tasks that should be included or how the authors might demonstrate the importance of PE in these tasks. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this expectation relates to, nor does it provide details on what specific tasks or aspects of PE should be included. This makes it difficult for the authors to identify the exact sections that need attention or improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a statement of expectation regarding the inclusion of various tasks beyond link prediction where Positional Encoding (PE) is important. It does not express an opinion, judgment, or suggestion that requires verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on which tasks or aspects of PE should be included. This makes it difficult for the authors to understand how to address the suggestion effectively. The comment is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. While it does not explicitly instruct the authors to make any changes, it implies that the authors should provide a detailed explanation of how their work differs from these other papers. This inference is clear, and the authors know exactly what action to take to address the comment. However, the comment could be more actionable if it provided specific guidance on how to elaborate on the differences. Overall, the comment is 4 as it clearly identifies an area for improvement and provides a concrete direction for the authors to follow.", "grounding_specificity_rationale": "The comment raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests that the authors should elaborate on the differences, it does not provide specific guidance on what aspects to focus on or how to address the question. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the differences between the current work and other papers focusing on semantic face editing, specifically those that demonstrate continuous control over different attributes. However, it does not make a claim or provide any specific critique or suggestion that requires verification. It is a request for clarification, which is factual and does not contain an opinion or judgment. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the differences between the current work and other papers that focus on semantic face editing, specifically those that demonstrate continuous control over different attributes. By asking the authors to elaborate on these differences, the comment encourages the authors to provide a clearer understanding of their work\"s originality and contributions. This feedback is 3 as it prompts the authors to address a potential gap in their paper, but it could be more helpful if it provided specific suggestions on how to frame the differences or what aspects to focus on. Overall, the comment is 3, as it guides the authors toward a meaningful area of improvement but lacks detailed guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reduce the use of footnotes in the paper, as they are \"very distracting.\" It provides a specific example by mentioning that details around parameter settings could be moved into the appendix, such as the example given at L468. This feedback is clear and actionable, as it directs the authors to make a specific change to improve the readability and structure of their paper. The comment provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes\" and provides a specific example at \"L468,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the extensive use of footnotes and suggests moving important content into the main body of the paper, while details like parameter settings could be moved to the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the extensive use of footnotes is distracting and suggests moving important content into the main body of the paper. However, the comment does not provide specific examples or detailed reasoning to support why the footnotes are distracting or how moving content would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the extensive use of footnotes in the paper, which it finds distracting. It provides a clear suggestion to move important content from the footnotes into the main body of the paper, which would improve the flow and readability of the draft. Additionally, it offers a concrete example by mentioning that details around parameter settings could be moved into the appendix. This feedback is actionable and provides the authors with a clear direction for improving their draft. However, it could be more helpful if it included additional suggestions or examples of how to effectively integrate the content into the main body. Overall, the comment is 4, as it offers valuable guidance for enhancing the paper\"s structure and clarity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations would be beneficial and that a discussion about this would be appreciated. It also questions the inclusion of zeroshot generation results, suggesting that it might be unnecessary. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The suggestions are implicit and somewhat vague, leaving the authors to infer that they should consider including fewshot demonstrations and discussing their relevance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a set of fewshot demonstrations\" and \"zeroshot generation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as the inclusion of fewshot demonstrations and the discussion of their relevance. Additionally, the comment questions the inclusion of zeroshot generation results, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results is \"a bit strange\" and questions their relevance. However, the comment does not provide specific reasoning or evidence to support why these results are unnecessary or how they might not contribute to the paper\"s goals. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting the inclusion of a set of fewshot demonstrations, which could enhance the paper\"s discussion. It also questions the inclusion of zeroshot generation results, suggesting that they might not be necessary. However, the comment lacks specific guidance on how to integrate the fewshot demonstrations or why the zeroshot results are unnecessary. While it points out areas for consideration, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it offers some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content from the appendix or an outdated caption. While the comment identifies the problem, it does not provide explicit instructions on how to address it. The authors are left to infer that they need to either update the caption, include the missing content, or clarify the reference to \"OAA\" in the body text. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that \"OAA\" is not referenced in the body text and suggesting that there might be missing content from the appendix or an outdated caption. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content from the appendix or an outdated caption. However, the comment does not provide specific examples or detailed reasoning to support the claim that the content is missing or the caption is outdated. This lack of detailed justification makes the claim 3, as the authors would need to investigate further to understand the issue fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, noting that \"OAA\" is not referenced in the body text. It suggests that there might be missing content from the appendix or an outdated caption. This feedback is 3 as it points out a potential inconsistency or error in the figure\"s reference, prompting the authors to review and correct it. However, the comment could be more helpful if it provided specific guidance on how to address the issue, such as suggesting where the reference should be included or how to update the caption. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference [2]. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to compute or analyze the effective receptive field. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the effective receptive field and suggests that it could be computed from reference [2]. This provides clear guidance on what aspect of the GS module needs further exploration or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module, suggesting that this could be computed from reference [2]. However, the comment does not provide any supporting evidence or reasoning to justify why the effective receptive field should be improved or how it relates to the GS module. Without additional context or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the effective receptive field of the GS module, suggesting that it could be computed from reference [2]. This prompts the authors to consider an important aspect of their work, specifically how the GS module affects the receptive field. However, the comment lacks depth and does not provide specific guidance on how to compute or analyze the effective receptive field. It also does not offer suggestions for improvement or potential experiments to conduct. While it identifies a relevant area for exploration, the feedback is incomplete and lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part would remain the same for both pretraining and finetuning, with the addition of another head in the finetuning stage to compute value functions for states. This comment provides a clear and explicit suggestion for how the authors could modify their approach, offering a concrete action to take. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"LSTM part\" and the objective for both pretraining and finetuning, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it provides a clear suggestion for how the authors might modify their approach by adding another head to the network to compute value functions for states. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, with the addition of another head to compute value functions for states. This claim is based on logical reasoning and provides a clear explanation of how the authors might modify their approach. However, it lacks specific examples or references to support the claim, which could make it more robust. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details or examples.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the LSTM part of the paper, particularly in the context of pretraining and finetuning. It points out that the objective for the LSTM part could remain the same for both stages, with the addition of another head to compute value functions for states. This feedback is clear and actionable, offering a concrete way for the authors to enhance their approach. However, the comment could be more helpful if it provided additional context or examples to further clarify the suggestion. Overall, the comment is 4 as it provides a valuable direction for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the rationale behind combining G4RL with HRAC, specifically asking if G4RL requires HRAC\"s regularization in the latent space. While it does not provide explicit instructions or suggestions for improvement, it implies that the authors should clarify the reasoning behind this combination. The action is implicit and somewhat vague, as it does not specify how the authors should address the question or what additional information should be included. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"G4RL with HRAC (i.e., HRACG4RL),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind combining G4RL with HRAC. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, the correct label is \"No.\"", "helpfulness_rationale": "The review comment poses a question about the rationale behind combining G4RL with HRAC, specifically asking if G4RL requires HRAC\"s regularization in the latent space. While it does not provide direct feedback or suggestions for improvement, it prompts the authors to clarify their methodology, which can lead to a better understanding of their approach. However, the comment lacks depth and does not offer actionable guidance on how to address the question or improve the draft. Therefore, it is 3, as it identifies an area for clarification but does not fully support the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" While the comment implies that the authors should include these older works, it does not specify which specific works should be acknowledged or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which works are being referred to and how to incorporate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This provides clear guidance on what needs to be addressed in the related works section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" However, the comment does not provide specific examples of these older works or explain why they are relevant. This lack of detailed justification or references makes the claim 3, as the authors would need to infer which works are being referred to and why they are important. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This feedback is 3 as it points out a potential gap in the related works section, encouraging the authors to provide a more comprehensive overview of the field. However, the comment lacks specific examples or references to the older works that should be included, which would make it more actionable and helpful. To be fully helpful, the comment could provide more detailed guidance on which specific works to acknowledge or how to integrate them into the related works section. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the comparison between linear/exponentialdecay sampling and uniform sampling. The reviewer expresses confusion about why the former underperforms the latter, given the argument that the predictor is accurate on the good subregion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this confusion or improve their analysis. Without actionable suggestions or questions that prompt further investigation, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The comment provides a clear rationale for the confusion, suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This level of detail helps the authors understand what needs to be addressed in their analysis. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The reviewer provides a logical reasoning by suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to delve deeper into the analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It provides a logical reasoning for why this underperformance might be expected, suggesting that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This feedback is 3 as it prompts the authors to reconsider their analysis and potentially provide additional insights or explanations to clarify the results. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the time complexity. The authors are left to infer that they should consider optimizing the method or reducing the computational cost, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the potential issues with the time complexity, such as the association of many users with a typical item and the expense of the elementwise function. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method seems high, citing three specific reasons: the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment provides a logical breakdown of potential issues, it lacks specific examples or references to support the claim about the time complexity. This makes the claim 3, as the authors would need to further investigate and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback highlights areas where the authors might need to optimize their approach to improve efficiency. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative methods or techniques for reducing computational complexity. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a direct and concrete action for the authors to take, which is to modify the figure labels to improve clarity. The suggestion is explicit and clear, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many of the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the figures by specifying \"pretrained solution encoders & solution decoders,\" which would help differentiate between multiple types of autoencoders. This level of detail guides the authors on what specific changes to make to enhance the clarity of their figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This is a logical suggestion based on the need for clarity in labeling figures, especially when dealing with multiple types of autoencoders. However, the comment does not provide specific examples or references to support why this change would improve clarity, making it 3. The authors would need to infer the reasoning behind the suggestion, which could be challenging without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. By recommending that the figures specify \"pretrained solution encoders & solution decoders,\" the reviewer helps the authors differentiate between multiple types of autoencoders, which could enhance the understanding and interpretation of the results. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and readability of their figures. However, the comment could be more helpful if it explained why this differentiation is important or how it would impact the reader\"s understanding. Overall, the comment is 4 as it provides a direct and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two specific comparisons that the authors should consider: one with NeRFbased methods, such as Zero1to3, and another with pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment implies that these comparisons and the evaluation of the occlusion experiment are necessary, it does not provide explicit instructions on how to conduct these comparisons or what specific aspects to focus on. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not specify which part of the paper these suggestions should be made in, such as the methodology or results sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting comparisons and questioning the relevance of the occlusion experiment, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. The lack of specific examples or references makes the claim 3, as the authors would need to infer the importance of these comparisons and the relevance of the occlusion experiment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that it may not be specific to the method being proposed. While the comment highlights areas for improvement, it lacks depth and does not provide detailed guidance on how to conduct these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out potential weaknesses, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding a brief explanation of \"multiaspect\" at specific line numbers (14 and 47), which is a clear and concrete instruction. Second, it requests a correction in Figure 1, specifying that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These actions are explicit and provide detailed guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the need for a brief explanation of \"multiaspect\" and the correction of subscripts in Figure 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate requests for clarification and correction. The first request for a brief explanation of \"multiaspect\" is a factual statement asking for additional information, which does not contain a claim. The second request for correcting subscripts in Figure 1 is also factual and does not express an opinion or judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the clarity and accuracy of the paper. First, it requests a brief explanation of the term \"multiaspect,\" which would help readers understand the context. Second, it points out a potential error in Figure 1, suggesting that the subscripts \"s\" and \"t\" should be \"1\" and \"2,\" respectively. These suggestions are clear and concrete, offering the authors direct guidance on how to enhance the readability and precision of their work. By addressing these issues, the authors can improve the overall quality and clarity of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the extraction of parts of sentences and documents, as well as the impact of extraction rules on the experiment. It explicitly requests a more detailed analysis, which provides a clear action for the authors to take. However, the comment does not specify how the authors should conduct this analysis or what specific details should be included. While the action is explicit, the lack of concrete guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the extraction of parts of sentences and documents and the impact of extraction rules on the experiment. The request for a more detailed analysis further clarifies the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the extraction process and its impact on the experiment. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the extraction process, specifically asking how parts of sentences and documents are extracted and whether the rules of extraction have any effect on the experiment. It also requests a more detailed analysis, which is a clear and actionable suggestion for the authors to improve their draft. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further exploration and explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to provide information about the computation required to implement the experiments, including the time taken and the hardware used. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is explicit and concrete, as it specifies exactly what information should be included in the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment requests information about the computation required for the experiments, including the time taken and the hardware used. However, it does not specify which part of the paper this information should be included in, such as the methods or results sections. This makes it difficult for the authors to pinpoint the exact location where this information should be added. The comment is specific in its request for additional details but lacks grounding, as it does not direct the authors to a specific section of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements and duration of the experiments, along with the hardware used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests additional information about the computational requirements and duration of the experiments, as well as the hardware used. While it identifies a gap in the paper regarding the experimental setup, it does not provide specific suggestions or guidance on how to address this issue. The authors are left with a clear understanding of what information is missing but without actionable steps to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled manner and if so, when it is applied. The comment explicitly asks for more discussion on this aspect and requests information about the epoch at which the meta sampler is started. This provides clear and specific guidance on what the authors need to address in their draft, making the comment 5. The authors know exactly what information is missing and how to provide it, ensuring that they can effectively implement the suggested action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and its application, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for more discussion on the decoupled application of the meta sampler and requests information about when the authors start applying it, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the application of the meta sampler. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, asking for additional information about the methodology. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler, inquiring whether it is used in a decoupled manner and, if so, when it is applied. This feedback is clear and actionable, as it prompts the authors to provide more discussion on this aspect of their methodology. By addressing this question, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests that the authors should conduct more experiments using fairnessaware metrics like Equality odds (EO) in addition to their own defined vanilla metric. Second, it encourages the authors to conduct experiments on more datasets, specifically mentioning COMPAS and Drug Consumption, and recommends following the AAAI paper \"Exacerbating Algorithmic Bias through Fairness Attacks\" for guidance. Both actions are concrete and provide specific guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a \"vanilla metric\" and the lack of related fairnessaware metrics like Equality odds (EO), allowing the authors to identify the specific part of the paper being addressed. It also provides a clear suggestion to conduct more experiments on datasets like COMPAS and Drug Consumption, and references a specific AAAI paper for guidance. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should use fairnessaware metrics like Equality odds (EO) and conduct experiments on more datasets, such as COMPAS and Drug Consumption. The comment provides a specific reference to an AAAI paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which supports the suggestion for additional experiments. However, the comment does not fully explain why these metrics or datasets are necessary or how they would improve the paper. While the reference to the AAAI paper provides some justification, the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of fairnessaware metrics like Equality odds (EO) alongside the authors\" defined vanilla metric. It provides a clear suggestion for the authors to conduct more experiments on datasets like COMPAS and Drug Consumption, and references a relevant AAAI paper for guidance. This feedback is actionable and offers a concrete direction for enhancing the paper by incorporating additional metrics and datasets. However, the comment could be more helpful if it provided a detailed explanation of why these metrics and datasets are important or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional context or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to rephrase a section of the paper (L107114) that is deemed speculative or overly opinionated. It suggests that this content should be presented as a remark or aside in the Discussion section or removed altogether. This feedback provides clear and direct guidance on what action to take, making it 5. The authors know exactly what needs to be done to address the issue, and the comment offers concrete steps to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it seems speculative or overly opinionated and suggesting that it should be rephrased as a remark or aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a specific section of the paper (L107114) is \"speculative or overly opinionated.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (L107114) as being speculative or overly opinionated. It provides clear guidance by suggesting that this content should be rephrased as a remark or aside in the Discussion section or removed altogether. This feedback is actionable and helps the authors to refine their draft by ensuring that speculative or opinionated content is appropriately presented. However, the comment could be more helpful if it offered additional context or examples to support the suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement made by the changes proposed in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need to include these baselines but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting the inclusion of these baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement. However, the comment does not provide any reasoning or evidence to support why these specific baselines should be considered or how they would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the paper would benefit from considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s evaluation and validation. By considering these baselines, the authors can more comprehensively assess the effectiveness of their approach and provide a more robust comparison with existing methods. However, the comment could be more helpful if it explained why these specific baselines are relevant or how they would contribute to the paper\"s evaluation. Overall, the comment is 4 as it offers a constructive suggestion for improving the paper\"s evaluation and validation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two missing elements in the paper: the value of neighborhood size \"h\" and an analysis of its influence on the model\"s performance. It also mentions the use of different hyperparameter sets per dataset, which is not ideal. The comment provides a clear action for the authors to take, which is to analyze the impact of \"h\" on the model\"s performance and to explore the use of a constant set of parameters across datasets. The feedback is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing elements of the paper, such as the value of neighborhood size \"h\" and the analysis of its influence on the model\"s performance. It also addresses the issue of using different hyperparameter sets per dataset. This allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what is missing and provides guidance on how to address these issues, such as analyzing the impact of \"h\" and exploring the use of a constant set of parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the neighborhood size \"h\" and its influence on the model\"s performance, as well as the use of different hyperparameter sets per dataset. The comment provides a logical reasoning for the importance of analyzing the neighborhood size and its impact on performance, which is a common practice in similar studies. However, it does not provide specific examples or references to support the claim about the use of different hyperparameter sets. While the comment highlights a potential issue, it lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed support.", "helpfulness_rationale": "The review comment identifies two important areas for improvement in the paper. First, it points out the lack of analysis on the value of neighborhood size \"h\" and its influence on the model\"s performance, which is a critical parameter in the proposed strategy. Second, it notes the use of different hyperparameter sets per dataset, which is not ideal. The comment provides clear and actionable feedback by suggesting that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is valuable as it guides the authors to address specific gaps in their analysis, potentially leading to a more comprehensive and robust evaluation of their method. However, the comment could be more helpful if it offered specific suggestions on how to analyze the impact of \"h\" or provided examples of how to standardize hyperparameter sets. Overall, the comment is 4, as it effectively directs the authors to enhance their analysis and presentation of results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and report on the model\"s performance under imperfect data conditions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to address this concern. The comment is specific in its inquiry but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It is purely a question seeking clarification, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the model when dealing with imperfect multimodal data, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors being constructed. This feedback is valuable as it highlights a potential weakness in the model\"s performance under realworld conditions and prompts the authors to consider and address this issue. However, the comment could be more helpful if it provided suggestions on how to investigate or mitigate these effects. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question and suggests a specific analysis that could be included in the general discussion section of the paper. It explicitly asks for statistics on the frequency of negation or intensity words, such as \"nothing,\" and how often they change the polarity of the context. This provides a clear and concrete action for the authors to take, as it specifies what data or analysis should be included to enhance the paper. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for analysis, asking for statistics on the frequency of negation or intensity words, such as \"nothing,\" and how often they change the polarity of the context. This level of detail gives the authors a clear understanding of what needs to be addressed in the general discussion section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a suggestion for additional analysis in the general discussion section, specifically asking for statistics on the frequency of negation or intensity words and their impact on the context. This is a request for clarification or additional information, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for enhancing the general discussion section of the paper. It questions the effectiveness of the SST dataset by suggesting that the authors should analyze the frequency of negation or intensity words, such as \"nothing,\" and how often they change the polarity of the context. This feedback is clear and provides a concrete direction for the authors to improve their analysis and presentation of results. By addressing this suggestion, the authors can gain a deeper understanding of their dataset and present more comprehensive insights, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the lack of verification of the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability on this dataset, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OGEAug\" and the \"DrugOOD\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not verifying the stability of OGEAug on OOD benchmarks, particularly on the DrugOOD dataset, where SPE is validated. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset. However, it does not provide any reasoning or evidence to support this claim, nor does it offer specific examples or references to substantiate the assertion. Without additional context or justification, the claim remains 1, as the authors may not be aware of the specific concerns or the expected verification process. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of verification of the stability of the OGEAug on OOD benchmarks, particularly on the DrugOOD dataset. It highlights a potential gap in the validation process by mentioning that SPE is validated on this dataset, suggesting that the authors should also verify the stability of OGEAug on this benchmark. This feedback is clear and actionable, as it directs the authors to a specific area where they need to enhance their validation process. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific aspects to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could benefit from more detailed suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests considering alternative methods, such as freezing some layers of the model while training a few layers or using parameterefficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these methods, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides specific alternatives to consider, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests exploring alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting alternative methods for experimental comparison, which provides clear guidance on what the authors could consider. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. The comment provides a logical reasoning by suggesting that these methods are \"natural to think about\" and could offer a valuable basis for comparison. However, it lacks specific examples or references to support the claim that these methods are particularly relevant or effective in the context of the paper. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests exploring alternative methods, such as freezing some layers of the model or using parameterefficient methods like LoRA, for experimental comparison. This feedback is valuable as it provides the authors with a specific direction for improving their work by considering different approaches that could enhance the experimental design. However, the comment could be more helpful if it included a detailed explanation of why these methods are relevant or how they might impact the results. Despite this, the suggestion is clear and actionable, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a precise direction for enhancement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is specific and directs the authors to a particular area where they can enhance their draft by providing a more comprehensive comparison. By doing so, the authors can better position their work within the existing literature and demonstrate its novelty and relevance. However, the comment could be more helpful if it included specific examples of strong baselines or suggested how to effectively integrate these comparisons into the related work section. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting multiple seed experiments to provide a more robust evaluation of the performance differences and the impact of the proposed cycle consistency loss on convergence. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the robustness of their evaluation. The comment provides concrete guidance on how to enhance the experimental setup, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of single seed experiments, which is a specific aspect of the paper\"s methodology. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation, but it does not specify where this should be implemented or how it would improve the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it highlights a potential limitation in the experimental setup, but it lacks specific examples or references to support the assertion that multiple seed experiments are necessary. The authors would need to consider this suggestion to improve the robustness of their evaluation, but the comment could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental setup, specifically the use of single seed experiments. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The comment provides a clear and actionable suggestion to conduct multiple seed experiments, which would significantly enhance the robustness of the evaluation. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete step to strengthen their experimental methodology. However, the comment could be more helpful if it provided additional context or examples of how multiple seed experiments could be implemented or what benefits they would bring. Overall, the comment is 4, as it offers a clear path for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, stating that the motivation behind this choice is unclear. While the comment raises a valid question, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the motivation. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation for their choice of distributions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice of distributions, which is a clear and actionable point. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, stating that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It points out that the motivation behind this choice is unclear, which is a relevant concern that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify the motivation or alternative approaches they could consider. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to clarify their choice but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires a multiGPU setup for optimizations, which may limit its accessibility to many potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or suggest alternatives that could make the method more accessible. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the accessibility of the proposed method, specifically mentioning the requirement for a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding. It is specific in highlighting the accessibility issue but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method requires a multiGPU setup for optimizations, which makes it inaccessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential limitation of the proposed method, noting that it requires a multiGPU setup for optimizations, which may limit its accessibility to many potential users. This feedback is 3 as it identifies a specific issue that could impact the practicality and usability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or make the method more accessible. Without actionable advice or potential solutions, the authors are left with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing citation for the public skipgram data set in a specific line of the paper (L425). This provides clear and direct guidance to the authors on what action to take: they need to include the missing citation. The comment is explicit and concrete, as it specifies the exact location and the action required, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing citations for the public skipgram data set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement indicating a missing citation for the public skipgram data set in a specific line of the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, pointing out a specific issue with missing citations for the public skipgram data set in a particular line of the paper. By identifying this omission, the comment provides actionable feedback that the authors can use to improve the accuracy and completeness of their references. However, the comment could be more helpful if it suggested where the citation should be included or provided additional context about the importance of the citation. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further suggests using Ref[2] as a strong baseline for comparison. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare their system with others that capture semantics and use Ref[2] as a baseline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also mentions Ref[2] as a potential strong baseline for comparison. However, the comment does not specify which part of the paper this suggestion should be applied to, nor does it provide detailed guidance on how to conduct these comparisons. The authors can infer that it relates to the experimental or results sections, but the lack of explicit grounding and specificity makes it challenging for them to pinpoint the exact areas needing attention. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further recommends using Ref[2] as a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It further recommends using Ref[2] as a strong baseline for comparison. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s evaluation. However, the comment lacks specific guidance on how to conduct these comparisons or what aspects to focus on, which limits its usefulness. The authors are given a general direction but need to infer the details themselves. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. While it identifies an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete details on what specific information should be included or how the authors should present their data. As a result, the authors may infer that they need to provide more detailed information about their data usage, but the action is not explicitly stated, making the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in its request for clarification on the data used, but it is 1 as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validation, and testing. This is a factual inquiry that seeks clarification rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a critical issue regarding the clarity of the quantitative results, specifically questioning the data used for training, validation, and testing. This is an important point that the authors need to address to ensure transparency and reproducibility of their findings. However, the comment lacks specific suggestions or guidance on how the authors might clarify this information, such as recommending the inclusion of detailed data descriptions or examples. While it highlights a significant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the model\"s performance in identifying true sources in the triangle dataset, asking if one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their model. The questions are implicit and lack concrete details on what actions the authors should take to resolve the problem. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the model\"s performance in identifying true sources in the triangle dataset, asking if one of the assumptions is not satisfied or if there are learning difficulties. However, it does not specify which part of the paper discusses the model\"s performance or the assumptions being referred to. The authors might infer that it relates to the results or methodology sections, but this is not explicitly stated. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the model\"s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. While it identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions for improvement. The authors are left with a general understanding of the problem but without clear steps to address it. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a clear explanation of how their SE framework improves and why it is beneficial. It also emphasizes the need to demonstrate the reasoning behind their achievements, going beyond just showing results. The comment provides a specific action for the authors to take, which is to include a detailed explanation of the framework\"s benefits and how it is implemented. Additionally, it suggests referencing a specific paper to support their claims, offering a concrete example of how to enhance the paper. This feedback is explicit and provides clear guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for a clearer explanation of how the SE framework improves and why it is beneficial, and it suggests showing the reasoning behind the achievements. Additionally, it references a specific paper, providing a concrete example of how to enhance the paper. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should provide a clearer explanation of how their SE framework improves and why it is beneficial. The reviewer suggests that the authors should demonstrate the reasoning behind their achievements, rather than just showing results. The comment references a specific paper, \"Neural architecture search with gbdt\" by Luo et al., which provides a relevant example of how to enhance the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how the referenced paper supports the claim. Overall, the claim is 4, as it provides some support but lacks comprehensive evidence or detailed examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by emphasizing the need for the authors to explain how their SE framework improves and why it is beneficial. It instructs the authors to go beyond just showing results and to provide a detailed explanation of the reasoning behind their achievements. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their paper. Additionally, the comment suggests referencing a specific paper, which could serve as a useful example for the authors to follow. However, the comment could be more helpful if it provided specific examples or more detailed guidance on how to structure the explanation. Overall, the comment is 4, as it offers clear and actionable feedback that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific changes should be made to the approach. The comment lacks concrete details or suggestions, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the approach\"s limitations but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the limitation of the approach to only two views, suggesting that the system should be able to generalize to more views without much difficulty. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation exists or how it could be addressed. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach being restricted to only two views, suggesting that the system should be able to generalize to more views without much difficulty. This is a valid point that could prompt the authors to consider expanding their approach to multiple views. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this limitation. Without detailed feedback or examples, the authors may find it challenging to understand how to improve their work based on this critique. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the applicability of the metrics used for evaluating continual learning in certain scenarios, such as when task boundaries are unknown or not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for alternative metrics or approaches that could be more suitable. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue with the applicability of these metrics in certain scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in scenarios where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It points out that these metrics might not be applicable in scenarios where task boundaries are unknown or not clearly defined. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative metrics. The feedback is 3 as it prompts the authors to consider the broader applicability of their evaluation metrics, but it could be more actionable with additional guidance or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors need to infer that they should clarify or justify the current approach, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the methodology but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the overall performance or understanding of the model. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. This is a valid point that could help the authors clarify their methodology and potentially improve the understanding of their model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what implications it might have for their results. While it identifies a potential area for improvement, the feedback is 3 as it prompts the authors to consider this aspect but does not fully support them in making improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the discussion on the arbitrary hyperparameter \u03b3 is missing, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear action for the authors to take: they need to include a discussion on how to set \u03b3 and its sensitivity. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion on arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion on how to set \u03b3 in practice for a given graph and an analysis of its sensitivity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion on the arbitrary hyperparameter \u03b3 is missing, which would make it difficult for researchers to follow. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why this discussion is crucial. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of discussing \u03b3 and its sensitivity based on general knowledge of hyperparameter tuning in graphrelated research. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion regarding the arbitrary hyperparameter \u03b3, specifically noting the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback is clear and actionable, as it highlights a critical area that needs attention to enhance the comprehensibility and usability of the paper for researchers. By addressing this gap, the authors can provide valuable insights and practical advice, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment explicitly suggests the need for a controlled baseline, it does not provide specific guidance on how to implement this or what specific locations should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of induction heads and FV heads appearing at different locations within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include a controlled baseline is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. The reviewer implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment provides a logical reasoning for the potential confounding factor, it lacks specific examples or references to support the claim. The suggestion for a controlled baseline is a reasonable one, but without detailed justification or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the experiment, specifically the location of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline should be included to ablate heads at different locations in the model. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their experimental design and analysis. By addressing this issue, the authors can gain a more accurate understanding of the factors influencing their results. However, the comment could be more helpful if it offered additional guidance on how to implement this controlled baseline or what specific locations should be tested. Overall, the comment is 4, as it effectively guides the authors toward a meaningful improvement in their experimental setup."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, which is to add this missing section. The comment is explicit and concrete, as it specifies exactly what needs to be included in the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, which allows the authors to accurately identify the part of the paper being addressed. It specifies what is missing, namely a description of how the multiplechoice task is approached, providing clear guidance on what needs to be added. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, namely the absence of a section on synonym identification under similarity measurement. It highlights the importance of this section in describing how the multiplechoice task is approached. This feedback is clear and actionable, as it provides a clear direction for the authors to improve their draft by adding this missing section. However, the comment could be more helpful if it offered suggestions on what aspects should be included in this section or how it could be integrated into the existing content. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. However, it does not specify what this overview should include or how it should be presented. The action is implicit, as the authors need to infer that they should add an overview section, but it is vague because it lacks concrete details on what this overview should cover. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a comprehensive understanding of the work. However, it does not specify which part of the paper this overview should be included in, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where this feedback applies. Additionally, the comment lacks specificity regarding what aspects of the workflow and model should be included in the overview. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would improve the comprehensibility of the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. This feedback is 3 as it identifies a potential area for improvement, namely the need for a clearer and more detailed explanation of the workflow and model. However, the comment lacks specificity and does not provide guidance on what aspects of the workflow and model should be included in the overview or how to present it. While it points out a necessary improvement, it does not offer detailed suggestions or actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with debiasing the sketch, noting that it requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest potential solutions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the bias issue but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It implies that this information cannot be computed accurately without a significant runtime, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue or where it should be addressed. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue with debiasing, but without explicit references to sections or specific parts of the paper, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that debiasing the sketch requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. The reviewer supports this claim by providing a logical explanation of the computational challenge involved in debiasing the sketch. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to consider the computational implications and potential biases in their approach, but the comment could be strengthened with additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing of the sketch, noting that it requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. The comment also mentions a similar issue arising when computing the surrogate sketch. While the comment highlights a critical concern, it lacks specific suggestions or guidance on how the authors might address this issue or mitigate the bias. Providing actionable advice or examples would enhance the helpfulness of the feedback. Therefore, the comment is 3, as it points out a significant problem but does not offer detailed solutions or improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to redefine Figure 3, as the expected quantities are scalars but are shown as vectors. This feedback is clear and direct, providing a specific action for the authors to take. The comment also specifies the issue, which is the inconsistent representation of scalar quantities as vectors in the figure. This level of detail ensures that the authors know exactly what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are shown as vectors. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the quantities in Figure 3 should be represented as scalars instead of vectors, as they are expected to be scalar values. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the clarity or accuracy of the figure. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out an inconsistency in the representation of quantities in Figure 3, noting that scalar values are shown as vectors. By suggesting a redefinition of the figure to accurately represent the quantities, the comment offers a clear path for the authors to enhance the presentation and clarity of their work. This feedback is direct and helpful, as it guides the authors toward a specific improvement that can enhance the overall quality of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the setup need attention. The comment implies that the authors should address these concerns, but it lacks concrete details or explicit instructions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific issues arise from the current setup. The authors may infer that it relates to the experimental section, but the comment lacks full grounding as it does not explicitly mention the section or provide detailed guidance on what needs to be improved. The comment is specific in identifying the need for a better experiment setup but lacks specificity in detailing what aspects need improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup due to the questions it raises. However, the comment does not provide specific examples of these questions or elaborate on why the current setup is inadequate. This lack of detailed justification or evidence makes it difficult for the authors to understand and address the issue effectively. As a result, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup due to the questions it raises. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the experiment setup need improvement or how the authors might address these questions. Without concrete suggestions or examples, the authors are left with a general idea of what might be lacking but without a clear path forward for improvement. Therefore, the comment is 3, as it highlights an area for improvement but does not offer actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct more empirical work but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further, which implies that the comment is related to the discussion or results sections where such claims are typically made. However, the comment does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing what is missing, namely empirical evidence to test the hypothesis, and it provides a suggestion for further exploration. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations of lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request for additional evidence. However, the comment does not provide specific examples or references to substantiate the claim, making it 3. The authors would need to infer the importance of empirical evidence and the potential improvements that could be made by conducting further analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what types of evidence would be most relevant. Additionally, it mentions that the explanation of improvements is not clear, which is another area for improvement. While the comment highlights important areas for enhancement, it lacks detailed guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the resolution of the 3D voxel and its potential impact on computational and memory costs. It suggests that studying the importance of the global feature by comparing different resolutions of voxel features could be more convincing. The comment also provides a specific example of reducing the resolution to 1x1x1, which is equivalent to using a single global feature. While the comment implies that the authors should explore this aspect further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparative study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely, the importance of the global feature and the potential impact of different resolutions of voxel features. The comment suggests a specific approach to study this aspect by comparing different resolutions, and it provides a concrete example of reducing the resolution to 1x1x1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its potential impact on computational and memory costs. It suggests that studying the importance of the global feature by comparing different resolutions of voxel features could be more convincing. The comment provides a specific example of reducing the resolution to 1x1x1, which is equivalent to using a single global feature. This reasoning is logical and provides a clear suggestion for improvement, making the claim 4. However, the comment could be strengthened by including references or examples of similar studies that have explored this aspect. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a pertinent question about the resolution of the 3D voxel and its potential impact on computational and memory costs. It suggests that studying the importance of the global feature by comparing different resolutions of voxel features could be more convincing. The comment also provides a specific example of reducing the resolution to 1x1x1, which is equivalent to using a single global feature. This feedback is clear and actionable, as it directs the authors to explore a specific aspect of their methodology that could enhance the paper\"s credibility. By suggesting a comparative study, the comment offers a concrete way for the authors to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, which is a critical piece of information for other researchers to continue working on this task. It clearly instructs the authors to include this analysis to provide insight into the model\"s failures. The comment provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"error analysis on the movie dataset,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the absence of this analysis, which is crucial for other researchers to understand the model\"s failures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is necessary for other researchers to continue working on the task. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the importance of the missing error analysis or how to address it. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, specifically the lack of error analysis on the movie dataset. It highlights the importance of understanding the model\"s failures to facilitate further research by other scholars. This feedback is clear and actionable, as it directly points out an area that needs attention and provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it effectively guides the authors toward a significant enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to identify trends in Table 3, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should analyze the trends further, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the trends in the development set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the difficulty in seeing trends in the table, particularly with the behavior of PM+CL compared to PM or CL alone. The comment further suggests that it would be interesting to see development set trends with respect to these hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are not apparent or how they should be analyzed. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is challenging to discern trends, particularly with the behavior of PM+CL compared to PM or CL alone. The reviewer suggests that it would be interesting to see development set trends with respect to these hyperparameters. This feedback is clear and actionable, as it points out a potential area for improvement and provides a specific suggestion for further analysis. However, the comment could be more helpful if it offered additional guidance on how to present these trends or what specific aspects of the development set should be explored. Overall, the comment is 4 as it directs the authors to a specific area that could enhance the clarity and depth of their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to the numerous lines overlapping, suggesting that the authors could improve clarity by reporting additional metrics such as flops or model size. While the comment implies that the authors should include these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for additional metrics but may not be entirely sure of the specific metrics to report. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, noting the difficulty in understanding due to overlapping lines, and suggests that reporting additional metrics like flops or model size would improve the clarity. This provides clear guidance on what needs to be addressed to enhance the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the numerous lines overlapping and suggests that reporting additional metrics like flops or model size would improve the clarity. However, the comment does not provide specific examples or detailed reasoning to support why these metrics are necessary or how they would enhance understanding. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of these metrics themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the numerous lines overlapping make it difficult to understand. It suggests that reporting additional metrics such as flops or model size would improve the clarity and concreteness of the figure. This feedback is clear and actionable, providing the authors with a direct suggestion for enhancing the presentation of their results. However, the comment could be more helpful if it offered specific guidance on how to present these metrics or suggested alternative visualizations. Overall, the comment is 4 as it directs the authors to a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any explicit or implicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks actionable advice or suggestions, leaving the authors without a clear understanding of what needs to be done to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which questions or sections are being referred to, making it difficult for the authors to identify the exact parts of the paper that need attention. This lack of specificity and grounding makes it challenging for the authors to determine what needs to be addressed, resulting in a comment that is 1 and highly unspecific. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or context to support this claim. Without detailed information on what details are missing, the authors may find it challenging to address the issue. The comment lacks verifiable evidence or reasoning, making it difficult for the authors to understand and respond to the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any specific guidance or suggestions on what these missing details are or how the authors might address them. Without actionable feedback or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance their draft. This lack of specificity and guidance makes the comment unhelpful, as it does not provide any meaningful direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides a clear action for the authors to simplify the description and explain the architecture and computations better. Additionally, it suggests specific sections and lines that could be reduced to gain more space. This feedback is direct and provides concrete guidance on how to improve the clarity and readability of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8\" and \"lines 3964,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of the paper being too dense and difficult to follow, and it provides actionable suggestions for simplifying the description and explaining the architecture and computations better. The comment also suggests reducing specific sections to gain more space. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. The reviewer suggests simplifying the description and explaining the architecture and computations better, specifically mentioning Figure 7, Section 8, and lines 3964 as areas for reduction. While the comment provides a clear suggestion for improvement, it lacks specific examples or detailed reasoning to support the claim that the paper is overly dense. This makes the claim 3, as the authors would need to infer the exact issues and how to address them based on the general feedback provided.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s density and difficulty in following the concepts and contribution. It provides a clear and actionable suggestion to simplify the description and explain the architecture and computations better. The comment also specifies particular sections, such as Figure 7, Section 8, and lines 3964, that could be reduced to gain more space. This feedback is valuable as it offers concrete guidance on how to improve the clarity and readability of the paper, making it 4 for the authors. However, it could be more helpful if it included additional suggestions or examples of how to simplify the content. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that it would be interesting to evaluate the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests evaluating the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular evaluation scenario and comparison, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to evaluate the EIGNN model in terms of oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that focus on dealing with oversmoothing, such as GCNII. The comment provides a logical suggestion for further evaluation, but it lacks specific examples or references to support the claim that this comparison would be beneficial. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an interesting direction for further evaluation of the EIGNN model, specifically in the context of oversmoothing under standard settings on realworld datasets. It also proposes a comparison with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included additional guidance on how to conduct this evaluation or what specific aspects to focus on. Overall, the comment is 4, as it offers a valuable suggestion for enhancing the paper, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing part in the paper, specifically the lack of a separate section or subsection to introduce the inference strategy for using multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to add a separate part or subsection to address this gap. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a lack of a separate part or subsection to introduce the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, namely the lack of a separate part or subsection to introduce the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by indicating where the authors should add more detail. However, the comment could be more helpful if it offered additional guidance on what specific aspects of the inference strategy should be included or how to effectively present this information. Despite this, the comment is 4 as it directs the authors to a critical area that needs expansion, making it a valuable feedback for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Figure 4 is confusing and that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take: they should clarify the meaning of the columns in the figure by adding an explanation in the text or caption. The feedback is explicit and concrete, giving the authors a precise step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure. The comment suggests that the columns are not explained in the text or caption, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 is confusing due to unclear column meanings, which is not explained in the text or caption. This is a subjective opinion based on the reviewer\"s interpretation of the figure. However, the comment does not provide specific examples or detailed reasoning to support why the columns are confusing, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that the columns are confusing and not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns, which is essential for the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to improve the figure or offered examples of how to clarify the column meanings. Despite this, the comment is 4 as it highlights a critical area for improvement, guiding the authors to enhance the clarity of their figure. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides several suggestions for improvement, including a request to discuss the experiment results more thoroughly and to clarify the realworld applications of the new problem setting. It also raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. While the comment identifies areas that need attention, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to discuss the experiment results more, clarify the applicability, and consider the computational complexity, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3, as it provides a general direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"the realworld applications,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific points for improvement, such as discussing the results of the Streetview experiment and clarifying the applicability to sorting/ranking problems. Additionally, it raises a question about the computational complexity of the proposed algorithm when applied to ranking problems. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several claims, including the need for more discussion of experiment results and the lack of clarity in realworld applications. However, it does not provide specific examples or detailed reasoning to support these claims, making them difficult for the authors to address effectively. The comment mentions the complexity of the algorithm (K^2) but does not elaborate on how this impacts the ranking problem, leaving a gap in the justification. Therefore, the claims are 3, as they lack sufficient evidence or detailed explanation to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the discussion of experiment results and the clarity of realworld applications. It suggests that the experiment results could be more thoroughly discussed, particularly in relation to the Streetview experiment, where it questions whether MaxGapTop2UCB is better than other methods. Additionally, it points out the lack of clarity in the realworld applications, specifically mentioning the applicability to sorting/ranking and the potential complexity of the proposed algorithm when applied to ranking problems. The comment provides some guidance by questioning the computational complexity of the algorithm in the context of ranking problems. However, it lacks detailed suggestions or examples on how to address these issues, which would make the feedback more actionable. Overall, the comment is 3 as it highlights important areas for improvement but could be more comprehensive in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. The reviewer suggests that more explanations are needed. While the comment implies that the authors should provide additional explanations for the observed results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to pinpoint the exact section being addressed. The comment suggests that more explanations are needed, but it does not provide specific guidance on what aspects of the results or methods should be clarified. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment lacks specific reasoning or evidence to support why these results are unexpected or how they compare to the mentioned methods. Without detailed analysis or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, noting that they are even lower than some simple early methods. It suggests that more explanations are needed to understand this observation. While the comment identifies a potential issue with the results, it lacks specific guidance or suggestions on how the authors might address this concern or provide additional explanations. The feedback is 3 as it points out a potential area for improvement, but it does not offer actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to conduct an ablation analysis, but the comment does not specify which components should be analyzed or how to implement this analysis. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for ablation analysis, but without clear grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. This is a valid observation, as ablation analysis is a common method used to understand the contribution of individual components to the overall performance. However, the comment does not provide specific examples or references to support why the lack of ablation analysis is problematic or how it affects the interpretation of the results. While the claim is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of ablation analysis, which makes it difficult to determine the source of the small performance gain. This is a critical observation that highlights a key area for improvement, as ablation analysis is a standard practice in evaluating the contribution of individual components to overall performance. However, the comment does not provide specific suggestions on how to conduct the ablation analysis or which components should be analyzed. While it points out a crucial weakness, it lacks actionable guidance, making it 3. The authors are left to infer that they need to conduct an ablation analysis, but without detailed instructions, the feedback is incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point presents a finding that when the number of classes is large (>8), the noise rate of similarity labels is less than that of class labels. It also mentions the use of \"Th.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the observation or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"2,\" which suggests that it is addressing a specific part of the paper, likely a figure or table. However, without further context or details, the authors may not be entirely sure which part of the paper \"2\" refers to. The comment also mentions the use of \"Th,\" which could be a reference to a specific method or technique, but without more context, it is not clear how this relates to the rest of the paper. The comment does specify that the noise rate of similarity labels is less than that of class labels when the number of classes is large, which provides some level of specificity. Therefore, the comment is weakly grounded due to the lack of explicit reference to the section or figure, but it is specific in its description of the observation. This aligns with a score of 3.", "verifiability_rationale": "The review point presents a factual observation about the noise rate of similarity labels compared to class labels when the number of classes is large. It also mentions the use of \"Th,\" which could refer to a specific method or technique. However, the comment lacks any subjective claims, opinions, or suggestions that would require verification. It is purely descriptive, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review point presents an observation about the noise rate of similarity labels compared to class labels when the number of classes is large. It also mentions the use of \"Th,\" which could be a reference to a specific method or technique. However, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer any guidance on how the authors might address this observation or how it could impact their work. Without specific advice or suggestions, the comment is 2, as it provides minimal value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment should be modified to compare the model trained on the original dataset with the model trained on a mixture of the original dataset and the generated adversarial examples. This would help highlight the impact of the augmented adversarial examples. The comment explicitly states the need for this comparison and provides a clear direction for improvement. However, it does not specify how to implement this change or what specific aspects of the experiment need to be adjusted. While the action is explicit, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiment, namely that it does not compare the model trained on the original dataset with the model trained on a mixture of the original dataset and the generated adversarial examples. This provides clear guidance on how to improve the experiment to make it more convincing. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not well verified by the designed experiment. It provides a specific critique by comparing the training methods of conventional models and the base model, suggesting that the experiment should compare the model trained on the original dataset with the model trained on a mixture of the original dataset and the generated adversarial examples. This critique is supported by logical reasoning and references to specific sections of the paper, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental design, specifically noting that the hypothesis is not well verified by the current experiment. It points out a discrepancy in the training methods between conventional models and the base model, suggesting that a comparison between models trained on the original dataset and those trained on a mixture of the original dataset and generated adversarial examples would be more convincing. This feedback is clear and actionable, providing the authors with a specific direction to enhance the validity and impact of their work. However, the comment could be more helpful if it offered additional suggestions or examples on how to implement this comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the experimental design and the overall credibility of their findings."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, such as revising the experimental design, providing additional data, or clarifying the results. Without any guidance or direction, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"CNN experiments\" but does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what makes the experiments not fully convincing. The authors cannot confidently determine which experiments are being referred to or what aspects need improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on what aspects of the experiments are lacking or how they could be improved. Without detailed guidance or actionable advice, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable feedback makes the comment unhelpful, as it does not provide the authors with a meaningful way to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify whether the results for model (3) (Chung et al. 2016) for CsEn were computed by the authors themselves or taken from the papers. It provides a clear action for the authors to take, which is to mention the source of these results. This feedback is concrete and direct, giving the authors a specific step to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results for model (3) (Chung et al. 2016) for CsEn, noting that these results were not taken from the papers and suggesting that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The reviewer suggests that if the authors computed these results themselves, they should mention it. This claim is based on a logical observation and a request for clarification, making it 3. The reviewer provides a clear rationale for the claim, but it lacks specific references or examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn were not taken from the papers, as they are not reported. The comment suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, providing the authors with a specific area to clarify and potentially improve the transparency and accuracy of their results. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context. Overall, the comment is 4 as it directs the authors to a critical area of improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. While the comment implies that the authors should focus on prompt design and discuss its effectiveness, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the discussion on prompt design without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. However, the comment does not specify which part of the paper should focus on prompt design or provide specific guidance on what aspects of prompt design need more emphasis. While the authors can infer that the discussion on prompt design should be enhanced, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. However, the comment lacks specific examples or detailed reasoning to support the claim that prompt design is a critical area for improvement. While the suggestion is logical, it requires more elaboration to be 5. Therefore, the comment is 3, as it provides a general direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper should place more emphasis on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to effectively design prompts. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the results with the current stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. This is an explicit action that provides a clear direction for the authors to follow. The comment specifies the SoTA approaches to compare with, giving the authors a concrete step to take in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. However, it does not specify which part of the paper this comparison should be made in, such as the results section or the discussion. This lack of explicit reference to a specific section makes it weakly grounded, as the authors cannot confidently determine where to address the suggestion. The comment is specific in suggesting a particular comparison, which is an improvement over vague suggestions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning the HateXplain models. However, it does not provide any reasoning or evidence to support why this comparison is necessary or how it would improve the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison with stateoftheart (SoTA) approaches, such as the HateXplain models. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by benchmarking their results against established models. However, the comment could be more helpful if it explained why this comparison is important or how it would contribute to the paper\"s impact. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection and suggests that if the adaptive method is good, it could be used instead. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors to infer that they should clarify the rationale for using freezing or consider alternative methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or freezing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to use the adaptive method, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be better or why freezing is used. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection, suggesting that if the adaptive method is good, it could be used instead. This feedback identifies a potential area for improvement by questioning the rationale behind the choice of method. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue or explore alternative methods. While it prompts the authors to consider an alternative approach, it does not offer detailed guidance or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it is somewhat vague because it does not specify what aspects of the plan should be detailed or how the authors should present this information. The authors know they need to provide a more detailed plan but may not be entirely sure of the exact steps or level of detail required. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. However, it does not specify which limitations are being referred to or where in the paper these limitations are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in its request for a detailed plan but lacks grounding, as it does not identify the specific sections or aspects of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This claim is 3 as it acknowledges the authors\" mention of limitations but highlights the need for a more detailed plan. However, the comment lacks specific examples or references to support the claim that the current plan is insufficient. Providing more detailed guidance or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the authors have mentioned limitations in the paper but suggests that they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to be more specific about their plans for addressing the limitations. However, the comment could be more helpful if it provided specific guidance on what aspects of the plan should be detailed or how the authors might structure their future work discussion. Overall, the comment offers a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests that the authors perform an analysis similar to existing work that combines text and KG. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the type of analysis to perform, but it lacks directness in terms of action. The authors can infer that they need to conduct this analysis, but the comment could be more explicit in its guidance. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests performing an analysis similar to existing work that combines text and KG. It references a specific paper (https://arxiv.org/abs/2104.06378) and mentions the need for analysis on the proposed model. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a particular analysis to be performed, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue is solved in the proposed knowledgeCLIP model and suggests performing an analysis similar to existing work that combines text and KG. The comment references a specific paper (https://arxiv.org/abs/2104.06378) as an example of closely related analyses, such as adding negation or changing entities in text to see if the KGaugmented method can robustly handle them. This provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed model might address these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a pertinent question about whether the issue addressed in the paper is resolved by the proposed knowledgeCLIP model. It references existing work that combines text and KG, suggesting that the authors perform a similar analysis on their proposed model. This feedback is valuable as it encourages the authors to consider additional analyses that could strengthen their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for further exploration, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several specific issues with the paper, including the inconsistency in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of \"\u03bc f\" in Alg. 2 without considering the variance. The reviewer also suggests replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These comments provide explicit actions for the authors to take, such as clarifying the reason for the inconsistency in Eq. 3 and considering the addition of variance in Alg. 2. The suggestions are concrete and direct, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the use of \"p m\" and \"p c\" in Eq. 3 and suggests considering the addition of variance in Alg. 2. Additionally, the comment provides a suggestion to replace \"\u03bc f\" with \"\u03bc g\" to maintain consistency. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises several specific issues with the paper, including the inconsistency in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of \"\u03bc f\" in Alg. 2 without considering the variance. The reviewer also suggests replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These points are based on logical reasoning and observations about the mathematical formulation and algorithmic implementation. However, the comment lacks specific references or detailed explanations to fully substantiate the claims, making it 3. The authors would need to provide additional context or evidence to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the inconsistency in using \"p m\" in the numerator and \"p c\" in the denominator in Eq. 3, and the use of \"\u03bc f\" in Alg. 2 without considering the variance. It also suggests replacing \"\u03bc f\" with \"\u03bc g\" to maintain consistency with Eq. These observations are clear and actionable, providing the authors with concrete feedback on how to improve their draft. By addressing these points, the authors can enhance the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or examples to further clarify the suggested improvements. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but lacks a comprehensive discussion on the computational complexity. The reviewer suggests that the paper should include a more detailed discussion on this aspect. While the comment implies that the authors should expand their discussion on computational complexity, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors know they need to discuss computational complexity but are not given explicit instructions on how to approach this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational cost, specifically questioning the lack of a comprehensive discussion on the computational complexity of the proposed approach. It mentions that the paper mentions the additional cost not leading to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on this aspect and wonders if the proposed approach becomes prohibitive in some settings. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the discussion of computational costs or the methodology section. The comment is specific in its request for a more comprehensive discussion on computational complexity, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of a comprehensive discussion on the computational cost of the proposed approach, noting that the paper mentions it does not lead to \"significant delays in computation\" but does not provide a clear explanation. The reviewer suggests that the paper should include a more detailed discussion on computational complexity and wonders if the proposed approach becomes prohibitive in some settings. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the computational cost is a significant concern. The reasoning is 3, as it provides a logical basis for the suggestion but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s discussion of computational cost, noting that while the paper mentions the additional cost does not lead to significant delays, it lacks a comprehensive discussion on the computational complexity of the proposal. The reviewer suggests that the paper should include a more detailed discussion on this aspect and questions whether the proposed approach becomes prohibitive in certain settings. This feedback is 3 as it points out a gap in the paper\"s discussion and encourages the authors to provide more detailed analysis. However, it could be more helpful if it offered specific suggestions on how to address the computational complexity or provided examples of settings where the approach might be prohibitive. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more clarification on how novel values in the test set are handled. This is an explicit action that the authors can take to improve their draft. The comment is specific in its request for additional explanation, providing clear guidance on what the authors need to do to enhance the clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more clarification on how novel values in the test set are handled. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point suggests that the authors should provide more clarification on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more clarification on how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors improve the clarity and comprehensibility of their paper. By addressing this suggestion, the authors can enhance the reader\"s understanding of their methodology and results. However, the comment could be more helpful if it provided additional context or examples of what specific aspects of novel values need clarification. Overall, the comment is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point mentions that similar methods have already been proposed for multitask learning and notes that this has not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper should be revised. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that similar methods have already been proposed for multitask learning and notes that this has not been discussed in the paper. However, it does not specify which part of the paper should include this discussion or which specific methods are being referred to. The authors can make an educated guess that it relates to the methodology or literature review sections, but the comment lacks full grounding. It is specific in pointing out the omission of discussing similar methods, but without explicit references or detailed guidance, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and have not been discussed in the paper. However, it does not provide any specific examples or references to these existing methods, making it difficult for the authors to understand the basis of the claim or how to address it. Without supporting evidence or detailed information, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that similar methods for multitask learning have already been proposed and not discussed in the paper. This is a relevant observation that could help the authors improve their draft by ensuring they are aware of existing work in the field and potentially incorporating it into their discussion or methodology. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or integrate the existing methods into their work. While it highlights an important area for consideration, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises an expectation about the computational complexity of FedMITR compared to other methods and asks if a comparison has been made. While it implies that the authors should consider comparing the computational complexity, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include a comparison if it has not been done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. However, it does not specify which part of the paper this comparison should be included in, nor does it provide guidance on how to conduct the comparison. The authors can infer that it relates to the experimental or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in its request for a comparison but does not provide detailed guidance on how to perform it. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that FedMITR\"s computational complexity is expected to be higher. Without additional context or justification, the authors may find it challenging to address the comment effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on how to conduct such a comparison or what aspects of computational complexity should be considered. This limits the usefulness of the feedback, as the authors are left without clear direction on how to address the issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide guidance on how to clarify it. The action is implicit and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment refers to \"1) and 2)\" and \"figure 3,\" which provides some grounding as it implies specific parts of the paper being addressed. However, it does not explicitly mention which sections or figures these numbers correspond to, making it weakly grounded. The comment suggests using a generic external knowledge base to address issues 1 and 2, but it does not specify what these issues are or how the knowledge base would resolve them. This lack of specificity makes it difficult for the authors to understand what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The mention of \"the writing is too confusing\" adds to the lack of clarity, as it does not specify what aspects of the writing are confusing or how they could be improved. Without detailed justification or examples, the claim remains 1.", "helpfulness_rationale": "The review comment suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague and lacks specificity, as it does not clearly explain what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide any guidance on how to clarify it. Without detailed feedback or actionable suggestions, the authors are left without a clear understanding of what needs to be improved or how to make those improvements. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of other influential loss functions. While it implies that the authors should provide more information or justification for their choices, it does not explicitly instruct them to do so. The suggestions are vague and lack concrete guidance on how to address these issues. The authors can infer that they need to provide more details, but the comment does not specify what specific actions to take or how to implement these suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of other influential loss functions. However, it does not specify which part of the paper these questions and suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its questioning and suggestions but lacks grounding, as it does not provide a clear reference to the specific sections or elements of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of other influential loss functions. However, it does not provide any supporting evidence, reasoning, or references to justify these questions or suggestions. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the inquiry, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of other influential loss functions. It prompts the authors to provide more information about their methodology and to consider alternative approaches. However, the comment lacks specificity and does not offer detailed guidance on how to address these questions or suggestions. While it identifies areas for improvement, it does not provide actionable steps or detailed feedback, making it 3. The authors are given some direction but need to infer the exact actions to take, which aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing indepth analysis of experimental results, specifically questioning why improvements are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be included. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the experimental results, questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing what is missing, namely an indepth analysis of the experimental results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of indepth analysis on experimental results, specifically questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of indepth analysis of experimental results. It provides a clear example of what is missing by questioning the limited improvements on the offense detection dataset and significant improvements on the coarse stereotype set. This feedback is actionable as it directs the authors to conduct a more detailed analysis of their experimental results, which could enhance the understanding and validity of their findings. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit suggestions for improving the draft, including using a new method of training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like Resnet50 or DenseNet121 for feature extraction. The comment also explicitly states that the current number of convolutional layers (3) is insufficient for nonsynthetic tasks. While the suggestions are clear, the comment could be more actionable by providing specific guidance on how to implement these changes or by offering examples of how to incorporate the suggested methods. Overall, the comment is 4 as it provides concrete suggestions for improvement, but it could be more detailed in its guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the new method of training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121. It also provides a clear suggestion to increase the number of convolutional layers. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it provides detailed suggestions for improvement, including the number of examples for input mask explanation annotations and the recommendation to use modern backbone baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses skepticism about the effectiveness of the proposed method, citing the failure of similar robustness/domain invariance interventions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the skepticism. The lack of detailed evidence or references limits the verifiability of the claim, rendering it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It suggests using a new method of training on labeled data and incorporating input mask explanation annotations for a few examples, which could enhance the robustness and domain invariance of the model. Additionally, it recommends using modern backbone baselines like Resnet50 or DenseNet121 for feature extraction, as the current number of convolutional layers (3) is deemed insufficient for nonsynthetic tasks. The comment also acknowledges the reviewer\"s skepticism about the proposed method, but this does not detract from the helpfulness of the suggestions. Overall, the feedback is clear and actionable, offering the authors concrete ways to improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should ensure the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how to implement this action, such as which specific resources should be matched or how to conduct the tuning. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. However, it does not specify which part of the paper this issue pertains to, such as which sections discuss the hyperparameters or the comparison with the baseline. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, while the comment highlights an important aspect of ensuring fairness in comparisons, it does not provide specific guidance on how to achieve this. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. This claim is 3 as it highlights a potential issue with the comparison between the proposed method and the baseline. However, the comment lacks specific examples or detailed reasoning on why this is important or how it affects the fairness of the comparison. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the proposed method and the baseline, suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. This is a relevant point, as ensuring that both the proposed and baseline methods are optimized under the same conditions is crucial for a valid comparison. However, the comment lacks specific guidance on how to achieve this, such as which hyperparameters need to be tuned or how to conduct the tuning process. While it highlights an important aspect of the paper, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential error in the definition of perplexity and its representation in the paper. It explicitly states that the definition provided is incorrect and suggests that it resembles crossentropy instead. However, the comment does not provide specific guidance on how to correct the definition or clarify the confusion. While it highlights an issue, it lacks actionable steps for the authors to take, such as suggesting alternative definitions or examples to illustrate the correct concept. Therefore, the comment is 3, as it points out a problem but does not offer concrete steps for resolution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and its representation, pointing out that it does not align with the actual definition of perplexity and instead resembles crossentropy. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity provided in the paper is incorrect and that it resembles crossentropy. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of perplexity provided in the paper, pointing out that it is incorrect and more accurately represents crossentropy. This feedback is clear and actionable, as it directs the authors to correct the definition and potentially clarify the confusion in their work. However, the comment could be more helpful if it provided additional guidance on how to accurately define perplexity or suggested examples to illustrate the correct concept. Overall, the comment is 4 as it highlights a critical error that needs correction, but it could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines for graph contrastive learning and test them on common datasets. It provides specific examples of missing baselines, such as MVGRL and gptgnn, which gives the authors a clear direction on what needs to be added. The comment is explicit and concrete, providing a direct action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of sufficient baselines, such as MVGRL and gptgnn, and suggests adding more baselines for graph contrastive learning and testing them on common datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL and gptgnn. The reviewer suggests adding more baselines for graph contrastive learning and testing them on common datasets. While the comment identifies a potential gap in the baseline comparison, it lacks specific reasoning or evidence to support why these particular baselines are necessary or how they would enhance the study. The suggestion is 3 as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient baseline comparison in the graph classification task. It points out the absence of certain baselines, such as MVGRL and gptgnn, and suggests adding more baselines for graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by enhancing the baseline comparison. However, the comment could be more helpful if it included specific suggestions on which additional baselines to consider or how to implement the suggested tests. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge mapbased defense strategies. It suggests that the authors should evaluate their defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. The comment implies that the authors should consider this type of attack to assess the robustness of their defense. While the action is implicit, it is concrete in suggesting a specific type of evaluation that the authors should conduct. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge mapbased defense strategies. It suggests evaluating the defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. However, the comment does not explicitly mention which part of the paper this evaluation should be conducted in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the evaluation against a specific type of adversarial attack. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge mapbased defense strategies. It suggests that the authors should evaluate their defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. The comment provides a logical reasoning for why this type of evaluation is crucial, as it highlights a potential vulnerability in the defense strategy. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this suggestion and provide evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge mapbased defense strategies. It highlights the importance of evaluating the defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. This feedback is valuable as it points out a potential vulnerability in the defense strategy and suggests a specific area for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct this evaluation or offered specific suggestions for addressing the identified issue. Overall, the comment is 4 as it directs the authors to a critical area that needs further exploration, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to make the legends in Tables 1, 2, and 3 longer and to clarify whether the numbers represent percentage errors or percentage correct. This feedback provides a clear and concrete action for the authors to take, ensuring they understand exactly what needs to be done to improve their draft. The explicit nature of the comment and the specific details provided make it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the legends should be longer and clarify whether the numbers represent percentage errors or percentage correct. This provides clear guidance on how to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct. This is a factual statement requesting clarification, as it does not express an opinion or judgment that requires verification. It is purely descriptive and does not contain any subjective claims or suggestions, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends in Tables 1, 2, and 3 should be longer and clarify whether the numbers represent percentage errors or percentage correct. This feedback is clear and directly addresses a potential source of confusion in the paper, offering a concrete step for the authors to improve the clarity and readability of their work. By making these changes, the authors can enhance the understanding of their results, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment explicitly identifies a missing element that needs to be included in the experimental section to enhance the clarity and interpretability of the results. However, it does not provide specific guidance on how to calculate or present the standard deviations. While the action is clear, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual observation that does not require additional evidence or justification, as it is a straightforward critique of the presentation of the results. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it challenging to assess the significance of the findings. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations in the experimental results. However, the comment could be more helpful if it offered guidance on how to calculate or present the standard deviations effectively. Despite this, the feedback is 4 as it directs the authors to a critical aspect of their results that needs attention. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a perceived weakness in the analysis, specifically regarding the theoretical work on sampling and particlebased optimization methods. It points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to strengthen their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more theoretical justification but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"SDE (2a)(2d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the analysis, such as the lack of evidence for the existence and smoothness of the solution and guarantees of discretization. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" in light of theoretical work on sampling and particlebased optimization methods. It specifically points out the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. While the comment highlights a potential issue, it does not provide detailed reasoning or references to support the claim. The lack of specific examples or detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis, noting that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It highlights the lack of evidence for the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization in time and space. This feedback is clear and actionable, as it directs the authors to address these theoretical gaps in their analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to strengthen the analysis or references to relevant literature. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the realism of the generated images or suggestions for further experimentation or analysis. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the image quality and realism but lacks grounding, as it does not provide a clear reference to the specific sections or figures being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the realism of the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it highlights a potential weakness in the paper, prompting the authors to consider improving the realism of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how to enhance the realism of the generated images. Without actionable advice or examples, the authors may find it challenging to address this issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take, including describing how G is built using the human skeleton, specifying the size and elements of G, and adding the dimensions of G, X, and W to better understand the DGCN. These instructions are clear and concrete, giving the authors a direct understanding of what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as describing how G is built using the human skeleton, specifying the size and elements of G, and adding the dimensions of G, X, and W. This level of detail helps the authors understand exactly what changes are needed to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual requests for clarification and additional information, such as asking for a description of how G is built using the human skeleton and suggesting the inclusion of dimensions for G, X, and W. These are not claims or opinions that require verification, but rather requests for clarification or additional details. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking for a detailed description of how G is built using the human skeleton in Section 3.3. It also suggests adding the dimensions of G, X, and W to better understand the DGCN. This feedback is clear and directs the authors to specific areas where additional information is needed to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the readability and understanding of their work. Therefore, the comment is rated as 4, as it offers constructive guidance for improvement but could be further enhanced by providing more detailed suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the statement in lines 559560, indicating that the claim made is not entirely true. It provides a clear and concrete suggestion by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This feedback is explicit and provides a direct action for the authors to take, which is to correct the statement in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that the claim made is not entirely true and providing an alternative explanation for the Cycle Consistency loss. This level of detail helps the authors understand what needs to be corrected in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific alternative explanation for the Cycle Consistency loss, suggesting that it can be iterated between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This explanation offers a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the statement in lines 559560, indicating that it is not entirely true. It provides a clear and actionable suggestion by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (ABA and BAB) using two separate standard backpropagation processes. This feedback is valuable as it corrects a potential misunderstanding and offers a concrete way for the authors to improve the accuracy of their draft. However, the comment could be more helpful if it provided additional context or examples to further clarify the concept. Overall, the comment is 4, as it provides clear and actionable feedback that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the term \"hyperspectral\" is confusing and provides a clear explanation of what hyperspectral imaging is. This feedback is direct and actionable, as it instructs the authors to avoid using the term \"hyperspectral\" and instead use the correct term \"hyperspectral imaging.\" The comment provides a concrete action for the authors to take, ensuring that the terminology in their draft is accurate and clear. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and providing a definition of hyperspectral imaging. This feedback is clear and actionable, guiding the authors on how to improve their terminology. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging as a technique that obtains the spectrum for each pixel in the image of a scene. This claim is supported by the explanation provided, which offers a clear and logical reasoning for why the term might be confusing. The comment does not require external references or additional evidence, as the explanation is sufficient to understand the issue. Therefore, the claim is considered 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, pointing out that \"hyperspectral\" is confusing and providing a clear explanation of what hyperspectral imaging is. This feedback is actionable and helpful as it guides the authors to use the correct term, ensuring clarity and accuracy in their draft. However, the comment could be more helpful if it suggested alternative ways to present the information or provided additional context on why the term is confusing. Overall, the comment is 4, as it directs the authors to a specific improvement that can enhance the clarity of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the concept of energy is introduced in Section 3.1, it would be beneficial to refresh the idea in Section 5.2, where it is used multiple times. The reviewer also suggests providing hints on how to interpret the concept, such as explaining that a high energy value indicates a split point for the morpheme. Additionally, the reviewer notes that the concept of peak in Figure 5 is not described. These suggestions are explicit and provide concrete guidance on how to improve the draft by clarifying the interpretation of energy and describing the peak concept. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also references \"Figure 5,\" providing clear grounding. The comment is specific because it details what needs to be addressed: refreshing the idea of energy in Section 5.2 and providing hints on its interpretation, as well as describing the concept of peak in Figure 5. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy should be refreshed in Section 5.2, where it is used multiple times, and provides a hint on how to interpret it. It also points out that the concept of peak in Figure 5 is not described. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to refresh the idea of energy and provide interpretation hints is 3, as it offers a logical direction for improvement. However, the lack of detailed examples or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it suggests refreshing the concept of energy in Section 5.2, where it is used multiple times, and provides a hint on how to interpret it, such as indicating that a high energy value might suggest splitting a morpheme at that point. Second, it points out that the concept of peak in Figure 5 is not described. These suggestions are clear and actionable, offering the authors concrete ways to enhance the clarity and comprehensibility of their work. By addressing these points, the authors can improve the coherence and readability of their draft. Therefore, the comment is rated as 4, as it provides valuable feedback that can significantly enhance the quality of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while some ablation studies are provided in Sections 3 and 4, the authors should further elaborate on how each component contributes to the final performance improvements. The comment explicitly states that the authors should provide more detailed information, such as how the performance of combining the Linformer and window attention in Big Bird contributes to the overall improvement. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections \"1), 2), and 3)\" and sections \"3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: a detailed explanation of how each component contributes to the final performance improvements. The comment provides a concrete example of what the authors should include, such as the performance of combining the Linformer and window attention in Big Bird. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while ablation studies are provided in Sections 3 and 4, the authors should further elaborate on how each component contributes to the final performance improvements. The comment provides a specific example of what could be included, such as the performance of combining the Linformer and window attention in Big Bird. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more examples or references to similar studies, which would further solidify the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for a more detailed explanation of how each component contributes to the final performance improvements. It suggests that while ablation studies are provided, the authors should elaborate on the specific contributions of each component, such as the performance of combining the Linformer and window attention in Big Bird. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, it could be more helpful if it included specific examples or suggestions on how to present this information. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detail in the paper regarding the models, specifically the grammar over kernels. It questions the explanation of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these gaps. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is 3, as it points out areas for improvement but does not fully direct the authors on how to implement those improvements.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the details of the models\" and \"grammar over kernels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: detailed explanations of how the approach is applied in practice, the probabilities associated with the grammar, and how inference is performed. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some details of the models are missing, specifically the explanation of grammar over kernels. It questions the understanding of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels. It highlights the need for a more detailed explanation of how this approach is applied in practice, including the probabilities associated with the grammar and how inference is performed. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar approaches that might be useful for comparison. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the role of visual information in the paper, specifically questioning the effectiveness of the ablation study in verifying the contribution of the knowledgegraph memory and visualdriven reasoning. It highlights that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it suggests that the improvements observed are unlikely to be significant given the sample size of 1000 users. While the comment identifies areas of concern and potential issues with the experiment results, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the role of visual information, provide more details on the ablation study, and consider the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the ablation study, particularly regarding the role of visual information, and highlights the similarity in performance between \"w/o perception module\" and \"w perception.\" Additionally, it points out the lack of implementation details for \"w/o perception\" and questions the significance of the results given the sample size. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown and questions the effectiveness of the ablation study. It provides specific details, such as the similarity in performance between \"w/o perception module\" and \"w perception\" in Table 10, and notes the lack of implementation details for \"w/o perception.\" Additionally, it points out that the sample size of 1000 users makes significant improvements unlikely. While the comment raises valid concerns, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to provide additional evidence or clarification to fully address the concerns. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically questioning the role of visual information and the effectiveness of the ablation study. It points out that the performance of \"w/o perception module\" and \"w perception\" is similar, and the implementation details of \"w/o perception\" are unknown. Additionally, it raises concerns about the significance of the results given the sample size of 1000 users. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed information and justification for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending additional experiments or analyses. Overall, the comment is 4, as it provides valuable insights for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This feedback is explicit in its request for the authors to include these references and comparisons, providing a clear action for the authors to take. The comment is also concrete, as it specifies the exact references that should be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of citation or comparison with previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper fails to cite or compare with previous works on Lasso screening, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" This claim is supported by the explicit mention of a specific reference, which provides a clear basis for the critique. The inclusion of the reference allows the authors to understand the gap in their work and take appropriate action to address it. Therefore, the comment is considered 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 claims Transfer Lasso shows the best accuracy in feature screening but fails to cite or compare with previous works on Lasso screening. It provides a specific reference to Ren et al. \"Safe feature screening for generalized LASSO,\" which the authors should include to support their claims. This feedback is clear and actionable, as it directs the authors to address a gap in their literature review and enhance the credibility of their findings. By suggesting the inclusion of relevant references, the comment empowers the authors to improve the comprehensiveness and validity of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that the authors may need to trace them in the source code. While the comment implies that the authors should provide more detailed information about these hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more details about the hyperparameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of missing hyperparameters for many components, suggesting that the authors should provide these details to ensure transparency. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters not fully provided, suggesting that the authors should include these details. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand which components are missing information. The lack of detailed evidence or examples renders the claim 3, as the authors would need to investigate further to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This is a critical piece of information that could impact the reproducibility and transparency of the work. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue, such as recommending specific hyperparameters to include or methods for documenting them. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the notation for results, specifically questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting alternative notation or clarifying the meaning of \"%p.\" The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the notation for results, specifically questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. However, it does not specify which part of the paper this notation is used in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with the notation, but without clear grounding, it is challenging for the authors to know where to make the necessary adjustments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation for results is unclear, specifically questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation for results, questioning the meaning of \"%p\" in the context of the claimed improvement for CIFAR10. This feedback is clear and actionable, as it directs the authors to clarify the notation used in their results section. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the notation or offered examples of alternative ways to present the results. Despite this, the comment still provides valuable guidance that can help the authors improve the clarity and readability of their paper. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should include qualitative results, specifically with a zoomedin view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these suggestions, such as which specific cases to focus on or how to analyze the limitations. The action is explicit but somewhat vague, as the authors know they need to include qualitative results and failure cases but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests showing qualitative results, particularly with a zoomedin view, for cases where previous methods failed but were successful with the proposed method. It also recommends including failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these suggestions should be applied to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but without explicit references, it is challenging to pinpoint the exact parts. The comment is specific in detailing what needs to be addressed, such as showing qualitative results and analyzing limitations. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that qualitative results, particularly with a zoomedin view, should be included for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not provide specific examples or detailed reasoning to support why these suggestions are necessary or how they would enhance the paper. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these suggestions based on the context of their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors include qualitative results, specifically with a zoomedin view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations of the proposed method. This feedback is clear and actionable, as it provides specific guidance on how to enhance the paper by adding qualitative results and failure cases. By following this advice, the authors can better demonstrate the effectiveness and limitations of their method, which can significantly improve the comprehensiveness and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text, rather than human reading comprehension. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on what needs to be changed, making it concrete and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should be clarified to distinguish between machine comprehension of text and human reading comprehension. The comment provides a clear direction for improvement by suggesting how to clarify the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text, rather than human reading comprehension. The reviewer provides a logical explanation by pointing out the common usage of \"reading comprehension\" and \"readability,\" which typically refer to human reading abilities. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened with specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title of the paper, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This is a clear and actionable suggestion that could help the authors improve the clarity and precision of their title. By making this distinction, the authors can ensure that their work is accurately represented and understood by the audience. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the paper\"s content or structure. Overall, the comment is 4 as it offers a specific and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific claim made by the authors on line 238 regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. However, it does not provide any guidance or suggestions on how the authors should address these inaccuracies or improve their understanding of the CLT. The comment lacks explicit or implicit actions, leaving the authors without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made about the Central Limit Theorem (CLT), pointing out that it makes multiple incorrect assertions. The comment provides a detailed explanation of the inaccuracies, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Central Limit Theorem (CLT) is incorrect. It provides a clear explanation of why the statement is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and wellsupported, making the claim 5. The reviewer provides specific details to substantiate the claim, ensuring that the authors can understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out that it contains multiple incorrect assertions. It provides a clear explanation of why the claim is incorrect, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is 5 as it directly addresses a critical error in the paper, allowing the authors to correct their understanding and presentation of the CLT. However, the comment could be more helpful if it offered suggestions on how to correct the statement or provided additional context for the authors to better understand the issue. Nonetheless, the comment is 5 and provides significant value to the authors, making it a 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. The authors know exactly what action to take and how to implement it, as the comment specifies the section of the paper that requires analysis. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the need to analyze the time complexity of the proposed policies, providing clear guidance on what needs to be addressed. This makes the comment 5, as it clearly directs the authors to a specific section and outlines the action required. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for analysis, which is not a claim but rather a suggestion for improvement. It does not express an opinion, judgment, or deduction that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly instructs the authors to analyze the time complexity of the proposed policies mentioned in Section 4. This feedback is valuable because it identifies a specific area where the paper could be improved, providing a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what aspects of time complexity should be considered. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should switch to a human metric, but it lacks concrete details on which human metric to use or how to implement the change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"human evaluation\" and \"TSS,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using an automatic metric (TSS) instead of a human metric for evaluating style control, which weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. The comment provides a logical reasoning by pointing out that using an automatic metric may weaken the convincingness of the human evaluation. However, it lacks specific examples or references to support why a human metric is more appropriate or how it would improve the evaluation. This makes the claim 3, as the authors would need to consider the reasoning and potentially conduct further research to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. This feedback is clear and actionable, as it identifies a potential weakness in the evaluation methodology and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on why a human metric is preferred or how to implement it effectively. Despite this, the feedback is 4 as it directs the authors to reconsider their evaluation approach, which could enhance the credibility and robustness of their findings. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including experiments across more diverse domains would strengthen the paper. While it implies an action for the authors to take, it does not provide specific guidance on which domains to consider or how to conduct these experiments. The suggestion is explicit but lacks concrete details, making it 3. The authors know they need to expand their experiments but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment suggests that the experiments are effective in proving the authors\" point but implies that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper the current experiments are in or which domains are being referred to. The authors can infer that the comment relates to the experimental section, but the lack of explicit references or detailed guidance makes it weakly grounded. The comment is specific in suggesting the inclusion of more diverse domains, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments effectively prove the authors\" point but suggests that including experiments across more diverse domains would strengthen the paper. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that other domains would provide additional insights. Without detailed justification or evidence, the claim remains 3, as the authors would need to infer the potential benefits of expanded experimentation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the experiments effectively support the authors\" claims but suggests that including experiments across more diverse domains would strengthen the paper. This feedback is 3 as it identifies a potential area for expansion and improvement, which could enhance the paper\"s impact and relevance. However, the comment lacks specific guidance on which domains to consider or how to conduct these additional experiments, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as [1] DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for results and the limited evaluation on only two datasets, which are standard in the RNP community. It provides specific references to external works, such as [1] DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing, such as confidence intervals and additional datasets. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment supports its claim by referencing external works, such as [1] DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. These references provide a basis for the claim that the evaluation could be more comprehensive. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of confidence intervals affects the interpretation of results. Overall, the claim is 4, as it provides some support but could be further substantiated with more detailed analysis or examples.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as [1] DiversitySensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pretrained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. This feedback is 4 as it highlights critical areas for improvement and provides references that could guide the authors in enhancing their evaluation and analysis. However, it could be more helpful if it offered specific suggestions on how to incorporate confidence intervals or expand the evaluation to more datasets. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, namely that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as whether the authors should include specific metrics or analyses to evaluate the interpretability tax or how they might approach this evaluation. Without concrete steps or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or analysis. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it does not provide detailed guidance on how to evaluate the interpretability tax. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant observation that could help the authors enhance their work by including such an evaluation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might approach this evaluation or what metrics or analyses could be used. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the design of the Logarithmic Unbiased Quantizer (LUQ) is straightforward once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper lies in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the paper or address the feedback, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the design of the Logarithmic Unbiased Quantizer (LUQ) and the approaches in Section 5. It suggests that the main contribution lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve good accuracy. However, the comment does not specify which part of the paper discusses the design of the LUQ or the approaches in Section 5, making it weakly grounded. The comment is specific in identifying the main contribution as the demonstration of the effectiveness of existing techniques, but it lacks detailed guidance on how to improve the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper lies in demonstrating that a simple combination of existing techniques is sufficient to achieve surprisingly good accuracy. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or comparisons to previous work, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a critique of the paper\"s contribution, suggesting that the main contribution lies in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. While this feedback highlights a potential limitation of the paper, it does not offer actionable suggestions or guidance on how the authors might enhance their contribution or address this critique. The comment lacks depth and does not provide specific advice for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this training process is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the training losses should be included or how they would address the question of stability. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the stability of the training process is a concern or why training losses are necessary. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While it identifies a potential area of concern, it lacks depth and does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the training process should be evaluated. The comment is 3 as it prompts the authors to consider the stability of their training process, but it does not offer actionable advice or detailed feedback to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for overclaiming the strength of the proposed BC loss in theoretical analysis. It identifies specific aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, which are claimed to be distinct but are actually the same concept from different viewpoints. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the claims. The action is implicit and vague, as the authors are left to infer that they need to revise their claims but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the paper\"s claims, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in theoretical analysis. It supports this claim by explaining that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This logical reasoning provides a clear explanation of why the claim is valid, making the comment 4. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that it overclaims the strength of the proposed BC loss in theoretical analysis. It points out that several aspects, such as geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability, are actually the same concept viewed from different perspectives. This feedback is clear and actionable, as it prompts the authors to revisit and clarify their claims to ensure accuracy and avoid overstatement. However, the comment could be more helpful if it provided suggestions on how to rephrase or reorganize the theoretical analysis to better reflect the actual contributions. Overall, the comment is 4, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract section\" and the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the proposed method to the authors\" motivations and suggesting that it may not be effective for evaluating a single dialogue system. The comment provides a clear critique of the proposed framework and its limitations, making it specific. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer provides a logical reasoning by pointing out that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are used for comparing dialogue systems, not for evaluating a single system. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical argument but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. It suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. This feedback is 3 as it identifies a potential limitation of the proposed method and encourages the authors to consider this aspect in their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the evaluation framework. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should investigate the impact of this sampling rate on the comparison with other methods, but the comment lacks concrete details on how to proceed. Therefore, the comment is 3, as it identifies a potential issue but does not provide clear instructions on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a logical reasoning by explaining the potential impact of this sampling rate on the comparison. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to investigate this claim further to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. This observation is relevant and could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure fairness in their comparisons. While it highlights a critical point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The comment implies that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative methods they could consider. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It suggests that the authors may have chosen focal loss solely for its unified form without considering the differences between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or where this issue is addressed. The authors can make an educated guess that it relates to the methodology or experimental setup sections, but the comment lacks full grounding. It is specific in detailing the potential issue with using focal loss for regression tasks, but without explicit references to the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks, suggesting that it may not be suitable for regressing the IoU due to its properties. The reviewer provides a logical explanation of why focal loss might be problematic in this context, noting that it has lower gradients on easy samples, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of focal loss in regression tasks, specifically in the context of regressing the IoU. It points out that focal loss is typically used to address class imbalance problems in classification tasks, but its properties may not be suitable for regression tasks. The comment suggests that the authors may have chosen focal loss solely for its unified form without fully considering the differences between classification and regression tasks. This feedback is 3 as it identifies a potential issue with the methodology and encourages the authors to reconsider their approach. However, it lacks specific suggestions or examples of alternative methods that could be used, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable steps or suggestions, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be considered or how the authors might address this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practical applicability and robustness of their approach. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what aspects of scalability they should focus on. Without actionable feedback or detailed advice, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the improvements of the proposed model over the RL without feedback model, noting that the differences are not significant, particularly for BLEU1. The reviewer suggests that the authors verify if these improvements are statistically significant. While the comment implies that the authors should conduct a statistical analysis to address this concern, it does not provide explicit instructions on how to perform the analysis or what specific tests to use. The action is implicit and somewhat vague, as the authors need to infer the need for a statistical test and figure out how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the improvements not being significant, particularly for BLEU1, and requests verification of statistical significance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. The reviewer provides specific references to rows 3 and 4 in Table 6, which allows the authors to verify the claim by examining the data. However, the comment lacks detailed reasoning or examples to fully substantiate the claim of statistical insignificance. While the reference to specific rows in the table provides some basis for the claim, the lack of additional evidence or analysis makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the improvements of the proposed model over the RL without feedback model are not significant, particularly for BLEU1. It suggests that the authors verify if these improvements are statistically significant, which is a clear and actionable piece of feedback. By pointing out this potential issue, the comment helps the authors to focus on a critical aspect of their work that may impact its validity and conclusions. However, the comment could be more helpful if it provided additional guidance on how to conduct the statistical analysis or what specific tests to use. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration, asking for minimal assumptions that could be made or what would happen if they are partially covered. While the comment implies that the authors should consider these aspects, it does not provide explicit guidance or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore these ideas further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is a continuation of a previous remark and does not explicitly mention a specific part of the paper, making it weakly grounded. However, it does provide a clear and specific question about relaxing the need to visit all ballaction pairs with each iteration, suggesting minimal assumptions that could be made or exploring the consequences of partially covering them. This level of specificity helps the authors understand what needs to be addressed, even if they cannot pinpoint the exact section being referred to. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking suggestions or ideas for improvement, rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration, seeking suggestions on minimal assumptions that could be made or exploring the consequences of partially covering them. While it does not provide specific guidance or suggestions for improvement, it encourages the authors to think critically about their approach and consider potential optimizations. This feedback is 3 as it prompts the authors to explore alternative strategies, but it lacks depth and actionable advice, making it incomplete for fully addressing the authors\" needs. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. This is an explicit suggestion, as it clearly indicates a potential improvement and provides a specific example of what could be used. However, the comment does not provide detailed guidance on how to implement this change or why RoBERTabase might be a better choice. While the action is explicit, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests an improvement by proposing the use of a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in suggesting a potential improvement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that an improvement could be observed by using a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. However, the comment lacks specific reasoning or evidence to support why RoBERTabase would be a better choice or how it would lead to an improvement. Without detailed justification or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that using a better encoder, such as RoBERTabase, could lead to an improvement in the results. This is a specific and actionable suggestion that could help the authors enhance their work. However, the comment lacks detailed reasoning or examples to support why RoBERTabase might be a better choice or how it could impact the results. Providing more context or explanation would make the feedback more comprehensive and helpful. Therefore, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This is an explicit action that provides a clear direction for the authors to follow. However, the comment lacks specific guidance on which datasets to use or how to integrate them into the study. While the action is explicit, the lack of concrete details makes it 3. The authors know they need to include more datasets but may not be entirely sure of the exact steps to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion should be implemented in, such as the methodology or results sections. The authors can infer that it relates to the evaluation or experimental setup, but this inference is not direct. The comment is specific in suggesting the inclusion of additional datasets, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any reasoning or evidence to support why these specific datasets are necessary or how they would enhance the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a potential area for improvement in the evaluation of the proposed method. However, the comment lacks specificity and does not provide detailed guidance on which datasets to use or how to integrate them into the study. It also does not explain why these specific datasets are important or how they would enhance the evaluation. While the suggestion is clear, it could be more actionable and helpful with additional context or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improving the choice of baseline methods, specifically recommending the inclusion of RefNeRF and MipNerF as baselines for evaluating appearance decomposition and larger outdoor scenes, respectively. This feedback is explicit and provides concrete suggestions on which methods to consider, giving the authors a clear direction on how to enhance their draft. The action is direct and specific, making it 5.", "grounding_specificity_rationale": "The comment suggests improving the choice of baseline methods, specifically recommending RefNeRF and MipNerF for evaluating appearance decomposition and larger outdoor scenes, respectively. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where baseline methods are discussed. The comment is specific in suggesting alternative baseline methods, providing clear guidance on how to enhance the evaluation. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing to other existing methods, specifically mentioning RefNeRF and MipNerF as examples. This claim is 3 as it provides specific examples of methods that could be used as baselines, offering a clear direction for improvement. However, the comment lacks detailed reasoning or references to support why these methods are particularly relevant or how they would enhance the evaluation. Therefore, the claim is categorized as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting improvements to the choice of baseline methods for evaluating appearance decomposition and larger outdoor scenes. It recommends using RefNeRF and MipNerF as baselines, which gives the authors clear guidance on how to enhance their evaluation. This feedback is detailed and constructive, empowering the authors to make informed decisions about their methodology. However, the comment could be more helpful if it included additional context or explanation for why these specific baselines are relevant or how they would improve the evaluation. Overall, the comment is 4, as it provides valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. While the comment implies that the authors should provide a demonstration or example of this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how to achieve this demonstration or what specific aspects of the method should be highlighted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this demonstration is necessary or how it would be beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. This is a clear and actionable suggestion that could help the authors improve their draft by providing a more comprehensive evaluation of their method. However, the comment could be more helpful if it offered specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should have been included in Section 4.1. This provides a clear and direct action for the authors to take, which is to add the missing implementation details to the specified section. The feedback is concrete, as it specifies exactly where the authors should make the additions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking implementation details of the proposed methods, which should be described in the implementation details section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why these details are crucial. The comment lacks evidence or justification, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods. It suggests that these details should have been included in Section 4.1, providing a clear and actionable piece of feedback. By pointing out this omission, the comment helps the authors to focus on a critical aspect of their work that needs improvement. However, the comment could be more helpful if it offered suggestions on how to present these implementation details or provided examples of what should be included. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant lack of empirical evaluation and comparison with other methods, which makes it difficult to assess the practical value of the contribution. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment identifies a critical issue with the paper, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to conduct empirical evaluations, comparisons with other methods, and provide theoretical arguments for the significance of their contribution. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it 3. The authors know they need to address the lack of empirical evaluation and theoretical justification but may struggle with the specifics of how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to identify the specific parts of the paper that need attention. It also specifies the issues, such as the absence of practical value and the need for theoretical arguments, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment highlights significant gaps in the paper, it does not provide specific examples or references to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It highlights that the absence of such evaluations makes it difficult to assess the practical value of the contribution. The comment also points out the need for theoretical arguments to justify the significance of the contribution. While the feedback is clear about the weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment is 3 as it directs the authors\" attention to important areas for improvement but lacks actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential source of confusion in the manuscript, where the symbol \"P\" is used to represent both a probability and a cumulative distribution function. However, it does not provide explicit guidance on how to resolve this issue or suggest specific actions for the authors to take. The comment implies that the authors should clarify the usage of \"P\" to avoid confusion, but it lacks concrete details on how to achieve this clarification. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line number (L44) in the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the confusion caused by the use of \"P\" to represent both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed to resolve the confusion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the symbol \"P\" is used inconsistently in the manuscript, sometimes representing a probability and other times a cumulative distribution function. The reviewer provides specific examples by referencing equations (3) and (4) and line 44 in the appendix, which supports the claim. This level of detail provides a clear basis for the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by explaining why this inconsistency is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the inconsistent use of the symbol \"P\" to represent both a probability and a cumulative distribution function. It provides examples from the paper, such as Eqs. (3) and (4) and L44 in the appendix, which helps the authors pinpoint the exact locations of the confusion. This feedback is clear and actionable, as it directs the authors to clarify the usage of \"P\" to avoid confusion. However, the comment could be more helpful if it suggested specific ways to resolve the issue, such as recommending a consistent notation or providing examples of how to clarify the distinction between probability and cumulative distribution functions. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and consistency of their manuscript."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the use of artificial patterns in analysis and ablation studies, suggesting that these may not accurately represent natural spurious correlations. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes they should make to their study. The comment implies that the authors should consider using natural spurious correlations, but it does not offer concrete steps or examples on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of artificial patterns in analysis and ablation studies, suggesting that these may not accurately represent natural spurious correlations. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in detailing the concern about the use of artificial patterns versus natural spurious correlations, but without clear references to specific parts of the paper, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the community lacks understanding of how neural nets learn natural rare spurious correlations and suggests that most analyses and ablation studies use artificial patterns instead. The comment provides a logical reasoning by highlighting the difference between artificial and natural spurious features, noting that the latter are complex and varied. However, the claim is 3 as it lacks specific examples or references to support the assertion about the community\"s understanding or the prevalence of artificial patterns in studies. Providing more detailed evidence or references would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a significant concern regarding the use of artificial patterns in analysis and ablation studies, suggesting that these may not accurately represent natural spurious correlations. It points out that duplicating artificial patterns is different from dealing with complex and varied natural spurious features. This feedback is valuable as it prompts the authors to consider the relevance and applicability of their methods to realworld scenarios. However, the comment could be more helpful if it provided specific suggestions on how to incorporate natural spurious correlations into the study or offered examples of how to address this issue. Despite this, the comment provides a clear direction for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~[1] and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this limitation or explore new applications. The action is implicit and somewhat vague, as it lacks concrete steps or detailed advice on how to implement the suggested exploration. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in applying the method to general MDPs, specifically mentioning navigation problems. It also references PRMRL~[1] as a related work that has already discussed combining RL and planning. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the limitation and suggesting further exploration of the method in more general tasks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper is limited to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL~[1]. The comment provides a reference to a specific work, PRMRL, which supports the claim that the idea of combining RL and planning is not novel. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the paper\"s limitations. While the reference to PRMRL provides some basis for the claim, the comment could be strengthened with more specific comparisons or examples. Therefore, the claim is 4, as it provides some support but could be further substantiated.", "helpfulness_rationale": "The review comment identifies a limitation of the paper, noting that the method discussed is primarily applicable to navigation problems and suggests that it could be more broadly applicable. It also references a related work, PRMRL, which has already discussed combining RL and planning. This feedback is 3 as it points out a potential area for expansion and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might apply the method to more general tasks or discussed potential challenges or benefits of doing so. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the suitability of feature spaces for 1NN (1nearest neighbor) classification. It suggests that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment also provides a potential solution by recommending the standardization of feature dimensions to avoid this issue. While the comment identifies a specific concern and offers a potential solution, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of feature space suitability and consider standardizing feature dimensions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces being wellsuited for 1NN and provides a potential solution by suggesting that standardizing feature dimensions could avoid performance issues. The comment details what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the suitability of feature spaces for 1NN classification, suggesting that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions could avoid this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the suitability of feature spaces for 1NN classification. It raises a potential issue with feature spaces that are not close to a spherical Gaussian, suggesting that this could lead to poor performance. The comment provides a constructive suggestion by recommending the standardization of feature dimensions as a potential solution to avoid this issue. This feedback is clear and actionable, offering the authors a specific direction for improving their work. However, it could be more helpful if it included additional context or examples to further illustrate the potential impact of this issue. Overall, the comment is 4 as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a critical concept in the paper. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap. While the action is implicit, it is concrete in suggesting that the authors need to define the concept more formally. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific concept in the paper. It also provides a clear indication of what is missing, namely a formal definition for the contrastive gap. The comment suggests that while an intuitive example is given, it is less convincing, and a clear definition is still lacking. This provides specific guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" is a critical concept in the paper but has not been defined clearly. It acknowledges that an intuitive example is provided but questions the setting of this example. The comment suggests that a clear, formal definition for the contrastive gap is lacking. While the reviewer provides some context and identifies the issue, the claim lacks specific examples or references to support the assertion that the definition is unclear or inadequate. This makes the claim 3, as it provides a general critique but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the work. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment highlights the need for a clear, formal definition of the contrastive gap, which is essential for understanding and evaluating the work. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered suggestions on how to define the contrastive gap or provided examples of how to clarify the concept. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues in the paper, namely the description of state changes and rewards in standard MDP formulations and the clarity of the description of actions as single features or the power set. The reviewer suggests making the description more clear, which is an explicit action. However, the comment does not provide detailed guidance on how to achieve this clarity, such as suggesting specific wording or examples. While the action is explicit, the lack of concrete details makes it 3. The authors know they need to clarify the description, but they may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the description of state changes and rewards in standard MDP formulations and the clarity of the description of actions. The comment provides clear guidance on how to improve the clarity of the description, suggesting that the authors make it more clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not true of standard MDP formulations. It suggests that the description implies rewards are given after each action, which is not accurate. The reviewer also points out a lack of clarity regarding whether each action is a single feature or the power set. While the comment identifies potential issues, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors may need to infer the exact nature of the problem and how to address it, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, namely the misrepresentation of standard MDP formulations and the lack of clarity in describing actions as single features or the power set. It provides explicit guidance by suggesting that the authors make the description more clear, which is a concrete and actionable suggestion. However, the comment could be more helpful if it offered additional details or examples on how to clarify these points. Overall, the feedback is 4 as it directs the authors to improve the clarity and accuracy of their description, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including other baselines, such as those discussed in the related work section, and recommends adding an explanation for why the chosen baseline is the most appropriate. The comment also includes a question about testing whether a specific condition can be met. While the suggestion to include additional baselines is explicit, the comment lacks concrete guidance on which specific baselines to include or how to implement the suggested testing. The question about testing a condition adds an element of vagueness, as it does not provide clear instructions on how to address it. Overall, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the inclusion of other baselines, such as those discussed in the related work section, and references specific works ([29, 5, 6]). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests including these additional baselines and provides a rationale for why the chosen baseline is the most appropriate. Additionally, it mentions that the authors have addressed the reviewer\"s previous concerns and questions, which further specifies the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including other baselines, such as those discussed in the related work section, and recommends adding an explanation for why the chosen baseline is the most appropriate. The reviewer also mentions that their previous concerns have been addressed and that the authors have provided explanations for their choices. However, the comment does not provide specific examples or detailed reasoning to support the claim that other baselines should be included. The suggestion is 3 as it highlights a potential area for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in the related work section, would enhance the paper. It also acknowledges that the authors have addressed previous concerns and questions, indicating a positive response to the authors\" efforts. However, the comment could be more helpful by providing specific examples of the additional baselines that should be included or offering guidance on how to integrate them effectively. Additionally, the mention of a question about testing a condition adds a vague element to the feedback. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance or specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. It suggests that this phrase is difficult to understand. However, the comment does not provide any guidance on how to address this issue or suggest alternative phrasing. The action is implicit, as the authors need to infer that they should clarify or rephrase the sentence to improve understanding. The feedback lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"to meet\" and its difficulty in understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the phrase \"to meet\" is difficult to understand, specifically mentioning \"a response candidate can meet each utterance\" on line 280. However, the comment does not provide any further explanation or justification for why this phrase is problematic or how it could be improved. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, which is described as difficult to understand. However, it does not provide any suggestions or guidance on how to improve the clarity of this phrase or where it might be causing confusion. Without actionable feedback or examples of alternative phrasing, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text and the notation used in Figure 1, specifically noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This comment explicitly identifies the inconsistency and suggests that the authors should ensure consistency in their notation across the paper. However, it does not provide specific guidance on how to resolve this issue, such as suggesting which notation should be used consistently or how to address the discrepancy. The action is explicit but somewhat vague, as the authors know what needs to be corrected but may not be entirely sure of the best approach to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in notation, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This provides clear guidance on what needs to be addressed, ensuring that the authors know exactly what part of the paper requires revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point points out a discrepancy in notation between the text and Figure 1, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This observation is factual and does not express an opinion or suggestion, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency in notation between the text and Figure 1, noting that \"L_task\" is used in the text but \"L_class\" is used in Figure 1. This feedback is clear and actionable, as it directly points out a potential source of confusion for readers. By addressing this inconsistency, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it suggested which notation should be used consistently or provided guidance on how to resolve the discrepancy. Despite this, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about other limitations beyond the shallow network in the graph case. While it implies that the authors should consider and address these limitations, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore and discuss additional limitations. However, the comment does not specify which limitations to focus on or how to address them, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking if the network is shallow in the graph case and if this is also the case here. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations and the depth of the network, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking about other limitations of the method and inquiring about the depth of the network in the graph case. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking if the network is shallow in the graph case and if this is also the case here. While it identifies a potential area for improvement by questioning the depth of the network, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or explore other limitations. The comment is 3 as it prompts the authors to consider these aspects, but it does not offer detailed suggestions or insights to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the work would be more convincing if it were evaluated in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word compared to \"open domain\" generation tasks like answer generation and summarization. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their evaluation to include machine translation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation tasks or where the authors should include the additional evaluation in machine translation. While the authors can infer that the comment relates to the evaluation section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting an additional evaluation task, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work would be more convincing if it were evaluated in machine translation, which is considered a \"close domain\" generation task with lower uncertainties per word. The reviewer provides a logical reasoning by contrasting the tasks used in the evaluation (answer generation and summarization) with machine translation, suggesting that the latter would provide a more convincing evaluation. However, the comment lacks specific examples or references to support the claim about the differences in uncertainties between these tasks. This makes the claim 3, as it provides a logical basis but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"open domain\" generation tasks. The reviewer suggests that the work would be more convincing if it were also evaluated in machine translation, a \"close domain\" generation task with lower uncertainties per word. This feedback is 3 as it points out a potential gap in the evaluation and suggests a specific area for improvement. However, the comment could be more helpful if it provided additional guidance on how to incorporate machine translation into the evaluation or why this would strengthen the paper. Overall, the comment offers a clear direction for enhancing the evaluation but lacks detailed suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these questions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the dropping rate and the number of masks generated. This provides clear guidance on what the authors need to address in their response. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout process, specifically regarding the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While it identifies areas that need further explanation, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their understanding of the dropout process. The feedback is 3 as it points out a gap in the explanation, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors need to provide further justification for the effectiveness of their proposed twostage optimization approach. It specifies that showing performance drops on fusion models is insufficient and recommends comparisons with other singlestage attacks to demonstrate effectiveness. Additionally, it emphasizes the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the effectiveness of the proposed twostage optimization approach, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what is missing, namely further justification of the approach, comparisons with other singlestage attacks, and proper benchmarks against stateoftheart algorithms. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing performance drops on fusion models is insufficient and recommends comparisons with other singlestage attacks to demonstrate effectiveness. The comment also emphasizes the importance of proper benchmarks and comparisons with other stateoftheart algorithms. While the comment provides a logical reasoning for the need for additional justification and comparisons, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to provide more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed twostage optimization approach. It points out that showing performance drops on fusion models alone is insufficient and suggests that comparisons with other singlestage attacks are necessary to demonstrate the approach\"s effectiveness. Additionally, the comment emphasizes the importance of proper benchmarks and comparisons with stateoftheart algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific guidance on how to strengthen their argument and improve the paper. However, it could be more helpful if it offered examples or suggestions on how to conduct these comparisons. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper lacks information about the type of GPUs used and the inference time during testing. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the authors should include this information in the paper, how to report it, or what specific details are needed. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the lack of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information should be included in, such as the methodology or results sections. Without explicit references to sections or specific details, the authors may find it challenging to identify where this information should be added. Therefore, the comment is weakly grounded as it does not clearly indicate the part of the paper being addressed, but it is specific in identifying the missing information. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks information about the type of GPUs used and the inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this omission or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a relevant point that could impact the reproducibility and comprehensiveness of the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific sections where this information should be included or suggesting methods for reporting inference times. Without actionable feedback, the authors are left with a general understanding of what is missing but without a clear path to improvement. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback provides a clear and direct action for the authors to take, ensuring that the Perceptual Metric is accurately represented. The comment is explicit and concrete, leaving no ambiguity about what needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the Perceptual Metric in Figure 2, suggesting a correction in how the images are connected. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for improving their draft. By addressing this issue, the authors can enhance the accuracy and clarity of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific sentence (9395) that is confusing and suggests that the authors should clarify it to improve the readability of their draft. However, it does not provide explicit guidance on how to clarify the sentence or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make the sentence clearer but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific sentence numbers (9395) that are confusing, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by explaining that the sentence is not immediately clear and provides a personal experience of rereading it to understand. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the authors should clarify it. However, the comment does not provide any reasoning or evidence to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific sentence (9395) that is confusing and suggests that the authors should clarify it. The reviewer provides a personal experience of rereading the sentence to understand it, which indicates that the issue is not immediately clear. This feedback is 3 as it points out a potential area for improvement in the draft, but it lacks specific suggestions or guidance on how to clarify the sentence. While it directs the authors to a specific part of the paper that needs attention, it could be more helpful with additional details or examples on how to improve the clarity. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, specifically requesting citations for certain statements in the paper. This feedback is clear and direct, leaving no ambiguity about what needs to be done. The authors are explicitly instructed to add citations for specific lines, which provides concrete guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (7879, 129130, 156158, and 217218) where citations are needed. This allows the authors to accurately identify the parts of the paper that require attention. The comment is also specific because it clearly specifies what is missing\u2014citations for certain claims and statements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting citations for specific claims made in the paper. It does not contain subjective opinions, suggestions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas in the paper where citations are needed to support claims made. It points out the lack of citations for statements about diffusion models outperforming generative adversarial networks, previous work on tackling certain issues, and the efficiency of diffusion models. By highlighting these gaps, the comment provides clear and actionable feedback that can help the authors improve the credibility and robustness of their arguments. However, the comment could be more helpful if it offered suggestions on how to integrate these citations or provided additional context for the claims. Overall, the feedback is valuable but could be more comprehensive, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, whereas Figure 1 depicts a single shared encoderdecoder for multiple tasks. This comment explicitly points out the inconsistency between the two figures, indicating that the authors should reconcile this discrepancy. However, it does not provide specific guidance on how to address the issue or suggest a way to resolve the inconsistency. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency between the two figures regarding the representation of encoderdecoders for auxiliary tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is inconsistent with Figure 2 regarding the representation of encoderdecoders for auxiliary tasks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed explanation or examples to help the authors understand the nature of the inconsistency or how it affects the paper. As a result, the claim is 1, making it difficult for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, whereas Figure 1 depicts a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it highlights a critical discrepancy that needs to be addressed to ensure the accuracy and consistency of the paper. However, the comment could be more helpful if it provided suggestions on how to reconcile this inconsistency or offered guidance on which figure is correct. Despite this, the comment is 4 as it directs the authors to a specific area needing clarification and correction."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or clarify the issue in their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether each node can attend to its own lowerlevel representation, referencing equation 2 and the description of N_l^(s). While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the equations or descriptions provided in the paper. However, the comment lacks specificity as it does not clearly specify what needs to be addressed or how the issue should be resolved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. While it identifies a potential issue with the interpretation of the model, it does not provide any specific guidance or suggestions on how the authors might address this question or clarify the issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It suggests that while the inequality seems to be a combination of previous inequalities, the authors should facilitate the reader\"s understanding by explicitly stating how Lemma 7 is applied. This feedback provides a clear and direct action for the authors to take, which is to add a clarification on the connection between the inequality and Lemma 7. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ineq. after l433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should clarify how the inequality follows from Lemma 7. The comment provides a clear request for additional explanation to facilitate the reader\"s understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logical connection between the inequality after line 433 and Lemma 7, suggesting that it might be inferred from a combination of previous inequalities. However, the comment does not provide specific examples or detailed reasoning to support this claim, leaving the authors without clear guidance on how to address the issue. The lack of explicit evidence or detailed explanation makes the claim 3, as the authors would need to infer the connection themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the logical connection between an inequality and Lemma 7. It points out that while the inequality seems to follow from a combination of previous inequalities, the authors should clarify how Lemma 7 is applied to facilitate the reader\"s understanding. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between the inequality and the lemma. By addressing this point, the authors can improve the clarity and coherence of their paper, making the comment 4. However, it could be more helpful if it provided additional guidance on how to present this explanation. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic largescale multitasking and achieves automation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback is implicit, as it points out areas that need improvement but does not specify what changes should be made. Additionally, the actions are vague, as the authors are left to infer what specific steps to take to clarify the main contribution and address the concerns. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically questioning the clarity of the proposed method\"s novel properties and its applicability. It also raises concerns about the lack of clarity regarding how the method copes with dynamic largescale multitasking and the achievement of automation. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding. It is specific in detailing the issues with the main contribution and the lack of clarity in certain aspects, but without explicit references to sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s novel properties are either overstated or not wellsupported. It also questions the clarity of how the method copes with dynamic largescale multitasking and achieves automation. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to substantiate the claims. The lack of concrete evidence or references makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic largescale multitasking and achieves automation. These are important areas that need to be addressed to improve the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the main contribution, address the overstated claims, or enhance the explanation of the method\"s capabilities. While it highlights key weaknesses, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to address them."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests two actions: first, to include the bottomup method [9] in the tables, and second, to evaluate the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. Both suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. The first suggestion is concrete, as it specifies the inclusion of a particular method in the tables, and the second is also concrete, as it outlines a specific evaluation to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"the bottomup method [9],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely including the bottomup method in the tables and evaluating the performance on the standard MS coco dataset. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method [9] has reported results on the crowdpose dataset that outperform all methods in Table 4, even when using a ResNet50. It recommends including this method in the tables and evaluating the performance on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. The claim is 3 as it provides a specific reference to the bottomup method [9] and suggests a comparison with the paper\"s results. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of the bottomup method [9] in the tables, as it has reported results outperforming all methods in Table 4, even with a ResNet50. This recommendation is clear and concrete, offering a direct path for the authors to enhance their draft. Additionally, the comment suggests evaluating the performance of the method on the standard MS coco dataset to assess any potential drop in performance in easy (nonoccluded) settings. This second suggestion is also actionable and provides a clear direction for further analysis. The comment is 5 as it offers detailed and constructive feedback that can significantly improve the draft by addressing specific weaknesses and suggesting additional evaluations. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides an example from the TACRED slot filling guidelines, highlighting the depth of annotation guidelines in the IE domain. While the comment raises a concern about the paper\"s claim, it does not provide explicit guidance on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their claim and possibly expand their annotation guidelines. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim of making use of \u201cannotation guideline\u201d\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details what is missing in the paper\"s claim, namely the depth of true guideline understanding, and provides a reference to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s use of \"annotation guidelines\" may be an overstatement, as it only considers label name, label description, and fewshot examples, whereas annotation guidelines in the IE domain are more complex and curated by linguists. The reviewer supports this claim by providing a specific example from the TACRED slot filling guidelines, which demonstrates the depth of annotation guidelines. This example provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by further elaboration or references to other examples or studies that highlight the complexity of annotation guidelines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the claim of using \"annotation guidelines\" in the paper, suggesting that the current approach may not fully capture the complexity of true annotation guidelines. The reviewer provides a specific example from the TACRED slot filling guidelines, which highlights the depth and complexity of annotation guidelines in the IE domain. This feedback is valuable as it prompts the authors to reconsider their claim and potentially expand their annotation guidelines to better align with the standards in the field. However, the comment could be more helpful if it offered suggestions on how to enhance the annotation guidelines or provided additional examples to support the claim. Overall, the comment is 4 as it identifies a potential weakness and provides a specific example for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the experiment comparison is weak because it only compares the method to the BERTbaseline, and suggests that the authors should also compare it to token pruning and token combination baselines. This provides a clear and direct action for the authors to take, which is to expand their comparison to include additional baselines. The feedback is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experiment comparison, specifically mentioning that the authors only compare their method to the BERTbaseline and suggesting that they should also compare it to token pruning and token combination baselines. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue is discussed in, so the authors might need to infer that it relates to the experimental section. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline, suggesting that the authors should also compare it to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need for additional comparisons. However, the comment lacks specific examples or references to support why these additional comparisons are necessary or how they would enhance the experiment. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline and suggesting that they should also include comparisons to token pruning and token combination baselines. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the robustness and comprehensiveness of their experimental evaluation. By addressing this point, the authors can enhance the validity and comparability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This is an explicit action that provides specific examples of methods to consider for comparison. The comment is clear and concrete, giving the authors a direct and actionable step to improve their draft by including these comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with methods that are aware of point coordinates, such as TFN or SchNet, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include comparisons with methods that are aware of point coordinates, such as TFN or SchNet. This claim is 3 as it provides a logical reasoning for the comparison, suggesting that including such methods would enhance the evaluation of the paper. However, the comment lacks specific examples or references to support the claim, making it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental section, noting that it only compares to methods that are unaware of point coordinates, except for input features. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup. By suggesting a comparison to coordinateaware methods, the comment offers a concrete way for the authors to enhance the validity and comprehensiveness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not provide any explicit guidance or concrete suggestions on how to do so. The action is implicit, as the authors need to infer that they should address the lack of discussion on potential weaknesses. Additionally, the comment lacks specificity, as it does not specify which aspects of the model might be vulnerable or how to present these weaknesses. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the possible weaknesses of the proposed model. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what specific weaknesses should be addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding the nature of the weaknesses that should be discussed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to potential weaknesses, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant gap in the paper by noting that the authors have not demonstrated the possible weaknesses of the proposed model. This is a critical observation that highlights an important area for improvement, as understanding and addressing potential weaknesses is crucial for the robustness and credibility of the model. However, the comment lacks specificity and does not provide guidance on how the authors might identify or discuss these weaknesses. While it identifies a key area for improvement, the feedback could be more actionable and helpful if it included suggestions or examples of potential weaknesses to consider. Therefore, the comment is 3, as it directs the authors to a critical area but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the novelty of the proposed methodology in the context of long document summarization. It questions what the system offers over previous extractthengenerate methodologies and notes the absence of a Related Work section or experiments comparing the proposed model with existing ones. While the comment highlights areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they should include a Related Work section and conduct comparative experiments, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3, as it identifies areas for improvement but does not provide specific instructions on how to address them.", "grounding_specificity_rationale": "The comment raises concerns about the novelty of the proposed methodology in the context of long document summarization, questioning what the system offers over previous extractthengenerate methodologies. It also notes the absence of a Related Work section and experiments comparing the proposed model with existing ones. However, the comment does not specify which part of the paper these concerns relate to, making it difficult for the authors to pinpoint the exact sections that need revision. The authors can make an educated guess that it pertains to the methodology or results sections, but the comment lacks full grounding. It is specific in detailing the issues with novelty and the absence of comparative work, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the novelty of the proposed methodology in the context of long document summarization, questioning what the system offers over previous extractthengenerate methodologies. It also notes the absence of a Related Work section and experiments comparing the proposed model with existing ones. While the comment highlights potential issues with the paper, it lacks specific examples or references to support the claim about the lack of novelty or the absence of comparative work. This makes the claim 3, as the authors would need to conduct additional research to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the novelty of the proposed methodology in the context of long document summarization. It questions what the system offers over previous extractthengenerate methodologies and notes the absence of a Related Work section or experiments comparing the proposed model with existing ones. This feedback is valuable as it highlights a potential weakness in the paper and suggests areas where the authors could improve their work by providing a more comprehensive comparison with existing methods. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of related work that could be included. Overall, the comment is 4 as it directs the authors to enhance the novelty and comparison aspects of their paper, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. While it implies that the authors should consider these alternatives, it does not provide explicit guidance on how to implement them or what specific steps to take. The suggestion is vague and lacks concrete details, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it does not specify which part of the paper this concern relates to, making it weakly grounded. The comment is specific in suggesting alternative directions for dealing with churn, such as using unlabeled data or constraints, and provides a concrete example of applying constraints. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the appeal of training multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it lacks specific reasoning, examples, or references to support the claim that training 3040 models is not appealing or to substantiate the suggestion of using unlabeled data or constraints. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practicality of training multiple models to test the approach, which could be a significant burden. It suggests exploring alternative directions, such as using unlabeled data or constraints, to improve the stability of the model. The comment provides a specific example of applying constraints, which is a valuable suggestion for the authors to consider. However, it could be more helpful if it offered additional guidance on how to implement these suggestions or provided more detailed examples. Overall, the comment is 3 as it identifies a potential issue and offers a direction for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as its distinction from BGLN. While the comment implies that the authors should expand the related work section, it does not provide specific guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of related work, specifically mentioning that it is insufficient and suggests including more work on GLN to highlight the advantages or differences of the proposed method. It also mentions the need to differentiate the proposed method from BGLN. However, the comment does not specify which part of the introduction is insufficient or where the additional information should be included, making it weakly grounded. The authors can infer that it relates to the introduction section, but the lack of explicit references makes it challenging to pinpoint the exact areas needing improvement. The comment is specific in suggesting what needs to be addressed, such as highlighting the advantages or differences of the proposed method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current introduction is insufficient. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively, as they are left without clear guidance on what aspects of GLN should be emphasized or how to differentiate the proposed method from BGLN. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the insufficient introduction of related work. It suggests that more work on GLN should be included to highlight the advantages or differences of the proposed method, such as its distinction from BGLN. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by expanding the related work section. However, the comment could be more helpful if it offered specific examples or references of GLNrelated work that should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inconsistency in the dropout rates used for Moon\"s approach and Variational dropout. It explicitly asks why only one dropout rate is used for Moon\"s approach, while Variational dropout has both an inputoutput and a recurrent dropout parameter. This question prompts the authors to clarify or justify their choice of dropout rates, providing a clear and specific action for them to take. The comment is explicit and concrete, as it directly addresses a specific aspect of the paper and provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a question about the inconsistency in dropout rates used for Moon\"s approach and Variational dropout. It explicitly mentions \"hypers > hyperparameters,\" which suggests that the comment is addressing a specific part of the paper where hyperparameters are discussed. However, it does not specify which section or part of the paper this discussion is in, making it weakly grounded. The comment is specific in its question about the dropout rates, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the use of a single dropout rate for Moon\"s approach compared to Variational dropout, which has both an inputoutput and a recurrent dropout parameter. This is a factual observation or question, as it does not express an opinion or make a claim that requires verification. It is a request for clarification or additional information, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in the dropout rates used for Moon\"s approach and Variational dropout. It points out that while Variational dropout has both an inputoutput and a recurrent dropout parameter, Moon\"s approach only uses one dropout rate. This observation prompts the authors to clarify or justify their choice of dropout rates, which could lead to a more comprehensive understanding of their methodology. However, the comment does not provide additional context or suggestions on how to address this issue, leaving the authors with a clear question but limited guidance on how to improve their draft. Therefore, the comment is 3, as it identifies a potential area for clarification but lacks depth in terms of actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should conduct largerscale experiments, specifically mentioning the inclusion of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It also recommends using simple videogame domains, which have a lowcardinality discrete state and actionspace, and suggests using publicly available simulators for these experiments. The comment provides specific examples and references to publicly available resources, offering concrete guidance on how to enhance the experimental scope and comparison with other approaches. This level of detail and explicit suggestions make the comment 5, as the authors know exactly what experiments to conduct and how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"largerscale experiments\" and \"stateaction spaces and nontrivial dynamics,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, such as experiments with gridworlds and other nontrivial tiles, and suggests using simple videogame domains for more convincing experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments with larger stateaction spaces and nontrivial dynamics, which makes it difficult to assess the scalability of the method. The reviewer provides a specific suggestion to conduct experiments on simple videogame domains, which are publicly available and have a lowcardinality discrete state and actionspace. This recommendation is supported by logical reasoning and common knowledge about the importance of scalability in AI experiments. However, the comment could be strengthened by providing examples of similar experiments or references to existing literature that demonstrate the value of such experiments. Overall, the claim is 4, as it provides a clear direction for improvement but lacks detailed examples or references to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental scope of the paper, specifically noting the absence of experiments with larger stateaction spaces and nontrivial dynamics. It questions whether the lack of such experiments is due to a lack of time or a scalability issue with the method. The comment provides a clear and actionable suggestion to conduct experiments on simple videogame domains, which are publicly available and have a lowcardinality discrete state and actionspace. This feedback is 5 as it not only points out a critical area for improvement but also offers a specific and feasible direction for enhancing the experimental validation of the method. By addressing this suggestion, the authors can significantly strengthen the robustness and scalability assessment of their work, making the comment highly valuable for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measurement regarding the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors might address this issue. There is no suggestion of what specific measurements could be used or how they might be implemented. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. The comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of missing quantitative measurements, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement, specifically regarding the extent of occupation bias relative to real distributions in society. This feedback is clear and highlights a gap in the analysis that the authors should address. However, the comment does not provide suggestions or guidance on how to measure or quantify this bias, which would make it more actionable. While it points out a significant area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings. It suggests considering whether such a method, which rescales gradient components, might affect the updates for weights associated with hard features. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or whether they should conduct additional experiments. The action is implicit and vague, as the authors are left to infer that they should consider this aspect but are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically mentioning the rescaling of gradient components and its effect on updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in detailing the potential issue with adaptive gradient methods, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically regarding the rescaling of gradient components and its effect on updates for weights associated with hard features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It lacks specific examples or detailed explanations that would help the authors understand the potential implications of this methodological choice. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the concern effectively.", "helpfulness_rationale": "The review comment raises a relevant question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically regarding the rescaling of gradient components and its effect on updates for weights associated with hard features. This is a thoughtful consideration that could influence the interpretation of the results. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or whether it is worth exploring further. While it identifies a potential area for consideration, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in the comparison, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide specific instructions on how to execute them.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. It references a table (Tab.) for the latter point, providing some grounding by indicating where the authors can find the information. However, the comment does not specify which section of the paper discusses the experiments, making it weakly grounded. It is specific in detailing the issues with the experiments, such as the limited types of teacher architectures and the outdated methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. The comment references a table (Tab.) for the second point, which provides some evidence to support the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the limited types of teacher architectures. Additionally, the reference to the table is not explicit, making it difficult for the authors to locate the specific information. Therefore, the claim is 3, as it provides some support but lacks comprehensive evidence or detailed examples.", "helpfulness_rationale": "The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. By pointing out these limitations, the comment provides the authors with clear areas for improvement. However, it lacks detailed guidance or suggestions on how to address these issues, such as recommending specific architectures to include or suggesting ways to incorporate more recent methods. While the comment highlights important weaknesses, it does not offer actionable advice, making it 3. The authors are left to infer the necessary steps to improve their experiments, which could be more effectively addressed with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that no information from 2hop neighbors is included and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what information should be included from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable suggestions or specific instructions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that \"no information from 2hop neighbors is included,\" which suggests that it is addressing a specific aspect of the methodology or results. However, it does not specify which part of the paper this information is missing from, making it weakly grounded. The comment also questions the effectiveness of the method but does not provide specific details or examples to support this claim. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is simple and questions its effectiveness, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant omission in the paper, noting that no information from 2hop neighbors is included. It also questions the effectiveness of the method, suggesting that it is unclear why the method is effective. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or examples, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for the authors to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends using the real DICOM image instead of the PNG image for experiment data and suggests the FastMRI challenge dataset as a good choice. It also explicitly states that inference speed should be compared between different methods. These suggestions are clear and direct, providing the authors with specific actions to take to improve their draft. The comment is 5 as it gives concrete guidance on what needs to be done and how to implement the changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a real DICOM image instead of a PNG image and suggests the FastMRI challenge dataset. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, namely, using the real DICOM image and comparing inference speeds between different methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using a real DICOM image instead of a PNG image for experiment data and recommends the FastMRI challenge dataset. It also advises comparing inference speeds between different methods. While the suggestion to use a real DICOM image is based on common knowledge in medical imaging, the specific recommendation for the FastMRI challenge dataset and the comparison of inference speeds could be further supported with references or examples. The comment provides some justification but lacks detailed evidence or references, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of real DICOM images instead of PNG images for experiment data. It also suggests the FastMRI challenge dataset as a good choice for this purpose. Additionally, the comment advises comparing inference speeds between different methods, which is a valuable suggestion for enhancing the experimental section of the paper. This feedback is clear and provides concrete guidance for the authors to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter, specifically noting that it only offers an empirical conformation estimation. However, the comment does not provide explicit guidance on how to achieve this optimization and validation. The authors are left to infer that they need to conduct additional experiments or analyses to improve the binder design, but without specific instructions on what these experiments should entail or how to validate the results. This lack of concrete guidance makes the action vague and difficult for the authors to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the \"binder design\" aspect of ProtPainter, suggesting that it only provides an empirical conformation estimation and that further optimization and validation are required. However, it does not specify which part of the paper discusses the binder design, making it weakly grounded. The comment is specific in identifying the need for further optimization and validation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that additional optimization and validation are necessary. Without these elements, the authors may find it challenging to understand the basis of the suggestion or to address it effectively. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, namely that ProtPainter only provides an empirical conformation estimation for binder design, and suggests that further optimization and validation are required. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work by conducting additional experiments or analyses. However, the comment could be more helpful if it provided specific suggestions on how to approach the optimization and validation process. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification on the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a specific study (Smirnakis et al. Nature 1997) to provide context for the adaptation time scale. This feedback is clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The inclusion of a reference to a relevant study adds concrete guidance on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the training of the model in Figure 7, including the stimulus used and the potential impact of changing the cycle duration on the adaptation time scale. The reference to Smirnakis et al. (1997) provides additional context and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training of the model in Figure 7, specifically asking about the stimulus used and whether the duration of the cycle changes. It also references a study by Smirnakis et al. (1997) to provide context for the adaptation time scale. While the comment raises a valid point, it does not provide any evidence or detailed reasoning to support the claim that the model cannot handle longer time scales. The reference to the study is mentioned but not fully integrated into the argument. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area of concern regarding the training of the model in Figure 7. It asks for clarification on the stimulus used and whether the duration of the cycle changes, which could impact the adaptation time scale. The reference to Smirnakis et al. (1997) provides a relevant context for understanding the potential implications of the model\"s limitations. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided additional guidance on what specific information should be included in the clarification. Overall, the feedback is clear and actionable, making it 4 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. While it implies that the authors should consider this scenario, the comment does not provide any explicit guidance or suggestions on how to address it. The action is implicit and vague, as the authors are left to infer that they should explore this scenario but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving CAD models and BRDF maps. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the scenario where the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. While it identifies a potential area of consideration, it lacks depth and does not provide any guidance or suggestions on how the authors might address this scenario or its implications. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. While the comment implies that the authors should conduct additional evaluations, it does not provide explicit guidance on how to perform these evaluations or what specific metrics or analyses should be included. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more evaluations but may not know exactly how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be added to, making it weakly grounded. The comment is specific in suggesting additional evaluation scenarios, which provides some guidance on what the authors could address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. However, the comment does not provide any reasoning or evidence to support why additional evaluation is necessary or how it would improve the paper. Without specific examples or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that more evaluation would be beneficial, specifically mentioning CIFAR10 in the full label and lower label scenarios. This feedback is clear and actionable, as it provides a specific area for the authors to consider expanding their evaluation. However, the comment could be more helpful if it offered guidance on what aspects of the evaluation should be explored or how the evaluation could be improved. Despite this, the suggestion is valuable and directs the authors to a meaningful area for enhancement, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. It suggests that comparisons should be made between experiments using the same amount of data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to ensure fair comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to ensure consistent data usage across comparisons, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of comparisons in the table, specifically regarding the use of different amounts of data. The comment provides examples of experiments that use less data than others, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. The reviewer points out that some experiments use less data than others, which could affect the validity of the comparisons. However, the comment does not provide specific examples or detailed reasoning to support the claim that these differences in data usage are problematic. While the reviewer highlights a potential issue, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. It points out that some experiments, such as H>N and H>B, use less data than others, like H>N+B. This observation is important for ensuring that the comparisons are meaningful and not skewed by differences in data usage. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the use of a common dataset or suggesting alternative methods for comparison. Despite this, the comment identifies a relevant area for improvement, making it 3 for the authors to consider in their revisions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and vague, leaving the authors to infer what needs to be done without clear guidance on how to address these issues. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not explicitly mention which part of the paper it addresses, such as a specific section or figure. However, it is specific in its content, as it raises questions about the placement of a section, the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. The authors can infer that the issues relate to the methodology or results sections, but the exact parts are not clearly identified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of a section, confusion about the application of Algorithm 1, and the lack of reference to Laplacian eigenmaps. However, the comment does not provide specific reasoning or evidence to support these claims, such as explaining why the placement is counterintuitive or how the application of Algorithm 1 is unclear. Additionally, it does not offer examples or references to substantiate the claim about Laplacian eigenmaps. Without detailed justification or evidence, the claims remain 1, making it difficult for the authors to address them effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several points that could be helpful for the authors to address. It questions the placement of a section, suggesting that it might be counterintuitive, and asks for clarification on the application of Algorithm 1, particularly regarding the number of iterations. Additionally, it points out the lack of reference to Laplacian eigenmaps and notes that it was not cited in the introduction. These observations could prompt the authors to reconsider the organization and clarity of their paper, as well as ensure that all relevant references are included. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity and completeness of the references. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the CBN approach. While the comment identifies a potential issue with the structure of the paper, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the content of Section 2.1 and potentially reorganize the material to better align with the proposed methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the inclusion of this section, questioning the relevance of describing general techniques like Batch Normalization and Conditional Batch Normalization (CBN) in this context. The comment further suggests that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the proposed CBN approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. The reviewer implies that the time spent on describing the ResNet architecture could be better used to provide more motivation and intuition for the CBN approach. However, the comment lacks specific examples or detailed reasoning to support why the inclusion of Section 2.1 is unnecessary or how it could be improved. This makes the claim 3, as the authors would need to infer the potential issues and address them based on the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1, suggesting that the description of Batch Normalization and Conditional Batch Normalization (CBN) is general and not specific to the proposed methodology. It implies that the time spent on describing the ResNet architecture could be better utilized to provide more motivation and intuition for the proposed CBN approach. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically suggesting that the authors could better align their content with the proposed methodology. However, the comment lacks specific guidance on how to reorganize the content or what additional information could be included to enhance the motivation and intuition for the CBN approach. Therefore, it is rated as 3, as it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the paper regarding the multiplication of a dense projection matrix in equation (1) and its expected outcome of a sparse matrix. The reviewer questions the logic behind this operation, suggesting that multiplying by a dense matrix would likely result in a dense matrix, not a sparse one. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the expected outcome. The action is implicit, as the authors need to infer that they should clarify the reasoning behind the operation, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, questioning the expectation of a sparse matrix resulting from multiplying by a dense projection matrix. The comment provides a logical critique by pointing out the apparent contradiction in the operation, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the logic behind the expectation of a sparse matrix resulting from multiplying a dense projection matrix. The reviewer provides a logical reasoning by pointing out that multiplying by a dense matrix would likely result in a dense matrix, not a sparse one. This reasoning is clear and straightforward, making the claim 5. The comment effectively challenges the authors to clarify their reasoning, providing a solid basis for the authors to address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the logic behind the expectation of a sparse matrix resulting from multiplying a dense projection matrix. It points out a potential contradiction in the operation, which could be a critical oversight in the paper. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or clarify the expected outcome. While it highlights a potential weakness, it lacks actionable feedback, making it 3. The authors are given some insight into a potential problem but are left without clear steps to resolve it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of the evidence for the motivation being indirect and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. While it does not explicitly mention a specific section or figure, the authors can infer that it relates to the introduction or motivation section, where the problem is described. The comment is specific in suggesting a particular type of figure that could support the claim, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct and suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings. This claim is 3 as it provides a logical reasoning for why the evidence is lacking and suggests a specific action to improve it. However, the comment could be strengthened by providing examples or references to similar studies that have effectively demonstrated this decline in accuracy. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evidence provided for the motivation, noting that it is not direct. It suggests that the authors should plot a figure showing the decline in accuracy of a predictor over time in different settings to support their claim. This feedback is clear and actionable, providing the authors with a concrete step to enhance the evidence and clarity of their work. By addressing this suggestion, the authors can strengthen their argument and improve the overall quality of their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition and calculation of excessive risk, particularly in relation to the expectation and the representation of fairness. It explicitly asks the authors to explain more about the definition of excessive risk, how it is calculated in practice, and whether the values are comparable among different groups. The comment also questions the use of excessive risk as a representation of fairness. While the questions are clear and direct, the comment does not provide specific guidance on how the authors should address these issues or what specific changes they should make to their draft. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the definition of excessive risk, how it is calculated, and whether the values are comparable among different groups. The comment further questions the use of excessive risk as a representation of fairness, providing a clear direction for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. The reviewer questions the positivity of excessive risk values and their comparability across different groups. While the comment highlights potential issues, it does not provide specific evidence, examples, or references to support the claims. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the definition and calculation of excessive risk, particularly in relation to its representation in Figures 3 and 7. It questions the positivity of excessive risk values and their comparability across different groups, which are critical aspects of the paper\"s methodology and results. By asking for clarification on these points, the comment encourages the authors to provide more detailed explanations and justifications for their methods, which can significantly enhance the clarity and robustness of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it identifies key areas for improvement and prompts the authors to provide more detailed explanations, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, implying that the authors should provide a more detailed explanation or clarification regarding the role of initialization in the context of NGD and NGF. While the comment implies that the authors should revise their statement, it does not provide specific guidance on how to do so or what aspects of the statement need clarification. The action is implicit and somewhat vague, as the authors can infer that they need to revise the statement but may not know exactly how to do it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the statement about initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as a pretraining step. The reference to a specific reference [1] adds further specificity by providing a basis for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in the context of NGD being a discretization of NGF, and that solving NGF is an initial value problem (IVP). It suggests that initialization should be considered as pretraining. The comment is supported by a reference to a specific paper, \"Limitations of the empirical Fisher approximation for natural gradient descent\" by Kunstner et al. (2019), which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional elaboration.", "helpfulness_rationale": "The review comment identifies a specific area where the statement about initialization could be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as a pretraining step. It provides a reference to a relevant paper, \"Limitations of the empirical Fisher approximation for natural gradient descent\" by Kunstner et al. (2019), which supports the claim that initialization should play a role in this setting. This feedback is clear and actionable, as it directs the authors to reconsider their statement and potentially incorporate insights from the referenced work. However, the comment could be more helpful if it offered specific suggestions on how to revise the statement or integrate the referenced material into the paper. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two separate comments. The first comment raises a concern about the clarity of named entity extraction from the datasets, implying that this aspect needs further explanation or clarification. However, it does not provide specific guidance on how to address this issue, leaving the authors to infer that they should provide more details about the extraction process. The second comment suggests an English proofreading to improve readability, which is a direct and concrete action. However, the first part of the comment is vague and lacks specific guidance, making the overall comment 3.", "grounding_specificity_rationale": "The comment raises two separate issues: the clarity of named entity extraction from datasets and the need for an English proofreading to improve readability. However, it does not specify which part of the paper discusses named entity extraction, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting improvements, such as clarifying the extraction process and enhancing readability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate claims. The first claim, \"It is not clear how named entities were extracted from the datasets,\" is 3 as it highlights a lack of clarity in the paper. However, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The second claim, \"An Englishproofreading would significantly improve the readability of the paper,\" is a factual statement and does not require verification. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two separate issues: the lack of clarity regarding the extraction of named entities from datasets and the need for an English proofreading to improve the paper\"s readability. While the comment highlights important areas for improvement, it does not provide specific guidance or suggestions on how to address these issues. For example, it does not explain what aspects of the named entity extraction process are unclear or how the authors might clarify them. Similarly, it does not offer specific advice on how to improve readability through English proofreading. As a result, the comment provides some insight but lacks depth and actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part raises a concern about the implication of \"for every arm a\" suggesting a single optimistic parameter, but notes that it actually depends on a. This part is 3 as it points out a potential misunderstanding but does not provide explicit guidance on how to address it. The second part suggests an alternative choice for T_0, which is a concrete suggestion for improvement. However, the comment does not fully explain why this alternative is better or how it should be implemented. Overall, the comment provides some guidance but lacks full specificity and explicitness, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts being addressed. It also provides specific suggestions for improvement, such as choosing T_0 = m Sqrt(T) and explaining the implications of this choice. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part raises a concern about the implication of \"for every arm a\" suggesting a single optimistic parameter, but notes that it actually depends on a. This part is a factual observation and does not contain a claim. The second part suggests an alternative choice for T_0 and provides a mathematical explanation of why it might be beneficial. This part is 3 as it offers a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the paper, addressing two distinct issues. The first part points out a potential misunderstanding in the text regarding the implication of \"for every arm a,\" which could be clarified. The second part offers a suggestion for improving the condition by choosing T_0 = m Sqrt(T), which is a concrete and actionable recommendation. This feedback is clear and provides the authors with a direct path to enhance their draft by addressing the identified issues and considering the suggested improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to define \"L\" and \"E\" in the immediate vicinity of line 296, addressing the inconsistency in their formatting. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The comment also points out the inconsistency in formatting, which is another actionable point. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the formatting of \"L\" and \"E,\" noting that they are sometimes italicized and sometimes not. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the formatting inconsistency in the paper, specifically noting that \"L\" and \"E\" are sometimes italicized and sometimes not. This is a descriptive statement without any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific formatting issue in the paper, noting that \"L\" and \"E\" are sometimes italicized and sometimes not. This feedback is clear and actionable, as it directs the authors to ensure consistency in the formatting of these variables throughout the paper. By addressing this issue, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided additional guidance on why consistency in formatting is important or suggested ways to maintain it. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the experimental section is weak and requires more experiments. However, it does not provide any specific guidance on what kind of experiments are needed or how they should be conducted. The action is implicit and vague, as the authors are left to infer what additional experiments would strengthen the section without clear direction. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and requires more experiments. However, it does not specify which part of the experimental section is weak or what specific experiments are needed. This makes it difficult for the authors to pinpoint the exact areas that require improvement. The comment lacks both grounding and specificity, as it does not provide clear guidance on what needs to be addressed or how to address it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and requires more experiments. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a weakness in the experimental section, noting that it is \"a little weak\" and suggests that more experiments are required. However, it lacks specificity and does not provide any guidance on what kind of experiments would strengthen the section or how they should be conducted. Without detailed suggestions or examples, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 2, as it points out a general area for improvement but does not offer concrete steps for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that the authors should conduct these comparisons, it does not provide specific guidance on which models or techniques to include or how to implement the comparisons. The action is implicit and somewhat vague, as the authors can infer the need for additional comparisons but may not know exactly how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper this suggestion pertains to, such as specific sections or experiments. This lack of grounding makes it difficult for the authors to determine where to address the suggestion. The comment is specific in suggesting additional comparisons, but without clear grounding, it is challenging for the authors to act on this feedback. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these additional comparisons are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and other parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the comprehensiveness and robustness of the paper. However, the comment could be more helpful if it provided specific examples of models or techniques that should be included in the comparisons. Despite this, the suggestion is 4 as it guides the authors toward expanding their analysis and improving the paper\"s depth. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of explicit corrections to grammatical errors and inconsistencies in the manuscript. Each correction is clearly stated, providing the authors with direct and concrete actions to take. The comment explicitly identifies the lines where these corrections are needed, ensuring that the authors know exactly where to apply the changes. This level of detail and specificity makes the feedback 5, as the authors can directly implement the suggested corrections to improve the clarity and accuracy of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper where corrections are needed, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the grammatical errors and inconsistencies that need to be corrected, providing detailed guidance on how to improve the manuscript. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of grammatical corrections and suggestions for improvement. Each correction is factual and does not express an opinion or claim that requires verification. The comment is descriptive and provides clear guidance on how to improve the manuscript\"s grammar and clarity. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of specific and actionable corrections to grammatical errors and inconsistencies in the manuscript. It identifies and corrects errors in punctuation, word choice, and sentence structure, which can significantly improve the clarity and readability of the draft. By pointing out these errors, the comment offers direct guidance to the authors on how to enhance the quality of their writing. However, the comment could be more helpful if it provided additional feedback on the content or suggested ways to improve the overall structure or flow of the paper. Nonetheless, the actionable feedback on grammatical corrections makes the comment 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide explicit guidance or suggestions on how to address the issue or clarify the confusion. The authors are left to infer that they need to correct the equation and possibly clarify the context, but the comment lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. This provides full grounding as it explicitly mentions the equation, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the equation, indicating that there is a mistake related to the inversion of matrix determination or the division of the number of samples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide any supporting evidence, reasoning, or references to justify the claim of a mistake. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. While it identifies a potential issue, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this problem. The comment does not offer actionable feedback or insights that could help the authors improve their draft. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the paper is somewhat incremental, noting that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the incremental nature of the work, whether it should be improved, or how to present it in a more substantial light. Without any actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being somewhat incremental and noting that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this observation pertains to, such as a particular section or methodology. Without explicit references or detailed guidance, the authors cannot confidently determine which aspects of the paper need attention or improvement. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"somewhat incremental\" and that the developed model is a \"fairly straightforward extension of the GAN for static images.\" However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is somewhat incremental, noting that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the novelty of their work. Without actionable feedback or constructive advice, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. While it implies that the authors should consider this comparison, the action is not directly stated, and the authors may not know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion for a comparison between sequential and combinational designs, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic versus sequential design, suggesting that it might be easier to model without staterelated registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed comparisons to substantiate the suggestion for a comparison between sequential and combinational designs. Without additional context or justification, the claim remains 1, as it does not provide sufficient information for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of the proposed method in pure combinational logic versus sequential design. It suggests that the method might be easier to model without staterelated registers and proposes a comparison between sequential and combinational designs. This feedback is 3 as it identifies a potential area for exploration and improvement in the paper. However, it lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it provides a direction for further analysis, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point expresses curiosity about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it does not explicitly instruct the authors to include this information, it implies that the authors should consider adding it to their analysis. The action is implicit, as the authors need to infer that they should include the performance metrics for the baseline. However, the comment provides a clear direction on what aspect of the baseline\"s performance is of interest, making the action somewhat concrete. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section\" and the specific baseline \"LDA+LSTM,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the interest in the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses curiosity about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not make a claim or provide any subjective opinion, judgment, or suggestion that requires verification. It is a factual question seeking clarification, which aligns with the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific aspect of the experiment section, namely the LDA+LSTM baseline, and expresses curiosity about its performance in terms of the topic switch percent metric. While it does not provide explicit suggestions for improvement, it highlights an area of interest that the authors might consider exploring further. This feedback is 3 as it prompts the authors to consider additional analysis or metrics that could enhance their study. However, it lacks depth and does not offer actionable steps for the authors to take, limiting its overall helpfulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations for occluded objects and the handling of uncertainty in amodal predictions. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide more detailed information on the motivation and potential applications of the work, as well as how uncertainty is handled. However, the lack of specific guidance makes the action vague, aligning with a score of 2.", "grounding_specificity_rationale": "The comment raises concerns about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not specify which part of the paper discusses the motivation or the potential applications, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that the motivation section might be the focus, the comment lacks full grounding. It is specific in detailing the concerns about the motivation and potential applications, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a critical concern about the motivation of the task, specifically regarding the difficulty in predicting the state of occluded objects and the potential benefits of amodal tracking. It questions the quality of annotations and the handling of uncertainty in amodal predictions, which is a valid point that could impact the validity and applicability of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their motivation. While it highlights important areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it identifies a critical issue but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option compared to GPT4, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action with concrete details on how to implement it, as it specifies the alternative model to be used and the purpose of the suggestion. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option compared to GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in suggesting the use of GPT3.5, but it lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 as a more affordable alternative to GPT4, implying that this would provide a more comprehensive evaluation of the proposed approach. However, the comment does not provide any reasoning or evidence to support why GPT3.5 is a suitable or necessary addition. Without specific examples or references to studies that have used GPT3.5, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option compared to GPT4, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific suggestion for improving the experimental setup. By incorporating GPT3.5, the authors can enhance the comprehensiveness of their evaluation, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided additional context or reasoning for why GPT3.5 is a suitable choice. Overall, the comment is 4 as it provides a concrete suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It also specifies that for WMT17WIKT, the best result in terms of BLEU is actually in the baselines, providing clear guidance on what needs to be corrected. This feedback is direct and concrete, leaving no ambiguity for the authors on how to implement the suggested changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear instructions on what needs to be included, namely bold numbers for the baselines of previous work, and specifies that the best result in terms of BLEU for WMT17WIKT is actually in the baselines. This level of detail guides the authors on what changes to make, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, asking for a specific formatting change in Table 4. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by requesting that the authors include bold numbers for the baselines of previous work in Table 4. It also points out a discrepancy in the results for WMT17WIKT, noting that the best result in terms of BLEU is actually in the baselines. This feedback is clear and directs the authors to make a precise correction, which can enhance the clarity and accuracy of their presentation. However, the comment could be more helpful if it explained why this correction is important or how it impacts the overall understanding of the results. Nonetheless, the feedback is 4 as it provides a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take to address the comment. The feedback is concrete, as it specifies exactly what the authors need to provide to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors,\" which clearly specifies what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that requires clarification. By asking for examples of \"unreliable neighbors,\" the reviewer highlights a potential gap in the explanation or evidence provided in the paper. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or provide examples themselves. While it points out a specific area for improvement, it does not provide detailed guidance or actionable steps for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient backing for the claim about the synergies between DQD and PPO, specifically noting the absence of mention of the TD3GA algorithm. It suggests that the study of combining DQD with TD3 is crucial for understanding these synergies and that a comparison to TD3GA should be central to the paper. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to include a comparison with TD3GA but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"claim about the synergies between DQD and PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing DQD with TD3GA to understand the synergies. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backed up. It specifically points out the absence of mention of the TD3GA algorithm, which is crucial for understanding these synergies. The comment also suggests that a comparison to TD3GA should be central to the paper. While the comment identifies a potential gap in the paper, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed evidence or references makes the claim 3, as the authors would need to further develop the argument to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It suggests that the comparison to TD3GA should be central to the paper, as it is relevant to the claim that using onpolicy RL better fits the DQD framework. This feedback is clear and actionable, as it directs the authors to include a comparison with TD3GA to strengthen their argument. However, the comment could be more helpful if it provided specific guidance on how to incorporate this comparison or what aspects to focus on. Overall, the comment is 4, as it effectively points out a critical area for improvement and offers a clear direction for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance in Sections 6.1 and 6.2. It explicitly asks the authors to explain why this occurs, providing a clear and direct action for the authors to take. The comment is specific and concrete, as it identifies the sections where the issue is observed and requests an explanation, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance and requests an explanation for this observation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the unexpected performance of the treesliced Wasserstein distance compared to the original optimal transport distance in Sections 6.1 and 6.2. It does not make a claim or provide an opinion but rather seeks clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a surprising observation in the paper, specifically that the treesliced Wasserstein distance outperforms the original optimal transport distance in Sections 6.1 and 6.2. It raises a question about the reason behind this unexpected outcome, prompting the authors to provide an explanation. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their results, which could significantly enhance the understanding and validity of their findings. However, the comment could be more helpful if it offered suggestions on how to approach the explanation or potential reasons for the observed performance difference. Overall, the comment is 4, as it provides a clear direction for improvement but lacks additional guidance or depth."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential ambiguity in the phrase \"ceterus paribus convexity\" and suggests that the word \"confident\" could be clarified to distinguish between model confidence and human interpretability. The reviewer implies that a slight rephrasing would be beneficial to avoid confusion. While the comment identifies an issue and suggests a possible solution, it does not provide explicit guidance on how to rephrase the sentence. The action is implicit and somewhat vague, as the authors need to infer the exact changes needed to clarify the text. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific phrase, \"ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the ambiguity caused by the word \"confident,\" and suggests that the authors should rephrase it to clarify whether it refers to model confidence or human interpretability. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a subjective opinion about the use of the phrase \"ceterus paribus convexity\" and suggests that the word \"confident\" is ambiguous. The reviewer provides a logical reasoning by questioning whether the confidence refers to model confidence or human interpretability, and suggests that a slight rephrasing would be beneficial. However, the comment lacks specific examples or references to support the claim of ambiguity, making it 3. The authors would need to infer the exact nature of the ambiguity and how to address it, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the phrase \"ceterus paribus convexity\" and questions the use of the word \"confident,\" suggesting that it could refer to either model confidence or human interpretability. The reviewer provides a clear suggestion to rephrase the sentence to clarify the intended meaning. This feedback is actionable and provides a specific direction for improvement, helping the authors to enhance the clarity and precision of their writing. However, the comment could be more helpful if it offered additional guidance on how to rephrase the sentence or provided examples of clearer phrasing. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this concern. It lacks guidance on how the authors might address the issue or improve the practicality of their work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practicality of the paper\"s approach, which relies on known causal relationships between features. However, it does not specify which part of the paper this concern is related to, such as a particular section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the reliance on prior knowledge and the potential inaccuracies for specific subpopulations, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. The comment provides a logical reasoning by explaining the potential limitations of relying on prior knowledge and the common practice in the field. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this perspective and potentially address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the paper\"s approach, which relies on known causal relationships between features. It highlights that prior knowledge may not always be available or accurate for specific subpopulations, and most researchers focus on mining causal relationships from data automatically. This feedback is 3 as it points out a potential limitation of the proposed method and encourages the authors to consider the practical implications of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the practicality of their work. While it provides some insight into a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of polish in the presentation of figures and empirical results, which affects the clarity and confidence in the empirical findings. It specifically mentions missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to improve the presentation of their figures and results, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses the lack of polish in figures and empirical results, which affects the clarity and confidence in empirical findings. It mentions specific issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. However, it does not explicitly mention which sections or figures these issues are found in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as improving figure presentation and experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks polish in its figures and empirical results, which affects the clarity and confidence in the empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or practices that support the importance of these aspects in empirical research. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the presentation of empirical findings, specifically mentioning the lack of polish in figures and results. It highlights specific problems such as missing axis labels, randomly masked out portions of curves, and the use of single seed experiments. Additionally, it points out the limited scope of the datasets and architecture types used, which can impact the confidence in the empirical results. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the clarity and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of best practices in presenting empirical results. Overall, the comment is 4, as it effectively guides the authors toward improving the presentation and robustness of their empirical findings."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the work\"s interesting findings but notes that the novelty is limited. It provides a specific observation that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any explicit or implicit actions for the authors to take to address the issue of limited novelty. It lacks guidance on how the authors might enhance the novelty of their work or what specific aspects could be explored further. As a result, the comment is 1, as it does not provide any direction for improvement.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically mentioning the observation of tighter CIs with finetuning. However, it does not specify which part of the paper discusses these findings or where the novelty is limited. The authors can infer that it relates to the results or discussion sections, but this is not explicitly stated. The comment is specific in its critique of the novelty but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, specifically mentioning that tighter CIs with finetuning are expected due to taskspecific finetuning. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The reasoning is based on a general understanding of finetuning effects, but without specific data or studies to back it up, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the work\"s interesting findings but points out that the novelty is limited. It provides a specific observation that tighter CIs with finetuning are expected due to taskspecific finetuning increasing confidence for a specific task while potentially reducing generalizability. However, the comment does not offer any suggestions or guidance on how the authors might enhance the novelty of their work or address this limitation. While it identifies a potential issue, it lacks actionable feedback, making it 3. The authors are informed of a potential weakness but are not provided with a clear path to improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include additional data from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This is an explicit suggestion for the authors to include more data to strengthen their case and further test their conjecture. The comment provides a clear direction for the authors to follow, making it 5. The authors know exactly what additional data to include and why it would be beneficial for their paper.", "grounding_specificity_rationale": "The comment suggests that the paper should include numbers from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This provides a clear direction for the authors to expand their analysis. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or figure, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding limits the comment\"s clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including numbers from a label noise experiment on ImageNet with 1000 classes would strengthen the case by further testing the conjecture. The comment provides a logical reasoning for why this additional data would be valuable, as it would help to stress test the conjecture even if the phenomenon weakens in this setting. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this additional data based on the reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would be strengthened by including numbers from a label noise experiment performed on ImageNet with 1000 classes, specifically focusing on nontail classes. This is a clear and actionable suggestion that could help further test the conjecture and provide additional insights into the robustness of the results. The comment is specific in its request for additional data and provides a rationale for why this would be beneficial, making it 4. However, it could be more helpful if it offered guidance on how to conduct this experiment or what specific aspects to focus on. Overall, the comment provides valuable feedback that could enhance the paper, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific changes should be made to the paper. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, nor does it provide any specific guidance on how to address this issue. The authors may infer that it relates to the experimental or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. It lacks specific examples or explanations that would help the authors understand the basis of the question or how it relates to the paper. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the choice of metric, specifically questioning why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on how the authors might address this concern or what specific aspects of their work need to be revised. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide any details on what aspects of the objective or scenarios should be considered. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the realworld scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. While it identifies a potential area for clarification, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The reviewer suggests that the paper should explore the effects of varying the number of InContext Examples and provide more comprehensive evaluation. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed information about the experiment setup and consider using multiple datasets, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment provides clear guidance on what needs to be addressed to improve the evaluation, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the reliance on a single dataset, which may limit the generalizability of the results. The comment provides logical reasoning by highlighting specific areas where the evaluation could be improved, such as exploring the effects of varying the number of InContext Examples. However, it could be strengthened by providing examples or references to support the claim about the lack of transparency and comprehensiveness. Overall, the comment is 4, as it provides a clear framework for improvement but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies several weaknesses in the evaluation section of the paper, including a lack of transparency regarding the experiment setup and the absence of information on the number of different sets of incontent examples used. It also points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. The comment provides specific suggestions for improvement, such as exploring the effects of varying the number of InContext Examples and using multiple datasets. This feedback is clear and actionable, offering the authors concrete steps to enhance the comprehensiveness and transparency of their evaluation. However, the comment could be more helpful if it included examples or references to support the suggestions. Overall, the comment is 4, as it effectively guides the authors toward improving their evaluation methodology."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point simply states that the contrastive learning framework is the same as SimCLR, without providing any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this observation or improve their work. As a result, the comment is 1, as it does not offer any direction for the authors to enhance their draft.", "grounding_specificity_rationale": "The comment claims that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where in the paper this claim is being made. Additionally, the comment lacks specificity regarding what aspects of the framework are identical or how this similarity affects the paper. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment simply states that the contrastive learning framework is the same as SimCLR without providing any context, explanation, or suggestions for improvement. It lacks depth and does not offer any actionable feedback or guidance for the authors to enhance their work. Without specific details or examples, the comment does not help the authors understand the implications of this observation or how to address it. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides specific examples of nonlinear blocks that could be included in the comparative experiments. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it provides a logical reasoning for the suggestion, noting that such experiments could showcase the unique advantages or potential shortcomings of the proposed method. However, the comment lacks specific examples or references to existing works that have conducted similar experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests a concrete way for the authors to enhance their draft by including these comparisons. By doing so, the authors can better demonstrate the unique advantages or potential shortcomings of their proposed method in a broader context. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors need to infer that they should include more references, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, literature review, or discussion sections. Without explicit references to these sections, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in suggesting the inclusion of related work, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not provide any explanation or justification for why these references are relevant or how they relate to the current work. Without specific reasoning or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate this related work into the paper. The authors are left with a general idea of what needs to be addressed but without detailed instructions on how to do so. Therefore, the comment is 3, as it points out a weakness but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons with existing text GANs, specifically mentioning that many have opensource implementations. It also notes that while SeqGAN is mentioned, it is not tested with a pretrained version. This feedback implies that the authors should include comparisons with existing text GANs and consider testing SeqGAN with a pretrained version. However, the comment does not provide explicit instructions on how to conduct these comparisons or which specific existing text GANs to include. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of comparisons with existing text GANs, specifically mentioning that many have opensource implementations. It also notes that while SeqGAN is mentioned, it is not tested with a pretrained version. This provides specific feedback on the lack of comparisons and the need to include SeqGAN with a pretrained version. However, the comment does not specify which sections of the paper should include these comparisons or tests, making it weakly grounded. The authors can infer that the discussion or results sections might be relevant, but the comment lacks explicit references to these parts. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks comparison with existing text GANs, specifically mentioning that many have opensource implementations. It also notes that while SeqGAN is mentioned, it is not tested with a pretrained version. This claim is 3 as it highlights a potential gap in the paper\"s methodology and suggests a specific area for improvement. However, the comment lacks detailed reasoning or examples of specific existing text GANs that should be compared, which would strengthen the claim. Therefore, the comment is rated as 3, as it provides a direction for improvement but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with existing text GANs, many of which have opensource implementations. It also notes that while SeqGAN is mentioned, it is not tested with a pretrained version. This feedback is clear and actionable, as it highlights an important area for improvement in the paper. By suggesting comparisons with existing text GANs and testing SeqGAN with a pretrained version, the comment provides the authors with specific directions to enhance the validity and comprehensiveness of their work. However, the comment could be more helpful if it included examples of specific existing text GANs or detailed guidance on how to conduct these comparisons. Overall, the comment is 4, as it effectively directs the authors to address a critical gap in their research."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the current focus on the concept of Blackwell winner limits the novelty of the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the algorithm should be explored. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the novelty of the paper is limited by its focus on the concept of Blackwell winner. However, it does not specify which part of the paper should be expanded to include these algorithmic aspects or how the current focus on Blackwell winner limits the novelty. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be explored or how the novelty could be enhanced. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper is limited by its focus on the concept of Blackwell winner. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed justification, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, implying that the current focus on the concept of Blackwell winner limits the novelty of the paper. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might expand their discussion on algorithmic aspects or enhance the novelty of their work. Without detailed suggestions or examples, the comment offers limited value to the authors in terms of actionable feedback. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific and explicit suggestion for improving the readability of Tables 4 and 5. It recommends splitting each table into two separate tables, one for each measure (SFII and SPDI), to enhance clarity. This feedback is clear and actionable, as it gives the authors a direct instruction on how to improve the presentation of their data. The suggestion is concrete, providing a clear path for the authors to follow, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, one for SFII and one for SPDI columns. This detailed guidance helps the authors understand exactly what needs to be done to enhance the clarity of their presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. This is a logical suggestion based on common practices in data presentation, aiming to improve the clarity and organization of the data. However, the comment does not provide specific examples or references to support why this arrangement would be beneficial or how it would enhance readability. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5. By recommending that each table be split into two, with one table for each measure (SFII and SPDI), the comment offers a clear and concrete way for the authors to enhance the clarity and organization of their data presentation. This feedback is valuable as it directly addresses a potential issue with the current format and provides a straightforward path for improvement. However, the comment could be more helpful if it explained why this change would be beneficial or if it suggested additional ways to improve the tables. Overall, the comment is 4, as it provides actionable guidance but could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in, as shown in Fig. 5. This is an explicit action that provides clear guidance on what needs to be clarified in the figure. The comment is concrete because it directly instructs the authors on how to improve their draft by providing more detailed information about the differences between \"valid\" and \"orig.\" Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to explain the differences between \"valid\" and \"orig\" in Fig. 5. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the differences between \"valid\" and \"orig\" in Fig. 5. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors could improve their draft by clarifying the differences between \"valid\" and \"orig\" in Fig. 5. This feedback is actionable, as it directs the authors to provide more detailed information in the figure, which could enhance the reader\"s understanding of the results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the feedback is clear and provides a specific direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors could improve their paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. This feedback is explicit and detailed, allowing the authors to know exactly what needs to be done to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Originality\" and references the work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic by comparing the best performance of each method. This provides clear guidance on how to enhance the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the closely related work of Zemel et al. (2013) more systematic. It suggests comparing the best performance of each method, which is a logical and reasonable suggestion. However, the comment does not provide specific examples or detailed reasoning to support why this would improve the paper. While the suggestion is clear, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It recommends comparing the best performance of each method, which is a clear and actionable piece of feedback. This guidance can help the authors enhance the clarity and effectiveness of their comparisons, making the comment 4. However, the comment could be more helpful if it included additional details or examples on how to implement these systematic comparisons. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. While the comment implies that the authors should consider adapting methods from computer vision to language tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore comparisons with computer vision methods. However, the comment provides a concrete suggestion by mentioning specific methods that could be adapted, which makes the action 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where comparisons are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a specific suggestion for improvement, it does not specify what aspects of the computer vision methods should be compared or how they could be adapted to language tasks. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including a comparison to methods from the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and typically require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. However, the comment lacks specific examples or references to support the claim that such adaptations are feasible or beneficial. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending a comparison to methods from the computer vision setting. It acknowledges that some of these methods may not be directly applicable but suggests that they could be adapted to language tasks with relative ease. This feedback is actionable and offers a specific direction for the authors to enhance their work by exploring comparisons that could provide more valuable insights. However, the comment could be more helpful if it included examples of specific methods from computer vision that could be adapted or suggested ways to adapt them to language tasks. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to \"explicitly estimate the time complexity of the learning algorithm\" to prove the scalability properties. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the time complexity is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its request for estimation of time complexity but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This claim is 3 as it provides a logical reasoning for why estimating time complexity is important for assessing scalability. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the context and the expected outcome of estimating time complexity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s rigor and clarity. By addressing this point, the authors can strengthen their argument about the scalability of their algorithm, which is a critical aspect of many computational models. However, the comment could be more helpful if it offered additional guidance on how to estimate the time complexity or provided examples of similar approaches. Overall, the comment is 4 as it directs the authors to a significant improvement area, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels. It suggests that the authors should consider this connection and references a specific chapter in Steinwart and Christmann that discusses universal kernels. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the connection and possibly incorporate the referenced chapter into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific guidance by suggesting a connection to properties of universal kernels and referencing a particular chapter in Steinwart and Christmann. This detailed reference helps the authors understand what needs to be addressed in terms of exploring the connection between the definition and universal kernels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This reference provides a clear and specific external source that supports the claim, making the comment 4. The mention of a specific chapter and the ability of universal kernels to separate an arbitrary finite data set with a margin arbitrarily close to one offers a robust basis for the claim. However, the comment could be more 5 if it included a brief explanation of how this connection might be relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a specific question about the connection between the third point of definition one and properties of universal kernels. It references a particular chapter in Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with a margin arbitrarily close to one. This feedback is helpful as it prompts the authors to consider a potential link between their work and existing literature, which could enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided a clearer explanation of how this connection might be relevant or suggested specific ways to incorporate this information into the paper. Overall, the comment is 4, as it offers a valuable direction for further exploration but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit guidance on how the authors should improve this section. There is no suggestion on what specific aspects need to be clarified or expanded upon. Without actionable advice or concrete steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment is specific in pointing out that the discussion around this equation is terse and not clearly explained, indicating what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and \"not very clearly explained.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is \"very terse\" and \"not very clearly explained.\" This feedback is clear and actionable, as it directs the authors to expand and clarify their discussion of this equation. However, the comment could be more helpful if it provided specific suggestions on what aspects of the discussion need further elaboration or examples of how to improve clarity. Despite this, the comment still offers valuable guidance for improving the manuscript, making it 4."}
