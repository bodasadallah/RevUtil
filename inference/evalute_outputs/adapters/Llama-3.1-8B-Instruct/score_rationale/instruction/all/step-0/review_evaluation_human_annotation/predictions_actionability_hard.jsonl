{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the description of HIERENC and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify the description or address the potential issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the description and potentially reconsider their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the description of HIERENC, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the description, namely that the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary may introduce a lot of noise. The comment provides a detailed critique of the method, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment lacks specific examples or references to support the claim that this approach is problematic. The reasoning is somewhat logical, but without detailed evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, questioning the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. This feedback is clear and highlights a potential weakness in the methodology, prompting the authors to reconsider their approach. However, the comment could be more helpful if it provided additional guidance or suggestions on how to improve the description or address the potential issue. Overall, the comment is 3 as it directs the authors to a specific area needing clarification or improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct an ablation study to demonstrate the importance of the postprocessing steps proposed in the paper. While the comment implies that an ablation study is necessary, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is required and figure out the details themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of integrated gradients for attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It suggests that the paper should include an ablation study to demonstrate the importance of these postprocessing steps. However, the comment does not specify which part of the paper discusses these methods, making it weakly grounded. The suggestion for an ablation study is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not demonstrate the importance of the postprocessing steps proposed for filtering out \"falsepositive\" neurons. It suggests that an ablation study may be needed to address this issue. The comment provides a logical reasoning for the claim by pointing out the lack of demonstration of the postprocessing steps\" importance. However, it does not provide specific examples or references to support the claim, which makes it 3. The authors would need to conduct an ablation study to fully understand the impact of these steps, but the comment itself lacks detailed evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the importance of the postprocessing steps for filtering out \"falsepositive\" neurons is not demonstrated. It suggests that an ablation study could be necessary to address this issue, providing a clear and actionable direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further exploration. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, particularly when the head of the noun phrase is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this challenge. The authors are left to infer that they need to clarify or improve their method for handling pronouns, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. However, it does not specify which part of the paper discusses the method for identifying antecedents or pronouns, making it weakly grounded. The comment is specific in detailing the issue with pronoun predictions, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. The comment highlights a potential issue with the proposed method but does not provide specific examples, references, or detailed reasoning to support the claim. This makes the claim 3, as the authors would need to infer the exact nature of the problem and how it affects the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. This is a relevant issue that the authors should address to ensure the robustness and accuracy of their method. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue, such as proposing alternative approaches or suggesting additional experiments. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work is a fairly straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not provided with specific guidance on how to implement these baselines or which ones to include. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work is a fairly straightforward extension of existing retrofitting work and recommends adding additional baselines, such as character embeddings. However, it does not specify which part of the paper this comment addresses, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, which provides clear guidance on what the authors could do to improve their work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is a \"fairly straightforward extension of existing retrofitting work\" and suggests adding additional baselines, such as character embeddings. However, the comment lacks specific examples or references to support the claim that the work is a straightforward extension or to justify the need for additional baselines. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment acknowledges that the work is a fairly straightforward extension of existing retrofitting work and suggests that adding additional baselines, such as character embeddings, would be beneficial. This feedback provides a clear direction for the authors to consider expanding their work by incorporating new baselines, which could enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered specific suggestions on which character embeddings to include or how they might impact the results. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to demonstrate that a particular approach, such as attention in seq2seq MTL, is not working, the true value lies in understanding why it fails and making adjustments to the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for the failure or how to modify the attention mechanism. The action is implicit and vague, as the authors are left to infer that they need to investigate the reasons for the failure and make adjustments, but without concrete steps or examples, it is challenging for them to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the difficulty of demonstrating that a particular approach, such as attention in seq2seq MTL, is not working, and suggests that the value lies in understanding why it fails and making adjustments to the attention mechanism. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how to address the issue. The authors may infer that it relates to the experimental results or methodology sections, but without explicit grounding, it is difficult to pinpoint the exact area needing attention. The comment is specific in its suggestion to investigate the failure and make adjustments but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that it is easier to demonstrate that a particular approach, such as attention in seq2seq MTL, is not working, but the value lies in understanding why it fails and making adjustments to the attention mechanism. However, the comment does not provide any specific examples, reasoning, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a common challenge in research, noting that it is easier to demonstrate that a particular approach is not working but more valuable to understand why it fails and make adjustments to improve it. This feedback is 3 as it encourages the authors to delve deeper into the reasons behind the failure of the attention mechanism in seq2seq MTL and suggests a potential path for improvement. However, the comment lacks specific guidance or actionable steps on how to investigate the failure or modify the attention mechanism, which would make it more helpful. The authors are left with a general direction but without detailed instructions on how to implement the suggested improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the paper, specifically related to the experiments. It mentions that the experiments are limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method could be applied to more NLP tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen their experiments or demonstrate the potential of their method on other tasks. The feedback is vague and lacks concrete actions for the authors to take, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiments in the paper, specifically mentioning the limitation to an extremely lowresource regime and the ease of sentence classification. It suggests that the proposed augmentation method could be applied to more NLP tasks, which is not demonstrated in the paper. However, the comment does not specify which part of the paper discusses the experiments or provide detailed guidance on how to address these issues. The authors can infer that the comment relates to the experimental section, but it lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s experiments are weak, specifically mentioning the limited setting to an extremely lowresource regime and the ease of sentence classification. The reviewer suggests that the proposed augmentation method has potential for broader application in NLP tasks, which is not demonstrated in the paper. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the experiments are weak or that the method could be applied to more tasks. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the paper\"s experiments, noting that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task. It suggests that the proposed augmentation method has potential for broader application in NLP tasks, which is not demonstrated in the paper. This feedback is 3 as it points out areas for improvement and provides a direction for further exploration. However, it lacks detailed guidance or suggestions on how the authors might address these issues or expand their experiments to demonstrate the method\"s potential on more NLP tasks. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are in need of further analysis or provide guidance on how the authors might conduct this analysis. The action is implicit and vague, as the authors are left to infer which claims require more depth and how to achieve it. Without explicit instructions or examples, the authors may struggle to determine the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a number of claims in the paper would benefit from more indepth analysis. However, it does not specify which claims are being referred to or provide any details on what aspects of the analysis are lacking. This makes it difficult for the authors to identify the specific parts of the paper that need improvement. The comment lacks both grounding and specificity, as it does not provide any clear guidance or examples. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a number of claims from this paper would benefit from more indepth analysis.\" However, it does not specify which claims are being referred to or provide any reasoning or evidence to support this claim. Without specific examples or detailed justification, the authors may find it challenging to understand which claims need further analysis and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that several claims in the paper would benefit from more indepth analysis. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which claims are in need of further analysis or how the authors might conduct this analysis. Without detailed suggestions or examples, the authors are left with a general idea of what might need more attention but without actionable steps to take. Therefore, the comment is 2, as it provides minimal guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the terminology used in the paper, specifically the claim that the model generalizes to different knowledge. The reviewer questions the use of \"knowledge\" in this context, suggesting that it might be misleading as it typically refers to external knowledge bases rather than syntax or semantics. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their terminology. The action is implicit and vague, leaving the authors to infer that they need to clarify their terminology but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim about generalizing to different knowledge, specifically questioning the use of \"knowledge\" in the context of substructure representation. The reviewer suggests that the substructure should be represented as a sequence of words and expresses hesitation about calling it \"knowledge,\" as it typically refers to external knowledge bases. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the terminology and its implications, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of the term \"knowledge\" in the context of the paper, suggesting that it might be misleading. The reviewer provides a logical reasoning by explaining that \"knowledge\" typically refers to external knowledge bases, whereas in the paper, it seems to refer to syntax or semantics. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the terminology used in the paper, specifically the claim that the model generalizes to different knowledge. The reviewer questions the use of \"knowledge\" in this context, suggesting that it might be misleading as it typically refers to external knowledge bases rather than syntax or semantics. This feedback is 3 as it identifies a potential confusion in the paper\"s terminology and encourages the authors to clarify their use of terms. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered alternative terminology. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the relatively poor performance of the model on nouns and the discrepancy between the oracle GAP for PPDBClus and most clustering approaches. The reviewer suggests that this issue contradicts the claim of generalizability to all parts of speech. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve the performance. It lacks actionable details, such as recommending specific experiments or analyses to conduct. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"relatively poor performance on nouns\" and references specific claims in the paper (124126) regarding generalizability to all parts of speech. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue with the performance on nouns and the discrepancy with the oracle GAP for PPDBClus, as well as the contradiction with the claim of generalizability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses concern about the relatively poor performance of the model on nouns, which contradicts the claim of generalizability to all parts of speech. The reviewer provides a logical reasoning by pointing out the discrepancy between the oracle GAP for PPDBClus and most clustering approaches, suggesting that this issue needs further explanation. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to delve deeper into the paper to understand the context and the specific claims being made, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the performance of the model on nouns, which is a critical aspect of the paper. It highlights a discrepancy between the expected performance of the model, given its nature, and the actual results, which are disconcerting. The comment also points out a contradiction with the claim of generalizability to all parts of speech, as the performance is not uniform. This feedback is valuable as it prompts the authors to investigate and address the issue of performance variability across different parts of speech. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the model\"s performance or clarify the generalizability claim. Overall, the comment is 3, as it directs the authors\" attention to a significant issue but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point consists of a statement that contradicts the claim made in the paper, stating that there is no corresponding set of tools for the reinforcement learning setting. However, it does not provide any actionable advice or suggestions for the authors to address this issue. It does not offer guidance on how to resolve the discrepancy or improve the draft. As a result, the comment lacks any explicit or implicit action for the authors to take, making it 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the claim about the lack of tools for the reinforcement learning setting is being made. It also lacks specificity because it does not provide details on what specific tools are missing or how they could be addressed. Without clear references or context, the authors cannot determine where to make changes or improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a statement that contradicts a claim made in the paper, stating that there is no corresponding set of tools for the reinforcement learning setting. The reviewer claims that this statement is false and provides a reference to support this claim. However, the comment does not elaborate on the specific references or how they contradict the claim, making it 3. The authors would need to access the references to fully understand the basis of the claim, which adds a layer of complexity to the verification process. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review point challenges a claim made in the paper by stating that it is false, specifically regarding the lack of tools for the reinforcement learning setting. However, it does not provide any further explanation, examples, or references to support this claim, nor does it offer suggestions for how the authors might address this issue. Without additional context or guidance, the comment lacks actionable value for the authors, leaving them without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods, given that it uses a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what specific steps to consider in the comparison or promotion of the proposed technique. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also mentions that the authors have adequately addressed the limitations and potential negative societal impact of their work, but this part is not specific enough to guide further improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the questions. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO. It also questions whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, the comment does not provide specific guidance or suggestions on how the authors might address these questions or improve their work. While it identifies potential areas for consideration, it lacks actionable feedback or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written too briefly and could be improved by developing the content at a slower pace for better readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more elaboration. The action is implicit and somewhat vague, as the authors are left to infer that they should expand the section but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, noting that it is \"tersely written\" and suggests that a slower development would improve readability. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is \"tersely written\" and suggests that it could benefit from a slower development for easier readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is \"tersely written\" and suggests that a slower development of the content would improve readability. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance or suggestions on how to achieve a slower development or what aspects of the section need more elaboration. While it provides some insight, the comment could be more helpful if it included actionable advice or examples to enhance the clarity and readability of the section. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should include a comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It also references a specific reference 1 that proposes a similar approach. This provides clear guidance on what action the authors need to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, which allows the authors to identify the specific part of the paper that needs attention. It also specifies the issue by pointing out the absence of method comparison or performance comparison, particularly referencing a specific reference 1 that proposes a similar approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning \"intertask ensemble\" and \"intratask\" ensemble. It references another work 1 that proposes a similar approach, providing some context for the claim. However, the comment does not fully substantiate the claim by explaining why this comparison is crucial or how it would impact the paper\"s contributions. While the reference to 1 offers some support, the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method, specifically mentioning the use of \"intertask ensemble\" and \"intratask\" ensemble. It references another work 1 that proposes a similar approach, highlighting the importance of including this comparison to enhance the paper\"s contributions. This feedback is clear and actionable, providing the authors with a specific area to address and a reference to consider for their comparison. However, the comment could be more helpful if it offered suggestions on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not provide specific guidance on how to improve the introduction of the baseline models or how to enhance the results of the pipeline style method. The lack of actionable advice or concrete suggestions makes it difficult for the authors to know exactly what steps to take to address these issues. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method involving two models on XVNLI and MaRVL, indicating that it does not yield better average results. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which sections of the paper discuss these baseline models or the pipeline style method, making it difficult for the authors to pinpoint the exact parts that need attention. The lack of specific guidance on what needs to be improved or clarified further exacerbates the issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the pipeline style method, including two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment lacks specific details or evidence to support these claims, such as comparisons with other methods or references to studies that demonstrate the effectiveness of the baseline models. Without such supporting information, the claims remain unsubstantiated and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the pipeline style method does not yield better average results for both XVNLI and MaRVL, which is a critical observation that could impact the paper\"s conclusions. Additionally, the comment highlights the lack of proper introduction of baseline models, which is essential for understanding the context and significance of the results. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative methods or providing examples of how to improve the introduction of baseline models. While it identifies important areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature using a \"coarse\" methodology. It questions the necessity of this observation, given that it has been made at each step of the evolution of language models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or address the critique, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used by the authors to reproduce a wellknown result in the literature, specifically the left political bias in ChatGPT and LLMs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the methodology, questioning the need for this observation given its repetition in the evolution of language models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the historical context of similar observations in word2vec, BERT, and ChatGPT, suggesting that the claim is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to consider this historical context to fully understand the critique, but the comment could be strengthened with more detailed references or examples.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models, from word2vec to BERT to ChatGPT. The comment highlights a lack of novelty in the observation, which could be seen as a critique of the paper\"s contribution. However, it does not provide specific suggestions or guidance on how the authors might address this critique or improve their work. The feedback is 3 as it points out a potential weakness in the paper, but it lacks actionable advice or depth, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive. While the comment identifies an area that needs further explanation, it does not provide specific guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the relationship between the community structure and degree bias is not intuitive enough, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between the community structure and degree bias is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the exact nature of the issue and how it relates to the theorems. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by requesting more explanations on how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove the conformity of GCL to a clearer community structure, but notes that the relationship with degree bias is not intuitive. This feedback is clear and actionable, as it directs the authors to provide additional explanations that could enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered specific suggestions on how to address the lack of intuition or provided examples of what additional information could be included. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential source of confusion in the notation and the explicit split between \"static\" and temporal features. The reviewer suggests that more information is needed, specifically regarding the variables \"S\" and \"Xt.\" However, the comment does not provide explicit guidance on how to address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the notation and variables but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a potential source of confusion regarding the notation and the explicit split between \"static\" and temporal features. It specifically mentions the variables \"S\" and \"Xt,\" indicating that the authors need to provide more information about these variables. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for more information about \"S\" and \"Xt.\" Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the notation and the explicit split between \"static\" and temporal features, suggesting that it is confusing and requires more information. However, the comment does not provide specific examples or references to support why this notation is confusing or how it could be clarified. The lack of detailed reasoning or evidence makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the notation and the explicit split between \"static\" and temporal features. It highlights the need for more information about the variables \"S\" and \"Xt,\" which could help clarify the paper. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the notation. While it points out a specific area for improvement, it lacks depth and actionable advice, making it 3. The authors are given some insight into a potential problem but are not fully directed on how to resolve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether the authors should reconsider their claim. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this characteristic is not an advantage. The comment provides a clear critique of the claim, making it specific. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer provides a logical reasoning by stating that a model that can only handle a single time series data is almost useless. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the implications of this limitation and potentially provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that INRs operate on a perdatainstance basis, suggesting that this characteristic is not an advantage. The reviewer argues that a model that can only handle a single time series data is almost useless, which provides a clear critique of the paper\"s claim. However, the comment lacks depth and does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the scalability of the learning rate condition, which is not seen in practice and could lead to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the learning rate condition, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer provides a logical reasoning by stating that in practice, the step size does not grow with the sample size, which supports the claim. However, the comment could be strengthened by providing specific examples or references to datasets where this issue is observed. Overall, the claim is 3 as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. This feedback is 3 as it highlights a potential weakness in the approach and encourages the authors to reconsider their condition. However, the comment could be more helpful if it provided suggestions or alternatives for addressing this issue, such as proposing different scaling methods or discussing potential workarounds. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). This implies an action for the authors to take, which is to modify their approach to better align with realworld applications. The suggestion is explicit and provides a concrete example of how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the impracticality of perfectly balanced unlabeled data in realworld applications and suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset is impractical in realworld applications. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in the Adaptive Semisupervised Learning for Crossdomain Sentiment Classification paper by He et al. (EMNLP 2018). The comment provides a specific reference to support the claim, which makes it 4. However, the authors might need to consult the referenced paper to fully understand the context and implementation of the suggested approach. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a practical issue with the use of perfectly balanced unlabeled data from the preprocessed Amazon review dataset, noting that this is impractical in realworld applications where label distribution cannot be controlled. It suggests using a more realistic setting by sampling unlabeled data from millions of reviews, as done in a referenced paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their approach by aligning it with more realistic scenarios. The reference to a relevant paper adds depth to the suggestion, making the comment 5 for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It also compares this issue to sampling from the leverage score in 3, suggesting that the authors should clarify how sampling from the DPP is easier than from the leverage score. While the comment identifies a potential issue and provides a comparison, it does not explicitly instruct the authors to address this point or offer specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the sampling process and its differences from the leverage score. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when eigenfunctions are inaccessible, and it provides a comparison with sampling from the leverage score in 3. This comparison adds specificity to the comment, as it highlights a potential problem and suggests a basis for comparison. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It also compares this issue to sampling from the leverage score in 3, suggesting that the authors should clarify how sampling from the DPP is easier than from the leverage score. The comment provides a logical comparison and highlights a potential problem, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible. It also provides a comparison with sampling from the leverage score in 3, suggesting that the authors should clarify how their method is easier or different. This feedback is clear and actionable, as it points out a potential weakness in the paper and offers a basis for comparison that could help the authors improve their draft. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment is 4, as it directs the authors to a critical area that needs clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on these cases, even simulated ones. While the comment highlights a potential gap in the experimental section, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should conduct experiments on the mentioned cases, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies a gap but does not provide clear instructions on how to fill it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value functions,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on specific cases, such as surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are not convincing and questions the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on these cases, even simulated ones. The comment provides a logical reasoning by questioning the relevance of the examples and the lack of experiments on more complex cases. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on these cases, even simulated ones. This feedback highlights a potential gap in the experimental section, suggesting that the authors should consider including experiments on more complex settings to better motivate their solution. However, the comment could be more helpful by providing specific suggestions on how to address this issue or by offering examples of experiments that could be conducted. Overall, the comment is 3 as it identifies a weakness and prompts the authors to consider additional experiments, but it lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to improve their work. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of noise accumulation in the context of homomorphic encryption for sequential ensembling, but it does not specify which part of the paper this concern is related to. The authors may infer that it pertains to the methodology or results sections, but without explicit grounding, it is difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the issue of noise accumulation and its impact on the use of homomorphically encrypted data, but it lacks grounding. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that studying the effect of noise accumulation in the context of homomorphic encryption is important for sequential ensembling. It also mentions a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights an important consideration for sequential ensembling in the context of homomorphic encryption, specifically the issue of noise accumulation. It points out a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment identifies a critical area for further study, it lacks specific suggestions or guidance on how the authors might address this limitation or explore potential solutions. The feedback is 3 as it directs the authors to a specific area needing attention, but it could be more beneficial with additional actionable advice or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While the comment implies that this is necessary for a fair comparison, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to apply the regularization trick or what specific standard regularization technique should be used. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the comparison is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide detailed guidance on which standard regularization trick should be used or how it should be applied. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. However, the comment does not provide any reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a stronglyconvex concave case. While it identifies a potential area for improvement by suggesting a specific approach, it lacks detailed guidance or explanation on how to implement this suggestion. The comment does not provide context or examples of standard regularization tricks that could be used, nor does it offer any rationale for why this approach is necessary. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct issues. First, it questions how the paper addresses different types of inputs, such as biomedical signals or speech, and suggests that discussing and presenting solutions for these inputs would be valuable. This is an explicit suggestion for the authors to expand their discussion and provide solutions. Second, it mentions that the citation seems disordered, which is an implicit action for the authors to reorder or clarify their citations. While the first part is explicit and provides a clear direction for improvement, the second part is implicit and lacks specific guidance on how to address the citation issue. Overall, the comment is 4 as it provides a clear direction for expanding the discussion on input types, but the action regarding citations is less concrete.", "grounding_specificity_rationale": "The comment raises two distinct issues: the handling of different types of inputs and the order of citations. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that the discussion on input types might be related to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting that the authors discuss and present solutions for different types of inputs and that the citations are disordered, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two separate issues: the handling of different types of inputs and the order of citations. The first issue is a suggestion for the authors to discuss and present solutions for different types of inputs, which is a logical request for improvement. However, it lacks specific examples or references to support why this discussion is necessary or how it would enhance the paper. The second point about the disordered citations is a factual observation that does not require verification, as it is a straightforward statement about the organization of references. Therefore, the comment is 4, as the first part requires more detailed justification, while the second part is factual.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it suggests that the authors should discuss and present solutions for dealing with different types of inputs, such as biomedical signals or speech. This is a valuable suggestion as it could enhance the applicability and relevance of the paper. Second, it points out that the citations seem disordered, which is a practical issue that the authors should address to improve the clarity and professionalism of their work. However, the comment could be more helpful if it provided specific guidance on how to reorder or clarify the citations. Overall, the feedback is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ICLHAR, noting that it has improved consistency and verifiability but has negatively impacted accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss or acknowledge the impact of ICLHAR on accuracy scores. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that while ICLHAR improves consistency and verifiability, it negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the main text, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has negatively impacted accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. While the comment provides specific numbers and references a particular dataset (TRIP), it lacks detailed reasoning or evidence to fully substantiate the claim. The authors might need additional context or explanation to understand the implications of this change. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it significantly impairs accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs further exploration or explanation. By pointing out the tradeoff between consistency, verifiability, and accuracy, the comment provides the authors with a specific area to address and potentially improve their draft. However, it could be more helpful if it offered suggestions on how to discuss or acknowledge this issue in the main text. Overall, the comment is 4, as it directs the authors to a significant area of improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what steps to take to rectify the problems. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is vague and lacks specificity, as it does not provide examples or details about the specific writing issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains \"severe writing issues\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand and address the issues. Without detailed examples or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. Without concrete suggestions or examples, the authors may find it challenging to understand and rectify the problems. The comment highlights areas for improvement but lacks actionable feedback, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement in the introduction regarding the biological plausibility of backpropagation is too weak and contradicts the widely accepted view that backpropagation is biologically implausible. However, it does not provide explicit guidance on how the authors should revise this statement or what specific changes should be made to strengthen the argument. The action is implicit, as the authors need to infer that they should revise the statement to align with the accepted view, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"statement in the introduction regarding the biological plausibility of backpropagation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that it may be too weak and contradicts the widely accepted view that backpropagation is biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation is too weak, as it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide specific references or detailed reasoning to support this claim, making it 3. The authors would need to look into the literature to understand the basis of this assertion, which could be a challenge. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, questioning the statement regarding the biological plausibility of backpropagation. It suggests that the statement may be too weak and contradicts the widely accepted view that backpropagation is biologically implausible. This feedback is clear and actionable, as it prompts the authors to reconsider and strengthen their argument regarding the biological plausibility of backpropagation. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested alternative ways to present the information. Overall, the comment is 4, as it directs the authors to a critical area that needs improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or expand their exploration to other NLP tasks. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide specific guidance on how to address this issue. The authors may infer that it relates to the discussion or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. The lack of supporting details makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential area for expansion or further exploration, which could enhance the generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their work to other NLP tasks. While it points out a relevant area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. However, it does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should clarify or redefine the term to avoid misinterpretation. The comment lacks concrete details on how to implement this change, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 267\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology \"certificate\" and its potential misinterpretation due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests that the term \"certificate\" might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the potential misinterpretation. This lack of supporting information makes the claim difficult for the authors to address effectively, rendering it 2. Therefore, the comment aligns with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. This feedback is 3 as it points out a potential source of confusion that could impact the clarity of the paper. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative terminology or providing examples of how to clarify the context. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. However, the comment does not provide explicit guidance on how to address this issue or which specific realworld problems should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their experiments to include realworld data sets. While the suggestion is clear, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. However, it does not specify which part of the paper discusses the experiments or where the authors should include examples of realworld applications. The authors can infer that the comment relates to the experimental section, but it lacks full grounding. The comment is specific in suggesting the inclusion of realworld examples, but without explicit references to specific sections or examples, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that it would be interesting to show the performance of the method on realworld problems. However, the comment lacks specific examples or references to realworld problems where barycenters can be applied, making it difficult for the authors to understand the scope of the suggestion. The claim is 3 as it provides a general direction for improvement but lacks detailed justification or examples to fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to toy data and suggests that it would be beneficial to demonstrate the method\"s performance on realworld problems. This feedback is 3 as it points out an area for improvement and provides a direction for expanding the scope of the experiments. However, the comment lacks specific guidance on which realworld problems to consider or how to adapt the experiments to these settings. While it highlights an important area for enhancement, the feedback could be more actionable and detailed to fully support the authors in making improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This implies that the authors should explore this reformulation to improve the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not provide explicit instructions on how to implement this reformulation or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the steps to take and how to apply the suggested reformulation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the proxlinear subproblem can be reformulated using the conjugate function, which makes the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This claim is 3 as it provides a logical reasoning for the equivalence, suggesting that the reformulation could simplify the proxlinear algorithms for solving the stochastic problem in Eq.(1). However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation implies that the motivation for Algorithm 1 may be unclear or unnecessary, as the reformulation could simplify the proxlinear algorithms for solving the stochastic problem in Eq.(1). The comment provides a clear and actionable suggestion for the authors to explore this reformulation, which could lead to a more streamlined and efficient approach. However, the comment could be more helpful if it offered specific guidance on how to implement this reformulation or what changes to make in the draft. Overall, the feedback is 4 as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that knowledge distillation (KD) and label smoothing (LS) are not identical but suggests that KD can be viewed as a special form of LS under certain conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment provides some insight into the theoretical relationship between KD and LS but lacks specificity in terms of how this understanding should influence the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point makes a claim about the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment acknowledges the distinction between knowledge distillation (KD) and label smoothing (LS) but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides some insight into the theoretical relationship between the two concepts. However, the comment lacks depth and does not offer any actionable suggestions or guidance for the authors to improve their draft. It does not address specific weaknesses or areas for improvement in the paper, leaving the authors without a clear path for enhancement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it instructs them to make the captions more descriptive, which is a clear and concrete action. Second, it suggests explaining the scramble network better, which is also a direct and actionable request. The comment provides specific guidance on how to improve the clarity of the figures and the explanation of the scramble network, making it 5. The authors know exactly what steps to take to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the captions\" and \"the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the captions more descriptive and explaining the scramble network better. This provides clear guidance on what the authors should focus on to enhance their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive and that the explanation of the scramble network is lacking. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks concrete evidence or references to substantiate the need for more descriptive captions or a better explanation of the scramble network. As a result, the claim is considered 1, as it does not offer sufficient justification or evidence to support the suggestions for improvement.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the captions should be more descriptive, allowing readers to understand the figures without needing to search through the text for interpretation. This is a clear and concrete suggestion that can help improve the clarity and accessibility of the paper. Additionally, the comment requests a better explanation of the scramble network, which is a valuable suggestion for enhancing the paper\"s comprehensibility. However, the comment could be more helpful if it provided examples of how to make the captions more descriptive or offered specific guidance on explaining the scramble network. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for a justification of why this particular dimension of difficulty is interesting. This provides a clear and direct action for the authors to take, which is to provide a motivation or explanation for this choice. The comment is explicit and concrete, as it specifies exactly what the authors need to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the images used in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, asking for a justification of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. The comment does not provide any specific reasoning, examples, or references to support why this particular dimension of difficulty is interesting. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It questions the interest in this particular dimension of difficulty and asks for a justification. This feedback is 3 as it prompts the authors to clarify their reasoning and provide a motivation for this choice, which could enhance the paper\"s clarity and relevance. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It suggests that the comparison model cannot capture periodic relationships and questions whether adding periodicity to the spectral kernel would be enough to achieve similar results to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of periodicity on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It references the comparison model and the experiments, specifically mentioning Experiment 1b, which implies that the authors can identify the relevant parts of the paper being discussed. However, the comment does not specify what needs to be addressed or how the authors should investigate this issue further. While it provides some context, it lacks specificity in terms of actionable steps or detailed guidance. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It provides a logical reasoning by comparing the comparison model, which cannot capture periodic relationships, to the experiments where periodicity is involved. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to delve deeper into the experiments and results to fully understand and address the question posed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity versus compositionality. It highlights a potential limitation in the comparison model, which cannot capture periodic relationships, and questions whether adding periodicity to the spectral kernel would be sufficient to achieve similar results to the explicitly compositional model. This feedback encourages the authors to consider the role of periodicity in their results and to explore whether it could be a key factor in achieving the observed outcomes. However, the comment could be more helpful if it provided specific suggestions or examples on how to investigate this aspect further. Overall, the comment is 3 as it identifies a potential area for improvement and prompts the authors to consider an important aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model with a proofofconcept test, it should be clearer and justified with a future useful application. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue, such as suggesting specific comparisons or justifications to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context and justification for their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper\" and references a specific existing work, \"PhaseNetDas, Zhu et al. 2023,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of comparison with existing DAS earthquake detectors and the need for a clearer justification of the benefit of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It suggests that if the claim is about the paper being a foundation model, it should be clearer and justified with a future useful application. The comment provides a specific reference to PhaseNetDas, which supports the claim that such detectors exist. However, it lacks detailed reasoning or examples of how the proposed method could be beneficial or how it differs from existing methods. This makes the claim 3, as it provides a starting point for further exploration but requires more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors like PhaseNetDas. It points out that no comparison was made, nor was there a justification for the benefit of the proposed method over existing ones. The comment suggests that if the paper claims to be a foundation model, it should be clearer and provide a future useful application. This feedback is 4 as it identifies a significant gap in the paper and provides a clear direction for improvement. However, it could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on for justification. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this is a fundamental limitation or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the limitation or whether it should be explored further. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the limitation but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this is a fundamental limitation or if extending to longer subsequences without a sliding window is straightforward. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is significant or how it affects the approach. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It prompts the authors to consider whether this is a fundamental limitation of the approach or if extending to longer subsequences without a sliding window is straightforward. This feedback encourages the authors to reflect on the scope and applicability of their method, which is a valuable consideration for improving the draft. However, the comment does not provide specific suggestions or guidance on how to address this limitation or explore potential extensions. While it highlights an important area for consideration, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two distinct issues. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This implies that the authors should clarify the meaning of this term. Second, it points out the absence of related work, suggesting that the paper seems to be related but does not negate its novelty. While the comment identifies areas for clarification and suggests the inclusion of related work, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the term \"sqeuence of episodes\" and suggesting that practice and evaluation might be the types of sequences being referred to. Additionally, it points out the absence of related work, which is a specific area for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two distinct claims. The first claim questions the term \"sqeuence of episodes\" and suggests that practice and evaluation might be the types of sequences being referred to. This is a subjective opinion that requires clarification but lacks specific reasoning or evidence to support the claim. The second claim points out the absence of related work, suggesting that the paper seems related but does not negate its novelty. While this claim is 3, it lacks specific examples or references to support the assertion about related work. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper. First, it questions the term \"sqeuence of episodes\" at line 167, suggesting that practice and evaluation might be the types of sequences being referred to. This feedback is helpful as it prompts the authors to clarify the terminology used in their work. Second, the comment points out the absence of related work, noting that the paper seems related but does not negate its novelty. This is a valuable observation that could help the authors contextualize their work within the existing literature. However, the comment could be more helpful if it provided specific examples of related work or suggested how to address the issue of novelty. Overall, the comment is 4 as it directs the authors to clarify terminology and consider the broader context of their research."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should distinguish between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. While the comment implies that this distinction is necessary, it does not provide explicit guidance on how to make this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests distinguishing between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. The authors may infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests distinguishing between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds. However, it does not provide any specific reasoning, examples, or references to support why this distinction is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a distinction between the \"allornothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or why it is important. The authors are left with a general idea of what might need improvement but without actionable steps to take. Therefore, the comment is 2, as it offers some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the clarity of Theorem 8, which is crucial for understanding the linear convergence rates. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the proof of Theorem 8, but it does not specify how to do so or what changes are needed. This makes the action vague and leaves the authors uncertain about the steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the clarity of the proof of Theorem 8, particularly its location at the end of the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and has a proof that is not clear enough. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Theorem 8, which is crucial for understanding the linear convergence rates. It points out that the theorem is buried at the end of the appendix and that its proof is not clear enough. This feedback is valuable as it highlights a potential obstacle for readers who may struggle to understand the theoretical foundation of the paper. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the proof or where it could be relocated for better accessibility. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two separate issues. The first part addresses a claim made in the Related Work section regarding the Walkman algorithm, pointing out that it is not accurate to state that all works are based on simple SGD for decentralized optimization. This feedback is explicit and provides a clear action for the authors to correct the statement. The second part identifies a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference. This is also an explicit action for the authors to clarify the reference. Both parts of the comment are clear and direct, providing the authors with specific actions to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the inaccuracy of the statement about the Walkman algorithm and the lack of a clear reference for the pronoun \"it.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim challenges the statement that all works are based on simple SGD for decentralized optimization, pointing out that the Walkman algorithm (Mao et al., 2020) uses ADMM with two versions. This claim is 4 as it provides specific details about the Walkman algorithm, but it could be strengthened by referencing the specific sections where the SGD claim is made. The second claim points out a grammatical issue with the pronoun \"it\" lacking a clear reference. This is a factual observation and does not require verification, as it is a straightforward request for clarification. Therefore, the overall comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first point addresses a claim made in the Related Work section regarding the Walkman algorithm, pointing out that it is inaccurately described as being based on simple SGD for decentralized optimization. This feedback is helpful as it corrects a potential misrepresentation of existing work, which is important for maintaining the integrity of the paper. The second point identifies a grammatical issue in Section 3, where the pronoun \"it\" lacks a clear reference. This feedback is also actionable, as it directs the authors to clarify the reference, which can improve the clarity and coherence of the text. However, the comment could be more helpful if it provided additional context or suggestions on how to address these issues. Overall, the feedback is 4, as it identifies specific areas for improvement and provides clear guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should expand their comparison to include a broader range of NAS approaches, but the comment lacks concrete details on which specific approaches to consider or how to incorporate them into the analysis. Therefore, the comment is 3, as it points out a gap but does not fully direct the authors on how to fill it.", "grounding_specificity_rationale": "The comment addresses the analysis of BRPNAS, specifically noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This provides full grounding as it explicitly mentions the specific part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies what is missing in the analysis, namely a comparison with other NAS approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of BRPNAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. The comment provides a specific critique by mentioning the omission of certain NAS approaches, which gives the authors a clear direction for improvement. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the importance of including these additional approaches and how they might impact the analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This feedback is clear and actionable, as it highlights an area where the authors could expand their analysis to provide a more comprehensive evaluation. By suggesting the inclusion of additional NAS approaches, the comment offers a concrete direction for improvement, which can help the authors enhance the depth and breadth of their analysis. However, the comment could be more helpful if it provided specific examples or references to these additional approaches, which would further guide the authors in making these additions. Overall, the comment is 4, as it provides a clear and actionable suggestion for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more experiments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. Additionally, while the comment provides some guidance on what could be improved, it does not specify how the authors should address these issues. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that the current results are insufficient or that the suggested additions would be beneficial. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiment results, suggesting that the inclusion of attacks with different strengths and an exploration of how different thresholds influence detection performance could enrich the results. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis. However, the comment could be more helpful if it offered specific suggestions on how to implement these enhancements or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, and suggests that it may have wider applications in the real world compared to digit or text images. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or whether the authors should explore the method\"s applicability to natural images. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, and suggests that it may have wider applications in the real world compared to digit or text images. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its questioning of the method\"s applicability but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, such as CIFAR10, and suggests that it may have wider applications in the real world compared to digit or text images. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the proposed method to natural images, such as CIFAR10, and suggests that it may have wider applications in the real world compared to digit or text images. While this comment identifies a potential limitation of the method, it does not provide any specific guidance or suggestions on how the authors might address this issue or explore its applicability to natural images. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit or implicit suggestions on how to improve the organization of the prompts. The authors are left without guidance on how to address this issue, making it difficult for them to know what changes to make. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the prompts, noting that they are not wellorganized and that all sentences are squeezed together. This provides clear guidance on what needs to be addressed to improve the presentation of the prompts. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a potential area for improvement in the presentation of the prompts. However, it lacks depth and does not provide specific suggestions or guidance on how to reorganize the prompts or improve their clarity. While it highlights a weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies issues with the clarity of the figures, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This provides clear and direct actions for the authors to take, which is to improve the clarity of the figures and ensure all components are labeled. The feedback is explicit and concrete, offering specific guidance on how to enhance the visual presentation of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2\" and \"some modules,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the figures, such as the confusion in the relation of subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning that figure 2 is confusing due to the relation of its subfigures and that some modules are not labeled. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback is clear and actionable, as it provides the authors with concrete areas to improve the visual presentation of their work. By addressing these issues, the authors can enhance the readability and understandability of their figures, which is crucial for the paper\"s overall impact. However, the comment could be more helpful if it offered suggestions on how to improve the labeling or organization of the figures. Overall, the comment is 4, as it directs the authors to specific areas that need improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically the use of perplexity as a measure of the model retaining semantic information after finetuning. It highlights the need to consider domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not provide explicit guidance on how to address these concerns or control these factors. The authors are left to infer that they need to explore alternative measures or methods to mitigate these issues, but without concrete suggestions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about \"questionable design choices\" related to the use of perplexity as a measure of the model retaining semantic information after finetuning. It mentions the need to consider aspects of domain drift and catastrophic forgetting, suggesting that these factors should be controlled. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address these concerns. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in identifying the issue with the design choices and the need to control domain drift and catastrophic forgetting, but without explicit references to specific sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of the model retaining semantic information after finetuning, suggesting that it may not fully account for domain drift and catastrophic forgetting. The comment questions how these factors are controlled, implying that the authors should provide a more comprehensive explanation or justification for their design choices. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact issues and how to address them, which adds to the complexity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of the model retaining semantic information after finetuning, suggesting that it may not fully account for domain drift and catastrophic forgetting. This is a relevant point that could impact the validity and robustness of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or explore alternative measures. While it identifies a potential issue, it lacks actionable feedback, making it 3. The authors are left to infer that they need to consider these factors, but without detailed guidance, the comment does not fully support their improvement efforts. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training of LLMs on trillions of tokens, implying that the dataset is insufficient. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size or diversity, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training of LLMs on trillions of tokens, implying that the dataset is insufficient. However, the comment does not specify which part of the paper discusses the dataset or training data, making it weakly grounded. The comment is specific in detailing the concern about the dataset size and its implications for capturing user traits and personalities. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training of LLMs on trillions of tokens, suggesting that the dataset is insufficient. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is based on a general comparison, which makes the claim 3. The authors would need to consider this comparison and potentially provide additional context or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training of LLMs on trillions of tokens, suggesting that the dataset may be insufficient. This feedback is 3 as it highlights a potential limitation in the dataset size, which could impact the model\"s ability to generalize. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or providing examples of how to improve the dataset. While it identifies a relevant concern, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or explore the applicability to other types of features. The comment implies that the authors should consider extending their method to handle real and categorical features, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the limitation of the work and suggests that the method should be tested with real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the method to real and categorical features, noting that the work currently only uses binary features. This is a subjective opinion that lacks specific examples or references to support the claim. The comment does not provide detailed reasoning or evidence to substantiate why the method might not be applicable to other types of features, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the work by noting that it only uses binary features, whereas realworld data often includes a mix of binary, real, and categorical features. This observation is relevant and highlights a potential gap in the applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore the applicability to other types of features. While it points out a weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of the issue but without detailed steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing need improvement or which points are unclear. The comment lacks explicit or implicit actions that the authors can take to address the issue. Without concrete suggestions or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not specify which points are unclear or provide any guidance on how to improve the writing. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not mention a specific section or part of the paper and does not provide detailed feedback on what needs to be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"The writing should be improved\" and mentions that \"some points in the paper are unclear.\" However, it does not provide any specific examples or details about what aspects of the writing are unclear or how they could be improved. Without supporting evidence or examples, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it lacks specificity and does not provide any detailed guidance or examples on what aspects of the writing need improvement or which points are unclear. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to address the issues identified. This makes the comment 2, as it identifies a general area for improvement but does not offer any concrete steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors use other metrics, specifically BERTScore, to evaluate the results. This is an explicit action with a concrete suggestion, as it provides a specific alternative metric that the authors can use. The comment is clear and direct, leaving no ambiguity about what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify where to implement the change. Additionally, while the suggestion is specific in terms of the metric to use, it lacks detail on why BERTScore might be more appropriate or how it would improve the evaluation. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning or justification for why BERTScore would be a better choice or how it would improve the evaluation. Without supporting evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests using alternative metrics, such as BERTScore, to evaluate the results. While this provides a specific suggestion for improvement, it lacks detailed reasoning or explanation about why BERTScore might be more appropriate or how it would enhance the evaluation. The comment does not offer guidance on how to implement this suggestion or address potential challenges, leaving the authors with a general idea but limited actionable steps. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements and computational complexity. While the comment identifies areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The action is implicit, as the authors need to infer that they should include a more detailed discussion on scalability bounds. However, the comment lacks concrete details on how to conduct this analysis or what specific aspects to focus on, making it 3. The authors know they need to expand the discussion on scalability but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Limited Discussion of Scalability Bounds,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of thorough exploration of the upper limits of FedDES\"s scalability, including no clear discussion of memory requirements or computational complexity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements or computational complexity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the limited discussion on scalability bounds. It highlights the lack of thorough exploration of the upper limits of FedDES\"s scalability and the absence of clear discussions on memory requirements or computational complexity. This feedback is clear and actionable, as it directs the authors to expand their discussion on scalability, which is an important aspect of evaluating the practicality and applicability of their method. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to consider. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It asks whether this means the base node affects the ordering, key nodes for attention, and ultimately the model performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what specific aspects of the paper need clarification or improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"NodeSort\" and \"base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node, asking whether this affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It does not contain a claim or opinion that requires verification. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It seeks clarification on whether this affects the ordering, key nodes for attention, and ultimately the model performance. While the comment identifies a potential area of confusion, it does not provide any specific suggestions or guidance on how the authors might address this issue or clarify the implications of \"NodeSort\" in their paper. The lack of actionable feedback limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i), implying that the current direction might not align with this purpose. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the direction of the arrow. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the purpose of the arrow and its direction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in Figure 2 and suggests that it should be from the latent space to n^(i) instead of from a Gaussian space. This provides clear guidance on what needs to be clarified or corrected in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of an arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space. The comment provides a logical reasoning by questioning the purpose of the arrow, implying that the current direction might not align with the intended influence on n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is sound, the lack of additional evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of an arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is 3 as it prompts the authors to clarify the purpose and direction of the arrow, which could be important for understanding the model\"s architecture and functionality. However, the comment lacks depth and does not provide suggestions on how to address the issue or improve the clarity of the figure. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the paper, namely that many abbreviations lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to avoid confusion. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of abbreviations lacking definition, providing a concrete example with \"AR\" in Table 5. This feedback is clear and actionable, guiding the authors on what needs to be addressed to improve the clarity of their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, providing a specific example with \"AR\" in Table 5. This claim is verifiable as it is supported by a concrete example, which helps the authors understand the issue and take corrective action. The mention of \"domain adaptation tasks and algorithms\" provides a clear context for the abbreviation, making the claim 4. However, the comment could be strengthened by suggesting how the authors might address this issue, such as by providing a glossary or defining the abbreviations in the text. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that many abbreviations lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to improve clarity. By addressing this issue, the authors can enhance the readability and understandability of their work. However, the comment could be more helpful if it suggested ways to present the definitions or provided additional guidance on how to handle abbreviations effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not provide any explicit guidance or suggestions on what these considerations might be or how the authors should address this issue. The action is implicit and vague, leaving the authors without a clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the technical considerations but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, the comment does not provide any supporting evidence, reasoning, or references to justify why \"advantage\" is more common in practice or what specific technical considerations might be involved. This lack of supporting information makes the claim difficult for the authors to address or understand, rendering it 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. While it identifies a potential area of interest, the comment lacks depth and does not provide any specific guidance or suggestions on how the authors might address this issue or explore the technical considerations. The feedback is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed insights to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the appropriateness of the term \"Unsupervised Online Adaptation\" given that the model requires a training set with documents, queries, and labels, which implies the need for annotations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what changes should be made or how the authors might clarify the terminology. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the appropriateness of the term \"Unsupervised Online Adaptation\" due to the requirement of a training set with documents, queries, and labels, which implies the need for annotations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"Unsupervised Online Adaptation\" due to the requirement of a training set with documents, queries, and labels, which implies the need for annotations. This claim is 3 as it provides a logical reasoning for the potential inconsistency in the terminology. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the terminology used in the paper, specifically questioning the appropriateness of the term \"Unsupervised Online Adaptation\" given that the model requires a training set with documents, queries, and labels, which implies the need for annotations. This feedback highlights a critical issue that could impact the clarity and accuracy of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the terminology. While it points out a significant problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an issue with the performance comparison in Table 1, specifically noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This implies that the comparison may not be fair due to the differing sample weights. However, the comment does not explicitly instruct the authors to address this issue or suggest how to make the comparison fair. The action is implicit and somewhat vague, as the authors can infer that they need to address the fairness of the comparison but are not provided with specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance comparison, noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed to ensure a fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This claim is 3 as it provides a specific reason for the perceived unfairness, namely the differing sample weights. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the different sample weights might impact the comparison or providing specific examples of how this affects the results. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This observation highlights a potential unfairness in the comparison, which could impact the validity of the results. However, the comment does not provide detailed guidance or suggestions on how to address this issue or ensure a fair comparison. While it points out a critical flaw, it lacks actionable advice or examples to help the authors improve their draft. Therefore, the comment is 3, as it identifies a weakness but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard safety violations in the first 1000 episodes. It questions the reason for presenting the results in this way, implying that the authors should clarify or justify their approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to improve the presentation of results. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the presentation but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the specific issue of disregarding safety violations in the first 1000 episodes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the problem with the presentation of results and questions the reason for this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted manner and questions the reason for disregarding safety violations in the first 1000 episodes. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence or detailed justification renders the claim 2, as it provides some basis for the critique but requires more substantial support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that they are convoluted and disregard safety violations in the first 1000 episodes. It questions the reason for this approach, which is a clear and actionable point for the authors to address. However, the comment could be more helpful if it provided suggestions on how to clarify the presentation or address the safety concerns. Despite this, the feedback is 3 as it directs the authors to a critical area that needs improvement, prompting them to reconsider their presentation and potentially revise their methodology or results. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment does not provide specific guidance on how to improve the allocation or what aspects of the figure could be revised. The feedback lacks concrete details or actionable steps for the authors to follow, leaving them uncertain about how to address the issue. As a result, the comment is vague and does not offer a clear path for improvement, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions \"Figure 1\" and suggests that its allocation is too naive, implying that the authors could have edited the space of the main paper more wisely. However, it does not specify which part of the paper this figure is located in, making it weakly grounded. The comment is specific in identifying the issue with the figure\"s allocation, but without explicit references to sections or specific elements, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific reasoning or examples to support this claim. Without detailed justification or references to alternative allocations or editing strategies, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment lacks specificity and does not provide actionable guidance on how the authors might improve the allocation or what specific aspects of the figure could be revised. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors, who may struggle to understand how to address the issue effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the generalizability of their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the planbased method and its requirement for manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also mentions the comparison with learned plan methods and the difficulty in generalizing to new datasets without ground truth summaries, as indicated by Table 2. However, the comment does not specify which part of the paper discusses these issues or where Table 2 is located, making it weakly grounded. The comment is specific in detailing the concerns about the planbased method and its limitations, but without clear grounding, it is challenging for the authors to pinpoint the exact sections that need revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. The comment provides a logical reasoning by highlighting the impracticality of manual plan design and the lack of comparability with predefined plans. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to consider the implications of this claim and potentially provide additional evidence or comparisons to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the planbased method, specifically that it requires manual design of a plan based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. This feedback highlights a critical issue with the generalizability of the proposed method, particularly in the absence of ground truth summaries. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. While it raises an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some conclusions in the paper are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It implies that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should explore more combination methods or consider the referenced works, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is 3, as it identifies an area for improvement but does not provide clear instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific conclusions that are not convincing, allowing the authors to identify the exact parts of the paper being addressed. It also provides specific examples and references to recent works that have shown potential in featurereplay methods for continual learning, such as R1, R2, and R3. This level of detail helps the authors understand what needs to be addressed and how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically questioning the claim that continuous learning with unlabeled data accumulates noise. The reviewer suggests that the results might be due to the limited exploration of combination methods and references recent works that have shown potential in featurereplay methods for continual learning. However, the comment lacks specific examples or detailed comparisons to substantiate the claim that the results are not convincing. While it provides some context by mentioning recent works, the reasoning is not fully developed, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the conclusions drawn in the paper, questioning their convincingness. It provides a detailed critique by suggesting that the results might be due to the limited exploration of combination methods. The reviewer also references recent works that have shown potential in featurereplay methods for continual learning, such as R1, R2, and R3, which could be relevant to the authors\" work. This feedback is 4 as it points out a potential weakness in the paper and offers references that could guide the authors in improving their draft. However, it could be more helpful if it included specific suggestions on how to address the issue or integrate the referenced works into the paper. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not provide explicit or implicit actions for the authors to take. The questions posed are more exploratory in nature, seeking clarification rather than directing the authors to make specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, while the comment identifies potential issues with the accuracy and differences in results, it does not provide specific guidance on how to address these concerns. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions seeking clarification on the accuracy of the ground truth and the differences observed in the results. These questions are factual and do not contain subjective opinions, claims, or suggestions that require verification. They are purely descriptive and do not necessitate any justification or evidence to be understood. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. It prompts the authors to consider whether the small differences are noticeable or due to noise or randomness in the training process. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address these concerns. Without detailed feedback or recommendations, the authors are left with a general understanding of the issues but without a clear path for improvement. Therefore, the comment is 3, as it identifies areas for consideration but does not fully support the authors in making meaningful changes to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies an issue with the wording in the conclusion, specifically mentioning that it is \"overly exaggerated\" and \"flamboyant.\" The reviewer suggests that the word choice is too flamboyant in multiple places in the writing. This feedback provides a clear and direct action for the authors to take, which is to revise the word choice in the conclusion to make it less exaggerated and more appropriate. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the wording being \"overly exaggerated\" and suggests that the word choice is \"flamboyant\" in multiple places. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide any supporting evidence or examples to substantiate this claim. Without specific examples or references to similar work, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the conclusion, noting that the wording is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it directs the authors to revise the language to make it more appropriate and less sensational. However, the comment could be more helpful if it provided specific suggestions or examples of alternative wording that would better convey the intended message. Despite this, the comment still offers valuable guidance for improving the draft, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests exploring other bit operations, which is a direct request for additional analysis. It also asks for more explanations regarding Fig. 5a, providing a clear action for the authors to enhance the clarity of their work. Additionally, it requests an explanation of how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, which are specific areas needing clarification. Finally, it suggests analyzing energy consumption as a reference, providing a concrete suggestion for improvement. Each of these actions is explicit and concrete, giving the authors clear guidance on how to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"11,\" \"Fig. 5 a,\" and \"aer format,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear requests for additional explanations and analysis, such as exploring other bit operations, clarifying the appearance of Fig. 5a, and explaining how the input is handled in the \"aer format.\" Additionally, it suggests analyzing energy consumption as a reference, which provides a specific area for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, but it lacks specific evidence or detailed reasoning to support each claim. The comment suggests exploring other bit operations, questions the appearance of Fig. 5a, and asks for explanations regarding the handling of DVS input in the \"aer format.\" It also suggests analyzing energy consumption as a reference, but without providing specific examples or references to support these claims. The lack of detailed justification or evidence makes the claims difficult for the authors to address effectively, rendering the comment barely verifiable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the paper. It starts by expressing appreciation for the work on bit operations, suggesting that the authors explore other bit operations, which could enhance the depth of their analysis. The comment also questions the appearance of Fig. 5a, prompting the authors to provide more explanations, which could clarify any confusion or ambiguity in the figure. Additionally, it raises a question about how the input is handled when it is in the \"aer format\" and how DVS input is dealt with, indicating areas where the authors might need to provide more detailed explanations. Finally, the comment suggests analyzing energy consumption as a reference, which could strengthen the paper by providing a more comprehensive analysis. These suggestions are clear and actionable, offering the authors specific ways to enhance their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the approach by stating that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or improve their work. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach by mentioning the introduction of multigranularity and multiscale to enhance model performance, which is a common approach in convolutional networks. It also discusses the use of algorithms from object detection and their limitations in MLMs. However, the comment does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. While the comment provides some specificity by detailing the critique of the approach, it does not specify what needs to be addressed or improved. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim 3, as it provides a general critique but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment critiques the novelty of the approach by pointing out that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks and not innovative when applied to Masked Language Models (MLMs). It also suggests that some algorithms used in the article for object detection only enhance information on the input side, while MLMs can already accomplish object detection tasks. This feedback highlights a potential weakness in the paper\"s contribution and provides some insight into the limitations of the approach. However, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. While it identifies an area for improvement, the comment could be more helpful with additional details or constructive feedback. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples, which could lead to lower generalization performance. The reviewer suggests conducting more experiments on different downstream tasks and across various domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to conduct these additional experiments or what specific metrics or analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and the specific aspects to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing and generalization performance. It suggests conducting more experiments on different downstream tasks and across various domains. However, the comment does not specify which part of the paper these concerns or suggestions relate to, making it difficult for the authors to pinpoint the exact sections that need revision. The authors can make an educated guess that it might relate to the experimental section, but the comment lacks full grounding. It is specific in detailing the concerns and suggestions, but the lack of explicit references to specific sections or parts of the paper makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples. The reviewer suggests that this could lead to lower generalization performance and expresses concern that the experiments conducted did not fully address these issues. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments are insufficient. The suggestion to conduct more experiments on different downstream tasks and across various domains is vague and does not provide a clear path for the authors to follow. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the lack of perturbation noise in selecting positive samples. It suggests that this could lead to lower generalization performance and recommends conducting more experiments on different downstream tasks and across various domains to address these concerns. While the comment identifies a potential issue and provides a direction for further experimentation, it lacks specific guidance on how to conduct these experiments or what metrics to use. The feedback is 3 as it points out a potential weakness and suggests a way to address it, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify or specify these aspects, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this concern. The comment is 1 as it does not identify a specific part of the paper, and it is also not specific because it lacks detailed guidance on what needs to be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the types of situations or social norms discussed in the main paper are not clear, specifically mentioning physical and psychological safety. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the information. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the inclusion of more baselines and domains to be tested, as well as stronger empirical results with different design choices. It also asks for stronger motivation for the current choices of weighting and learning density functions. This feedback provides clear and specific actions for the authors to take, such as conducting additional experiments and providing more detailed justification for their methods. The explicit nature of the request and the concrete suggestions make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for more baselines and domains to be tested, and it references the choices of weighting and the way of learning density functions, which the reviewer has previously mentioned. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of more baselines and domains, and stronger empirical results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks sufficient baselines and domains for comparison, and it questions the motivation behind the chosen weighting and learning density functions. While the comment highlights areas for improvement, it does not provide specific examples or references to support the claim that more baselines and domains are needed. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the necessity of these additions based on the reviewer\"s general feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the need for more baselines to be compared and more domains to be tested. It also questions the motivation behind the choices of weighting and the way of learning density functions, suggesting that stronger empirical results are required. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s robustness and validity. However, the comment could be more helpful if it offered additional guidance on how to select and implement these baselines or domains, or if it provided examples of alternative weighting and learning density functions that could be explored. Overall, the comment is 4, as it directs the authors toward meaningful improvements but could benefit from more detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights ambiguity in Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies areas of ambiguity and potential issues, it does not provide explicit guidance on how to address these concerns or clarify the symbols. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the symbols and address the issues of redundancy and interference, but they are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that some symbols are not explained clearly. Additionally, it raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the ambiguity of Figure 2, specifically mentioning that some symbols are not explained clearly. It also expresses curiosity about potential information redundancy and interference in the multisphere icosahedral discretization process. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of supporting evidence or detailed explanation renders the claim 3, as it provides a general direction for improvement but does not fully guide the authors in making the necessary changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multisphere icosahedral discretization process. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out specific weaknesses, but it lacks actionable advice or examples to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, specifically the assumption that the spectrum of a kernel is subgaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this limitation or whether it should be explored further. The comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the limitation of the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, whose spectrum decays polynomially. However, the comment does not specify which part of the paper discusses these assumptions or limitations, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the implications for the results, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. The reviewer provides a logical explanation by contrasting the behavior of Gaussian and Matern kernels, which supports the claim. However, the comment could be strengthened by providing specific examples or references to Matern kernels to further substantiate the claim. Overall, the comment is 4, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that the assumption of a subgaussian spectrum for kernels is restrictive, as it excludes other popular classes like Matern kernels. This feedback is valuable as it highlights a potential gap in the paper\"s scope and suggests that the authors might need to consider broader applicability. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand their analysis to include other kernel types. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide any specific guidance or examples on how to achieve this simplification. The action is implicit, as the authors can infer that they need to make their writing clearer, but it is vague because it lacks concrete details on how to simplify the writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and can be simplified. However, it does not specify which parts of the paper are problematic or provide examples of where the writing is unclear. This makes it difficult for the authors to identify the exact areas that need improvement. The comment lacks both grounding and specificity, as it does not provide any details or references to specific sections or elements of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests it can be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a general issue with the writing being difficult to follow in many places, suggesting that it can be simplified. However, it lacks specificity and does not provide any actionable guidance or examples on how to achieve this simplification. Without detailed feedback or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of their writing. Therefore, the comment is 2, as it points out a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited scope of the method\"s testing, noting that it is only evaluated on two datasets. The comment suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. However, it does not provide specific guidance on which additional datasets to use or how to conduct the evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to expand their dataset testing but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the limited scope of the method\"s testing, noting that it is only evaluated on two datasets. However, it does not specify which part of the paper this issue is addressed in, such as the results section or the discussion of experimental methodology. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment pertains to. The comment is specific in its suggestion to test the method on more datasets, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is only tested on two datasets, suggesting that the authors should test it on more datasets to gain a better understanding of its performance. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how it could improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method is only tested on two datasets. It suggests that the authors should consider testing their method on more datasets to gain a better understanding of its performance. This feedback is 3 as it points out a potential area for improvement, encouraging the authors to expand their experimental evaluation. However, the comment lacks specific guidance on which additional datasets to use or how to conduct the evaluation, which would make it more actionable. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the differences between the two normalization methods. Without actionable suggestions or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Batch Normalization\" and \"Online Normalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. The comment raises a question about the difference between the two normalization methods, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the claim or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. It points out a potential confusion in the paper regarding the estimation of the real gradient distribution. However, the comment does not provide any specific suggestions or guidance on how the authors might clarify this issue or address the confusion. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a contradiction between the statement that overparametrization leads to overfitting and worse performance, and the observation that it is beneficial for supervised learning of deep neural networks in practice. The reviewer also mentions theoretical works that support the benefits of overparametrization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this contradiction or incorporate the theoretical works into their paper. The action is implicit and vague, as the authors are left to infer that they should clarify or reconcile the apparent contradiction, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 4748, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a contradiction between the statement about overparametrization leading to overfitting and the observation that it is beneficial for supervised learning of deep neural networks in practice. The comment further supports this observation by referencing theoretical works that show the benefits of overparametrization. This provides clear guidance on what needs to be addressed in the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparametrization is beneficial for supervised learning of deep neural networks in practice, contradicting the statement that it leads to overfitting and worse performance. The reviewer supports this claim by referencing theoretical works that show the benefits of overparametrization. However, the comment lacks specific references to these theoretical works, which would strengthen the verifiability of the claim. Additionally, the reviewer does not provide detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential contradiction in the paper regarding the impact of overparametrization on deep neural networks. It points out that the statement about overparametrization leading to overfitting and worse performance seems to contradict the observation that it is beneficial for supervised learning in practice. The reviewer also references theoretical works that support the benefits of overparametrization, which could be valuable for the authors to consider. However, the comment does not provide specific suggestions on how to reconcile this contradiction or integrate the theoretical works into the paper. While it highlights an important issue, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be conducted on more than one game environment, implying that the authors should expand their experimental scope. However, the comment does not provide specific guidance on which additional game environments should be considered or how to conduct these experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be conducted on more than one game environment, implying that the current scope is limited. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or results. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify the exact area needing revision. Additionally, the comment lacks specificity regarding which additional game environments should be considered or how the experiments should be expanded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment lacks specific reasoning or evidence to support why additional game environments are needed or how this would improve the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point for improvement. However, the comment lacks specificity and does not provide guidance on which additional game environments should be considered or how the experiments should be expanded. This makes it 3, as it points out a potential area for improvement but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items are comprised of all items available in memory minus those seen. The reviewer questions how such an exhaustive list could be effectively implemented and tested with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the argument about recalling items based on lists in the context of recognition. It provides a detailed critique of the feasibility of this approach, particularly in the common case of recognition where new items comprise all items available in memory minus those seen. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in detailing the issue with the approach, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items comprise all items available in memory minus those seen. The reviewer questions how such an exhaustive list could be effectively implemented and tested with simulations. While the comment provides a logical critique, it lacks specific examples or references to support the claim. The reasoning is 3, as it highlights a potential challenge in the approach, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items comprise all items available in memory minus those seen. It questions how such an exhaustive list could be effectively implemented and tested with simulations. While the comment identifies a potential weakness in the approach, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a critical area for consideration, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar scale pretrained model as the proposed method. It highlights a potential issue with the experimental setup, suggesting that the proposed method without SSL performs inferior to most compared methods. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the pretraining conditions for the compared methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning the fairness due to the pretraining stage and the potential difference in pretrained models used by the compared methods. The comment specifies the concern about the performance of the proposed method without SSL compared to other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental comparison is unfair due to the pretraining stage of the proposed method. It questions whether the compared methods were initialized with the same or similar scale pretrained model, which could impact the fairness of the comparison. The comment provides a logical reasoning by pointing out the potential discrepancy in pretraining conditions, which could affect the results. However, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable argument but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, questioning the fairness of the comparison due to the pretraining stage of the proposed method. It highlights a specific concern about the initialization of the compared methods and suggests that the proposed method without SSL performs inferior to most of the compared methods. This feedback is clear and actionable, as it prompts the authors to clarify the pretraining conditions for the compared methods and potentially adjust the experimental setup to ensure a fair comparison. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to improve the fairness of the comparison. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests exploring these options for better performance. The comment explicitly instructs the authors to update the paper with the performance of their method using better metadata embeddings. This feedback is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metadata used for zeroshot learning on the CUB dataset and suggests exploring better metadata embeddings options, referencing a specific paper for further guidance. This provides clear guidance on what needs to be addressed and how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that while the use of \"attribute\" metadata for zeroshot learning on the CUB dataset is good for fair comparison, better metadata embeddings options are available. It references a specific paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides a basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these better metadata embeddings options could improve performance. The reference to the external work is a good start, but the claim could be more fully verified with additional supporting evidence or examples. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the use of \"attribute\" metadata is good for fair comparison but suggests that better metadata embeddings options are available. It references a relevant paper, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which could offer insights into improving performance. The comment is actionable as it suggests exploring better metadata embeddings and provides a specific reference for further investigation. This feedback is clear and constructive, offering the authors a concrete direction for enhancing their work. Therefore, it is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the paper regarding the nature of the contribution related to ECE_sweep. It explicitly states that the contribution amounts to a way to choose the number of bins using data, which is akin to autotuning a hyperparameter in the estimate. The reviewer suggests that the paper should be more upfront about this contribution. While the comment identifies the issue and provides a clear direction for improvement, it does not offer specific guidance on how to rephrase or present the contribution in the paper. The action is explicit but somewhat vague, as the authors know they need to clarify the contribution but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the contribution, namely that it is not clearly described in the text. The reviewer explains that the contribution amounts to a way to choose the number of bins using data, which is akin to autotuning a hyperparameter in the estimate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the nature of the contribution related to ECE_sweep is not clearly described in the text. The reviewer provides a detailed explanation of what the contribution entails, specifically that it involves choosing the number of bins using data, akin to autotuning a hyperparameter in the estimate. This explanation is logical and provides a clear understanding of the issue. However, the comment could be strengthened by referencing specific sections of the paper where this lack of clarity is observed, which would make the claim 5. As it stands, the comment is 4, as it provides a solid foundation for the claim but lacks detailed references to support it fully.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the nature of the contribution related to ECE_sweep is not clearly described. It provides a clear explanation of what the contribution entails, specifically that it involves choosing the number of bins using data, akin to autotuning a hyperparameter in the estimate. The reviewer suggests that this is not fundamentally different from existing approaches and that the paper should be more upfront about its contribution. This feedback is actionable as it directs the authors to clarify their contribution and its significance. However, the comment could be more helpful if it offered suggestions on how to rephrase or present the contribution in a clearer manner. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of different projection matrices on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an investigation into the resilience of the metric, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. The reviewer acknowledges that pathological projection matrices could skew the MFTMA capacity and width scores, but notes that this is unlikely with random projections. The comment provides a logical reasoning for the concern and suggests a potential area for further investigation. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this suggestion to fully address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the variability in results due to the choice of random projection matrix. It suggests that the authors should investigate the resilience of the metric to different projection matrices, which is a reasonable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Additionally, the mention of \"pathological projection matrices\" adds a layer of complexity that could be clarified further. Overall, the comment identifies a potential issue and offers a direction for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This implies that the authors should expand the evaluation of FGT to include its use in comparing the proposed method with other methods. However, the comment does not provide specific guidance on how to implement this change or what aspects of FGT should be evaluated. The action is implicit and somewhat vague, as the authors can infer the need for a broader evaluation but may not know exactly how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This claim is based on a logical reasoning that the evaluation of FGT should be comprehensive and not limited to a specific study. However, the comment lacks specific examples or references to support why this evaluation is necessary or how it would improve the paper. The reasoning is 3, as it provides a logical basis for the suggestion, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is only used in the ablation study and suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to include a more comprehensive assessment of the proposed method and its comparisons. However, the comment could be more helpful if it offered suggestions on how to implement this expanded evaluation or what specific aspects of FGT should be evaluated. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions would be necessary to enhance the originality of their paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the paper\"s contribution to the understanding of the winnertakeall property, questioning the novelty of the findings given the simplified settings and the fact that most findings have been reported in previous works. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty in its understanding of the winnertakeall property, particularly given its simplified settings and the fact that most findings have been reported in previous works. The reviewer supports this claim by referencing previous works that have used the winnertakeall property, such as NNbased clustering algorithms. However, the comment could be strengthened by providing specific examples or references to the previous works that have reported similar findings, which would enhance the verifiability of the claim. As it stands, the comment is 4, as it provides a logical reasoning and some supporting evidence, but it lacks detailed references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winnertakeall property, given its simplified settings and the fact that most findings have been reported in previous works. This feedback is 3 as it identifies a potential weakness in the paper\"s originality and prompts the authors to consider how their work differs from existing literature. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their findings. To be more helpful, the comment could provide examples of how previous works have addressed similar topics or suggest ways to differentiate the current work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" use of the Witness oracle, specifically mentioning its \"polynomial time\" complexity in the tabular case. However, it does not specify which part of the paper discusses this aspect, making it weakly grounded. The comment is specific in its critique, suggesting that the approach does not address the problem in a direct way. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors are not addressing the problem in a direct way by leveraging the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the authors\" approach by suggesting that leveraging the complexity of checking on the Witness oracle does not address the problem in a direct way. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer any guidance on how the authors might address the issue or what alternative approaches could be considered. Without detailed feedback or constructive suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to clarify or address the confusion, making it 1. The authors are left without a clear understanding of what steps to take to improve their draft based on this feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion regarding the statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a specific statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. While the comment identifies a potential issue, it lacks depth and does not provide any actionable suggestions or guidance on how the authors might clarify or address this confusion. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an area of confusion but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, which is crucial for task domain adaptation. While the comment highlights an important area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more detailed information on this aspect, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a gap in the paper but does not offer specific guidance on how to fill it.", "grounding_specificity_rationale": "The comment raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what needs to be addressed, namely the need for more information on crossdomain morphologic segmentation and its potential variations. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. The reviewer questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of supporting evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of this issue and how it relates to their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the application of morphologic segmentation across different domains. It questions whether morphologic segmentation should be conducted differently for various domains and highlights the importance of this consideration in the context of task domain adaptation. The comment points out that the paper assumes morphologic segmentation to be invariant across domains, which is a critical oversight. By raising this issue, the comment provides the authors with a clear direction for improvement, encouraging them to explore and discuss the applicability of morphologic segmentation across different domains. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the feedback is 4 as it directs the authors to a critical area that needs further exploration and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the object detection based attention, specifically whether it is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detection based attention, seeking clarification on whether it is performed on the image or on a convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a need for clarification, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing discussion about the Set Transformer and other related works that use summary tokens. It provides a specific reference to the Set Transformer paper, which gives the authors a clear action to take: they should include a discussion about this work and other related works in their paper. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a reference to the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. By mentioning a specific reference (https://arxiv.org/abs/1810/00825), the comment provides a clear and actionable suggestion for the authors to include a discussion about these works. This feedback is valuable as it directs the authors to a relevant area that could enhance the comprehensiveness and depth of their paper. However, the comment could be more helpful if it offered additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not explicitly instruct the authors to perform such a test or provide guidance on how to do so. The action is implicit, as the authors can infer that they need to consider conducting a statistical significance test, but it lacks concrete details on how to implement this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not specify which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in its suggestion to consider a statistical significance test, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, the comment does not provide any evidence, reasoning, or references to support the claim that the numbers are close or that a statistical significance test is required. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. This is a valid point that could help the authors improve their draft by ensuring that their results are statistically significant. However, the comment lacks specificity and does not provide detailed guidance on how to conduct such a test or what specific aspects of the comparison might be problematic. While it identifies a potential issue, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors have reported significance testing but questions the choice of test. It implies that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. While the comment identifies a potential issue with the choice of test, it does not explicitly instruct the authors to use a paired test setting. The action is implicit and somewhat vague, as the authors need to infer that they should consider using a paired test. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the significance testing reported in the paper, questioning the choice of test. It suggests using a paired test setting, such as the Wilcoxon signedrank test, for comparing two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing, making it weakly grounded. The suggestion to use a paired test setting is specific, as it provides a clear alternative approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. The comment provides a logical reasoning for the suggestion, as it explains the context in which a paired test would be more suitable. However, it lacks specific examples or references to support the claim that the current test choice is incorrect. This makes the claim 3, as the authors would need to consider the reasoning and potentially conduct further research to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of significance test used in the paper, suggesting that a paired test setting, such as the Wilcoxon signedrank test, might be more appropriate for comparing two samples generated from the same input. This feedback is 3 as it points out a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it explained why the current test choice is inappropriate or offered additional guidance on how to implement the suggested paired test setting. Overall, the comment provides valuable insight but lacks depth, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the strength of the demonstration of capability by stating that \"better than random\" is not a strong indicator. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to strengthen the demonstration of capability or what specific improvements could be made. As a result, the authors are left without a clear understanding of what changes are needed to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the section being addressed. It is also specific because it questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. This provides clear guidance on what aspect of the paper needs further elaboration or justification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the strength of the demonstration of capability by suggesting that \"better than random\" is not a strong indicator. While it identifies a potential issue with the paper, it lacks depth and does not provide specific guidance or suggestions on how the authors might strengthen their demonstration of capability. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. While the comment implies that these changes should be made, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement these changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, it does not specify which part of the paper is lacking in this regard, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding, as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge on the proposed method and moving the description of related literatures forward. However, the comment lacks specific examples or detailed reasoning to support why these changes are necessary or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the organization of the paper, suggesting that more background knowledge on the proposed method and a forward placement of related literature descriptions could enhance the paper. While the comment highlights a specific area for improvement, it lacks detailed guidance or actionable suggestions on how to implement these changes. The feedback is 3 as it points out a general area for improvement, but it does not provide the authors with specific steps or examples to follow, leaving them with limited direction for revision. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. While it identifies a gap in the comparison, it does not provide explicit guidance on which models should be included or how to incorporate them into the evaluation. The action is implicit, as the authors need to infer that they should add these models to the comparison, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment points out the absence of comparisons with other representative panoptic segmentation models, specifically mentioning PanopticFPN and Mask2Former. However, it does not specify which part of the paper this comparison should be included in, such as the experimental section or the discussion of related work. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the models that should be included in the comparison, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models are not compared, specifically mentioning PanopticFPN and Mask2Former. However, the comment does not provide any reasoning or evidence to support why these models should be included in the comparison. Without specific examples or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of comparisons with other representative panoptic segmentation models, such as PanopticFPN and Mask2Former. This feedback is clear and actionable, as it directs the authors to expand their evaluation by including these models. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these models into the comparison or why they are relevant. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the paper\"s motivation for \"diversity\" but notes that the model does not enforce diversity explicitly. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might incorporate diversity into their model or what changes could be made to better align the model with the paper\"s motivation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the paper\"s motivation for \"diversity\" and the lack of explicit enforcement of diversity in the model. However, it does not specify which part of the paper this concern relates to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. The comment is specific in detailing the issue with the model\"s lack of diversity enforcement, but it lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the model does not enforce diversity, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for \"diversity\" and the lack of explicit enforcement of diversity in the model. This is a critical observation that could impact the paper\"s validity and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. Without actionable advice, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is 3, as it highlights a key area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides clear guidance on what experiments are lacking and gives the authors a direct action to take: including these experiments in their study. The comment is explicit and concrete, as it specifies the exact experiments that need to be added, making it 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically referencing contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are missing from, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the missing experiments but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would enhance the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the significance of these missing experiments. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, such as contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to include these experiments in their study. However, the comment could be more helpful if it offered additional context or explanation about why these experiments are important or how they might enhance the paper. Despite this, the feedback is 4 as it gives the authors a clear direction for improving their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as it might be applicable. However, the comment does not provide explicit guidance on how to conduct these tests or which specific models to consider. The action is implicit and somewhat vague, as the authors can infer that they need to explore other models but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as it might be applicable. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting an additional test, but it lacks grounding as it does not clearly reference a particular part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as it might be applicable. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider testing the use of inverse triples in other embedding models besides CP, as it might be applicable. This feedback is 3 as it identifies a potential area for exploration and improvement in the paper. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these tests or which specific models to consider. While it points out a possible direction for further research, it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the S2D structure, questioning why the number of parameters does not change despite an increase in depth. The reviewer acknowledges that efficiency could be improved but notes that more details are needed regarding parameters. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific details are expected. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the parameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of why the number of parameters does not change, even when the kernel height/width stay the same, and suggests that more details are expected regarding parameters. The comment provides a clear direction for the authors to address the lack of clarity in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite an increase in depth. The reviewer provides a logical explanation based on the relationship between kernel height/width and depth, suggesting that more parameters would be expected. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is sound, the absence of supporting evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite an increase in depth. It provides a logical explanation based on the relationship between kernel height/width and depth, suggesting that more parameters would be expected. The comment also acknowledges the potential for improved efficiency but emphasizes the need for more details regarding parameters. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their model, which could significantly impact the paper\"s technical rigor and clarity. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or provide additional details. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, improve the interpretation, or suggest alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the limitation of the Atari game results being based on a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, namely that the Atari game results are based on a single game and a single baseline, making it difficult to interpret. This is a clear and actionable feedback that highlights an area where the authors could improve the robustness and comprehensiveness of their results. However, the comment could be more helpful if it provided suggestions on how to expand the results or improve the interpretation. Despite this, the feedback is still valuable as it directs the authors to a critical aspect of their work that requires attention. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should quantify and clarify the claim about ReLU not working well in very deep or convolutional networks. The reviewer provides a specific example from the AlexNet paper, which used ReLU in a deep and convolutional network, challenging the claim. However, the comment does not explicitly instruct the authors to revise their claim or provide guidance on how to quantify and clarify it. The action is implicit and somewhat vague, as the authors need to infer that they should address the claim and provide more detailed evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about the performance of ReLU in deep or convolutional networks, referencing the AlexNet paper as an example. This provides full grounding as the authors can accurately identify the part of the paper being discussed, which is the claim about ReLU. The comment is also specific because it suggests quantifying and clarifying the claim by providing evidence from the AlexNet paper, which makes it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"ReLU does not work very well in very deep or in convolutional networks\" by referencing the AlexNet paper, which used ReLU in a deep and convolutional network. This provides a logical counterexample to the claim, making the comment 3. However, the comment could be strengthened by providing more detailed analysis or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions a claim made in the paper regarding the performance of ReLU in deep or convolutional networks. It provides a specific example from the AlexNet paper, which used ReLU in a deep and convolutional network, challenging the claim. This feedback is 3 as it prompts the authors to reconsider their claim and potentially provide more evidence or clarification. However, the comment could be more helpful if it offered suggestions on how to address the claim or provided additional context for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two new hyperparameters, k and \u03b7, which require finetuning. It notes that this finetuning depends on the availability of the environment or a good OPE (Online Planning Evaluation) method. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting alternative methods for finetuning or providing recommendations for handling the dependency on the environment or OPE method. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two new hyperparameters, k and \u03b7, and their requirement for finetuning. However, it does not specify which part of the paper discusses these hyperparameters, making it weakly grounded. The comment is specific in detailing the issue with the finetuning dependency on the environment or a good OPE method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two new hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two new hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the environment or a good OPE (Online Planning Evaluation) method, which could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or further elaboration, the feedback is 3 as it points out a potential problem but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses confusion about Figure 5, either suggesting that the reviewer does not understand the figure or questioning the accuracy of the labels. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the figure, correct the labels, or improve the figure\"s clarity. Without actionable steps or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is either the reviewer\"s misunderstanding of the figure or the incorrect labels. This provides clear guidance on what needs to be clarified or corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about Figure 5, either questioning the reviewer\"s understanding of the figure or the accuracy of the labels. However, it does not provide any supporting evidence, reasoning, or examples to clarify the issue. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about Figure 5, either questioning the reviewer\"s understanding of the figure or the accuracy of the labels. While it identifies a potential issue, it lacks specificity and does not provide any actionable guidance or suggestions for improvement. The authors are left without a clear understanding of what needs to be clarified or corrected, making it difficult for them to address the issue effectively. Therefore, the comment is 2, as it highlights a potential problem but does not offer any actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal, suggesting that the results may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The authors are left to infer that they should consider updating their benchmarks or exploring other methods to improve the significance of their results. While the comment identifies areas for improvement, it lacks concrete steps or suggestions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Performance differences between methods are minimal across evaluations,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by noting that the performance differences are less than 1 percentage point and may be due to random variation. Additionally, it points out that the benchmarks selected are outdated and likely saturated, providing a specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, citing that the differences are less than 1 percentage point, which may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated, referencing a specific paper, \"LoRA Learns Less and Forgets Less\" 1. This provides some support for the claim, as the reference to the paper suggests that the benchmarks are indeed outdated. However, the comment could be strengthened by providing more detailed analysis or examples of how the benchmarks are outdated or saturated. Therefore, the claim is 4, as it has some justification but could be further substantiated with more specific evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal, with differences less than 1 percentage point. It suggests that these differences may be due to random variation and that the benchmarks used are outdated and likely saturated. This feedback is valuable as it highlights a potential limitation in the paper\"s results and suggests that the authors should consider updating their benchmarks or exploring other methods to improve the significance of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of more suitable benchmarks. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights to explain why the proposed gyrostructures outperform existing methods. Second, it notes that the paper lacks comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance relative to simpler or more commonly used techniques. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific methods to compare or how to incorporate interpretive insights. The actions are implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part\" and the \"related discussion,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the lack of interpretive insights and the omission of comparisons with other stateoftheart methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights to explain why the proposed gyrostructures outperform existing methods. It also notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. The comment provides a logical reasoning for the claim by highlighting the need for interpretive insights and comparisons with other methods. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the experiments section of the paper. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance relative to simpler or more commonly used techniques. This feedback is clear and actionable, as it directs the authors to enhance the interpretability of their results and broaden the scope of their comparisons. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is 4, as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation, as the finetuning is performed for 10 epochs without earlystopping. It suggests that proper ablation studies are needed to verify this claim. While the comment implies that the authors should conduct additional studies to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer the need for ablation studies but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim that distillation improves the teacher\"s performance, suggesting that the improvements could be due to regularization effects rather than distillation. It specifically mentions the finetuning process on GLUE without validation earlystopping, which is known to have high variances. The comment implies that proper ablation studies are needed to verify the claim. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental setup and results sections. The comment is specific in detailing the potential issue with the finetuning process and the need for ablation studies. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that finetuning without earlystopping and for a fixed number of epochs (10) can lead to high variances, which might mask the actual effect of distillation. The comment suggests that proper ablation studies are needed to verify the claim. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the impact of regularization effects. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical point about the potential impact of regularization effects on the observed improvements in the teacher\"s performance, rather than attributing them to distillation as claimed. It highlights the need for proper ablation studies to verify the claim, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to conduct these ablation studies or what aspects to focus on. Despite this, the feedback is 4 as it identifies a potential flaw in the paper and suggests a way to address it, prompting the authors to consider additional experiments to strengthen their claims. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why selfsupervised learning is necessary for 360 video data with spatial audio. It implies that the authors should provide more justification or explanation for this choice. However, the comment does not explicitly instruct the authors to add this information or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add an explanation but are not given specific instructions on how to do it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results section, specifically questioning the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more insight into why this approach is valuable. However, the comment does not explicitly mention which part of the experimental results section it is referring to, making it weakly grounded. The comment is specific in its request for additional insight into the necessity of selfsupervised learning on this type of data. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of selfsupervised learning on 360 video data with spatial audio, suggesting that the paper lacks insight into why this approach is valuable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, it lacks insight into why selfsupervised learning is necessary for this type of data. This observation highlights a critical area for improvement, as it prompts the authors to provide a more detailed explanation of the rationale behind their approach. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing potential explanations or examples. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the analysis, specifically noting that only the SimCLR case is covered and that the projection head, an important part of the approach, is not analyzed. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include an analysis of the projection head, but it does not specify how this should be done or what aspects of the projection head should be analyzed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SimCLR\" and \"projection head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis on an important aspect of the SimCLR approach, namely the projection head, and references recent papers like SimCLRv2 that highlight its importance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is incomplete because it only covers the SimCLR case and neglects the projection head, an important aspect of the approach. The reviewer supports this claim by referencing SimCLRv2 and other recent papers that highlight the significance of the projection head. This provides a logical reasoning and external references to substantiate the claim, making it 4. However, the comment could be strengthened by providing more specific examples or detailed references to these recent papers. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis by noting that only the SimCLR case is covered, while the projection head, an important aspect of the approach, is not analyzed. It references SimCLRv2 and other recent papers that highlight the importance of the projection head, providing a clear direction for the authors to expand their analysis. This feedback is actionable and constructive, as it guides the authors to include a critical component of the SimCLR approach, thereby enhancing the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it suggested specific aspects of the projection head that should be analyzed or provided examples of how other papers have addressed this aspect. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these experiments to enhance the paper. The comment is specific and concrete, as it outlines exactly what experiments are missing and what the authors should focus on. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the parts of the paper that need improvement. The comment is also specific because it clearly specifies what is missing, providing a clear direction for the authors to enhance their work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or reasoning to support why these experiments are necessary or how they would enhance the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work to improve its comprehensiveness and robustness. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or provided examples of similar studies that have included such analyses. Despite this, the comment is 4 as it directs the authors to important areas for improvement, making it a valuable feedback for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method has no advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models learned based on each dataset, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their experimental setup or provide additional context to justify the use of prior knowledge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method has no advantage over the stateoftheart without prior information and that the comparison is unfair due to the added complexity and cost of using two representation models. The comment provides a clear critique of the experimental setup and suggests that the authors should consider these factors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method has no advantage over the stateoftheart (SOTA) without prior information, but shows an advantage when using prior knowledge. The reviewer argues that this comparison is unfair because the proposed method requires two representation models learned based on each dataset, adding complexity and cost. While the comment provides a logical reasoning for the unfairness of the comparison, it lacks specific examples or references to support the claim about the proposed method\"s performance without prior information. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show an advantage over the stateoftheart (SOTA) without prior information. It highlights that the advantage is only observed when using prior knowledge, which could be considered unfair due to the added complexity and cost of using two representation models. This feedback is 3 as it points out a critical aspect of the experimental setup that needs to be addressed. However, it lacks specific suggestions or guidance on how the authors might improve the comparison or address the issue of added complexity. To be more helpful, the comment could provide actionable advice or examples of how to better evaluate the proposed method. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that it lacks theoretical support. It implies that the authors should consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. While the comment provides a specific suggestion, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, providing a specific critique about its adhoc nature and lack of theoretical support. It suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is specific in suggesting a potential improvement and provides a clear direction for the authors to consider. However, it does not explicitly mention which part of the paper discusses the regularization term, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, despite the author providing an intuitive explanation. The reviewer suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the median is a better choice. The comment could be strengthened by providing more detailed reasoning or examples, making it 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s regularization term, noting that it seems adhoc and lacks theoretical support. It suggests that the authors consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is clear and actionable, providing a specific direction for the authors to explore and potentially improve their work. However, the comment could be more helpful if it included examples or references to support the use of the median or other alternative statistics. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the theoretical foundation of the regularization term."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and suggests that they should also include the iteration cost of related methods, including baseline methods. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be added to their draft to address the reviewer\"s concern, and the comment provides concrete guidance on how to implement this action. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and also include the iteration cost of related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for additional discussion on iteration costs, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and include the iteration cost of related methods, including baseline methods. This is a reasonable suggestion for improving the paper, as it would provide valuable information to readers about the computational efficiency of the proposed method compared to others. However, the comment does not provide specific examples or references to support the claim that discussing iteration costs is necessary or beneficial. Without additional context or evidence, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to discuss the iteration cost (computational budget) of the proposed method. It also recommends including the iteration cost of related methods, including baseline methods, which would enhance the paper\"s comprehensiveness. This feedback is specific and offers a concrete way for the authors to improve their draft by providing additional context and comparison. However, the comment could be more helpful if it suggested specific metrics or methods for evaluating iteration costs or offered examples of how this information could be presented. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the description of VAD (Voice Activity Detection) in the paper, suggesting that it is misleadingly referred to as a VAD. The reviewer argues that the method described is not a true VAD, as it discards TF bins with a magnitude less than epsilon, which is equivalent to discarding bins with zero magnitude to avoid division by zero. The reviewer provides a clear critique of the method\"s description and suggests that a VAD should look for the presence of speech, not just energy, and typically operates over time, not frequency. However, the comment does not provide explicit guidance on how the authors should revise their description or improve their method. While it highlights a potential issue, it lacks actionable advice on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"VAD description\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the VAD description, pointing out that the method described is not a true VAD and explaining why. The reviewer provides a detailed critique of the method\"s logic and suggests that a VAD should look for the presence of speech, not just energy, and typically operates over time, not frequency. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description in the paper is puzzling and suggests that it is not a true VAD. The reviewer provides a logical explanation by stating that the method described discards TF bins with a magnitude less than epsilon, which is equivalent to discarding bins with zero magnitude to avoid division by zero. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by referencing specific literature or examples of how VADs are typically defined and implemented. Overall, the claim is 4, as it provides a logical explanation but lacks detailed references or examples to fully substantiate the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and specific critique of the VAD (Voice Activity Detection) description in the paper. It points out that the method described is misleadingly referred to as a VAD, as it simply discards TF bins with a magnitude less than epsilon, which is not a true VAD. The reviewer explains that a VAD should look for the presence of speech, not just energy, and typically operates over time, not frequency. This feedback is actionable as it highlights a misunderstanding in the paper and suggests a more accurate description of the method. However, the comment could be more helpful if it offered suggestions on how to revise the description or improve the method to align with the correct definition of VAD. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide explicit guidance on how to achieve this or what specific aspects of the results should be included. The action is implicit and somewhat vague, as the authors are left to infer that they should include ImageNet results but are not given detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper should include these results or how they would enhance the method\"s convincingness. The authors might infer that it relates to the results section, but the comment lacks specificity and grounding, making it difficult for them to pinpoint the exact area needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any reasoning or evidence to support why ImageNet results would be more convincing or how they would enhance the method\"s validity. Without specific examples or justification, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to incorporate these results or what specific aspects of the method would benefit from them. The comment does not offer actionable advice or detailed suggestions, leaving the authors with a general idea but no clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the sufficiency of the contribution, noting that while the paper studies the connection between complementary and model robustness, it lacks further studies on how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and expects more insightful findings or solutions. However, the comment does not provide explicit guidance or actionable steps for the authors to address this concern. It lacks concrete suggestions on what specific analyses or solutions should be explored or how the authors might enhance their contribution. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the paper\"s contribution, specifically regarding the connection between complementary and model robustness. However, it does not explicitly mention which part of the paper this concern is based on, such as specific sections or analyses. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique, suggesting that the paper lacks further studies on how to leverage these characteristics to improve model robustness and that more insightful findings or solutions are expected. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient because it only studies the connection between complementary and model robustness without exploring how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and that more insightful findings or solutions are expected. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or that the conclusion is easily obtainable. The reasoning is somewhat vague and does not provide detailed evidence or logical reasoning to substantiate the claim. Therefore, the comment is classified as 3, as it provides some justification but lacks key elements to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the paper\"s contribution, noting that while it studies the connection between complementary and model robustness, it lacks further studies on how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily obtained and that more insightful findings or possible solutions are expected. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and encourages the authors to explore more indepth analyses or solutions. However, the comment could be more helpful if it provided specific suggestions or examples of what additional insights or solutions could be explored. Overall, the feedback is 3 as it guides the authors toward enhancing their contribution but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the connection between the theoretical analysis and the proposed method. It suggests that the method seems to simply adopt the selfattention mechanism from transformers without explaining how it enhances generalization for distant nodes. However, the comment does not provide explicit guidance or suggestions on how the authors could improve this aspect of their paper. The feedback is vague and lacks actionable steps, leaving the authors uncertain about what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not explicitly mention which part of the paper discusses the theoretical analysis or the proposed method, making it weakly grounded. The comment is specific in detailing the issue with the connection between the theoretical analysis and the proposed method, but without explicit references, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method does not clearly demonstrate how it enhances generalization for distant nodes, suggesting that it merely adopts the selfattention mechanism from transformers without providing a strong connection to the theoretical analysis. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references to relevant literature makes the claim 3, as it provides a general critique but does not offer sufficient detail for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s explanation regarding the connection between the theoretical analysis and the proposed method. It points out that the method seems to merely adopt the selfattention mechanism from transformers without clarifying how it enhances generalization for distant nodes. This feedback highlights a critical area for improvement, as it suggests that the authors need to provide a stronger link between their theoretical analysis and the practical application of their method. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as proposing alternative approaches or additional experiments to demonstrate the enhancement. While it provides some insight into the paper\"s limitations, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have made an incorrect statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It specifies that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback provides clear and explicit guidance on what needs to be corrected in the draft, ensuring that the authors know exactly what action to take to improve the accuracy of their statement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific statement in the paper (\"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\") and references Section 3 of Wang et al., 2023, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the statement, indicating that the heads are active at the S2 token but do not primarily attend to it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Induction, Duplicate Token, and Previous Token heads primarily attending to the S2 token is incorrect, as per Section 3 of Wang et al., 2023. The comment provides a specific reference to external work, which supports the claim by indicating that the heads are active at the S2 token but do not primarily attend to it. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including a direct quote or more detailed explanation from Wang et al., 2023, to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the authors\" statement regarding the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It corrects the authors\" claim by pointing out that these heads are active at the S2 token but do not primarily attend to it, as per Section 3 of Wang et al., 2023. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and reliability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the distribution of the eta_ri term, specifically asking why it is a noncentral chisquared distribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify the distribution. The comment lacks actionable details, such as suggesting additional information or examples that could help resolve the confusion. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distribution of the eta_ri term, specifically asking why it is a noncentral chisquared distribution. However, it does not specify which part of the paper this question pertains to, such as a specific section or equation where this distribution is discussed. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper being addressed. The comment is specific in its inquiry but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point questions the choice of a noncentral chisquared distribution for the eta_ri term, but it does not provide any reasoning, evidence, or references to support why this choice might be problematic or why it is unclear. Without additional context or justification, the authors may find it difficult to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distribution of the eta_ri term, specifically asking why it is a noncentral chisquared distribution. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might clarify or address this issue in their paper. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of speed analysis in the experiments, noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. This feedback is explicit in its request for additional analysis and comparison, but it lacks specific guidance on how to conduct this analysis or what metrics to use. While the authors know they need to include speed analysis, the comment does not provide detailed instructions on how to implement this, making it 3.", "grounding_specificity_rationale": "The comment highlights a lack of speed analysis in the experiments, noting that while GFLOPs are compared among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. This suggests that the authors should include an analysis of inference speed, which would be a specific area for improvement. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology section, but this inference is not direct. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of speed analysis in the experiments is a significant omission, as it only compares GFLOPs among different segmentation networks without evaluating inference speed. The reviewer suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. While the comment highlights a potential gap in the analysis, it does not provide specific examples or references to support the claim that inference speed is more important than FLOPs. The reasoning is logical but lacks detailed evidence or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs among different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The comment suggests that an analysis of inference speed would be more interesting than just reducing FLOPs. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their analysis and presentation of results. By addressing this gap, the authors can provide a more comprehensive understanding of their work and its implications. However, the comment could be more helpful if it offered specific suggestions on how to conduct the speed analysis or what metrics to use. Overall, the comment is 4, as it provides a clear direction for improvement but could be more detailed in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is not wellpositioned in the literature and recommends a thorough literature review to better understand its novelty. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to improve the positioning of their method in the literature. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific concept of representing the marginal score as the expectation of scores of distributions conditioned on inputs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that this concept is not novel and has been used in other works, such as denoising score matching and scoreinterpolation. The reviewer provides specific references to support this claim, which further enhances the specificity of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, which use similar concepts. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed method, suggesting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. It references specific works, such as denoising score matching and scoreinterpolation, which use similar concepts, and recommends a thorough literature review to better understand the method\"s positioning. This feedback is clear and actionable, as it directs the authors to conduct a more comprehensive literature review to contextualize their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this literature review or what aspects to focus on. Overall, the comment is 4, as it provides valuable insights and encourages the authors to improve the paper\"s context within the existing literature."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion or guidance on how to address this curiosity or whether it is relevant to the current draft. As a result, the authors are left without any actionable steps to improve their work based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this question pertains to, nor does it provide any guidance on what specific aspects of performance or the adaptive metric are being questioned. This makes it difficult for the authors to determine the exact section that needs attention or what specific issues need to be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question expressing curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any specific guidance or suggestions for the authors to address this curiosity or improve their work. The comment lacks actionable feedback or detailed insights that could help the authors enhance their draft. As a result, it is 2, as it identifies a potential area of interest but does not offer any actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only descriptions of the related works but also discussions of the differences to the presented work. This feedback is explicit, as it clearly states what the authors should do to improve their draft. It is also concrete, as it provides a specific action with clear guidance on how to enhance the related work section. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the discussion of related work should not only describe the related works but also discuss the differences to the presented work. This provides clear guidance on what needs to be addressed in the related work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including descriptions and discussions of differences with the presented work. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance and importance of a more detailed discussion based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a more detailed discussion of related work. It not only suggests describing the related works but also encourages the authors to discuss the differences between the presented work and the existing literature. This feedback is valuable as it can help the authors enhance the context and relevance of their work by highlighting its unique contributions. However, the comment could be more helpful if it provided specific examples or references to guide the authors in their discussion. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these experiments. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup, but the comment lacks full grounding. It is specific in suggesting the need for additional experiments, but without explicit references to sections or specific tasks, it remains weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not provide any reasoning or evidence to support why this would be beneficial or necessary. The comment lacks specific examples or references to other architectures or tasks that could be explored, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential limitation in the scope of the experiments and encourages the authors to consider broader applicability. However, the comment lacks specific guidance on which architectures or tasks to explore, which could be beneficial for the authors in planning their next steps. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that could be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the output from the algorithm depends on the order in which the data are processed and recommends that this should be clarified. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to clarify this dependency or what steps to take to resolve it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data are processed and recommends clarification. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the dependency on data processing order. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm, suggesting that the output depends on the order in which the data are processed. This is a critical observation that could impact the reliability and reproducibility of the results. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or clarify the dependency. Without actionable suggestions or examples, the feedback is 3 as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or evaluate the tradeoffs. The comment implies that the authors should consider the potential impact of these strategies on the model\"s utility, but it lacks concrete steps or recommendations for improvement. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, suggesting a potential tradeoff between reducing a particular behavior and maintaining high performance. However, it does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on the model\"s utility, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting a potential tradeoff between reducing a particular behavior and maintaining high performance. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the potential impact based on the general reasoning provided, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the potential impact of mitigation strategies on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or evaluate the tradeoffs. While it identifies a relevant area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of using 6fold crossvalidation, suggesting that it is unclear why this method is required for the problem at hand. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the reasoning behind their choice of crossvalidation method, but it does not specify what additional information or explanation should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of 6fold crossvalidation in the paper and questions the necessity of this method, particularly since other papers being compared did not use crossvalidation. However, it does not specify which part of the paper discusses the use of crossvalidation or which specific papers are being compared. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the rationale behind the choice of crossvalidation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, suggesting that it is unclear why this method is required for the problem at hand. The reviewer provides a logical reasoning by comparing the current work to other papers that did not use crossvalidation, implying that the choice of crossvalidation method should be justified. However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is sound, the lack of additional evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of 6fold crossvalidation in the paper, questioning the necessity of this method given that other papers being compared did not use crossvalidation. This is a relevant point that could help the authors clarify their methodology and provide a clearer justification for their choice. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern that the presented method, while using ODA as a method for solving the MOIP problem, does not clearly demonstrate how it improves performance and computation speed over just using ODA. However, it does not provide explicit guidance or suggestions on how the authors could address this issue. The comment implies that the authors should provide a clearer explanation of the improvements, but it lacks concrete details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the use of ODA as a method for solving the MOIP problem and questions how the presented method improves performance and computation speed over just using ODA. However, it does not specify which part of the paper discusses ODA or the presented method, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of lacking clarity in demonstrating improvements over ODA. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presented method, ODA, has not clearly demonstrated how it improves performance and computation speed over just using ODA. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises a concern about the paper\"s presentation of the ODA method, suggesting that it does not clearly demonstrate how the method improves performance and computation speed over simply using ODA. This feedback is 3 as it identifies a potential gap in the paper\"s explanation and prompts the authors to clarify their method\"s advantages. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analysis to demonstrate the improvements. To be more helpful, the comment could provide more detailed advice or examples of how to enhance the explanation. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum. It notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. The comment implies that the authors should conduct more comprehensive experiments to evaluate the impact of sampling on convergence. However, it does not provide specific guidance on how to conduct these experiments or what metrics to use, leaving the authors to infer the necessary actions. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 1 in supplementary,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the importance of the sampling performed to obtain different initializations x_0 for convergence to the optimum and notes that this aspect is not experimentally evaluated thoroughly on the proposed benchmarks. The comment specifies the need for more comprehensive evaluation, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum, but it is not experimentally evaluated thoroughly on the proposed benchmarks. The comment provides some support by mentioning that this aspect is only compared to sampling from a uniform distribution in Table 1 of the supplementary material. However, the claim lacks detailed reasoning or specific examples of how the sampling affects convergence, making it 3. The authors would need to delve deeper into the experimental setup and results to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights an important aspect of the paper that has not been thoroughly evaluated: the sampling performed to obtain different initializations x_0 and its impact on convergence to the optimum. It points out that this aspect is only briefly mentioned in the supplementary material, specifically in Table 1, where it is compared to sampling from a uniform distribution. This feedback is valuable as it identifies a potential gap in the experimental evaluation and suggests that the authors should conduct more comprehensive experiments to assess the impact of sampling on convergence. However, the comment could be more helpful if it provided specific suggestions on how to design these experiments or what metrics to use. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, although it notes that this is not necessary. The comment implies that the authors could consider exploring this aspect, but it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they might need to include an analysis or experiment involving tabular data. However, the comment does not specify how to conduct this analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multimodal data, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, noting that this is not necessary. However, the comment does not provide any reasoning, evidence, or examples to support why exploring tabular data would be beneficial or how it relates to the current work. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. While it acknowledges that this is not necessary, it still provides a direction for potential expansion or analysis. However, the comment lacks depth and does not offer specific guidance on how to approach this exploration or what aspects to focus on. The feedback is 3 as it identifies a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more details on using attention, potentially as an additional appendix. This is an explicit action that the authors can take to enhance their draft. The suggestion is clear and concrete, as it specifies a particular aspect of the paper that needs more detail and provides a potential location for this additional information. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not specify which part of the paper currently lacks these details or where the additional information should be included. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion to include more details is specific, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, possibly as an extra appendix. However, it does not provide any reasoning or evidence to support why this additional information is necessary or how it would enhance the paper. Without specific examples or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more details on the use of attention, which could be beneficial for readers who are interested in understanding this aspect of the paper. The suggestion to include this information as an extra appendix is clear and actionable, offering a specific way for the authors to enhance their draft. However, the comment could be more helpful if it provided additional context or examples of how the attention mechanism is used, which would give the authors a clearer understanding of what specific details to include. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two distinct issues. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a request for clarification. Second, it points out the absence of the pseudocode for the proposed method, which is a clear and explicit action for the authors to take. The inclusion of specific references to relevant literature, such as 1 and 2, provides concrete guidance on how to address the second issue. However, the first part of the comment, while important, is more of a question than a directive, making it less actionable. Overall, the comment is 4 because it provides a clear action for the authors to take regarding the pseudocode, but it could be more actionable if it included a more explicit suggestion for addressing the first issue.", "grounding_specificity_rationale": "The comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which is a general observation and does not specify where in the paper this is discussed. This part of the comment is 1 as it does not refer to a specific section or part of the paper. Second, it points out the absence of the pseudocode for the proposed method, which is a specific issue that could be addressed by adding the missing code. However, the comment does not specify where the pseudocode should be included, making it weakly grounded. The comment is specific in identifying the missing pseudocode, but the lack of grounding makes it difficult for the authors to pinpoint the exact location. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two distinct claims. The first claim questions why explicit methods perform better than implicit methods on locomotion tasks, but it does not provide any supporting evidence or reasoning to substantiate this claim. The second claim points out the absence of the pseudocode for the proposed method, which is a factual observation. However, the comment does not provide any justification or explanation for why the pseudocode is missing or how it impacts the paper. The inclusion of references to external works, such as 1 and 2, is relevant but does not directly support the claims being made. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which is a valid point for further clarification or discussion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue. Second, it points out the absence of the pseudocode for the proposed method, which is a clear and actionable request for improvement. The inclusion of references to relevant literature, such as 1 and 2, provides additional context and could be helpful for the authors. Overall, the comment identifies a specific area for improvement but lacks depth in addressing the first issue, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a need to simplify the description of results, specifically mentioning an example of convoluted language. It provides suggestions for improvement by referencing related work and suggesting a check on whether useful communication is happening, given the differences in figures seem too small. The comment also references specific papers for further context. While the suggestions are explicit and provide concrete references, the action is 4 because it gives the authors a clear direction on how to improve the clarity of their results section, but it could be more detailed in terms of specific changes to make. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"result description\" and provides specific examples of convoluted language, allowing the authors to accurately identify the parts of the paper being addressed. It also suggests related work and references specific papers, which further grounds the comment. The comment is specific because it details what is wrong with the result description, provides suggestions for improvement, and references relevant literature. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the result description is needlessly convoluted and suggests simplifying it. It provides specific examples of convoluted language and references related work (1 and 2) to support the suggestion. The references to 1 and 2 offer a basis for the claim, as they provide context for the idea of speakerlistener communication from a teachability perspective. However, the comment could be strengthened by providing more detailed examples or explanations of how the convoluted language affects the clarity of the results. Overall, the claim is 4, as it provides some support but could benefit from more detailed justification. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the result description, noting that it is needlessly convoluted. It provides a concrete example of the language used, which helps the authors understand the problem. The comment also offers suggestions for improvement by referencing related work and suggesting a check on whether useful communication is happening, given the differences in figures seem too small. Additionally, it references specific papers (1 and 2) for further context, which can guide the authors in refining their results section. This feedback is clear, actionable, and provides valuable insights for improving the clarity and relevance of the results, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the experimental validation and related work sections. It points out that only shallow networks are considered, and the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it mentions that the positioning of the work with respect to related works is limited, specifically referencing a paper on layer redundancy. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to expand their experimental validation to include deeper networks, describe their optimization strategy, and better position their work within the context of related studies. However, the lack of explicit guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the experimental validation and related work sections. It mentions that only shallow networks are considered and that the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it points out a minor issue with the positioning of the work with respect to related works, specifically referencing a paper on layer redundancy. The comment provides specific examples and references, such as the paper by He et al. (2020), which helps the authors understand what needs to be addressed. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing due to the limited consideration of shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also mentions a minor issue with the positioning of the work with respect to related works, specifically referencing a paper on layer redundancy. The comment provides a specific reference to support the claim about layer redundancy, which enhances the verifiability of the comment. However, the claim about the experimental validation could be further supported by providing more detailed examples or explanations of why the current approach is insufficient. Overall, the comment is 4, as it provides a solid foundation for the claim but could benefit from additional details. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation and related work sections. It points out that only shallow networks are considered, which limits the experimental validation, and that the optimization strategy, including the grid search for hyperparameter selection, is not described. Additionally, it notes that the positioning of the work with respect to related works is limited, specifically mentioning a paper on layer redundancy. The comment provides a specific reference to support the claim about layer redundancy, which could help the authors better understand the context of their work. However, the comment could be more helpful if it offered suggestions on how to expand the experimental validation or improve the description of the optimization strategy. Overall, the feedback is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. While the comment implies that the authors should expand their testing to include other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should test the model on other tasks but are not provided with specific guidance on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, it does not specify which part of the paper this question pertains to, such as a specific section or results section where the testing results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a potential limitation in the testing scope, it does not provide specific guidance on how to address this issue or what additional tasks should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the scope of the model\"s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a question about the scope of the model\"s testing, specifically noting that it was only tested on the single supporting fact dataset (Task 1 of bAbI) and asking if other tasks were considered. While this comment identifies a potential limitation in the testing scope, it does not provide specific guidance or suggestions on how the authors might address this issue or expand their testing to include other tasks. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends improving it by providing more illustrations and examples. While the comment implies that the authors should enhance the clarity of this section, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly how to improve the section or what kind of illustrations and examples would be beneficial. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it is hard to follow and suggesting improvements by providing more illustrations and examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.2 is difficult to follow and suggests improving it with more illustrations and examples. However, the comment does not provide any specific reasons or examples of why the section is hard to follow, nor does it offer detailed guidance on what kind of illustrations or examples would be beneficial. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively, rendering it 1.", "helpfulness_rationale": "The comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the authors improve the section with more illustrations and examples. This feedback is valuable as it directs the authors to a specific area of their draft that needs enhancement, offering a concrete step to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on what kind of illustrations or examples would be most beneficial. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include a comparison of their approach, GCG, with other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action, as it clearly instructs the authors on what additional content should be included in the paper. The comment also mentions a minor point about the jailbreaking percentage being low for certain LLMs, which could be a separate action for the authors to address. However, the suggestion to include the comparison is the primary actionable point. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included, namely a comparison of the approach with other LLMs, and mentions a minor point about the jailbreaking percentage. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors showed their approach, GCG, could be transferred to other LLMs and that it could craft adversarial prompts and transfer them to other LLMs. The comment suggests including a comparison to support this claim. However, the review does not provide specific examples or references to substantiate the claim about the effectiveness of GCG in transferring adversarial prompts to other LLMs. This lack of detailed evidence or references makes the claim 3, as the authors would need to provide additional information to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include a comparison of their approach, GCG, with other LLMs. This is a clear and actionable piece of feedback that could enhance the paper by demonstrating the versatility and applicability of GCG. Additionally, the comment mentions a minor point about the jailbreaking percentage being low for certain LLMs, which could be an area for further exploration or clarification. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects of the comparison should be highlighted. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not provide any explicit guidance or suggestions on how to address this issue. The comment lacks concrete details or actionable steps for the authors to follow, leaving them without a clear understanding of what needs to be done to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not specify which part of the paper discusses this parameter or where the issue arises. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of setting the parameter S are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the parameter S, stating that its setting remains a problem. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the parameter S, noting that its setting remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the draft. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to resolve the problem. This lack of specificity and guidance makes the comment 2, as it highlights a potential issue but does not offer any actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer argues that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback implies that the authors should clarify or address this point in their introduction, possibly by discussing the implications of these choices or providing guidance on how they are determined. While the comment identifies an area for improvement, it does not provide explicit instructions on how to address it, leaving the authors to infer the necessary actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the specific claim about \"shape constraints not requiring tuning a free parameter.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue by pointing out that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that while the introduction states that \"these shape constraints do not require tuning a free parameter,\" the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. The reviewer provides a logical reasoning by pointing out that the choice of these constraints can indeed be considered a hyperparameter, which supports the claim. However, the comment could be strengthened by providing examples or references to similar cases where such choices are considered hyperparameters. Overall, the claim is 4, as it provides a clear logical argument but lacks specific examples or references to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the introduction, where it claims that \"these shape constraints do not require tuning a free parameter.\" However, the reviewer points out that the choice between convex or concave constraints, and increasing or decreasing constraints, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback highlights a specific area where the introduction may be misleading or incomplete, prompting the authors to clarify or address this point. By pointing out this discrepancy, the comment provides a clear and actionable suggestion for improvement, making it 4. However, it could be more helpful if it offered specific guidance on how to address this issue or suggested ways to clarify the introduction. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the paper regarding the datasets and models used, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or what specific datasets or models should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include more diverse datasets and models, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in terms of datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what is missing, such as assessments of other biases and datasets, and the inclusion of stateoftheart generative models. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper has limited datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights a limitation, it does not provide specific examples or references to support the claim about the absence of other biases or datasets. The lack of detailed justification or evidence makes the claim 3, as the authors would need to conduct further research to fully understand the scope of the limitation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is clear and actionable, as it highlights areas where the authors can expand their analysis to provide a more comprehensive understanding of the biases and models involved. However, the comment could be more helpful if it suggested specific datasets or models that should be included or provided guidance on how to incorporate them. Despite this, the comment provides valuable insights that can guide the authors in improving their work, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with Figure 3, stating that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback provides a clear and direct action for the authors to take: improving the clarity of Figure 3 by enhancing the workflow and captions and clarifying the representation of communication modes. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, including the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be improved in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, and confusion regarding the representation of communication modes. However, the comment does not provide any specific examples or detailed reasoning to support these claims. Without additional context or explanation, the authors may find it difficult to understand and address the issues. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes. This feedback is clear and actionable, providing the authors with a direct area for improvement. By addressing these issues, the authors can enhance the clarity and effectiveness of their figure, which is crucial for communicating complex information to readers. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the figure or provided examples of better practices. Overall, the comment is 4 as it directs the authors to a specific area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. While it identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this point in their draft. The action is implicit, as the authors need to infer that they should provide a clearer explanation of this term. However, the comment lacks concrete details on how to achieve this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the issue with the term \"learned MASK embedding,\" but it lacks grounding as it does not provide a clear reference to the part of the paper where this term is used. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the clarity of the term \"learned MASK embedding\" in the SSL pretraining stage. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned MASK embedding\" in the SSL pretraining stage of the proposed method. By pointing out this ambiguity, the comment provides a clear direction for the authors to clarify their work. However, it lacks further guidance or suggestions on how to address this issue, such as recommending additional explanations or examples. While it highlights an important area for improvement, the comment could be more helpful if it offered more detailed advice. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in the paper and provide detailed explanations of the model\"s performance under different scenarios. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The comment also provides a rationale for why this is important, stating that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where error analysis could be integrated. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. While the comment is specific in its request for error analysis, it is 1, as it does not direct the authors to a particular part of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not provide specific examples or references to support why error analysis is necessary or how it would aid in guiding subsequent improvements. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of error analysis based on general knowledge. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would provide more detailed guidance for the authors. Overall, the comment is 4, as it directs the authors toward a significant improvement in their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as it does not see any NLPspecific elements in the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific aspects of the work should be revised to better align with the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, the reviewer questions this claim by stating that they do not see any NLPspecific elements in the approach. This provides a clear critique of the paper\"s claim, but it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the lack of NLPspecific elements, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the claim that the work is one of the preliminary works discussing the application of LLP to NLP tasks, as the reviewer does not see any NLPspecific elements in the approach. This is a subjective opinion that lacks specific evidence or references to support the claim. The reviewer does not provide detailed reasoning or examples to substantiate why the work is not NLPspecific, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks, as the reviewer does not see any NLPspecific elements in the approach. This feedback identifies a potential inconsistency in the paper\"s claims and highlights an area where the authors may need to clarify or substantiate their assertions. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. While it points out a weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the use of a newly collected large dataset (209M) compared to the smaller datasets used by existing methods. The reviewer implies that the superior performance of the proposed method could be due to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of dataset size on their results and potentially adjust their analysis or comparisons accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset versus smaller datasets used by existing methods like GEM, which employs only 20M unlabeled data. This provides a clear context for the issue, allowing the authors to identify the part of the paper being discussed as the section comparing the proposed method with SOTA methods. However, the comment does not specify what needs to be addressed or how the authors should adjust their comparison to make it more fair. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a larger dataset. The reviewer provides specific examples, such as GEM using only 20M unlabeled data, and highlights the significant impact of dataset scale on accuracy. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by including more detailed comparisons or references to specific studies that demonstrate the effect of dataset size on performance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods, pointing out that the proposed method\"s performance is based on a newly collected large dataset (209M), while existing methods use smaller datasets. This observation is important as it highlights a potential bias in the evaluation that could impact the perceived superiority of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending adjustments to the comparison or suggesting alternative evaluation metrics. While it identifies a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. The comment implies that the authors should include references to existing studies that have discussed these factors. While the action is explicit, it lacks concrete guidance on which specific references to include or how to integrate them into the paper. The authors know they need to add references but may not be entirely sure how to do so effectively. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that some claims may be inspired by existing studies and suggests adding supportive references. The comment provides an example of the factors discussed in the paper and notes that most of these factors have been discussed in existing studies. This level of detail helps the authors understand what needs to be addressed and why, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. The comment implies that these factors have been discussed in existing studies, but it does not provide specific references or examples to support this claim. While the suggestion to include references is logical, the lack of detailed evidence or examples makes the claim 3. The authors would need to conduct additional research to verify the claim, making it a borderline case.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, suggesting that some claims may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 5564, where it mentions four critical factors affecting the performance of chainofthought prompting. By pointing out the need for references, the comment offers a clear and actionable suggestion for improving the paper. However, it could be more helpful if it included specific references or examples of existing studies that have discussed these factors, which would provide more detailed guidance for the authors. Overall, the comment is 4 as it directs the authors to enhance the paper by providing necessary references, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the first paragraph of the Introduction for being too general and not relevant to the paper\"s focus on detecting drift types and magnitude. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion to revise or remove the paragraph, nor is there guidance on how to improve the introduction to better align with the paper\"s focus. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first paragraph of the Introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, namely that it focuses too much on a general introduction to DNNs without mentioning drift, which is the core focus of the paper. The comment provides a clear critique of the relevance of the content, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not relevant to the paper because it focuses on a general introduction to DNNs without mentioning drift, which is the core focus of the paper. The reviewer provides a logical reasoning by pointing out the mismatch between the content of the paragraph and the paper\"s focus. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of the general introduction to the paper\"s focus on drift detection. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of the paper, noting that the first paragraph focuses too much on a general introduction to DNNs without mentioning drift, which is the core focus of the paper. This feedback is clear and actionable, as it suggests that the introduction should be more focused on the specific aspects of drift detection and magnitude, rather than providing a general overview of DNNs. However, the comment could be more helpful if it provided suggestions on how to reorganize or rephrase the introduction to better align with the paper\"s focus. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). The reviewer implies that more carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not provide explicit guidance on how to improve the prompting technique or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer that they should enhance the prompting technique but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). However, it does not specify which part of the paper discusses the prompting technique, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the prompting technique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is \"very basic\" and fails to leverage the full potential of Large Language Models (LLMs). However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate the assertion that more carefully curated prompts could lead to better results. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the use of a \"very basic\" prompting technique that fails to fully leverage the potential of Large Language Models (LLMs). It suggests that more carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks depth and does not provide specific guidance or examples on how to improve the prompting technique. It does not offer actionable steps or suggestions for the authors to enhance their approach. As a result, while the comment highlights an area for improvement, it is incomplete and does not fully support the authors in making meaningful changes to their draft. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed method, noting that it achieves only a 1% gain on a small backbone ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to their smaller receptive fields. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance on larger backbone models like SwinB or SwinL. The action is implicit and vague, as the authors are left to infer that they should investigate the performance on larger models but are not given specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvement consistency across different frameworks and tasks, specifically mentioning the relative gains and the use of global pooling in the proposed method. It also raises a concern about the performance on larger backbone models like SwinB or SwinL. However, the comment does not explicitly mention which part of the paper discusses these improvements or the specific results related to ResNet50 and Swin models. While the authors might infer that it relates to the experimental results or methodology sections, the comment lacks full grounding as it does not directly reference these sections. The comment is specific in detailing the concern about the relative gains and the potential impact of global pooling, but it is not fully grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the improvement is consistent across different frameworks and tasks but notes that the relative gains are not very strong, particularly for most baselines where the proposed method achieves only a 1% gain on a small backbone ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to their smaller receptive fields and questions whether it would work well on larger backbone models like SwinB or SwinL. While the comment provides some reasoning and observations, it lacks specific examples or references to support the claim about the relative gains and the impact of global pooling. The reasoning is 3, as it provides a logical basis for the concern, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the improvement achieved by the proposed method is consistent across different frameworks and tasks but is not very strong, particularly for most baselines where it only achieves a 1% gain on a small backbone ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to their smaller receptive fields and questions whether it would work well on larger backbone models like SwinB or SwinL. This feedback is 3 as it points out a specific area for improvement and encourages the authors to consider the performance on larger models. However, it lacks detailed guidance or suggestions on how to address this issue, such as recommending additional experiments or analyses. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should consider adding more datasets or ensuring that all algorithms can be used on the existing ones, but it does not specify which datasets are problematic or how to resolve the issue. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not specify which datasets are problematic or how they impact the evaluation. The comment also mentions an addendum that provides additional context, but it does not explicitly mention which part of the paper this issue pertains to. The authors can make an educated guess that it relates to the sections discussing datasets and experiments, but the comment lacks full grounding. It is specific in identifying the issue with the datasets but not specific in terms of which datasets or how to address the problem. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The addition of an addendum that acknowledges the authors\" response and provides context does not address the initial claim. Without detailed justification or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the evaluation process. The comment acknowledges the authors\" response and the provision of a repository and online platform for reproducing experiments, which clarifies the novelty of the datasets and motivations for their choice. While the comment acknowledges the authors\" efforts, it lacks actionable feedback or detailed suggestions for improvement, making it 3. The authors gain some insight into the evaluation process but are not fully guided on how to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to improve the paper. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"confusing mistakes in the proof of the main results,\" which suggests that it is addressing the section where the proof is presented. However, it does not specify which part of the proof is confusing or provide details on the mistakes. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but it does not specify which previous work or how the comparison should be conducted. The comment is weakly grounded as it does not explicitly mention the section, but it is specific in identifying the issues with the proof and the lack of comparison. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence and detailed justification renders the claims 1, as the authors are left without a clear path to improve their work based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to take. Therefore, the comment is 3, as it points out weaknesses but does not provide detailed feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to clarify the motivation, improve the comparison, or address the model size issue. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, while the comment identifies specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises several claims, including that the motivation for using an adversarial network is unclear and that the comparison of experimental results is unfair. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the assertion that the comparison is unfair or how the addition of CAT and GAN affects the model size. Without such support, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pretrained model is being compared with other models. However, the comment lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to improve the reliability of the results or what specific changes should be made to the experimental setup or analysis. Without actionable advice or suggestions, the authors are left without a clear path forward to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, specifically the discrepancy between the MSE and MAE values, which raises concerns about the validity of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically pointing out the discrepancy between the MSE and MAE values in Table 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about the validity of the results. This feedback is clear and highlights a potential problem that the authors should address. However, the comment does not provide any suggestions or guidance on how to resolve this issue or improve the reliability of the results. While it points out a critical area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of an adversarial loss to ensure that the perturbed data is similar to the authentic data. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details on what specific adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of the action needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the absence of an adversarial loss to ensure the perturbed data is similar to the authentic data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment. Without explicit references or context, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that there is no adversarial loss to guarantee the perturbed data is similar to the authentic data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the absence of an adversarial loss to ensure that the perturbed data is similar to the authentic data. This is a clear and actionable feedback that highlights a potential weakness in the methodology or results. However, the comment lacks depth and does not provide suggestions on how to address this issue or what specific adversarial loss could be used. While it points out a critical area for improvement, it does not offer detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the verylongterm forecasting task has limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments and provide a more appropriate context for their results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct these experiments or what constitutes the \"correct\" forecast horizon. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the discussion section of the paper, specifically mentioning the need for improvement in the context of the verylongterm forecasting task. It suggests conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. However, the comment does not explicitly mention which part of the discussion is being addressed, making it weakly grounded. The suggestion to conduct additional experiments and improve the context is specific, as it provides clear guidance on how to enhance the discussion. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task has limited practical significance and suggests improvements to the discussion, such as conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. However, the comment lacks specific reasoning or evidence to support the claim about the limited practical significance of the task. It also does not provide examples or references to substantiate the need for additional experiments or the definition of the \"correct\" forecast horizon. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task and suggests ways to improve the discussion. It recommends conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a more appropriate context for the results. This feedback is clear and actionable, as it offers specific suggestions for enhancing the discussion and providing a more robust evaluation of the task. However, the comment could be more helpful if it provided additional guidance on what constitutes the \"correct\" forecast horizon or how to select datasets for the experiments. Overall, the comment is 4 as it directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. This is a clear and direct action for the authors to take, as it identifies a specific area that needs to be addressed in the draft. However, the comment does not provide guidance on how to conduct this analysis or what aspects of security should be considered. While the action is explicit, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment points out that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. However, it does not specify which part of the paper this issue is related to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this analysis is lacking. The comment is specific in its critique of the security analysis but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security of the proposed framework, specifically the protection of privacy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security and privacy protection of the proposed framework. This is a critical area that authors should address to ensure the robustness and trustworthiness of their work. However, the comment does not provide specific guidance or suggestions on how to conduct this analysis or what aspects of security should be considered. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it directs the authors to a critical area but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point points out that \"Memb\" is mentioned as the previous stateoftheart but lacks any reference. This implies that the authors should include a reference to support the claim about \"Memb\" being the previous stateoftheart. However, the comment does not explicitly instruct the authors to add a reference, leaving it to be inferred. The action is concrete in terms of what needs to be done (adding a reference), but it is implicit in the instruction. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment mentions \"Memb\" as the previous stateoftheart but notes the absence of any reference. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of missing references but lacks grounding, as it does not provide a clear reference to the part of the paper where \"Memb\" is mentioned. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that \"Memb\" is the previous stateoftheart but notes the absence of any reference. This claim is 3 as it points out a potential oversight in the paper, but it lacks specific details or references to support the assertion that \"Memb\" is indeed the previous stateoftheart. The comment does not provide enough information for the authors to fully understand the basis of the claim or to verify it themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a significant oversight in the paper, noting that \"Memb\" is mentioned as the previous stateoftheart but without any reference. This is a critical observation that highlights a gap in the paper\"s documentation and could impact the credibility of the claims made. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which references should be included or how to integrate them into the text. While it identifies a key area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide specific guidance or suggestions on how the authors might address these issues. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not specify which part of the paper these weaknesses are discussed in. The authors can make an educated guess that it relates to the sections discussing the FSR metric, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for clearer examples and weaknesses in the FSR metric, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide any specific claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not contain any subjective claims or requests for changes, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difficulty in finding examples that illustrate the loss principles clearly, similar to those presented in the paper and the supplement. It also mentions weaknesses in the proposed FSR metric but does not provide specific details or suggestions on how these weaknesses could be addressed. The comment lacks actionable feedback and does not offer any guidance on how the authors might improve their draft. As a result, it is 2, as it identifies a potential issue but does not provide enough information for the authors to make meaningful improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases generated for the training data, specifically questioning how different these paraphrases are from the original sentences. It emphasizes the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment suggests that if the paraphrases are not significantly different from the originals, the quality of the final training data will be low, leading to a limited number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting methods to evaluate or improve the paraphrasing process. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess and potentially improve the paraphrasing process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of paraphrasing for the training data, specifically questioning how different the paraphrases are from the original sentences. It highlights the importance of this aspect for the subsequent steps in the process. However, it does not specify which part of the paper discusses the paraphrasing process, making it weakly grounded. The comment is specific in detailing the concern about the quality of paraphrases and their impact on the final training data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases generated for the training data, suggesting that if the paraphrases are not significantly different from the original sentences, the quality of the final training data will be compromised. The comment logically connects the quality of paraphrases to the impact on the training data, providing a clear rationale for the claim. However, it lacks specific examples or references to support the assertion about the impact of paraphrase quality on the training data. This makes the claim 3, as it requires further evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paraphrasing process for the training data, specifically questioning the difference between the paraphrases and the original sentences. It highlights the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment logically explains that if the paraphrases are not significantly different, the quality of the final training data will be compromised, leading to a limited number of pairs being added to the new training data. This feedback is clear and actionable, as it prompts the authors to evaluate and potentially improve the paraphrasing process to ensure the quality of their training data. However, it could be more helpful if it provided specific suggestions or examples on how to assess or enhance the paraphrasing process. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the text input or object elements are being questioned. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text inputs by the four text elements of an object. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review point raises a question about whether the text input can be concatenated by the four text elements of an object. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the text. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer justification for why the subject matter is important or relevant. However, the comment does not specify how to achieve this motivation or what aspects of the paper need to be revised to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a motivation section but are not provided with concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should better motivate the \"Why\" behind the topic being presented, implying that the authors should provide a clearer justification for why the subject matter is important or relevant. However, the comment does not specify which part of the paper lacks this motivation or where it should be added. The authors can make an educated guess that it relates to the introduction or background sections, but the comment lacks full grounding. It is specific in suggesting the need for motivation but does not provide detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks motivation for why the topic is important or relevant. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that it lacks motivation for why the topic is important or relevant. This is a valid observation, as the paper may benefit from a clearer explanation of its significance and relevance. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending additional background information, context, or examples to enhance the motivation. While it points out a potential weakness, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the unfairness of comparing the domainspecific model trained on Pix3D to zeroshot singleimage 3D reconstruction models, also tested on Pix3D. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of unfair comparisons or suggestions for alternative experiments or methodologies. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the domainspecific model\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the unfair comparisons to zeroshot singleimage 3D reconstruction models, even though they are also tested on Pix3D. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparisons to zeroshot singleimage 3D reconstruction models are unfair because both the domainspecific model and the models being compared are trained and tested on Pix3D. However, the comment lacks specific reasoning or evidence to support why this comparison is unfair. It does not provide examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the fairness of the comparisons made in the paper, specifically regarding the use of Pix3D for both the domainspecific model and the zeroshot singleimage 3D reconstruction models. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable feedback or specific recommendations, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the comment implies that such experiments would be beneficial, it does not explicitly instruct the authors to perform them. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments to strengthen their work. However, the suggestion is concrete in terms of the specific datasets to use, which provides some guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments would be beneficial or how they would enhance the support for C2D. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any reasoning or evidence to support why these specific datasets would be beneficial or how they would enhance the support for C2D. Without such justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper\"s support for the C2D method. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D method would benefit from them. While it offers a direction for improvement, it does not fully address the authors\" needs for actionable feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. While it implies that the authors should clarify this aspect, the comment does not provide explicit guidance on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to clarify this point but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential area of confusion, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify this point or address any potential issues related to the grid search. The comment is 3 as it prompts the authors to consider this aspect, but it does not offer actionable advice or detailed feedback to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to address these issues or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the diversity of the sample, particularly regarding racial and economic diversity, and how well the results might generalize to other groups, especially marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, especially marginalized ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the sample lacks diversity or that the results may not generalize. Without additional context or justification, the authors may find it challenging to address this concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, especially marginalized ones. This is a critical consideration for ensuring the applicability and relevance of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the diversity of their sample. While it highlights a potential weakness, it lacks actionable feedback, making it 3. The authors are left with a clear area for improvement but without detailed guidance on how to implement it. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential nonconvexity issue or what properties of function Z should be considered. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182184, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of nonconvexity and suggests that it may not be a problem for the SGD to converge if the function Z has good properties. This provides clear guidance on what needs to be addressed in the specified part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of what \"good properties\" might entail or how they would affect convergence. Without detailed justification or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has good properties. While this observation is insightful, it lacks depth and does not provide actionable guidance or suggestions for the authors to address the issue. The comment identifies a potential area of concern but does not offer ways to resolve it or improve the draft. Therefore, it is 3, as it provides some insight but lacks comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental settings are not properly mentioned, which is crucial for result reproducibility. It also mentions that the code is not provided. This feedback is clear and direct, providing the authors with specific actions to take: they need to ensure that the experimental settings are properly documented and provide the code. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the experimental settings and the lack of code, which are critical for result reproducibility. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the experimental settings and the absence of code, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental settings are not properly mentioned, which is critical for result reproducibility. It also mentions that the code is not provided. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, noting that they are not properly mentioned, which affects result reproducibility. It also points out the absence of code, which is essential for reproducibility. This feedback is clear and actionable, as it highlights specific areas that need improvement to enhance the credibility and reliability of the research. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific documentation or code sharing practices. Overall, the comment is 4 as it directs the authors to important aspects of their draft that require attention."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could be improved with a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify how to achieve this or what aspects of the motivation need more detail. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the motivation but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation behind applying CMD in federated learning, suggesting that it could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of the motivation, but without explicit references to specific sections, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and suggests that a more explicit demonstration or explanation would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the unclear motivation behind applying CMD in federated learning. It suggests that a more explicit demonstration or explanation would be beneficial. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to enhance the explanation or demonstration. Without detailed advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it points out a weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"CoNO model\" and the \"UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the source of the performance boost and suggesting that comparisons to UNets are necessary. The reference to specific works (Raonic et al. and Gupta et al.) adds further detail to the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. The reviewer suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This provides a logical reasoning and supports the claim with specific examples, making the comment 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how UNets perform in similar contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical point about the complexity of the proposed CoNO model, specifically questioning whether the performance boost is due to the fractional transform or the UNet operation. It suggests that comparisons to UNets are necessary, especially given their strong performance in regular gridded domains, as evidenced by references to Raonic et al. and Gupta et al. This feedback is clear and actionable, as it directs the authors to include comparisons to UNets to clarify the source of the performance boost. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment highlights a potential area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the additional experiments should be emphasized or clarified. As a result, the comment lacks actionability, leaving the authors without a clear path for improvement.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. This provides some specificity about the part of the paper that the reviewer did not fully engage with, but it does not specify what aspects of the additional experiments need attention or improvement. The comment is weakly grounded because it does not explicitly mention which section of the paper the additional experiments are located in, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a factual statement expressing appreciation for the comprehensive Appendix and acknowledging the reviewer\"s inability to thoroughly read the additional experiments due to time constraints. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive Appendix as a valuable addition to the paper, providing additional detail about certain aspects. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment appreciates the effort to provide more detail, it lacks actionable feedback or suggestions for improvement. It does not guide the authors on how to address the issue of not fully engaging with the additional experiments or what specific aspects might need further clarification or emphasis. As a result, the comment is 2, as it provides some insight but does not offer actionable advice for enhancing the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that certain terms, such as W1, W2, and W, are not defined in the paper. The reviewer suggests that these terms might denote the Encoder and Decoder network, but this is only a guess. The comment does not provide explicit guidance on how to define these terms or where they should be defined in the paper. While it implies that the authors should clarify the definitions, the action is not explicitly stated, and the authors may not know exactly how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections and equations (p.3, A4, eq.3) where terms like W1, W2, and W are not defined. This allows the authors to accurately identify the parts of the paper that need clarification. The comment is also specific because it clearly specifies what is missing\u2014definitions for these terms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements regarding the absence of definitions for certain terms (W1, W2, and W) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of definitions for certain terms (W1, W2, and W). It provides clear guidance by suggesting that these terms might denote the Encoder and Decoder network, which is a reasonable inference. However, the comment could be more helpful if it offered suggestions on where or how these definitions should be included in the paper. Despite this, the feedback is 3 as it directs the authors\" attention to a critical area that needs clarification, allowing them to make improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per number of residents. While the comment identifies a potential limitation and provides some context, it does not explicitly instruct the authors to address this issue or suggest specific changes to their formulation. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative aggregation methods but are not provided with concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption that observations are obtained by averaging over the corresponding support, suggesting alternative aggregation methods such as simple summation or populationweighted average. The comment further provides context by noting that disease incident data are often available in count or rate per number of residents. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to a specific model or process, and it suggests that the authors\" formulation assumes a particular method of aggregation. The reviewer provides references to Law et al., NeurIPS\"18 and 4, which supports the claim by linking it to established work. However, the comment could be strengthened by providing more detailed reasoning or examples of how the formulation might be improved or generalized to accommodate different aggregation methods. While the references provide some basis for the claim, the lack of detailed explanation or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the assumption that observations are obtained by averaging over the corresponding support. It suggests that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per number of residents. This feedback is 3 as it points out a limitation in the authors\" formulation and provides some context for alternative aggregation methods. However, it lacks specific guidance or suggestions on how the authors might address this issue or improve their formulation. To be more helpful, the comment could include recommendations or examples of how to incorporate these alternative aggregation methods. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. This is an explicit action, as it clearly instructs the authors on what to do to improve their draft. The suggestion is also concrete, as it provides a specific direction for enhancing the study by introducing more complexity and comparing it with a reinforcement learning baseline. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors consider making the policy nonfixed to allow for more complicated tasks, which would enable a comparison with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion should be applied to, nor does it provide detailed guidance on how to implement this change. The authors can infer that it relates to the sections discussing policy and reinforcement learning, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the current setting is a subset of reinforcement learning with a fixed policy and proposes making the policy nonfixed to allow for more complicated tasks. The reviewer provides a logical reasoning by suggesting that this change would enable a comparison with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support the claim that the current setting is a subset of reinforcement learning or that the suggested change would be beneficial. This makes the claim 3, as it provides a logical basis but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment suggests a potential enhancement to the study by proposing that the authors consider making the policy nonfixed to allow for more complicated tasks. This would enable a comparison with a reinforcement learning algorithm baseline, which could provide a more comprehensive understanding of the setting. The comment offers a clear and actionable suggestion for improving the draft by expanding the scope of the study. However, it could be more helpful if it provided specific guidance on how to implement this change or what aspects of the policy should be made nonfixed. Overall, the comment is 4 as it provides a valuable direction for enhancing the study, but it could be more detailed to fully support the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps should be taken to complete the study. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, it does not specify which part of the paper this issue pertains to, such as a particular section or analysis. Without explicit references or context, the authors cannot confidently determine where in the paper this comment applies. Additionally, the comment lacks specificity regarding what aspects of the relationship need to be established or how it could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease has not been established. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease has not been established. This is a critical observation that highlights a major weakness in the paper. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or direction, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a problem but does not offer any constructive advice for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, specifically that it is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should consider using real data or adjusting their comparison, but it does not specify which data or comparisons would be more appropriate. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation and the comparison with a specific reference, 5, which is designed for a more complex problem. However, it does not specify which part of the paper discusses the numerical evaluation or the comparison, making it weakly grounded. The comment is specific in pointing out the issue with the comparison and the use of synthetic data, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the use of synthetic data and an unfair comparison with a method designed for a more complex problem. The reviewer provides a logical reasoning by pointing out the difference in the complexity of the problems addressed by the two methods, which supports the claim. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that it is not fully convincing due to the use of synthetic data. It also points out that the comparison with another method, 5, is not fair because it is designed for a more complex problem. This feedback is valuable as it highlights a critical weakness in the evaluation process and suggests that the authors should consider using real data or adjusting their comparison to make it more meaningful. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of alternative approaches. Despite this, the comment provides a clear direction for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. While the comment implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"QRS and RS,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between QRS and RS and the need for clarification on a specific value of u that would cause them to behave differently. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide any supporting evidence or reasoning to justify why importance sampling should have been used or why the current approach is inferior. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific but still lacks detailed reasoning or examples to fully substantiate the claim. Overall, the comment lacks sufficient evidence and reasoning to be considered 5, making it 2.", "helpfulness_rationale": "The review comment raises two distinct points. The first part questions the authors\" decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. This feedback is 3 as it prompts the authors to reconsider their approach and potentially improve it. However, it lacks specific guidance on how to address this issue or why importance sampling might be more appropriate. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific and actionable, as it provides a clear direction for the authors to improve their explanation. Overall, the comment is 3 as it identifies areas for improvement but could be more comprehensive and detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost and running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of computation cost or running time should be compared or how this comparison should be presented. Without any actionable steps or suggestions, the authors are left without a clear understanding of what changes or additions are needed to address this point. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost and running time but does not specify which part of the paper this comparison should be made in. It lacks grounding as it does not identify a specific section, figure, or table where this comparison is discussed. Additionally, it is not specific about what aspects of computation cost or running time should be compared. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for a comparison of computation cost and running time, which does not contain a claim or opinion that requires verification. It is a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost and running time, which is an important aspect of evaluating the efficiency and practicality of the proposed method. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of computation cost or running time should be compared. Without actionable feedback or detailed guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of a comparison against baselines in the paper, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment suggests that this is a common practice in binary analysis applications and that many papers have developed architectureagnostic similarity comparisons or reported similar tasks. While the comment implies that the authors should include baselines for comparison, it does not explicitly instruct them to do so or provide specific guidance on which baselines to use. The action is implicit and somewhat vague, as the authors can infer the need for baselines but may not know exactly which ones to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the lack of baselines in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not comparing against baselines and references a common practice in binary analysis applications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment supports this claim by referencing a \"widelyunderstood binary analysis application\" and mentioning that many papers have developed architectureagnostic similarity comparisons or reported similar tasks. This provides a logical reasoning and common knowledge basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines. It highlights that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines, which is a common practice in binary analysis applications. The comment also references other papers that have developed architectureagnostic similarity comparisons or reported similar tasks, providing context and relevance to the issue. This feedback is clear and actionable, as it directs the authors to include baselines for comparison, which is a crucial aspect of evaluating the effectiveness of their methodology. By addressing this gap, the authors can strengthen their paper and provide a more comprehensive evaluation of their approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text, specifically regarding the requirement for the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for correction, clarification, or improvement. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the abstract requires the proposal distribution to upper bound the target everywhere, which is contradicted by the text. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a clear and actionable feedback that the authors can use to correct the inconsistency in their paper. However, the comment does not provide additional context or suggestions on how to address this issue or its implications for the paper. While it highlights a critical error, it lacks depth and guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, implying that the authors should clarify or justify the purpose of this section. However, it does not provide explicit guidance on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or explanation but are not given concrete steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the intent of this section, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2, rather than a claim or opinion that requires verification. It does not contain any subjective statements, judgments, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, indicating that the authors should clarify the purpose or content of this section. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the approach, specifically regarding how it integrates knowledge about objects and verbs to overcome reporting bias. It also notes that the paper quickly delves into technical details without adequately explaining the overall approach or its rationale. While the comment identifies areas that need clarification, it does not provide explicit guidance on how to address these issues or suggest specific changes to improve the clarity of the explanation. The action is implicit and somewhat vague, as the authors are left to infer what needs to be clarified and how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many aspects of the approach\" that need clarification, implying that the reviewer has specific parts of the paper in mind. It also highlights a particular concern about the interaction between knowledge about objects and verbs and how it relates to overcoming reporting bias. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach integrates knowledge about objects and verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of concrete evidence or references leaves the claim 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity, specifically regarding the integration of knowledge about objects and verbs to overcome reporting bias. It highlights that the paper quickly delves into technical details without adequately explaining the overall approach or its rationale. This feedback is valuable as it points out a critical area where the authors need to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue, such as recommending additional explanations or diagrams to illustrate the approach. Despite this, the comment is 4 as it directs the authors\" attention to a key area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a critique of the chatGPT baseline, labeling it as \"very rudimentary\" and suggesting that a fewshot approach is not tested. It also offers a potential improvement by recommending the inclusion of discourse relation information in the prompts, possibly using a ChainofThought style approach. While the comment identifies areas for improvement, it does not provide explicit instructions on how to implement these suggestions or test the fewshot approach. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the chatGPT baseline, describing it as \"very rudimentary\" and suggesting that a fewshot approach is not tested. It also proposes including discourse relation information in the prompts, possibly using a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatGPT baseline or where the evaluation is presented, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific suggestions for improvement, it lacks grounding, as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the chatGPT baseline is \"very rudimentary\" and suggests that a fewshot approach is not tested. It also proposes including discourse relation information in the prompts, possibly using a ChainofThought style approach, as a potential improvement. However, the comment lacks specific evidence or references to support the claim that the baseline is rudimentary or that the fewshot approach is not tested. Additionally, while the suggestion to include discourse relation information is logical, it is not fully substantiated with examples or references. Therefore, the claim is 3, as it provides some justification but lacks detailed evidence or references to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by labeling the chatGPT baseline as \"very rudimentary\" and noting that a fewshot approach is not tested. It provides a constructive suggestion by recommending the inclusion of discourse relation information in the prompts, possibly using a ChainofThought style approach, which could potentially yield good results. This feedback is actionable and offers a clear direction for improving the paper by expanding its evaluation. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to implement the suggested approach. Overall, the comment is 4 as it identifies a significant area for improvement and offers a concrete suggestion, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the author was unclear about the numbers of parameters used in each approach, specifically in Section B.3. This provides a direct action for the authors to take, which is to clarify or provide the specific numbers of parameters used in each approach. The comment is explicit and concrete, as it clearly identifies the issue and suggests a specific action to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the numbers of parameters used in each approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting clarification on the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the numbers of parameters used in each approach, as mentioned in Section B.3. This feedback is clear and actionable, as it directs the authors to clarify or provide the specific numbers of parameters used in each approach. By addressing this point, the authors can improve the clarity and transparency of their paper, making it more understandable for readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation results reported in Table 1, specifically noting that they are based on only three trials for each case. The reviewer suggests that this is statistically insignificant and questions the relevance of reporting deviations. The comment also critiques statements claiming performance superiority over baselines due to the lack of statistical significance. While the comment identifies a potential issue with the evaluation methodology and the interpretation of results, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should either increase the number of trials or rephrase their claims to reflect the limitations of the current evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation results, noting that they are based on only three trials for each case, which is statistically insignificant. The comment further explains why this affects the interpretation of deviations and the validity of certain performance claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically insignificant. The reviewer argues that this lack of statistical significance makes it nonsensical to report deviations and supports the claim that statements about performance superiority over baselines are not valid. The comment provides a logical reasoning for the claim, explaining why the limited number of trials affects the reliability of the results. However, it could be strengthened by providing specific examples or references to support the assertion about the impact of limited trials on statistical significance. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that they are based on only three trials for each case. This is a critical observation because it highlights a potential flaw in the statistical significance of the results. The comment further explains that this limitation makes it nonsensical to report deviations and supports claims of performance superiority over baselines. This feedback is clear and actionable, as it prompts the authors to reconsider their evaluation methodology and potentially rephrase their claims to reflect the limitations of their current approach. However, the comment could be more helpful if it suggested specific ways to address this issue, such as increasing the number of trials or using more robust statistical methods. Overall, the comment is 4, as it provides valuable insights into a critical area of the paper that requires attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the architecture used for the experiments is not clearly explained in the paper, and instead, the authors refer to Jiang et al. (2019) for details. This makes the paper not selfcontained. The comment implies that the authors should provide a clear explanation of the architecture used in their experiments, rather than relying on external references. However, it does not specify how to do this or what details should be included in the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper relies on an external reference (Jiang et al., 2019) for details, making it not selfcontained. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s architecture is not clearly explained, relying on an external reference (Jiang et al., 2019) for details. This claim is 3 as it highlights a potential issue with the paper\"s selfcontainment. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the problem. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained within the paper. Instead, the authors refer to an external source, Jiang et al. (2019), for details. This makes the paper not selfcontained, which is a critical concern for readers who may not have access to the external reference. The comment highlights a clear area for improvement, suggesting that the authors should provide a detailed explanation of the architecture used in their experiments. This feedback is actionable and provides a specific direction for the authors to enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several specific issues with the presentation quality of the paper, including problems with figures and tables. It mentions issues such as the use of \"\" for methods, uninformative \"Dataset\" columns, and unclear indications in tables. However, the comment does not provide explicit instructions or suggestions on how to address these issues. While the authors can infer that they need to improve the presentation quality, the feedback lacks concrete guidance on what specific changes to make. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figs 1&2,\" \"the tables with a \"\" for the method,\" \"the \"Dataset\" columns in the tables,\" \"the management of Fig 3 and Table 2,\" and \"a \"*\" appearing in Table 1 with no indication of meaning.\" This allows the authors to accurately identify the sections that need attention. The comment is also specific because it details the issues with each of these elements, such as the use of \"\" for methods, uninformative \"Dataset\" columns, and unclear indications. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that certain aspects of the presentation quality are a weakness for a highquality publication like NeurIPS. It provides specific examples, such as issues with figures and tables, including the use of \"\" for methods, uninformative \"Dataset\" columns, and unclear indications. These examples are detailed and provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to specific standards or best practices in NeurIPS publications. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, including problems with figures and tables. It highlights issues such as the use of \"\" for methods, uninformative \"Dataset\" columns, and unclear indications in tables. By pointing out these specific areas, the comment provides the authors with clear and actionable feedback on how to improve the presentation and clarity of their work. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as recommending alternative ways to present data or suggesting improvements to the formatting. Overall, the comment is 4 as it directs the authors to areas that need improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that they do not significantly impact idiomatic vs. random data, as indicated by Figure 3. The comment implies that the results do not demonstrate idiomspecific improvements, instead suggesting that better NMT systems are generally better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, noting that the impact on idiomatic vs. random data is similar for most language and score combinations. The comment further specifies that the results suggest better NMT systems are generally better at idiomatic translations, rather than demonstrating idiomspecific improvements. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods do not significantly impact idiomatic vs. random data, as indicated by Figure 3. The comment suggests that the results merely show that better NMT systems are better at idiomatic translations, rather than demonstrating idiomspecific improvements. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to delve deeper into the data and results presented in Figure 3 to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the proposed upweighing and KNN methods, suggesting that they do not demonstrate significant impact on idiomatic vs. random data, as shown in Figure 3. It implies that the results may not be idiomspecific, but rather indicate that better NMT systems are generally better at idiomatic translations. This feedback is 3 as it highlights a potential limitation in the paper\"s findings and prompts the authors to consider whether their methods are truly idiomspecific. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the methods to demonstrate idiomspecific improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include important references for domain adaptation and to cite and discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or which parts of the paper should include these references. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its request for additional references but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss them in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are crucial for the paper. This lack of detailed justification or examples makes it difficult for the authors to understand the significance of the missing references and how to address the issue. As a result, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully support it.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it highlights a critical area for improvement and offers a specific step for the authors to take to enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it specified which references are missing or provided examples of relevant literature. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more detailed to fully support the authors\" efforts."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a claim in the paper as misleading and suggests that the authors should clarify that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. However, the comment does not provide explicit guidance on how to make this clarification or what specific details should be added to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to address the claim but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific claim in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out that the claim is misleading and suggests that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement \"To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction\" is misleading because prior work, such as ClimateBench or ClimateSet, already addresses this gap. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as the authors would need to conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper as misleading, suggesting that prior work, such as ClimateBench or ClimateSet, already addresses the gap being claimed. This feedback is valuable as it points out a potential error in the paper and encourages the authors to clarify their contribution. However, the comment could be more helpful if it provided specific examples or references to support the claim, or if it offered suggestions on how to address the issue. Despite this, the comment provides a clear direction for the authors to improve their draft by clarifying the novelty of their work. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential source of confusion in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit guidance or suggestions on how to resolve this issue. The comment lacks concrete details on how to address the confusion, such as recommending alternative notation or suggesting a clearer distinction between the two types of risks. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of confusion caused by the dual use of \"r\" and suggests that this notation is problematic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is problematic or how it might cause confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, where \"r\" is used to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable feedback that can help the authors clarify their notation and avoid potential confusion in their readers. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending alternative notation or explaining the context in which each use of \"r\" is appropriate. Despite this, the comment is still 3 as it directs the authors to a specific area needing attention and improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to improve the presentation of the factors or what specific changes could be made to enhance the clarity or effectiveness of the information. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where factors are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the information are missing or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that presenting factors in a table does not provide any additional information compared to presenting them in pure text. However, it lacks specificity and does not offer any suggestions or guidance on how the authors might improve the presentation of the factors or what specific changes could be made to enhance the clarity or effectiveness of the information. Without actionable feedback or detailed advice, the comment does not provide the authors with a clear path for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with pruning in large networks, specifically mentioning the need to consider global top Q values of the metric over the average of gradients. It suggests that this could break acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this aspect further but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning\" and \"large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with pruning in large networks, specifically the need to consider global top Q values of the metric over the average of gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks, which are typically trained in distributed settings, and suggests that the authors should consider the global top Q values of the metric over the average of gradients. This claim is 3 as it provides a logical reasoning about the potential impact of pruning on acceleration techniques like quantization and sparsification. However, the comment lacks specific examples or references to support the claim fully, making it 3. The authors would need to explore this issue further to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of pruning in large networks, specifically highlighting the need to consider global top Q values of the metric over the average of gradients. It suggests that this oversight could break acceleration techniques like quantization and sparsification. While the comment points out a critical area for consideration, it lacks specific guidance or suggestions on how the authors might address this issue or integrate it into their work. Providing more detailed advice or examples would enhance the comment\"s helpfulness. Therefore, the comment is 3, as it offers a valuable insight but requires further elaboration to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what changes should be made to the draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, pointing out that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual statement about the existence of multiple entities in both sentences and documents, which is a general observation in the field of natural language processing. It does not express an opinion, make a claim, or suggest changes, and it does not require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific issue with the text, noting that multiple entities can exist in both sentences and documents, which is relevant even for relation classification tasks beyond documentlevel RE or joint entity and relation extraction. This feedback is 3 as it highlights a potential misunderstanding or oversimplification in the paper. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or clarify their text. While it identifies a potential area for improvement, the comment could be more helpful with additional context or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method compares to prior art, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of the comparison should be addressed or how the authors might conduct this comparison. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or additions are needed to their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed method with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the introduction or results sections, but without explicit guidance, it is difficult to pinpoint the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison are being questioned or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for a comparison with prior art, which does not contain any claims, opinions, or suggestions that require verification. It is purely factual and does not necessitate a response or further explanation from the authors. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the comparison of the proposed method with prior art. While it identifies an important area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples, the authors are left without a clear understanding of what changes or additions are needed to their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer any actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a redundancy in RQ1, suggesting that it does not add any new information for the audience. It implies that the authors should consider analyzing the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. While the comment suggests an alternative analysis, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore this new analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with RQ1, stating that it adds no extra information for the audience and suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The reference to a specific paper (\"https://aclanthology.org/2023.findingseacl.9/\") provides additional context and supports the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that RQ1 is redundant and does not add new information for the audience. It suggests an alternative analysis regarding the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. The comment provides a reference to a specific paper, which could support the suggestion for an alternative analysis. However, the claim about RQ1 being redundant lacks detailed reasoning or evidence, making it 3. The authors would need to consider the context and the referenced paper to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a redundancy in RQ1, suggesting that it does not provide any additional information for the audience. It implies that the performance variation across multiple HS datasets in a crossdata setting is expected and therefore not novel. The comment also offers a constructive suggestion for an alternative analysis, focusing on the impact of explicit hate information on implicit hate speech detection performance and its effect on RQ2 and RQ3 tsne plots. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. However, it could be more helpful if it included specific guidance on how to implement this new analysis or examples of how to incorporate the suggested perspective. Overall, the comment is 4, as it effectively points out a potential area for improvement and offers a valuable suggestion for further exploration."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part would remain the same for both pretraining and finetuning, with the addition of another head in the finetuning stage to compute value functions for states. This comment provides a clear and explicit suggestion for how the authors could modify their approach, offering a concrete action to take. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the \"LSTM part\" and the objective for both pretraining and finetuning, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it provides a clear suggestion for how the authors might modify their approach by adding another head to the network to compute value functions for states. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning, and proposes adding another head to the network to compute value functions for states. This suggestion is based on logical reasoning and provides a clear explanation of how the authors might modify their approach. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the feasibility and potential impact of this suggestion, but the comment provides a solid foundation for further exploration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the LSTM part of the paper, particularly in the context of pretraining and finetuning. It points out that the objective for the LSTM part could remain the same for both stages and proposes adding another head to the network to compute value functions for states. This feedback is clear and actionable, offering a concrete way for the authors to enhance their approach. However, the comment could be more helpful if it provided additional context or examples to further clarify the suggestion. Overall, the comment is 4 as it provides a valuable direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" While the comment implies that the authors should include these older works, it does not specify which specific works should be acknowledged or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which works are being referred to and how to incorporate them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Regarding the related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This provides clear guidance on what needs to be addressed in the related works section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" However, the comment does not provide specific examples or references to these older works, making it difficult for the authors to understand which works are being referred to. This lack of detailed support or examples makes the claim 3, as the authors would need to infer or research the specific works being suggested. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This feedback is clear and actionable, as it provides a specific direction for improving the related works section by including a broader range of references. However, the comment could be more helpful if it specified which older works should be included or why they are relevant. Despite this, the suggestion is 4 as it guides the authors to enhance the comprehensiveness of their literature review. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The reviewer suggests that if the predictor is accurate in identifying good subregions, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or address the discrepancy in the results. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The comment further clarifies the expectation that increasing the sampling probability for topperforming predicted architectures should lead to better performance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. The reviewer provides a logical reasoning by suggesting that if the predictor is accurate in identifying good subregions, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This reasoning is based on the assumption that the predictor\"s accuracy in identifying good subregions should result in better performance when sampling is focused on these regions. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this reasoning and potentially provide additional evidence or clarification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It provides a logical reasoning that if the predictor is accurate in identifying good subregions, increasing the sampling probability for topperforming predicted architectures should lead to better performance than uniform sampling. This feedback is 3 as it points out a potential inconsistency in the results and suggests a possible explanation, prompting the authors to reconsider their findings and potentially provide additional analysis or clarification. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a clear explanation of how their SE framework improves and why it is beneficial. It also emphasizes the need to demonstrate the reasoning behind their achievements, going beyond just showing results. The comment provides a specific action for the authors to take, which is to include a detailed explanation of the framework\"s benefits and how it is implemented. Additionally, it suggests referencing a specific paper to support their claims, offering a concrete example of how to enhance the paper. This feedback is explicit and provides clear guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for a clearer explanation of how the SE framework improves and why it is beneficial, and it suggests showing the reasoning behind the achievements. Additionally, it provides a reference to a relevant paper, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should provide a clearer explanation of how their SE framework improves and why it is beneficial. The reviewer suggests that the authors should demonstrate the reasoning behind their achievements, rather than just showing results. The comment references a specific paper, \"Neural architecture search with gbdt\" by Luo et al., which provides a relevant example of how to enhance the explanation. However, the comment could be strengthened by providing more detailed reasoning or examples from the authors\" work to support the claim. Overall, the claim is 4, as it provides some justification but could benefit from more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by instructing the authors to explain how their SE framework improves and why it is beneficial. It emphasizes the need to go beyond just showing results and to provide a detailed explanation of the reasoning behind their achievements. This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their work. Additionally, the reference to a specific paper provides a relevant example of how to improve the explanation, offering a concrete suggestion for the authors to consider. However, the comment could be more helpful if it provided specific examples or more detailed guidance on how to structure the explanation. Overall, the comment is 4, as it offers clear and actionable feedback that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the applicability of the metrics used for evaluating continual learning in certain scenarios, such as when task boundaries are unknown or not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for alternative metrics or approaches that could be more suitable. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the issue with the applicability of these metrics in certain scenarios, such as when task boundaries are unknown. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in scenarios where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the \"loss after switch\" and \"recovery time after switch.\" It points out that these metrics might not be applicable in scenarios where task boundaries are unknown or not clearly defined. This feedback is 3 as it highlights a potential weakness in the evaluation approach, prompting the authors to consider alternative metrics or methods that could be more suitable for their dataset. However, the comment lacks specific suggestions or guidance on how to address this issue, which limits its usefulness. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the approach to debiasing the sketch, specifically the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this information cannot be computed accurately without a significant computational cost, which could defeat the purpose of the approach. The comment also mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors might address this issue or suggest alternative methods for debiasing the sketch. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to address this computational challenge. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It highlights a potential problem with the approach, noting that this information cannot be computed accurately without a significant computational cost, which could defeat the purpose of the approach. The comment also mentions a similar issue with computing the surrogate sketch. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these concepts are discussed. The comment is specific in detailing the issue but lacks full grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the approach to debiasing the sketch is flawed because it requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant computational cost. This would potentially defeat the purpose of the approach. The comment provides a logical reasoning for the claim, explaining the computational challenge involved. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the computational implications and potential biases in their approach, but the comment could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach to debiasing the sketch, specifically the need to know the statistical dimension d_lambda of the design matrix A. It highlights that this information cannot be computed accurately without a significant computational cost, which could defeat the purpose of the approach. The comment also mentions a similar issue with computing the surrogate sketch. While the comment points out a critical weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the computational challenges. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, which is a clear action for the authors to take. It also provides a concrete suggestion by specifying that the authors need to identify the cases where the model fails. This level of detail gives the authors a direct and actionable path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the absence of error analysis, which is crucial for other researchers to continue working on the task. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it would benefit the research. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of error analysis on the movie dataset. This is a critical aspect for other researchers to build upon the work, as understanding where the model fails is essential for further development. The comment provides a clear and actionable suggestion by emphasizing the need for error analysis, which would significantly enhance the paper\"s utility and impact. However, it could be more helpful if it offered specific guidance on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it lacks concrete details on how to develop this plan or what specific aspects should be included. The action is clear but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how to address the limitations mentioned in the paper. However, it does not specify which limitations are being referred to or where in the paper these limitations are discussed. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. The comment is specific in its request for a detailed plan but lacks grounding, as it does not identify the specific sections or elements being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the authors have mentioned limitations in the paper, they should provide a more detailed plan on how to address these drawbacks in their future work. This claim is 3 as it acknowledges the authors\" mention of limitations but highlights the need for a more detailed plan. However, the comment lacks specific examples or references to the limitations mentioned, which would strengthen the justification. The authors may need to infer the specific limitations being referred to, making the claim 3.", "helpfulness_rationale": "The review comment acknowledges that the authors have mentioned limitations in the paper but suggests that they should provide a more detailed plan on how to address these drawbacks in their future work. This feedback is 3 as it encourages the authors to be more specific and proactive in their approach to addressing the limitations. However, the comment could be more helpful if it provided specific guidance on what aspects of the limitations should be addressed or how the authors might develop a detailed plan. Overall, the feedback is clear but incomplete, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an expectation about the computational complexity of FedMITR compared to other methods and asks if a comparison has been made. While it implies that the authors should consider comparing the computational complexity, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors may infer that it relates to the experimental or results sections, but this is not explicitly stated. The comment lacks specificity as it does not provide details on what aspects of computational complexity should be compared or why this comparison is important. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the expectation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that it is expected to be higher. While it prompts the authors to consider this aspect, it lacks specificity and does not provide any guidance on how to address the issue or what specific comparisons should be made. The comment identifies a potential area for improvement but does not offer actionable advice or detailed suggestions, making it 3. The authors are left with a general direction but without clear steps to enhance their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague because it does not specify what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide guidance on how to clarify it. The action is implicit and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment refers to \"1) and 2)\" and \"figure 3,\" which provides some grounding as it implies specific parts of the paper being discussed. However, it does not explicitly mention which sections or figures these numbers correspond to, making it weakly grounded. The comment suggests using a generic external knowledge base to address issues 1 and 2, but it does not specify what these issues are or how the knowledge base would resolve them. This lack of specificity makes it difficult for the authors to understand what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as shown in Figure 3. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion. The mention of \"the writing is too confusing\" adds to the lack of clarity, as it does not specify what aspects of the writing are confusing or how they could be improved. Without detailed reasoning or examples, the claim is not verifiable, aligning with a score of 1.", "helpfulness_rationale": "The review comment suggests that issues 1 and 2 could be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment is vague and lacks specificity, as it does not clearly explain what issues 1 and 2 are or how the use of a generic external knowledge base would address them. Additionally, the comment mentions that the writing is confusing, but it does not provide any guidance on how to clarify it. Without detailed feedback or actionable suggestions, the authors are left without a clear understanding of what needs to be improved or how to make those improvements. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential error in the definition of perplexity and its representation in the paper. It explicitly states that the given definition is incorrect and suggests that it resembles crossentropy instead. However, the comment does not provide specific guidance on how to correct the definition or clarify the confusion. While it highlights an issue, it lacks actionable steps for the authors to take, such as suggesting alternative definitions or explanations. Therefore, the comment is 3, as it points out a problem but does not fully guide the authors on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and its representation, pointing out that it does not align with the actual definition of perplexity and instead resembles crossentropy. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity provided in the paper is incorrect and that it resembles crossentropy. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of perplexity provided in the paper, pointing out that it is incorrect and more accurately represents crossentropy. This feedback is clear and actionable, as it directs the authors to correct the definition and potentially clarify the confusion in their work. However, the comment could be more helpful if it provided additional guidance on how to accurately define perplexity or suggested alternative explanations. Overall, the comment is 4 as it highlights a critical error that needs correction, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the model has many components with hyperparameters that are not fully provided, suggesting that the authors may need to trace them in the source code. While the comment implies that the authors should provide more detailed information about these hyperparameters, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more details about the hyperparameters. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that many components of the model have hyperparameters that are not fully provided, suggesting that the authors should include this information. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model has many components with hyperparameters not fully provided, suggesting that the authors should include this information. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand which components are missing information. The lack of detailed evidence or examples renders the claim 3, as the authors would need to investigate further to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has many components with hyperparameters that are not fully provided. This is a critical piece of information that could impact the reproducibility and understanding of the model. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue, such as recommending specific hyperparameters to include or how to present them in the paper. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific claim made by the authors on line 238 regarding the Central Limit Theorem (CLT) and points out that it is incorrect. However, it does not provide any guidance or suggestions on how the authors should address this issue or correct their statement. The comment lacks explicit or implicit actions, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made about the Central Limit Theorem (CLT), pointing out that it does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the Central Limit Theorem (CLT) is incorrect. It provides a clear explanation of why the claim is invalid, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This reasoning is logical and wellsupported, making the claim 5. The reviewer provides specific details to substantiate the claim, ensuring that the authors understand the basis of the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out that it is incorrect. It provides a clear explanation of why the claim is invalid, stating that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is actionable as it directs the authors to correct their understanding and presentation of the CLT. However, the comment could be more helpful if it offered suggestions on how to accurately represent the CLT or provided additional context for the authors to better understand the issue. Overall, the comment is 4 as it effectively points out a critical error and guides the authors toward a correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. The reviewer suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract section\" and the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of the proposed method to the authors\" motivations and suggesting that it may not be effective for evaluating a single dialogue system. The comment provides a clear critique of the proposed framework and its limitations, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method may not be relevant to the authors\" motivations, as it is used for comparing dialogue systems rather than evaluating a single system. The reviewer supports this claim by mentioning specific frameworks like FFAEVAL and Chatbot Arena, which are used for comparison purposes. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to consider the context and implications of the proposed method to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically questioning its effectiveness in evaluating a single dialogue system. It suggests that the proposed framework, FFAEVAL, and similar frameworks like Chatbot Arena are more suited for comparing dialogue systems rather than evaluating a single system. This feedback is 3 as it identifies a potential limitation of the proposed method and encourages the authors to consider the applicability of their framework. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the evaluation framework. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. This is an explicit suggestion, as it clearly indicates a potential improvement and provides a specific example of what could be used. However, the comment does not provide detailed guidance on how to implement this change or why RoBERTabase might be a better choice. While the action is explicit, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests an improvement by proposing the use of a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting a potential improvement but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that using a better encoder, such as RoBERTabase, could lead to improvement. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase would be a better choice or how it would impact the results. The claim lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that using a better encoder, such as RoBERTabase, could lead to improvements in the paper. This is a specific and actionable suggestion that could help the authors enhance their work. However, the comment lacks depth and does not provide detailed guidance on how to implement this change or why RoBERTabase might be a better choice. While it identifies a potential area for improvement, it does not fully address the authors\" needs for comprehensive feedback. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. While the comment implies that the authors should provide a demonstration or example of this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how to achieve this demonstration or what specific aspects of the method should be highlighted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this demonstration is necessary or how it would be beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. This is a valuable suggestion as it highlights a potential tradeoff between fairness and performance that the authors should address. However, the comment lacks specificity and does not provide detailed guidance on how to achieve this demonstration or what specific aspects of the method should be emphasized. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. It suggests that this phrase is difficult to understand. However, the comment does not provide any guidance on how to address this issue or suggest alternative phrasing. The action is implicit, as the authors need to infer that they should clarify or rephrase the sentence to improve readability. The feedback lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"to meet\" and its difficulty in understanding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the phrase \"to meet\" is difficult to understand, specifically mentioning \"a response candidate can meet each utterance\" on line 280. However, the comment does not provide any further explanation or justification for why this phrase is problematic or how it could be improved. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, which is described as difficult to understand. However, it does not provide any suggestions or guidance on how to improve the clarity of this phrase or where it might be causing confusion. Without actionable feedback or examples of alternative phrasing, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback provides a clear and direct action for the authors to take, ensuring that the Perceptual Metric is accurately represented. The comment is explicit and concrete, leaving no ambiguity about what needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the Perceptual Metric in Figure 2, suggesting a correction in how the images are connected. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for improving their draft. By addressing this issue, the authors can enhance the accuracy and clarity of their figure, which is crucial for the reader\"s understanding. However, the comment could be more helpful if it explained why this correction is important or how it affects the overall interpretation of the results. Nonetheless, the feedback is 4 as it directs the authors to a specific area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, whereas Figure 1 depicts a single shared encoderdecoder for multiple tasks. This comment explicitly points out the inconsistency between the two figures, indicating that the authors should reconcile this discrepancy. However, it does not provide specific guidance on how to address the issue or suggest a way to resolve the inconsistency. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency between the two figures regarding the representation of encoderdecoders for auxiliary tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Fig. 1 and Fig. 2 are inconsistent regarding the representation of encoderdecoders for auxiliary tasks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks detailed explanation or examples to help the authors understand the nature of the inconsistency or how it affects the paper. As a result, the claim is 1, making it difficult for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 2 shows one encoderdecoder per auxiliary task, whereas Figure 1 depicts a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it points out a discrepancy that needs to be addressed to ensure consistency in the presentation of the methodology. However, the comment could be more helpful if it provided suggestions on how to reconcile this inconsistency or offered guidance on which figure is correct. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic largescale multitasking and achieves automation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback is implicit, as it points out areas that need improvement but does not specify what changes should be made. Additionally, the actions are vague, as the authors are left to infer what specific steps to take to clarify the main contribution and address the concerns. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically questioning the clarity of the proposed method\"s novel properties and its applicability. It also raises concerns about the lack of clarity regarding how the method copes with dynamic largescale multitasking and the achievement of automation. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding. It is specific in detailing the issues with the main contribution and the lack of clarity in certain aspects, but without explicit references to sections, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s novel properties are either overstated or not wellsupported. It also questions the clarity of how the method copes with dynamic largescale multitasking and achieves automation. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to substantiate the claims. The lack of concrete evidence or references makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic largescale multitasking and achieves automation. These are important areas that need to be addressed to improve the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the main contribution, address the overstated claims, or enhance the explanation of the method\"s capabilities. While it highlights key weaknesses, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to address them."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. While it implies that the authors should consider these alternatives, it does not provide explicit guidance on how to implement them or what specific steps to take. The suggestion is vague and lacks concrete details, leaving the authors uncertain about how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it does not specify which part of the paper this concern or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative directions for dealing with churn, but without clear references to specific sections or elements of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the appeal of training multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it lacks specific reasoning, examples, or references to support the claim that training 3040 models is not appealing or to substantiate the suggestion of using unlabeled data or constraints. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practicality of training multiple models to test the approach, which could be seen as a limitation. It also suggests exploring alternative directions, such as using unlabeled data or constraints, to improve the stability of the model. While the comment identifies a potential issue and offers a direction for improvement, it lacks specific guidance or examples on how to implement these suggestions. The feedback is 3 as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in the comparison, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide specific instructions on how to execute them.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. It references a table (Tab.) for the latter point, providing some grounding by indicating where the authors can find the information. However, the comment does not specify which section of the paper discusses the experiments, making it weakly grounded. It is specific in detailing the issues with the experiments, such as the limited types of teacher architectures and the outdated methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning two issues: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. The comment references a table (Tab.) for the latter point, which provides some evidence to support the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the limited types of teacher architectures. While the reference to the table provides some basis for the claim, the lack of additional evidence or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the fact that most compared methods were proposed before 2019. By pointing out these limitations, the comment provides the authors with clear areas for improvement. However, it lacks detailed guidance or suggestions on how to address these issues, such as recommending specific architectures to include or suggesting ways to incorporate more recent methods. While the comment highlights important weaknesses, it does not offer actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. It suggests that comparisons should be made between experiments using the same amount of data. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific changes they should make to ensure fair comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to ensure consistent data usage across comparisons, but they are not given concrete guidance on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of comparisons in the table, specifically regarding the use of different amounts of data. The comment provides examples of experiments that use less data than others, which helps the authors understand the issue and what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. The reviewer points out that some experiments use less data than others, which could affect the validity of the comparisons. However, the comment does not provide specific examples or detailed reasoning to support the claim that these differences in data usage are problematic. While the reviewer highlights a potential issue, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons in Table 2, specifically regarding the use of different amounts of data. It points out that some experiments, such as H>N and H>B, use less data than others, like H>N+B. This observation is important because it highlights a potential issue with the experimental design that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure that comparisons are made fairly. While it identifies a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the work, noting that prior knowledge may not always be available or accurate for specific subpopulations. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue of practicality or suggestions for alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practicality of using known causal relationships between features, noting that prior knowledge may not always be available or accurate for specific subpopulations. However, it does not specify which part of the paper this concern relates to, making it difficult for the authors to identify the exact section that needs attention. The comment provides some specificity by explaining the concern about practicality, but without grounding, the authors cannot pinpoint the exact part of the paper being discussed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the practicality of using known causal relationships between features, noting that prior knowledge may not always be available or accurate for specific subpopulations. The reviewer provides a logical reasoning by explaining that most researchers focus on mining causal relationships from data automatically due to these limitations. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this point to their work and consider how to address the practicality of their approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the paper\"s approach, noting that prior knowledge may not always be available or accurate for specific subpopulations. It highlights a potential limitation of the work by pointing out that most researchers focus on mining causal relationships from data automatically. This feedback is 3 as it identifies a potential weakness in the paper\"s approach and encourages the authors to consider the practical implications of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the practicality of the approach. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of polish in the figures and empirical results, which affects the clarity and confidence in the empirical findings. It specifically mentions missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to improve the presentation of their figures and empirical results, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses the lack of polish in figures and empirical results, which affects the clarity and confidence in empirical findings. It mentions specific issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. However, it does not explicitly mention which sections or figures these issues are found in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as improving figure presentation and empirical results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks polish in its figures and empirical results, which affects the clarity and confidence in the empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed guidance on how to address these issues or by referencing specific studies or practices that support the need for improved figure presentation and experimental rigor. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a lack of polish in the figures and empirical results, which affects the clarity and confidence in the empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of smallscale datasets and a single architecture type. This feedback is clear and actionable, as it directs the authors to improve the presentation of their results, which is crucial for the credibility and impact of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of best practices in figure presentation and experimental design. Overall, the comment is 4, as it highlights important areas for improvement that can significantly enhance the quality of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This feedback is explicit, as it clearly states what action the authors should take to improve their draft. It is also concrete, as it provides specific examples of nonlinear blocks that could be included in the comparative experiments. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2, to showcase the unique advantages or potential shortcomings of the proposed method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks comparative experiments with other nonlinear blocks, such as bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it provides a logical reasoning for the suggestion, noting that such experiments could showcase the unique advantages or potential shortcomings of the proposed method. However, the comment lacks specific examples or references to existing works that have conducted similar experiments, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it suggests a concrete way for the authors to enhance their draft by including these comparative experiments. By doing so, the authors can better demonstrate the unique advantages or potential shortcomings of their proposed method in a broader context. This guidance is valuable for the authors, as it provides a specific direction for expanding their experimental analysis. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit guidance on how the authors should improve the clarity of the discussion. There is no suggestion on what specific aspects need to be expanded or clarified, nor are there any concrete steps offered for enhancing the explanation. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion around this equation, noting that it is \"very terse\" and \"not very clearly explained.\" This provides clear guidance on what needs to be improved. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and \"not very clearly explained.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is \"very terse\" and \"not very clearly explained.\" This feedback is clear and actionable, as it directs the authors to expand and clarify their discussion around this equation. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or offered examples of what additional information could be included. Despite this, the comment still provides valuable guidance for the authors to enhance their draft, making it 4."}
