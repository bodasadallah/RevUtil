{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the dataset, suggesting that it may contain noise due to its artificial creation. The reviewer notes that the \"pristine\" set of tweets might not be pristine and could include misinformation and out-of-context images. While the comment identifies a concern, it does not provide explicit guidance on how the authors should address this issue or what specific analyses should be conducted to evaluate the dataset\\'s quality. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct additional analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the quality of the dataset, specifically mentioning that it is artificially created and may contain noise. It provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and out-of-context images. However, it does not explicitly mention which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing the potential issues with the dataset, such as the presence of noise and misinformation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and out-of-context images. This example provides a logical basis for the claim, making it somewhat verifiable. However, the comment could be strengthened by including references to similar issues in other datasets or studies, which would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, specifically noting that it is artificially created and may contain noise. The reviewer provides a specific example of how the \"pristine\" set of tweets might not be pristine and could include misinformation and out-of-context images. This feedback is valuable as it highlights a critical aspect of the dataset that could impact the validity of the results. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as proposing methods to evaluate the dataset\\'s quality or suggesting ways to mitigate potential noise. Despite this, the comment provides a clear direction for the authors to consider, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the description of HIERENC and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify the description or address the potential issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the description and potentially reconsider their approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the description of HIERENC, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies the issue with the description, namely that the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary may introduce a lot of noise. The comment provides a detailed critique of the method, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and questions the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. However, the comment lacks specific examples or references to support the claim that this approach is problematic. The reasoning is somewhat logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, questioning the approach of averaging representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer suggests that this approach may introduce a lot of noise, implying that it is not a good idea. This feedback is clear and highlights a potential weakness in the methodology, prompting the authors to reconsider their approach. However, the comment could be more helpful if it provided additional guidance or suggestions on how to improve the description or address the potential issue. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing clarification or improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it does not explicitly instruct the authors to make any changes, it implies that the authors should provide a justification or explanation for this selection process. The action is implicit, as the authors need to infer that they should address the question raised. However, the comment is somewhat actionable because it provides a clear direction for the authors to explore and address the issue. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this selection is discussed. Without explicit references or context, the authors may find it challenging to determine where to address this concern. The comment is specific in its inquiry but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. It does not contain a claim or opinion that requires verification. It is a factual inquiry, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it does not provide a direct suggestion for improvement, it prompts the authors to consider the rationale behind this selection process and its implications. This feedback encourages the authors to reflect on their methodology and potentially address any potential biases or limitations. However, the comment lacks depth and does not offer specific guidance on how to address the issue or improve the draft. Therefore, it is somewhat helpful, as it provides a direction for the authors to explore but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests clarification regarding the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it specifies exactly what needs to be clarified. The comment provides a clear and actionable instruction, ensuring that the authors know exactly what to address in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by requesting clarification on the splits used for obtaining the ATIS numbers in Table 4. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the understanding and reproducibility of their results. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity of their work, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" The reviewer suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance. However, the comment does not provide explicit guidance on how to correct this issue or suggest alternative wording. While the action is implicit, it is somewhat actionable as it points out a potential problem that the authors should address, even if the exact steps to take are not fully outlined. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"l.791\") where the issue is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias in the wording used to describe performance, suggesting that \"on par or better\" might be misleading. The comment provides a clear suggestion for improvement by recommending a correction in the wording. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a general cognitive bias among NLP researchers to label instances where they perform worse as \"on par\" and instances where they perform better as \"better.\" The reviewer suggests that this wording should be corrected. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the reasoning and evidence presented to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording used in the paper, specifically the claim of performing \"on par or better.\" It suggests that there might be a cognitive bias among NLP researchers that leads to inconsistent labeling of performance, where instances of worse performance are labeled as \"on par\" and better performance is labeled as \"better.\" This feedback is somewhat helpful as it points out a potential problem with the language used in the paper, but it does not provide specific guidance on how to correct this issue or suggest alternative wording. While it highlights an area for improvement, the comment could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and image-text models, and that the paper only applies similar ideas to video-text models. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty of the work or suggestions for potential improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of novelty in the paper, specifically mentioning that adversarial attacks by perturbing text have been done on many NLP models and image-text models. It notes that the paper only applies similar ideas to video-text models. However, the comment does not specify which part of the paper discusses these related works or where the novelty issue is most relevant. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of novelty but lacks grounding, as it does not clearly identify the specific parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, as adversarial attacks by perturbing text have been done on many NLP models and image-text models, and the paper only applies similar ideas to video-text models. The comment provides a logical reasoning by referencing the related work section of the paper, which suggests that the novelty is not in the concept itself but in its application to video-text models. However, the comment could be strengthened by providing specific examples or references to existing works on NLP models and image-text models, which would enhance the verifiability of the claim. As it stands, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the paper, noting that adversarial attacks by perturbing text have been explored in many NLP models and image-text models, and that the paper only applies similar ideas to video-text models. This feedback is somewhat helpful as it points out a potential weakness in the paper's originality. However, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or examples, the authors may find it challenging to improve their draft effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, particularly when the head of the noun phrase is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this challenge. The authors are left to infer that they need to clarify or improve their method for handling pronouns, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. However, it does not specify which part of the paper discusses the method for identifying antecedents or pronouns, making it weakly grounded. The comment is specific in detailing the issue with pronoun predictions, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. The comment highlights a potential issue with the proposed method but does not provide specific examples, references, or detailed reasoning to support the claim. This makes the claim somewhat verifiable, as the authors would need to infer the exact nature of the problem and how it affects the method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the identification of antecedents when the prediction is a pronoun, specifically questioning how the method handles situations where the head word is not a pronoun. This is a relevant issue that the authors should address to ensure the robustness and accuracy of their method. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue, such as proposing alternative approaches or suggesting additional experiments. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit, as it clearly states what needs to be added to the paper. However, it lacks concrete guidance on how to structure these discussions or what specific aspects should be covered. While the authors know they need to address this issue, the comment could be more actionable with additional details on how to implement the suggested discussions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for discussions on convergence, but without clear grounding, the authors may find it challenging to determine where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussions on the convergence of the proposed joint learning process are necessary to help readers understand how stable points in the probabilistic metric space are obtained. However, the comment does not provide specific examples, references, or detailed reasoning to support why this discussion is crucial or how it would impact the reproducibility of the results. The lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of this discussion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks clarity, namely the convergence of the proposed joint learning process for RNN and CopyRNN. It suggests that discussions on this topic are necessary to help readers understand how stable points in the probabilistic metric space are obtained, which is crucial for reproducibility. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the comprehensibility and reliability of the results. However, the comment could be more helpful if it offered suggestions on how to structure these discussions or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a critical gap in the paper.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the potential impact of societal biases on their work, but it lacks concrete steps or examples to help the authors implement this consideration. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the potential impact of societal biases, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the lack of information regarding the knowledge bases used and whether they are free from societal biases. It also mentions a specific example related to Fig., suggesting that the authors should address these issues. However, the comment does not provide detailed guidance or suggestions on how to address these concerns, such as recommending specific methods or references for mitigating societal biases. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more information about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also asks specific questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what non-experts would do, as well as whether it introduced any linguistic challenges. These questions and requests are clear and concrete, providing the authors with a direct and detailed guide on what needs to be addressed in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly relates to the first point mentioned in the review, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the traits of the experts involved in the annotation process and the justification for using expert annotation beyond its commercial value. The comment asks detailed questions about the nature of the experts and the differences in annotation compared to non-experts, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions and requests for clarification regarding the annotation process, specifically asking about the traits of the experts involved and the justification for using expert annotation. These questions are factual and seek additional information to better understand the paper, but they do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by asking the authors to describe more about the traits of the experts involved in the annotation process and to justify why expert annotation is necessary beyond its commercial value. It also raises questions about the nature of the experts (linguistic or domain experts) and whether the annotation process differed from what non-experts would do, as well as whether it introduced any linguistic challenges. These questions and requests for clarification are clear and direct, offering the authors a structured approach to enhancing their draft by providing more detailed information and justification. By addressing these points, the authors can improve the clarity and robustness of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, it does not provide specific guidance on how to implement this suggestion or what kind of examples would be most useful. The action is implicit, as the authors need to infer that they should include examples, and it is vague, as it lacks concrete details on how to execute this action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, rather than just other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. Without explicit references or clear guidance on where these examples should be included, the authors may find it challenging to determine the exact area needing attention. This makes the comment weakly grounded, as the authors cannot confidently identify the part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of examples would be beneficial or how they should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include examples of the system on actual texts, rather than just other components and models. However, the comment does not provide any reasoning, examples, or references to support why this would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including examples of the system on actual texts would be beneficial, rather than just focusing on other components and models. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors could enhance the paper by providing more concrete examples. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what kind of examples would be most relevant. While it provides a direction for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. The reviewer requests clarification on the data split used. While the comment implies that the authors should provide more information about the use of the CS, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the use of the CS but are not given specific guidance on how to present this information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. It also requests clarification on the data split used. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections where the Challenge Set is discussed. The comment is specific in detailing what needs to be clarified regarding the use of the Challenge Set, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and aim to gather more information, making the comment a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically asking how it is used for evaluation purposes and whether it is also used to augment the training material. It also requests clarification on the data split used. While the comment identifies a potential area of confusion and seeks clarification, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a need for clarification, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the relatively poor performance of the model on nouns and the discrepancy between the oracle GAP for PPDBClus and most clustering approaches. The reviewer suggests that this issue contradicts the claim of generalizability to all parts of speech. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve the performance. It lacks actionable details, such as recommending specific experiments or analyses to conduct. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relatively poor performance on nouns\" and references specific claims in the paper (124-126) regarding generalizability to all parts of speech. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue with the performance on nouns and the discrepancy with the oracle GAP for PPDBClus, as well as the contradiction with the claim of generalizability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses concern about the relatively poor performance of the model on nouns, which contradicts the claim of generalizability to all parts of speech. The reviewer provides a logical reasoning by pointing out the discrepancy between the oracle GAP for PPDBClus and most clustering approaches, suggesting that this issue needs further explanation. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to delve deeper into the paper to understand the context and the specific claims being made, which could be challenging without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the performance of the model on nouns, which is a critical aspect of the paper. It highlights a discrepancy between the expected performance of the model, given its nature, and the actual results, which are disconcerting. The comment also points out a contradiction with the claim of generalizability to all parts of speech, as the performance is not uniform. This feedback is valuable as it prompts the authors to investigate and address the issue of performance variability across different parts of speech. However, the comment could be more helpful if it provided specific suggestions or guidance on how to improve the model\\'s performance or clarify the generalizability claim. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide examples of spurious structures to clarify the discussion in section 5.2, which is currently too abstract. This request is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what is needed to enhance the clarity and effectiveness of the discussion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion being too abstract and requests examples of spurious structures to clarify why the new model is better than MH. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 5.2 is too abstract and lacks clarity regarding why the new model is better than MH. The reviewer requests examples of spurious structures to clarify this point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the discussion is abstract or to justify the need for examples of spurious structures. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 5.2, noting that it is too abstract and lacks clarity regarding why the new model is better than MH. The reviewer requests examples of spurious structures to clarify this point, which is a clear and actionable suggestion for improvement. By providing this feedback, the comment helps the authors to focus on making their discussion more concrete and understandable, which is valuable for enhancing the clarity and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to present these examples or suggested specific aspects of the discussion that need further elaboration. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection in the paper is not well-drawn and should be formalized or clarified. The reviewer provides a clear action for the authors to take, which is to either \"cement this connection more formally\" or \"adjust the language to clarify.\" This feedback is explicit and provides concrete guidance on how to improve the draft. The authors know exactly what needs to be done to address the issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the probabilistic connection in the paper, suggesting that it is not formally established and should be clarified. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the connection should be formalized or the language clarified, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection in the paper is not well-drawn and suggests that it should be formalized or clarified. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the probabilistic connection in the paper, suggesting that it is not well-drawn and lacks formalization. The reviewer provides a clear and actionable suggestion for improvement, recommending that the authors either formalize the connection more rigorously or adjust the language to clarify it. This feedback is valuable as it directs the authors to a critical area that needs attention and provides a concrete path for enhancement. However, the comment could be more helpful if it included specific examples or further guidance on how to formalize the connection. Overall, the comment is mostly helpful, as it offers actionable feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include additional evidence, it does not specify what kind of evidence or how it should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence and figure out how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without a clear reference to the section where this claim is made, the authors may struggle to identify the exact part that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or reasoning to substantiate why this evidence is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that their proposed algorithm works better for the Column Subset Selection problem. This is a clear and actionable suggestion that could help strengthen the paper by adding concrete evidence to substantiate the claim. However, the comment could be more helpful if it provided specific guidance on what kind of evidence or experiments would be most relevant or how to present the results effectively. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of the 4-year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. While it implies that the authors should provide more information or analysis on this aspect, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of datasets, specifically questioning whether a 4-year period is sufficient to study style shifts and what kind of style shifts occur within this timeframe. However, it does not specify which part of the paper discusses the datasets or style shifts, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the dataset choice and its implications but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. However, it does not provide any specific evidence, examples, or references to support the claim that a 4-year period is insufficient. The comment lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the sufficiency of the 4-year period for studying style shifts. It questions whether this timeframe is adequate to capture the kind of style shifts that occur, which is a relevant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional information could be included to better support their analysis. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the paper is generally easy to follow but identifies specific places that may cause confusion. However, it does not provide explicit guidance on which places are causing confusion or how the authors might address these issues. The comment implies that the authors should review their draft to identify and clarify these areas, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions that the paper is not difficult to follow but identifies several places that may cause confusion, referencing point 3. However, it does not specify which specific places or sections are causing confusion, making it weakly grounded. The authors can infer that it relates to the points listed in point 3, but without explicit references, it is challenging to pinpoint the exact areas needing attention. The comment is specific in identifying the issue of potential confusion but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not difficult to follow but identifies several places that may cause confusion. However, it does not specify which places are causing confusion or provide any supporting evidence or examples to substantiate the claim. Without detailed information or references, the authors may find it challenging to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide detailed guidance or suggestions on how to address these potential sources of confusion. Without specific examples or actionable advice, the authors are left with a vague understanding of what needs improvement. This lack of clarity and detail limits the comment\\'s usefulness, making it barely helpful. The authors may need to infer the areas of concern and figure out how to address them on their own, which is not ideal for constructive feedback. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results are based on \"standard\" techniques but are not immediately obvious and require technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of making the results more accessible or how to enhance the clarity of the techniques used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results section, noting that while the techniques used are considered \"standard,\" they are not immediately obvious and require a high level of technical competency. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in its critique of the technical complexity, but without explicit references to specific sections or results, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results are based on \"standard\" techniques but are not immediately obvious, requiring a high degree of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential issue with the accessibility of the results, noting that while the techniques used are considered \"standard,\" they may not be immediately obvious to all readers. This observation suggests that the authors should consider making their results more accessible to a broader audience. However, the comment lacks specific suggestions or guidance on how to achieve this, such as recommending additional explanations or examples. While it identifies a relevant area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is clearly better, given the small difference in performance between the two systems. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should reconsider their conclusion or provide additional data or analysis to support their claims. Since the action is implicit and lacks concrete details, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the difference in data used for training the text disambiguation model and the end-to-end system. It questions the conclusion that the direct model is clearly better, given the small performance difference between the two systems. However, the comment does not specify which sections of the paper discuss these models or the data used for training, making it weakly grounded. The comment is specific in detailing the issue with the conclusion, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the conclusion drawn from the comparison between the text disambiguation model and the end-to-end system. It points out that the difference in performance between the two systems is only a few percentage points, which challenges the claim that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, nor does it offer detailed reasoning or examples to substantiate the assertion. This lack of supporting evidence makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential issue with the conclusion drawn from the comparison between the text disambiguation model and the end-to-end system. It points out that the difference in performance between the two systems is only a few percentage points, which challenges the claim that the direct model is clearly better. This feedback is somewhat helpful as it prompts the authors to reconsider their conclusion and potentially provide more detailed analysis or data to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided additional context for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two main issues: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. The comment explicitly suggests that the authors should provide evidence or justification for GaRare\\'s advantages over GaLore and offer a more detailed algorithmic presentation. These are clear and concrete actions that the authors can take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it details what is missing, such as evidence or justification for GaRare\\'s advantages over GaLore and a more detailed algorithmic presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clear motivation for GaRare and insufficient evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly regarding the recovery of updated parameters from projected gradients. The comment provides a logical reasoning for the claim by identifying specific areas where the paper is lacking, such as theoretical analysis and algorithmic details. However, it does not provide specific examples or references to support the claim, which would make it more verifiable. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper. First, it points out the lack of clear motivation for GaRare, specifically noting the absence of evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable as it prompts the authors to provide a more robust justification for their approach. Second, the comment suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is specific and provides a clear direction for enhancing the understanding of the method. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should incorporate this information into their draft. The action is implicit, as the authors need to infer that they should include references to these works, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a link to these similar works that have a similar structure to the CRF and can perform exact inference. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and can perform exact inference. The claim is somewhat verifiable as it references specific works, providing a basis for the claim. However, the comment could be strengthened by including more detailed reasoning or examples of how these works relate to the current paper, which would make the claim more fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the current paper. By mentioning these references, the comment provides the authors with a clear direction to enhance the context and relevance of their work. However, the comment could be more helpful if it included a suggestion on how to incorporate these references or why they are important for the paper. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the authors to provide more clarification on this issue. This request is direct and clear, giving the authors a specific action to take\u2014namely, to clarify the differences or similarities between their method and the cited work. The feedback is concrete and actionable, as it provides a clear direction for the authors to address the concern. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It asks for clarification on this issue, which suggests that the authors should address the overlap or differences between their method and the cited work. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or elements, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any specific examples or detailed reasoning to support the claim of similarity. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable, as it lacks sufficient justification or evidence to substantiate the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the similarity between the method part and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a valid concern that could impact the originality and contribution of the paper. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or differentiate their work from the cited work. While it points out a potential problem, it does not offer actionable advice or suggestions for improvement, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods, given that it uses a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment implies that the authors should consider these issues, but it lacks concrete actions or details on how to resolve them. As a result, the comment is barely actionable, as the authors can infer the need for further discussion but are not provided with specific steps to take.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the fairness of comparing the proposed method with other methods, given that it uses a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, such as a specific section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. The comment is specific in detailing the concerns about fairness and potential impact, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO, and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the fairness of comparing the proposed method with other methods, given its use of a proposal generator pretrained on MSCOCO. It also questions whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies potential areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider these issues but does not offer detailed guidance on how to address them.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written too briefly and could be improved by a slower development for easier readability. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the section. The action is implicit and somewhat vague, as the authors can infer that they need to expand the section but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the section is \"tersely written\" and suggests that a slower development would improve readability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is \"tersely written\" and suggests that a slower development would improve readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the assertion that the section is too brief or that a slower development would enhance readability. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style of Section 4, noting that it is \"tersely written\" and suggests that a slower development would improve readability. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks specific guidance or suggestions on how to achieve a slower development or what changes could be made to enhance readability. While it provides some insight, the comment could be more helpful if it offered concrete examples or detailed advice on how to address the issue. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is highly actionable as it offers concrete steps for improvement, making it easy for the authors to implement the suggested changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the importance of the distribution of videos of different lengths within the benchmark for assessing reasoning ability and robustness. It also specifies that the paper lacks relevant explanations and suggests including a table showing the distribution of video lengths across the dataset, along with an explanation of how a balanced representation of different video lengths was ensured across the 11 categories. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, and that the paper lacks relevant explanations. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The suggestion to include a table and explanation is logical, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the paper that is lacking: the distribution of videos of different lengths within the benchmark. It emphasizes the importance of this distribution for assessing reasoning ability and robustness, and suggests that the authors include a table showing the distribution of video lengths across the dataset. Additionally, it advises the authors to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing specific guidance on how the authors can enhance their paper by addressing a crucial aspect of their methodology. The comment is highly helpful as it offers detailed and constructive suggestions that can significantly improve the draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a cautious approach should be taken regarding the contribution of the dataset until it is made publicly available. However, it does not provide explicit guidance on what actions the authors should take to address this issue. The comment implies that the authors should wait for the dataset to be publicly accessible before considering it a significant contribution, but it does not specify how the authors should handle this situation or what steps they should take to ensure the dataset is made available. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the promised dataset not being publicly available, suggesting a cautious approach until it is made accessible. However, it does not specify which part of the paper discusses the dataset or where this issue is mentioned, making it weakly grounded. The comment is specific in its suggestion to take a cautious approach regarding the contribution until the dataset is openly accessible. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the promised dataset has not been made publicly available, suggesting a cautious approach regarding its contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a critical issue regarding the availability of the promised dataset, which is a significant concern for the contribution of the paper. It suggests that a cautious approach should be taken until the dataset is made publicly accessible. While the comment identifies an important issue, it lacks specific guidance or suggestions on how the authors might address this problem or what steps they could take to ensure the dataset is made available. The feedback is somewhat helpful as it points out a critical area for improvement but does not provide actionable advice, leaving the authors with a general direction but no detailed guidance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It mentions that the group attention design is related to ResNeSt but not discussed in the paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their method from existing ones. The action is implicit and vague, as the authors are left to infer that they need to discuss the differences or provide a more detailed comparison with existing works. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relation to ResNeSt. However, it does not explicitly mention which part of the paper discusses these similarities or the proposed method, making it weakly grounded. The comment is specific in detailing the issue of limited novelty and the similarity to existing works, but it lacks grounding as it does not direct the authors to a specific section or part of the paper where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works [1, 2, 3] and noting the similarity to ResNeSt [4]. However, the comment lacks detailed comparisons or specific examples of how the proposed method is similar to or different from these existing works. This makes the claim somewhat verifiable, as the authors would need to conduct their own analysis to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically that the proposed method lacks novelty due to its similarity to other attentional modules in previous works. It highlights the similarity to ResNeSt and notes that the paper does not discuss these similarities. This feedback is valuable as it points out a critical weakness in the paper's originality and suggests that the authors should address this issue by discussing the differences or similarities with existing works. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the proposed method or offered examples of how to discuss these similarities. Overall, the comment is somewhat helpful as it directs the authors to a key area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results and suggests that the performance is primarily due to the first step, implying that comparisons with existing detection methods are necessary. However, the comment does not provide explicit guidance on how to conduct these comparisons or what specific experiments should be performed. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks and questions the validity of this claim. It suggests that the performance is primarily due to the first step and recommends conducting comparisons with existing detection methods. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in suggesting a comparison with existing detection methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim of achieving state-of-the-art results, suggesting that the performance is primarily due to the first step. The reviewer implies that comparisons with existing detection methods are necessary to substantiate this claim. However, the comment lacks specific examples or references to support the claim that the performance is mainly due to the first step. This makes the claim somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the authors\\' claim of achieving state-of-the-art results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to substantiate this claim. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or conduct the recommended comparisons. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the \"required implicit call to the Witness oracle,\" indicating that it is confusing. However, it does not provide any guidance or suggestions on how to clarify or address this confusion. The comment lacks explicit instructions or concrete details on what changes should be made to improve the clarity of the implicit call. As a result, the authors are left without a clear understanding of how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the \"required implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is located in, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine where to address the confusion. The comment is specific in its critique but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this is confusing or how it could be clarified. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the \"required implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation or suggestions on how to clarify this confusion or improve the clarity of the paper. Without actionable guidance or detailed feedback, the authors are left without a clear understanding of how to address the issue, making the comment barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, specifically its inability to handle headpose, and questions why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021) does. While the comment identifies a specific issue and references a relevant work, it does not provide explicit guidance on how the authors should address this limitation or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should explore ways to condition headpose parameters similar to the referenced work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the issue of handling headpose, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the problem by referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose, and it questions why the proposed method cannot condition headpose parameters similarly. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method cannot handle headpose and questions why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). The comment provides a specific reference to a previous work that addresses the issue, which is a good starting point for justification. However, the comment lacks detailed reasoning or examples of how the proposed method could be adapted to handle headpose, making the claim somewhat verifiable. The authors would need to delve deeper into the referenced work and the proposed method to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose, which is a critical aspect of facial expression control. It questions why the method cannot condition headpose parameters similar to a previous work (Gafni et al. ICCV 2021), which can control both facial expression and headpose. This feedback is valuable as it highlights a specific area for improvement and provides a reference to a related work that addresses the issue. However, the comment could be more helpful if it offered suggestions on how the authors might adapt their method to handle headpose or provided additional context on why this limitation is important. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the structural optimization being directly taken from previous works, which it claims reduces the contribution of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to make the optimization more original. The comment implies that the authors should consider explaining the novelty of their optimization algorithm or providing a more detailed comparison with previous works, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component, which is mentioned as a main part of the paper. However, it does not specify which part of the paper discusses this optimization, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm is directly taken from previous works, which it claims reduces the contribution of the paper. This provides clear guidance on what aspect needs to be addressed, such as explaining the novelty of the optimization algorithm or providing a more detailed comparison with previous works. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the structural optimization algorithm is directly taken from previous works, which reduces the contribution of the paper. However, the comment does not provide specific references or examples of the previous works, nor does it explain how the current work differs from or builds upon these previous works. This lack of detailed justification or evidence makes it difficult for the authors to understand and address the claim effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the structural optimization component, noting that it seems to be directly taken from previous works. This observation is relevant as it could impact the originality and contribution of the paper. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or enhance the novelty of their optimization algorithm. Without actionable suggestions or examples, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not provide specific guidance on how to improve the introduction of the baseline models or how to enhance the results of the pipeline style method. The lack of actionable advice or concrete suggestions makes it difficult for the authors to know exactly what steps to take to address these issues. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of a pipeline style method involving two models on XVNLI and MaRVL, indicating that it does not yield better average results. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which sections of the paper discuss these baseline models or the pipeline style method, making it difficult for the authors to pinpoint the exact parts that need attention. The lack of explicit references to specific sections or elements of the paper results in weak grounding. Additionally, while the comment identifies the issue with the baseline models, it does not provide specific guidance on how to improve their introduction. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the pipeline style method, including two models, does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment lacks specific details or evidence to support these claims, such as comparisons with other methods or references to studies that have achieved better results. Without such supporting information, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, is not better than the baseline models for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. However, the comment lacks specific suggestions or guidance on how the authors might improve the performance of the pipeline style method or enhance the introduction of the baseline models. Without actionable advice or detailed feedback, the authors are left with a general understanding of the issues but no clear path forward for improvement. Therefore, the comment is barely helpful, as it identifies areas for improvement but does not provide sufficient guidance to be fully beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for reproducing a well-known result in the literature using a \"coarse\" methodology. It questions the necessity of this observation, given that it has been made at each step of the evolution of language models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or address the critique, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used by the authors to reproduce a well-known result in the literature, specifically the left political bias in ChatGPT and LLMs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the methodology, questioning the need for this observation given its repetition across the evolution of language models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models. The comment provides a logical reasoning by referencing the historical context of similar observations in word2vec, BERT, and ChatGPT, suggesting that the claim is not novel. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consider this historical context to fully understand the critique, but the comment could be strengthened with more detailed references or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the authors for reproducing a well-known result in the literature regarding left political bias in ChatGPT and LLMs. It questions the necessity of this observation, given that it has been made at each step of the evolution of these models, from word2vec to BERT to ChatGPT. The comment highlights a lack of novelty in the observation, which could be seen as a critique of the paper's contribution. However, it does not provide specific suggestions or guidance on how the authors might address this critique or improve their work. The feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks actionable advice or depth, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include related work on modular networks for VQA, specifically mentioning a reference \"[A]\" that should be cited. This provides a clear and direct action for the authors to take, ensuring that the introduction accurately reflects the current state of research in modular architectures for VQA. The comment is highly actionable because it specifies exactly what needs to be added and provides a concrete reference to guide the authors. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"When discussing related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that related work on modular networks for VQA should be included, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction lacks a mention of related work on modular networks for VQA, which could give the impression that no one uses modular architectures for VQA. This claim is somewhat verifiable as it highlights a potential omission in the related work section. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand the context and address the issue effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the discussion of related work, noting the importance of mentioning modular networks for VQA. By suggesting the inclusion of specific references, the comment provides clear and actionable feedback that can help the authors improve the comprehensiveness and accuracy of their introduction. This feedback is valuable as it directs the authors to a particular area where their work could be more effectively contextualized within the existing literature. However, the comment could be more helpful if it offered additional guidance on how to integrate these references or why they are particularly relevant. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include comparisons with these methods, but the comment lacks concrete details on which specific aspects to focus on or how to conduct these comparisons. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific area of focus in the paper, namely the authors\\' emphasis on SSC and the lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure where these comparisons should be made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for comparisons with other methods, but without clear grounding, it is challenging for the authors to know where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The claim is somewhat verifiable as it provides a logical reasoning for the comparison, noting the computational efficiency and similar guarantees of the mentioned methods. However, the comment lacks specific examples or references to these methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a reasonable basis for the claim but could be more robust with additional details.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by noting that the authors primarily focus on SSC and do not compare their method with other subsequent methods like TSC and greedy subspace clustering by Park. It highlights the importance of these comparisons, as these methods are computationally efficient and have similar guarantees. This feedback is somewhat helpful as it points out an area where the authors could enhance their work by providing a more comprehensive comparison. However, the comment lacks specific suggestions on how to conduct these comparisons or which aspects to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to remove statements about semantic segmentation being a low-level cue from the paper. This is a direct and clear action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the removal of statements about semantic segmentation being a low-level cue. This provides clear guidance on what the authors should revise in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level since categories are specified for each pixel, and therefore, statements about semantic segmentation being a low-level cue should be removed. However, the comment lacks specific reasoning or references to support this claim. It does not provide examples or detailed explanations of why semantic segmentation cannot be considered low-level, making it difficult for the authors to understand and address the issue. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the characterization of \"semantic\" segmentation as a low-level cue. It provides a clear and actionable suggestion to remove these statements from the paper, which is a direct and helpful piece of feedback. However, the comment could be more helpful if it offered additional context or explanation about why this characterization is incorrect or how it affects the paper\\'s content. Despite this, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the validity of the claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider alternative datasets for their study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore other datasets but are not provided with specific guidance on how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to a specific claim made in the paper regarding the improvement in accuracy and completeness, which can be identified by the authors. It also provides a specific suggestion to use another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This level of detail allows the authors to understand exactly what needs to be addressed and how to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using another dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a reasonable suggestion to test the robustness of the findings, but it lacks specific reasoning or evidence to fully substantiate the claim. The comment provides a logical suggestion for further investigation but does not fully justify the initial claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the validity of a specific claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is somewhat helpful as it points out a potential weakness in the paper and offers a specific suggestion for improvement. However, it could be more helpful if it provided additional context or reasoning for why the current dataset might not be sufficient or why the alternative dataset would be beneficial. The authors are given a clear direction for further investigation, but the comment could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It contrasts this approach with previous work that considers multiple CVEs or CWEs simultaneously. The reviewer asks if the authors are arguing that identifying one vulnerability at a time is an intended use case and notes that the results are difficult to interpret. While the comment highlights a potential issue with the methodology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the methodology and its implications. However, the comment lacks concrete details on how to improve the methodology or interpret the results, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It contrasts this approach with previous work that considers multiple CVEs or CWEs simultaneously. The reviewer asks if the authors are arguing that identifying one vulnerability at a time is an intended use case and notes that the results are difficult to interpret. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology and results sections. The authors can infer that the comment relates to these parts of the paper. The comment is specific in detailing the issue with the methodology and the interpretation of results, but it lacks full grounding as it does not explicitly mention the sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It contrasts this approach with previous work that considers multiple CVEs or CWEs simultaneously, suggesting that the results may be difficult to interpret. The reviewer asks if the authors are arguing that identifying one vulnerability at a time is an intended use case, which adds a layer of questioning to the claim. While the comment provides some context and references to previous work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The lack of concrete evidence or detailed analysis makes the claim somewhat verifiable, as the authors would need to provide more information to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It contrasts this approach with previous work that considers multiple CVEs or CWEs simultaneously, suggesting that the results may be difficult to interpret. The reviewer also asks if the authors are arguing that identifying one vulnerability at a time is an intended use case, which adds depth to the critique. This feedback is somewhat helpful as it identifies a potential weakness in the methodology and prompts the authors to consider the broader implications of their approach. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive. While the comment identifies an area that needs further explanation, it does not provide specific guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the relationship between the community structure and degree bias is not intuitive enough, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the relationship between the community structure and degree bias is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the exact nature of the issue and how it relates to the theorems. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by noting that the relationship between the community structure and degree bias is not intuitive enough, despite Theorem 1 and 2 providing evidence of a clearer community structure. This feedback is clear and actionable, as it directs the authors to provide more explanations on how a small degree of bias can be obtained from a clear community structure. However, the comment could be more helpful if it offered suggestions on how to enhance the explanation or provide additional insights. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with specific guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment identifies areas where more detail is needed, it does not provide explicit instructions on how to incorporate these details or what specific information should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides some specific suggestions for improvement, such as providing more details on the definition of the resistance distance and offering additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. However, it does not explicitly mention which part of the paper these suggestions relate to, making it weakly grounded. The authors can infer that these suggestions pertain to the sections discussing graph notions and algorithms, but the lack of explicit references makes it challenging to pinpoint the exact parts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of factual statements and suggestions for improvement, without making any subjective claims or opinions that require verification. It describes the content of the paper and suggests additional details could be provided, which is a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to follow, but praises the writing as generally good. It suggests that more details could be provided, specifically mentioning the need for a clearer definition of the resistance distance and additional explanations for Algorithm 1, including brief sentences defining A_t, Y_t, etc. While the comment identifies areas for improvement, it lacks specific guidance on how to enhance the clarity or provide these additional details. The feedback is somewhat helpful as it points out potential areas for improvement but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, such as suggesting new ideas to incorporate or ways to differentiate their approach. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper discusses variable splitting or the algorithm, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could improve the novelty of their work. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific examples, references, or suggestions on how the authors could address this issue or improve the originality of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what needs to be done to enhance the novelty of their paper. This lack of detail and specificity makes the comment unhelpful, as it does not offer any meaningful insights or directions for improvement. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation of shape model invariance, specifically asking for quantitative results on testing images. While it does not explicitly instruct the authors to conduct such an evaluation, it implies that this is a necessary step to fully prove the point. The action is implicit, as the authors need to infer that they should include quantitative results on testing images. However, the comment provides a clear direction on what needs to be done, making it somewhat actionable. The authors know that they need to focus on evaluating the shape model invariance on testing images, but the comment does not specify how to conduct this evaluation or what metrics to use. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether there are quantitative results on testing images, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images are needed to fully substantiate the claim. However, the comment does not provide specific examples, references, or detailed reasoning to support why testing images are necessary or how they would improve the evaluation. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of testing images based on the context of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the evaluation of shape model invariance, specifically questioning whether the evaluation on transformations of training images is sufficient to prove the point. It suggests that quantitative results on testing images are needed to fully substantiate the claim. This feedback is clear and actionable, as it directs the authors to consider an important aspect of their study that could impact the validity of their findings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the evaluation on testing images or what metrics to use. Overall, the comment is mostly helpful as it identifies a critical area for improvement and guides the authors toward a more comprehensive evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment explicitly instructs the authors to discuss and compare this work to provide a better understanding of the state-of-the-art. This feedback is clear and direct, providing a concrete action for the authors to take. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is a clear reference point for the authors. It also specifies what needs to be addressed, namely discussing and comparing this work to provide a better understanding of the state-of-the-art. This level of detail allows the authors to accurately identify the part of the paper that requires revision and understand the nature of the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors missed a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this work should be discussed and compared to provide a better understanding of the state-of-the-art. While the claim is based on a specific reference, it lacks detailed reasoning or examples of how this work relates to the authors\\' research. The authors would need to investigate the paper to understand its relevance and potential impact on their work. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further exploration by the authors.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a related work, specifically the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. It suggests that this work should be discussed and compared to provide a better understanding of the state-of-the-art. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance the context and depth of their work. By incorporating this comparison, the authors can provide a more comprehensive overview of their research in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate this comparison into the paper. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the scalability of the approach, specifically the computation of optimal transport distance, and questions the method used to achieve this. It suggests testing the method on machines with fewer cores to assess its scalability. Additionally, it questions the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. While the comment implies that the authors should address these concerns, it does not provide explicit instructions on how to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should test the scalability on fewer cores and clarify the process of obtaining optimal transport. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"Approach\" section of the paper, specifically questioning the scalability of the method for computing optimal transport distance. It raises concerns about the computational expense and suggests testing the method on machines with fewer cores. Additionally, it questions the process of obtaining optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. This provides clear guidance on what needs to be addressed, making the comment fully grounded as it explicitly mentions the \"Approach\" section. The comment is also specific because it details the issues with scalability and the method used, offering clear directions for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the scalability of the approach for computing optimal transport distance, questioning whether it is feasible on machines with fewer cores. It also questions the method used to obtain optimal transport from the doubly stochastic matrix provided by the Sinkhorn method. While the comment highlights potential issues, it lacks specific examples or references to support these claims. The reasoning is somewhat logical, but the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some justification but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important concerns about the scalability of the approach for computing optimal transport distance, questioning whether it is feasible on machines with fewer cores. It also questions the method used to obtain optimal transport from the doubly stochastic matrix provided by the Sinkhorn method, seeking clarification on this process. These are valid points that could help the authors improve their draft by addressing potential limitations and providing more detailed explanations. However, the comment could be more helpful if it offered specific suggestions or examples on how to test the scalability or improve the method. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of their work. There is no guidance on how to enhance the experimental procedures or evaluations to make them more understandable. Without specific suggestions or recommendations, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which parts of the paper need revision. The comment is not grounded as it does not identify a specific area, and it is also not specific because it lacks detailed feedback on what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper was \"extremely hard to follow,\" specifically mentioning difficulty in understanding the experimental procedures and evaluations. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to particular sections or experiments that were unclear, the authors may find it challenging to identify and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the paper was difficult to follow, specifically mentioning trouble understanding the experimental procedures and evaluations. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their work. Without actionable feedback or detailed recommendations, the authors are left without a clear path for improvement. This lack of specificity and actionable advice makes the comment barely helpful, as it identifies a problem but does not offer any meaningful guidance for addressing it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests introducing specific aspects of the model that are relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and actionable, as it directs the authors to include specific details that would enhance the clarity and understanding of their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, such as introducing specific aspects of the model relevant to the example being discussed. The comment suggests highlighting that the model operates in a setting with finite subdivisions for certain parameters and that others are bounded. This level of detail provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify specific aspects of the model relevant to the example being discussed. It provides a concrete example of what should be clarified, such as the finite subdivisions for gamma^1 and gamma^m and the bounded parameters like acceleration and scaling parameters. This feedback is clear and actionable, but it does not contain a subjective claim or opinion that requires verification. It is a suggestion for improvement, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors clarify certain aspects of the model that are specific to the example being discussed. It highlights the need to explicitly mention that the model operates in a setting with finite subdivisions for gamma^1 and gamma^m and that certain parameters are bounded on one side, such as acceleration and scaling parameters. This feedback is clear and constructive, offering the authors a direct way to enhance the clarity and understanding of their work. By addressing these points, the authors can improve the comprehensibility of their draft, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the scalability of the learning rate condition, which is not seen in practice and could lead to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their approach. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the learning rate condition, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer provides a logical reasoning by stating that in practice, the step size does not grow with the sample size, which supports the claim. However, the comment lacks specific examples or references to substantiate the claim further, making it somewhat verifiable. The authors would need to consider this critique and potentially provide additional evidence or reasoning to fully address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the learning rate condition, which is not scalable and leads to unreasonably large learning rates when dealing with large datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the realism of the current condition. This feedback is somewhat helpful as it highlights a potential weakness in the approach and encourages the authors to reconsider their condition. However, the comment could be more helpful if it provided suggestions or alternatives for addressing this issue, such as proposing different scaling methods or discussing potential workarounds. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing Equation (10) and line 130. It also compares this issue to sampling from the leverage score in [3], questioning the ease of sampling from the DPP. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their sampling method. The action is implicit and vague, leaving the authors to infer that they need to clarify or address the sampling process. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when eigenfunctions are inaccessible, and it compares this to the problem of sampling from the leverage score in [3]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of sampling from the DPP when eigenfunctions e_n are inaccessible, referencing Equation (10) and line 130. It also compares this issue to sampling from the leverage score in [3], questioning the ease of sampling from the DPP. The comment provides a logical comparison and highlights a potential problem, but it lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out a potential issue, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the lack of clarity in sampling from the DPP when the eigenfunctions e_n are inaccessible. It references Equation (10) and line 130, providing a clear indication of where the issue is located. The comment also makes a relevant comparison to sampling from the leverage score in [3], which helps the authors understand the context of the problem. However, the comment could be more helpful if it offered suggestions or guidance on how to address this issue, such as proposing alternative methods or providing examples of how to clarify the sampling process. Despite this, the comment provides valuable insight into a potential weakness in the paper, making it somewhat helpful. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the abstract effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. It mentions \"minor language issues\" but does not specify what these issues are or how they should be addressed. The comment provides a general direction for improvement by suggesting that the abstract should include more details on evaluation and outcomes, but it lacks concrete guidance on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the abstract effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The comment is somewhat verifiable as it highlights a potential gap in the abstract, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive observation about the abstract, noting that it effectively explains the proposed idea but lacks details on how the idea was evaluated and the outcome. This feedback is somewhat helpful as it identifies a specific area for improvement, suggesting that the authors should include more information on the evaluation and results in the abstract. However, the comment could be more helpful if it offered specific suggestions on how to present this information or what aspects of the evaluation should be highlighted. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on these cases, even simulated ones. While the comment identifies a gap in the experimental section, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should conduct experiments on the mentioned cases, but the comment lacks concrete details on how to implement these experiments or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the lack of experiments on specific cases, such as surveillance in museums with thresholded rewards and privacy-preserving data collection, which are mentioned as examples of POMDP problems with non-convex value functions. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are not convincing and questions the lack of experiments on specific cases, such as surveillance in museums with thresholded rewards and privacy-preserving data collection. The reviewer provides a logical reasoning by pointing out the absence of experiments on these cases, which are mentioned as examples of POMDP problems with non-convex value functions. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by including specific examples or references to similar studies that have addressed these cases. Overall, the claim is mostly verifiable, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the critique. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the experimental results, questioning the motivation for the solution proposed in the paper. It points out that the examples provided to motivate the solution are limited to two specific cases and asks why there are no experiments on these cases, even simulated ones. This feedback is somewhat helpful as it identifies a gap in the experimental section and prompts the authors to consider conducting experiments on the mentioned cases. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of experiments that could be conducted. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies areas that need attention, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to identify the specific parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the article is incremental, essentially a combination of GraphRAG and GraphCare, and that key baselines were not cited. It also suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. The claim is somewhat verifiable as it provides a logical reasoning for the incremental nature of the contribution and highlights specific missing references. However, the comment lacks detailed examples or references to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several specific points for improvement, including the observation that the contribution is incremental and essentially a combination of GraphRAG and GraphCare. It also highlights the lack of citation for key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. This feedback is actionable and helps the authors identify areas where they can enhance their paper by providing more comprehensive references and discussing relevant algorithms. However, the comment could be more helpful if it offered suggestions on how to integrate these references or algorithms into the paper. Overall, the comment is mostly helpful as it directs the authors toward specific improvements, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take. Additionally, the comment offers a rationale for why this graph is important, explaining that it can help determine whether performance improvements are due to network design or the nature of ImageNet. This provides concrete guidance on how to implement the suggested action, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on what specific part of the paper needs to be addressed. The comment is also specific because it explains the importance of this graph in understanding whether performance improvements stem from network design or the nature of ImageNet. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph to better understand whether performance improvements are due to network design or the nature of ImageNet. The comment provides a logical reasoning by explaining that the graph would help determine if the performance gain is from exploiting spatial redundancies or from the characteristics of ImageNet, such as a large fraction of images that can be represented with lower resolution. This reasoning is clear and provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened with specific examples or references to similar studies that support the need for this analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include a graph to plot T vs the number of images and Expectation(T) over the ImageNet test set. This recommendation is aimed at helping the authors understand whether the performance improvement is due to the network design or the nature of ImageNet, which is a critical aspect of evaluating the methodology. The comment also offers a nuanced perspective by considering the potential impact of ImageNet\\'s characteristics on the results. By addressing this point, the authors can gain a deeper understanding of their findings and potentially refine their conclusions. Therefore, the comment is mostly helpful, as it offers clear guidance for improvement while requiring further elaboration to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the performance of the proposed method compared to the baseline model when trained and evaluated at the same time-step. It questions the effectiveness of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation time-steps differ. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should explore scenarios with different time-steps to demonstrate the method\\'s effectiveness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance of the proposed methods when trained and evaluated at the same time-step, questioning their effectiveness. The comment further suggests that the proposed method might be beneficial in scenarios where the training and evaluation time-steps differ. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the time-aware model when trained and evaluated at the same time-step. The reviewer questions the value of the proposed methods under this condition, suggesting that they might only be beneficial in scenarios where the training and evaluation time-steps differ. However, the comment lacks specific examples or references to support the claim that the proposed methods are ineffective under the current conditions. The reasoning is somewhat logical but lacks detailed evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the effectiveness of the proposed methods, noting that Figure 5 shows similar performance between the baseline model and the time-aware model when trained and evaluated at the same time-step. This observation questions the value of the proposed methods under the current conditions. The comment suggests that the proposed method might be more beneficial in scenarios where the training and evaluation time-steps differ. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or explore alternative scenarios. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the disentanglement process, noting that it is not clear how disentanglement is guaranteed. While it mentions that the \"Broader Impacts and Limitations\" section acknowledges obtaining fully disentangled latent vectors as a limitation, the comment emphasizes the need to clarify how disentanglement is realized and guaranteed without certain bias types. This feedback implies that the authors should provide more detailed information on the disentanglement process, but it does not specify exactly how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the disentanglement process, but they are not given explicit guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the disentanglement process, noting that it is not clear how disentanglement is guaranteed and suggesting that the authors highlight how disentanglement is realized and guaranteed without certain bias types. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of clarity regarding how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which acknowledges obtaining fully disentangled latent vectors as a limitation. However, the comment suggests that more detail is needed on how disentanglement is realized and guaranteed without certain bias types. While the comment provides some context, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the disentanglement process in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges the limitation of obtaining fully disentangled latent vectors, it does not provide clear guidance on how disentanglement is realized and guaranteed without certain bias types. This feedback is somewhat helpful as it highlights a critical aspect of the paper that needs further clarification. However, it could be more helpful if it provided specific suggestions or examples on how the authors might address this issue, such as proposing methods or techniques for ensuring disentanglement. Overall, the comment directs the authors' attention to an important area for improvement but lacks detailed guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a strongly-convex concave case. While the comment implies that this is necessary for a fair comparison, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to apply the regularization trick or what specific trick should be used. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a strongly-convex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the comparison is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide detailed guidance on which standard regularization trick should be used or how it should be applied. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a strongly-convex concave case. However, the comment does not provide any reasoning, examples, or references to support why this approach is necessary or beneficial. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests using a standard regularization trick to compare the obtained complexity of the proposed method with previous results in a strongly-convex concave case. While it identifies a potential area for improvement by suggesting a specific approach, it lacks detailed guidance or explanation on how to implement this suggestion. The comment does not provide context or examples of which standard regularization trick should be used, nor does it offer any rationale for why this approach is necessary. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions how the paper addresses different types of inputs, such as bio-medical signals or speech, and suggests that discussing and presenting solutions for these inputs would be valuable. This provides an explicit action for the authors to consider and address in their paper. Second, it mentions that the citation seems disordered, which is an implicit action for the authors to reorder or clarify their citations. While the comment does not provide specific guidance on how to reorder the citations, it is clear that the authors need to address this issue. Overall, the comment is mostly actionable as it provides a clear direction for addressing the first issue and implies a need for citation clarification.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises two distinct issues: the handling of different types of inputs and the order of citations. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in suggesting that the authors discuss and present solutions for different types of inputs, but it lacks specificity regarding the citation issue, as it does not indicate which citations are disordered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two separate issues: the handling of different types of inputs and the order of citations. The first issue is a suggestion for improvement, as it encourages the authors to discuss and present solutions for various input types. This is a logical suggestion, but it lacks specific examples or references to support why this is important or how it could be addressed. The second point about the disordered citations is a factual observation that does not require verification. However, the first part of the comment is somewhat verifiable as it provides a logical suggestion but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper. First, it suggests that the authors should discuss and present solutions for handling different types of inputs, such as bio-medical signals or speech, which is a valuable suggestion for enhancing the paper\\'s scope and applicability. Second, it points out that the citation seems disordered, which is a practical issue that the authors should address to improve the clarity and professionalism of their work. However, the comment could be more helpful if it provided specific guidance on how to address the citation issue or offered examples of how to discuss and present solutions for different input types. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Wh-types\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of template mapping in question answering, specifically mentioning the potential for poor generalization to questions that are not \"Wh-types\" or transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the template mapping approach, but without clear references to specific sections or examples, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalization of the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Wh-types\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to infer the potential issues and explore ways to address them, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Wh-types\" or transformable. This feedback is somewhat helpful as it points out a specific area where the model might struggle, prompting the authors to consider alternative approaches or modifications to improve generalization. However, the comment lacks depth and does not provide specific suggestions or examples of how to address this issue, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the ICL-HAR, noting that it has improved consistency and verifiability but has negatively impacted accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss or acknowledge the impact of ICL-HAR on accuracy scores. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ICL-HAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that while ICL-HAR improves consistency and verifiability, it negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the main text, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ICL-HAR has negatively impacted accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ICL-HAR, noting that while it improves consistency and verifiability, it significantly impairs accuracy scores. The reviewer suggests that this should be discussed or acknowledged in the main text in more detail. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs further exploration or explanation. By pointing out the trade-off between consistency, verifiability, and accuracy, the comment provides the authors with a specific area to address and potentially improve their draft. However, it could be more helpful if it offered suggestions on how to present this trade-off or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a significant area of improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to cite the source of the rock-paper-scissors example, which is clearly inspired by previous work. This is a direct and concrete action that the authors can take to improve their draft. The comment provides a specific and actionable step, ensuring that the authors know exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not citing the source of the example, which is inspired by previous work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and requests that the authors cite the source. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the claim or understand the basis of the suggestion. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the rock-paper-scissors example is inspired by previous work and requests that the authors properly cite the source. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide proper attribution. By addressing this issue, the authors can ensure the integrity and transparency of their work. However, the comment could be more helpful if it provided additional context or examples of similar work, which would enhance the authors\\' understanding of the issue and guide them more effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that comparing the performance of the model only pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional experiments to demonstrate the significance of the proposed projection errors. The suggestion is concrete, as it specifies the type of experiments needed to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that comparing the performance of the model only pre-trained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by providing the performance of models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs revision. The comment is specific in its suggestion but lacks grounding, as it does not clearly indicate where in the paper this feedback should be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparing the performance of the model only pre-trained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The reviewer provides a logical reasoning by suggesting that fine-tuning on real-world datasets with different losses is necessary to evaluate the model\\'s performance comprehensively. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair or to substantiate the importance of the proposed projection errors. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the model\\'s performance, suggesting that it is unfair to only compare the model pre-trained on synthetic data. It provides a clear and actionable suggestion to demonstrate the importance of the proposed three projection errors by comparing the performance of models pre-trained on synthetic data but fine-tuned on real-world datasets with different losses. This feedback is specific and offers a concrete direction for the authors to improve their draft by providing a more comprehensive evaluation of the model\\'s performance. However, the comment could be more helpful if it included examples or specific guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful as it provides a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these analyses or what specific aspects of the traditional method should be discussed. The actions are explicit but somewhat vague, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as demonstrating the consistency between predicted scores and actual risks, and suggests conducting calibration curves to show agreement. Additionally, it encourages the authors to prove the feasibility of the generated scoring system and discuss the differences between the traditional method and their approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model AUC can assess discriminant ability but may not demonstrate consistency between predicted scores and actual risk. It encourages the use of calibration curves to show agreement, which is a common practice in evaluating predictive models. The comment also suggests discussing the differences between the traditional method and the proposed method. While the suggestion is logical and based on common practices in model evaluation, it lacks specific examples or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that while the model AUC can assess discriminant ability, it may not demonstrate consistency between predicted scores and actual risk, which is crucial for clinical scoring systems. The comment encourages the authors to conduct calibration curves to show this agreement, which is a valuable suggestion for enhancing the paper\\'s credibility and relevance. Additionally, it suggests discussing the differences between the traditional method and the proposed method, which could provide a more comprehensive understanding of the work. However, the comment could be more helpful if it offered specific guidance on how to conduct these analyses or what aspects of the traditional method should be highlighted. Overall, the feedback is mostly helpful as it directs the authors toward important areas for improvement, but it could be more detailed to be fully comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern that all sparsity patterns seem to perform equally well, without providing any insight into what is happening. It also suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" While the comment identifies a potential issue and offers a specific correction, it does not provide guidance on how the authors might address the lack of insight into the sparsity patterns. The action is explicit but somewhat vague, as it lacks detailed instructions on how to improve the analysis or presentation of the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that all sparsity patterns seem to perform equally well and lacks insight into what is happening. Additionally, it suggests a correction in the section title from \"presentation bits\" to \"representation bits.\" This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that all sparsity patterns perform equally well and questions whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the analysis of sparsity patterns, noting that all patterns seem to perform equally well without providing any insight into what is happening. It questions whether this is unique to the sparsity detection problem or a general characteristic of Graph Neural Networks (GNNs). This feedback highlights a gap in the paper's analysis and suggests that the authors should explore this further. Additionally, the comment includes a minor correction in the section title, which is a helpful suggestion for improving the paper\\'s clarity. However, the comment could be more helpful if it provided specific guidance on how to address the lack of insight or offered suggestions for further analysis. Overall, the comment is somewhat helpful as it points out a significant issue and offers a minor correction, but it could be more comprehensive in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to provide a more robust argument for using Shapely values over other methods by comparing them experimentally with methods like CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not specify how to conduct these experiments or what aspects to focus on in the discussion. The action is implicit and somewhat vague, as the authors can infer the need for additional work but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed, such as comparing Shapely values with other methods like CaCE or raw gradients, and discussing the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to provide a more robust argument for using Shapely values over other methods, such as CaCE or raw gradients, by comparing them experimentally. It also recommends a discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. While the comment provides a logical reasoning for the need for comparison and discussion, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to provide additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to strengthen their argument by comparing Shapely values with other methods, such as CaCE or raw gradients. It also suggests that the paper would benefit from a more comprehensive discussion on the advantages and disadvantages of each method for transforming high-dimensional data to low-dimensional latent space. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance their draft by including comparative analyses and discussions. However, the comment could be more helpful if it offered examples of how to conduct these comparisons or discussed potential pitfalls in the current approach. Overall, the comment is mostly helpful, as it directs the authors toward meaningful improvements but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a comparison, but they are not provided with specific guidance on how to execute this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should compare the perspective taken in the present manuscript to the contributions of prior efforts, providing clear guidance on what needs to be addressed in Section 6. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that while the related work section is comprehensive, it could benefit from comparing the current manuscript\\'s perspective to prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why such a comparison is necessary or how it would enhance the paper. This lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper, specifically suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by contextualizing their contributions within the broader literature. However, the comment could be more helpful if it offered examples or guidance on how to effectively make these comparisons. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with additional details or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not provide explicit guidance on how to conduct this examination or what specific numbers of scenarios should be tested. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of scenario numbers on performance but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental setup or results section, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a potential relationship between the number of scenarios used for training and the performance of the model. However, it does not provide any evidence, reasoning, or references to support this claim. The suggestion to examine the performance with different numbers of scenarios is logical but lacks specific examples or data to substantiate the assumption. As a result, the comment is considered unverifiable, as it does not provide sufficient justification or evidence to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance of the model might be closely related to the number of scenarios used for training, which is fixed at 200 in the paper. It recommends examining the performance with different numbers of scenarios, which could provide valuable insights into the model\\'s robustness and generalizability. This feedback is clear and actionable, as it identifies a potential area for exploration and improvement in the draft. However, it could be more helpful if it provided specific suggestions on how to conduct this analysis or what numbers of scenarios to consider. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful area of investigation that could enhance the paper\\'s quality and impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, clarification, or additional analysis that the authors should consider. As a result, the comment lacks any actionable guidance, leaving the authors without a clear understanding of how to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. However, it does not specify which part of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact sections being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments need improvement or clarification. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a factual statement describing the experiments conducted by the authors to validate the efficacy of CATER in various settings. It does not express an opinion, make a claim, or suggest changes, and it does not require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it lacks any specific feedback, suggestions, or critiques that could help the authors improve their work. Without actionable guidance or detailed analysis, the comment does not provide the authors with a clear understanding of how to enhance their draft. Therefore, it is rated as not helpful at all, as it does not offer any meaningful insights or directions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Appendix A.2 does not clearly illustrate the state space representation of the environment. This provides a direct action for the authors to take, which is to clarify or improve the illustration in Appendix A.2. However, the comment does not specify how to improve the illustration or what specific aspects need clarification, leaving the authors with a general direction but lacking detailed guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the state space representation of the environment is not illustrated clearly. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Appendix A.2 does not illustrate the state space representation of the environment clearly.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation of the environment in Appendix A.2. This feedback is clear and actionable, as it directs the authors to improve the illustration or explanation of this critical aspect of their work. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or offered examples of what a clear illustration might look like. Despite this, the comment still offers valuable guidance for improving the draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors' approach is limited to small or medium-scale problems and that truly large problems will overwhelm current LP-solvers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation, such as suggesting alternative methods for handling large-scale problems or proposing modifications to the current approach. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors\\' approach is limited to small or medium-scale problems and that truly large problems will overwhelm current LP-solvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach are problematic or how the authors might address the issue of scalability. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems and that truly large problems will overwhelm current LP-solvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is challenging for the authors to understand the basis of this assertion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out a limitation in the authors' approach, suggesting that it is only applicable to small or medium-scale problems and that truly large problems will overwhelm current LP-solvers. This feedback identifies a potential weakness in the applicability of the method, which is valuable for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the scalability of their approach. While it highlights an important area for improvement, the feedback could be more helpful if it included actionable advice or potential solutions. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in the context of stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue in their draft. The references to other works imply that the authors should consider these extensions, but the comment lacks concrete instructions on how to incorporate this information into their paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"bounded noise assumption\" in the context of stochastic optimization literature, suggesting that it is somewhat restrictive. It references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou, which provide extensions to these noise conditions. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The comment is specific in suggesting that the authors consider these extensions, but it lacks detailed guidance on how to incorporate this information into their work. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou. These references provide a basis for the claim, as they are recent and relevant studies that have explored extensions to the noise conditions. However, the comment could be strengthened by providing more detailed explanations or examples of how these works address the limitations of the bounded noise assumption. Overall, the claim is mostly verifiable, as it is supported by references to relevant literature, but it could benefit from more detailed justification. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights a potential limitation in the paper\\'s use of the bounded noise assumption, noting that it is somewhat restrictive in the context of stochastic optimization literature. It references specific works by A. Khaled and P. Richt\\'arik, and R. Gower, O. Sebbouh, and N. Loizou, which have explored extensions to these noise conditions. This feedback is somewhat helpful as it points out a potential area for improvement and provides references to relevant literature. However, it lacks detailed guidance or suggestions on how the authors might address this issue in their draft, such as how to incorporate these extensions or what specific aspects to focus on. Therefore, the comment is somewhat helpful, as it provides some direction but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the motivation or what specific aspects of the motivation need further explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the motivation for using characteristic function regularization. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the motivation is discussed. Without explicit references or detailed guidance, the authors cannot confidently identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the overall motivation for using characteristic function regularization is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the motivation for using characteristic function regularization. However, it does not provide any specific suggestions or guidance on how the authors might clarify this aspect or improve the motivation. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. There is no guidance on how the authors might enhance their contribution or improve the novelty of their work. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the existing techniques used, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is limited to a combination of existing techniques, specifically mentioning Lykouris et al. (2018), Zhou et al. (2021), and variable decision sets. The reviewer provides specific references to support the claim, which makes the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these existing techniques are combined, which would further solidify the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. It references specific works, such as Lykouris et al. (2018) and Zhou et al. (2021), to support this claim. However, the comment does not provide actionable feedback or suggestions on how the authors might enhance their contribution or improve the novelty of their work. While it highlights a potential weakness, it lacks depth and does not offer a clear path for the authors to address the issue. Therefore, the comment is somewhat helpful, as it identifies a limitation but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if referenced. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be clarified and how to address the issue, ensuring that they can make the necessary improvements to their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and \"aggregation operation after \"Integration,\"\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified\u2014more details about the aggregation operation and proper acknowledgment of other architectures if referenced. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification and requests more details in the main paper. It also advises acknowledging the structure of other architectures if referenced. However, the comment does not provide specific examples or references to support the claim that the aggregation operation is unclear or that other architectures should be acknowledged. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and address them without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires clarification, namely the aggregation operation after \"Integration\" in the context of multiscale modeling. It provides a clear and actionable suggestion for improvement by asking the authors to provide more details in the main paper. Additionally, it advises acknowledging the structure of other architectures if referenced, which is a constructive feedback that can help the authors enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific examples or further guidance on how to clarify the aggregation operation. Overall, the feedback is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. While the comment highlights an area for further exploration and a potential overlap with existing work, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is somewhat actionable as it identifies a potential area for improvement but lacks concrete steps or detailed advice on how to proceed. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation and goals of the model\" and the \"related work review part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the similarity between the model\\'s goals and those of a prior VAE paper, suggesting that the authors should be aware of this overlap. This provides clear guidance on what needs to be addressed in the related work section. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to those of a prior VAE paper. The comment provides a logical reasoning by comparing the novelty of energy models to GANs and VAEs, and by referencing a prior VAE paper for context. However, it lacks specific details or references to the prior VAE paper, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could be further supported with more detailed references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the novelty of using energy models for image generation and encourages further exploration. It also points out that the motivation and goals of the model are similar to those of a prior VAE paper, suggesting that the authors should be aware of this similarity. This feedback is somewhat helpful as it highlights an area for further exploration and a potential overlap with existing work. However, it lacks specific guidance or suggestions on how the authors might differentiate their work or address the similarity with the prior VAE paper. While it provides some insight, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\\'s generalizability to other domains. It also suggests verifying whether the method works with discrete action spaces and high-dimensional observations. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The recommendation is specific and actionable, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation being conducted only on the tasks from Meta World, a robotic manipulation domain, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that it is difficult to judge whether the results will generalize to other domains. The comment further provides a clear and specific suggestion to run experiments on a different benchmark, such as Atari, to verify the method\\'s generalizability and applicability to discrete action spaces and high-dimensional observations. This level of detail and guidance makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is limited to a single domain, Meta World, and suggests that this makes it difficult to judge the generalizability of the results to other domains. The reviewer recommends running experiments on a different benchmark, such as Atari, to verify the method\\'s applicability to discrete action spaces and high-dimensional observations. This claim is somewhat verifiable as it provides a logical reasoning for the need to evaluate the method on multiple domains and suggests a specific benchmark for further evaluation. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on the Meta World domain, a robotic manipulation domain. This limits the ability to judge the method\\'s generalizability to other domains. The reviewer provides a clear and actionable suggestion to address this issue by recommending the use of a different benchmark, such as Atari, which is commonly used in the literature. This suggestion not only highlights a critical area for improvement but also offers a specific and practical solution for the authors to enhance the robustness and applicability of their results. By suggesting a specific benchmark and highlighting the importance of evaluating the method in different domains, the comment is highly helpful in guiding the authors to improve their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the method is presented well and the experiments are good and complete. However, it suggests that there is a missing analysis of what the model does, which could be interesting. The comment implies that the authors should include this analysis, but it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. However, it does not specify which part of the paper lacks this analysis, making it weakly grounded. The comment is specific in suggesting that an analysis of the model could be interesting, but it does not provide detailed guidance on what aspects of the model should be analyzed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the presentation of the method and the completeness of the experiments but notes a missing analysis of what the model does. The comment suggests that this analysis could be interesting, but it does not provide specific examples or reasoning to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this analysis themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the presentation of the method and the completeness of the experiments, which is a positive observation. However, it points out a missing analysis of what the model does, suggesting that this could be an interesting aspect to explore. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects of the model should be examined. This limits the helpfulness of the feedback, as the authors are left with a general idea of what to consider but without detailed instructions on how to implement it. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the task setup, specifically questioning which notes from the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these issues. The authors can infer that they need to provide more detailed information about the task setup, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is somewhat actionable, as it points out a problem but does not fully direct the authors on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"task setup\" and provides specific examples of what is unclear, such as which notes in the EHR are used as input and how far away the outcomes are from the last note date. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, providing a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the task setup, specifically regarding which notes in the EHR are used as input and how far away the outcomes are from the last note date. However, it does not make a claim or provide an opinion that requires verification. It is a factual question seeking clarification, which aligns with the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity in the task setup. It raises questions about which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the task setup, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how similar tasks have addressed similar issues. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the proposed algorithm DMLCBO and previous works like SUSTAIN and MRBO, which achieve a faster convergence rate of $\\mathcal{\\widetilde O}(\\epsilon^{-3})$ compared to DMLCBO's $\\mathcal{\\widetilde O}(\\epsilon^{-4})$. The reviewer encourages the authors to discuss the reason for this difference and the theoretical technique differences between DMLCBO and the mentioned works. While the comment explicitly suggests that the authors should discuss these differences, it does not provide specific guidance on how to conduct this discussion or what aspects to focus on. The action is explicit but somewhat vague, as it lacks detailed instructions on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed algorithm DMLCBO\" and references specific previous works, such as SUSTAIN and MRBO, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the convergence rate and encourages the authors to discuss the reason for the difference and the theoretical technique differences between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works like SUSTAIN and MRBO, which are cited as references. The reviewer provides a specific comparison of the convergence rates, indicating that DMLCBO achieves $\\mathcal{\\widetilde O}(\\epsilon^{-4})$ while the previous works achieve $\\mathcal{\\widetilde O}(\\epsilon^{-3})$. This comparison is based on logical reasoning and references to specific works, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works like SUSTAIN and MRBO. The reviewer points out that while these previous works achieve a convergence rate of $\\mathcal{\\widetilde O}(\\epsilon^{-3})$, DMLCBO only achieves $\\mathcal{\\widetilde O}(\\epsilon^{-4})$. The comment encourages the authors to discuss the reason for this difference and the theoretical technique differences between DMLCBO and the mentioned works. This feedback is clear and actionable, as it prompts the authors to address a critical aspect of their algorithm's performance and theoretical underpinnings. By doing so, the authors can provide a more comprehensive understanding of their work and its place within the existing literature. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the heuristic design of the modulator and questions whether it might lead to scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the modulator\\'s design. The comment lacks actionable details, such as recommending alternative methods for modulator design or suggesting ways to evaluate scalability. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the modulator\\'s design and potential scalability issues but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the heuristic design of the modulator and questions its scalability, particularly in the context of diverse training data. However, the comment lacks specific examples or references to support the claim that the modulator might lead to scalability issues. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the heuristic design of the modulator, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the modulator's design. Without actionable advice or examples, the authors are left with a general understanding of the problem but no clear path forward for improvement. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not provide sufficient detail or direction for the authors to effectively address it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It suggests that the authors should conduct experiments to address these issues. While the comment implies that the authors should conduct experiments, it does not provide specific guidance on how to design these experiments or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of experiments on obtaining labeled data for imitation learning and how performance changes with varying data sizes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for experiments on data acquisition and performance changes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are difficulties in obtaining labeled data for imitation learning and that the performance changes depending on the size of the labeled data. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the challenges of obtaining labeled data for imitation learning and how the performance changes with varying data sizes. It highlights the need for experiments to address these issues, which is a crucial aspect of the methodology. However, the comment lacks specific suggestions or guidance on how the authors might conduct these experiments or what metrics to use. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or expand their exploration to other NLP tasks. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation is discussed in, nor does it provide specific guidance on how to address this issue. The authors may infer that it relates to the discussion or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the limitations in exploring other NLP tasks. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant and could prompt the authors to consider expanding their work to other NLP tasks, potentially increasing the generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore other NLP tasks. Without actionable advice, the feedback is somewhat helpful as it identifies an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. However, it does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should clarify or rephrase the term to avoid misinterpretation. The comment lacks concrete details on how to implement this change, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"line 267\"), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue with the terminology \"certificate\" and its strong meaning in complexity theory, providing a clear direction for the authors to address the potential misinterpretation. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the term \"certificate\" might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the potential misinterpretation. This lack of supporting information makes the claim somewhat verifiable, as the authors would need to infer the potential issue and address it themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the terminology \"certificate\" being used in certain contexts, specifically mentioning its strong meaning in complexity theory. This feedback is somewhat helpful as it alerts the authors to a potential source of confusion and suggests that they should clarify the usage of this term. However, the comment lacks specific guidance on how to address this issue or provide alternative terminology, which would make it more actionable. The authors are left with a general understanding of the problem but without detailed instructions on how to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to strengthen the paper. It also provides specific references to relevant works, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. This feedback is clear and provides concrete guidance on what experiments should be conducted and where to find relevant references. The authors know exactly what actions to take to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to strengthen the paper. It provides specific references to relevant works, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific in terms of the experiments needed, but without clear grounding, the authors may struggle to identify where these suggestions should be implemented. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. It provides specific references to relevant works, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation, which supports the claim. However, the comment could be strengthened by explaining why these specific experiments are necessary or how they would contribute to the paper\\'s findings. Despite this, the references provided offer a solid foundation for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from additional experiments on deeper networks (e.g., ResNet-50) and other network structures (e.g., MobileNet) to further strengthen its findings. This feedback is clear and actionable, as it provides specific examples of experiments that could be conducted to enhance the paper. The inclusion of references to relevant works, such as MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing for Semantic Segmentation, offers valuable guidance on where to find inspiration for these experiments. However, the comment could be more helpful if it explained why these specific experiments are necessary or how they would contribute to the paper\\'s overall impact. Despite this, the feedback is mostly helpful as it provides a clear direction for improving the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited scope of the models evaluated in the results/analysis, noting that only two relatively old and small models are considered. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should evaluate more models, newer models, or larger models, or how they might expand their analysis to include a broader range of models. Without specific actions or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results/analysis section, indicating that it is detailed and comprehensive but limited in scope due to the evaluation of only two relatively old and small models. However, it does not specify which part of the results/analysis section this critique pertains to, such as specific tables, figures, or sections. The authors can make an educated guess about the general area being discussed, but the comment lacks full grounding. It is specific in pointing out the limitation in model evaluation, but without explicit references, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results/analysis are detailed and comprehensive but limited because only two relatively old and small models are evaluated. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples of how the evaluation could be expanded or improved, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the analysis, noting that only two relatively old and small models are evaluated. While it identifies a potential weakness in the scope of the analysis, it does not provide specific suggestions or guidance on how the authors might address this issue or expand their evaluation to include a broader range of models. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that knowledge distillation (KD) and label smoothing (LS) are not identical but suggests that KD can be viewed as a special form of LS under certain conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without actionable suggestions or questions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment provides some insight into the theoretical relationship between KD and LS but lacks specificity in terms of how this understanding should influence the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point makes a claim about the relationship between knowledge distillation (KD) and label smoothing (LS), suggesting that KD can be viewed as a special form of LS under certain conditions. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges the distinction between knowledge distillation (KD) and label smoothing (LS) but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides some insight into the theoretical relationship between the two concepts. However, the comment lacks depth and does not offer any actionable suggestions or guidance for the authors to improve their draft. It does not address specific weaknesses or areas for improvement in the paper, leaving the authors without a clear path for enhancement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include more recent works in the comparison and provide results on large-scale datasets, including ImageNet, to further verify the effectiveness of their proposed method. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to update the comparison and include additional results. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamic-pruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of outdated methods and suggests including more recent works and results on large-scale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the competing dynamic-pruning methods are outdated and suggests including more recent works. It also points out that only results on small-scale datasets are provided and recommends including results on large-scale datasets like ImageNet. While the comment provides a logical basis for the suggestion by noting the lack of recent works and the limited scope of the results, it lacks specific references or examples of recent works that should be included. This makes the claim somewhat verifiable, as the authors would need to conduct their own research to identify relevant recent works. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the inclusion of more recent works in the comparison and the provision of results on large-scale datasets, such as ImageNet. This feedback is clear and actionable, as it directs the authors to expand their evaluation to include more contemporary methods and datasets, which would enhance the robustness and generalizability of their results. By suggesting this addition, the comment provides valuable guidance for the authors to strengthen their draft. However, it could be more helpful if it offered specific examples of recent works or datasets to consider. Overall, the comment is mostly helpful, as it effectively points out a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It explicitly asks for a justification of why this particular dimension of difficulty is interesting. This provides a clear and direct action for the authors to take, which is to provide a motivation or explanation for this choice. The comment is explicit and concrete, as it specifies exactly what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the images used in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, asking for a justification of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not well-motivated. The comment does not provide any specific reasoning, examples, or references to support why this particular dimension of difficulty is interesting. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It questions the interest in this particular dimension of difficulty and asks for a justification. This feedback is somewhat helpful as it prompts the authors to clarify their reasoning and provide a motivation for this choice, which could enhance the paper\\'s clarity and relevance. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that this text should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to adjust the font size of the text inside the figure and the labels to match the size of the manuscript text. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text size being too small and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and the labels are too small to read without zooming. However, it does not provide any supporting evidence, such as examples or comparisons with standard font sizes, to substantiate this claim. The comment lacks specific details or references that would help the authors understand the issue or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figure, noting that the text and labels are too small to read without zooming. It provides a clear and actionable suggestion to adjust the font size to match that of the manuscript text. This feedback is direct and helpful as it guides the authors on a specific aspect of the figure that needs improvement, allowing them to enhance the readability and accessibility of their work. However, the comment could be more helpful if it suggested specific font sizes or provided examples of how to achieve this adjustment. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the motivation is unclear and suggests that the introduction should be revised to make the paper easier to follow. However, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation is unclear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction is unclear or what aspects of the motivation need clarification. This makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is not grounded as it does not identify a specific section or part of the paper, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the motivation is unclear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It provides a clear and actionable suggestion to revise the introduction to make the paper easier to follow. However, the comment lacks specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. While it points out a critical area for improvement, the feedback could be more helpful if it included detailed suggestions or examples of how to clarify the motivation. Therefore, the comment is somewhat helpful, as it directs the authors to a key area for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including multiple local prompts may be beneficial, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of varying features and positions across different categories. Without specific suggestions or instructions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on how the features and positions differ or how this affects the analysis. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including multiple local prompts may be beneficial, but it notes that the features and their positions are not the same for different categories. However, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might address this issue or improve their draft. Without detailed feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to act upon.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the validation process. The action is implicit, as the authors need to infer that they should focus on validating the alignment, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as it does not provide a clear reference to the relevant section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that this aspect remains insufficiently validated. While the comment highlights a potential weakness in the paper, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples, the authors may find it challenging to understand how to improve the validation process. Therefore, the comment is somewhat helpful, as it points out a concern but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and only provides in-distribution testing for these samples. The reviewer suggests that the value of the method would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their experiments. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to a broader range of molecules or exploring alternative approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limited scope of the experiments, specifically mentioning the number of molecules tested and the lack of out-of-distribution testing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation of the experiments and the potential impact on the method\\'s value, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s value is limited due to its focus on a small number of molecules and in-distribution testing. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar studies or experiments that demonstrate the potential impact of this limitation. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant limitation in the paper's scope, noting that it only conducts experiments on a limited number of molecules and lacks out-of-distribution testing. This feedback is valuable as it highlights a potential constraint on the generalizability and applicability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation, such as proposing alternative datasets or testing scenarios. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and actionable steps for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment indicates that the symbols used in the paper are complicated and time-consuming to understand. However, it does not provide any explicit or implicit suggestions on how to simplify the symbols or improve their clarity. Without guidance on what specific aspects of the symbols are causing the complexity or how to address it, the authors are left without a clear path for improvement. As a result, the comment lacks actionable advice, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complicated and time-consuming to understand. However, it does not specify which symbols are causing the issue or where in the paper they are used. This lack of detail makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is not grounded as it does not mention specific sections, tables, or figures, and it is also not specific about what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Symbols are a little bit complicated and takes a lot of time to understand.\" However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the symbols used in the paper are complicated and time-consuming to understand. However, it lacks specificity and does not provide any actionable advice or suggestions on how to simplify the symbols or improve their clarity. Without guidance on what aspects of the symbols are causing the complexity or how to address it, the authors are left without a clear path for improvement. This makes the comment barely helpful, as it identifies a potential issue but does not offer any constructive feedback or direction for the authors to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It suggests that the comparison model cannot capture periodic relationships and questions whether adding periodicity to the spectral kernel would be enough to achieve similar results to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of periodicity on their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It references the comparison model and the experiments, specifically mentioning Experiment 1b, where relationships involved periodicity. However, it does not explicitly mention which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its inquiry about the impact of periodicity on the results, but without explicit references to sections or experiments, the authors may find it challenging to pinpoint the exact parts needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity versus compositionality. It provides a logical reasoning by comparing the comparison model, which cannot capture periodic relationships, to the experiments where periodicity is involved. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of periodicity to the results and consider how it might impact the spectral kernel. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity versus compositionality. It highlights a potential limitation by noting that the comparison model cannot capture periodic relationships, which are involved in most of the experiments except Experiment 1b. The comment suggests that adding periodicity to the spectral kernel might be enough to achieve similar results to the explicitly compositional model. This feedback is somewhat helpful as it prompts the authors to consider the role of periodicity in their results and potentially explore its impact on their model. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or if it offered a more detailed analysis of the implications of periodicity on the results. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not well-written and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique of the paper\\'s writing quality and suggests that it may have been written in a hurry, making it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are problematic, nor does it provide detailed feedback on how to improve the presentation or formatting. This makes it difficult for the authors to identify the exact areas that need attention. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is \"not very well-written\" and suggests it may have been written in a hurry, making it difficult to read. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion about the writing quality or the impact of a hurried writing process. Without concrete evidence or examples, the claim remains vague and unverifiable, making it difficult for the authors to understand and address the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a general critique of the paper\\'s writing quality, suggesting that it may have been written in a hurry, which makes it difficult to read. It also mentions that there is a lot left desired in terms of presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not offer any actionable suggestions or guidance on how the authors might improve the writing, presentation, or formatting. Without detailed feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance their draft. Therefore, the comment is barely helpful, as it identifies a general issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction need more detail or how the authors might enhance it. The action is implicit, as the authors can infer that they need to add more detail, but it is vague because it lacks concrete suggestions on what specific details should be included. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of Part 2 is being referred to, nor does it provide details on what aspects of the introduction need more detail. This makes it difficult for the authors to pinpoint the exact section that needs improvement. The comment is not grounded as it lacks specific references, and it is also not specific in terms of what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand what aspects of the introduction need more detail or how to improve it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the introduction need more detail or how the authors might enhance it. Without actionable suggestions or examples, the authors are left with a general idea of what might need attention but without a clear path for improvement. Therefore, the comment is barely helpful, as it provides minimal guidance for the authors to address the issue effectively.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. However, the comment does not explicitly instruct the authors to address this issue or suggest how to differentiate their work from existing research. The action is implicit, as the authors can infer that they need to discuss the novelty and originality of their work in relation to prior studies. The feedback is somewhat actionable because it points out a potential weakness but lacks specific guidance on how to address it. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses are already present in prior works, making the results not particularly surprising. This provides clear guidance on what needs to be addressed in terms of novelty and originality. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses are already present in prior works, making the results in the current paper not particularly surprising. It supports this claim by referencing specific prior works, such as RobustBench and [Croce et al. (2021)], which have studied the robustness of CIFAR-10 models on distribution shifts. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from or builds upon these prior studies. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that similar analyses are already present in prior works, which makes the results in the current paper not particularly surprising. It provides specific examples of prior works, such as RobustBench and references to [Croce et al. (2021)] and [A, B], which evaluate the robustness of models to unseen attacks. This feedback is somewhat helpful as it highlights a potential weakness in the paper, namely the lack of novelty in the analyses presented. However, it does not offer specific suggestions or guidance on how the authors might address this issue or differentiate their work from existing research. While it provides some insight into the need for originality, it lacks depth and actionable advice, making it somewhat helpful but not fully comprehensive. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) that may introduce significant computational overhead. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this issue, such as recommending specific values for these parameters or suggesting alternative approaches to optimize the trade-off between model size and accuracy. Without any guidance or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), which are mentioned in the context of computational overhead. However, it does not specify which part of the paper discusses these parameters, making it weakly grounded. The comment is specific in identifying the potential issue with these parameters but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. This is a relevant observation that could impact the efficiency and practicality of the model. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending alternative approaches or providing examples of how to optimize these parameters. Without actionable advice, the authors are left with a general awareness of the problem but no clear path forward for improvement. Therefore, the comment is somewhat helpful, as it highlights an important consideration but does not provide sufficient detail for the authors to effectively address it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what changes might be necessary to clarify the nature of the study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique of the study\\'s classification, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This claim is based on a logical reasoning that ablation studies typically involve removing or varying a specific component to assess its impact. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the context of their study and the typical definitions of ablation studies to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions the classification of the study on different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. This feedback is somewhat helpful as it points out a potential misunderstanding or mislabeling in the study\\'s methodology. However, it lacks depth and does not provide specific guidance on how the authors might clarify or correct this classification. The comment identifies a potential issue but does not offer actionable steps for improvement, leaving the authors with a general direction but not a clear path forward. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN, in addition to the proposed TransferNorm architecture. This implies that the authors should include these competitors in their evaluation to make the comparison more comprehensive. However, the comment does not provide specific guidance on how to implement this suggestion, such as which specific experiments to conduct or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not fully understand the scope of the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation would be stronger if the base DA methods were compared with and without architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This provides clear guidance on what needs to be addressed to enhance the evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. This claim is somewhat verifiable as it provides a logical suggestion for enhancing the evaluation by including direct competitors to the proposed TransferNorm architecture. However, the comment lacks specific examples or references to support the claim that these competitors are direct competitors or how they would enhance the evaluation. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a reasonable suggestion but requires more detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for enhancing the evaluation section of the paper. It acknowledges the current evaluation as a good start but suggests that it could be strengthened by including comparisons with architectural competitors like AutoDial and AdaBN, which are direct competitors to the proposed TransferNorm architecture. This feedback is actionable and offers a clear direction for the authors to improve their evaluation methodology, making it mostly helpful. However, the comment could be more helpful if it provided specific guidance on how to incorporate these competitors or what aspects of the evaluation should be focused on. Therefore, the comment aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to strengthen the evaluation or which alternative baselines might be more suitable. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation as weak and mentions that the baselines used are not designed for fair classification. However, it does not specify which part of the paper discusses the evaluation or the baselines, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved for fair classification. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation methodology, specifically noting that the baselines used are not designed for fair classification. This is a critical observation that highlights a potential flaw in the paper\\'s evaluation process. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or suggest alternative baselines that could be used. Without detailed suggestions or examples, the feedback is somewhat helpful as it points out a weakness but does not fully support the authors in making improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to clarify the setting in the first three paragraphs of section 2. It implies that the current presentation may give the impression of a more general contribution than what is actually made, which \"muddles the exposition.\" However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be detailed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more clarity but are not given concrete steps on how to achieve this. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the setting needs to be clarified to avoid giving the impression of a more general contribution than what is actually presented. This provides clear guidance on what needs to be addressed to improve the exposition. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their contribution. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references leaves the claim somewhat verifiable, as the authors would need to infer the exact areas that need clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their contribution. It points out that this lack of clarity \"muddles the exposition,\" which is a valuable observation for the authors to address. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or what aspects need more detail. Despite this, the feedback is somewhat helpful as it directs the authors to a critical area that needs improvement, even if it lacks detailed guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experiments, specifically questioning the choice of the old baseline (R3D and C3D) and suggesting that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the authors should either test their method on these newer approaches or explain the advantage of their method compared to these alternatives. While the action is implicit, it is concrete in suggesting specific alternatives to consider or compare with. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically questioning the choice of the old baseline (R3D and C3D) and suggesting that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. It implies that the authors should either test their method on these newer approaches or explain the advantage of their method compared to these alternatives. This provides clear guidance on what needs to be addressed in the experiments section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of the experiments by suggesting that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. The comment implies that the current baseline (R3D and C3D) may not be the most appropriate choice. However, the review does not provide specific examples or detailed reasoning to support why these newer approaches should be considered or how they might impact the results. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these newer approaches based on the comment alone.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline (R3D and C3D) and suggesting that the authors should consider more recent approaches like X3D and SlowFast to reduce computation complexity. It also prompts the authors to explain whether their method works on these newer 3D CNNs and what advantage it offers compared to these approaches. This feedback is clear and actionable, as it directs the authors to address a specific weakness in their experimental setup and to provide a clearer comparison with existing methods. However, the comment could be more helpful if it provided specific examples or references to these newer approaches, which would further guide the authors in making improvements. Overall, the comment is mostly helpful, as it provides valuable insights for enhancing the experimental section of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on how the attention module is attached to the ResNet-20 architecture during the search process. It specifically requests information on the number of attention modules used and their placement, such as after each block or stage. This provides clear and concrete guidance on what the authors need to address in their draft. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module\" and \"backbone ResNet-20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the exact placement and number of attention modules used during the search process. The comment provides detailed guidance on what information should be included to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the attachment of the attention module to the ResNet-20 architecture during the search process. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of the attention module into the ResNet-20 architecture during the search process. It asks for clarification on the number and placement of attention modules, which is a critical aspect of the methodology. By requesting this information, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar architectures for comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions the precise bitrate range used for the BD-rate comparison, implying that the authors should provide more detailed information on this aspect. Second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, specifically referencing a paper by Guo Lu et al. The comment provides explicit actions for the authors to take: clarify the bitrate range and consider discussing or comparing with the mentioned related work. These actions are concrete and directly guide the authors on what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BD-rate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the precise bitrate range used for the comparison and suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The reference to a specific paper by Guo Lu et al. provides additional guidance on what aspect to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the performance of the proposed method, stating that it is stronger at high bitrate but closer to baselines at low bitrate. It also suggests discussing or comparing the method with a related work on content adaptive algorithms in learned video compression, referencing a specific paper by Guo Lu et al. The claim is somewhat verifiable as it provides a logical observation about the method\\'s performance and suggests a relevant reference for further discussion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct points of feedback. First, it questions the precision of the bitrate range used for the BD-rate comparison, which is an important detail that could impact the interpretation of the results. This feedback is clear and actionable, as it prompts the authors to clarify this aspect of their methodology. Second, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, specifically referencing a paper by Guo Lu et al. This suggestion is valuable as it could enhance the paper\\'s context and relevance by exploring additional approaches. However, the comment could be more helpful if it provided a more detailed explanation of why this comparison is important or how it could benefit the paper. Overall, the comment is mostly helpful as it offers actionable feedback and a relevant suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should distinguish between the \"all-or-nothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. While the comment implies that this distinction is necessary, it does not provide explicit guidance on how to make this distinction or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests distinguishing between the \"all-or-nothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. The authors may infer that it relates to the methodology or results sections, but the comment lacks grounding and specificity. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests distinguishing between the \"all-or-nothing\" or \"cutoff\" phenomenon and usual statistical bounds. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would improve the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a distinction between the \"all-or-nothing\" or \"cutoff\" phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or why it is important. Without actionable advice or examples, the authors may find it challenging to address this feedback effectively. Therefore, the comment is barely helpful, as it highlights a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, specifically that the main theoretical result provides utility guarantees only under the assumption of Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific issue and suggests a comparison with existing literature, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the strong requirement of Gaussian features and noise, which is a critical assumption that may limit the applicability of the proposed algorithm. Additionally, the comment suggests comparing the rates achieved by the procedure to existing rates in the literature, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only under the assumption of Gaussian features and noise, which is a strong requirement on the data. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. The claim is somewhat verifiable as it provides a logical reasoning about the limitation of the theoretical result and suggests a comparison with existing literature. However, the comment lacks specific references or examples of existing rates in the literature, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation in the paper's theoretical result, noting that it provides utility guarantees only under the assumption of Gaussian features and noise. This is a critical observation that highlights a strong requirement on the data, which may limit the applicability of the proposed algorithm. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable suggestion for improving the paper's contribution and relevance. However, the comment could be more helpful if it provided specific examples or references to existing literature for comparison, or if it offered guidance on how to address the limitation. Overall, the comment is mostly helpful as it points out a key area for improvement and suggests a direction for further analysis, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how this comparison should be conducted or what aspects should be focused on, leaving some room for interpretation. While the action is explicit, the lack of detailed guidance makes it somewhat actionable. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the comparison are missing. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, the comment is specific in suggesting a comparison but does not provide detailed guidance on how to conduct it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any reasoning or justification for why this comparison is necessary or how it would enhance the paper. Without supporting evidence or explanation, the claim remains unverifiable, as the authors are left without a clear understanding of the importance or relevance of this comparison. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a useful comparison between the proposed extension and the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including a comparative analysis. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or what aspects to focus on. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It implies that the current comparison with only two baselines is insufficient and that additional comparisons with other works, such as those mentioned (e.g., [1,2,3]), are necessary. However, the comment does not specify which additional works should be included or how the experiments should be conducted. While the action is clear, the lack of detailed guidance on implementation makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, referencing specific works ([1,2,3]) that focus on the same questions. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. It supports this claim by referencing specific works ([1,2,3]) that focus on the same questions, suggesting that these works could be used for additional comparisons. However, the comment lacks detailed reasoning or examples of how these works could be integrated into the experimental section, which would strengthen the justification. Therefore, the claim is mostly verifiable, as it provides some support but could be more comprehensive with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that additional experimental comparisons with other works that focus on the same questions could be beneficial in demonstrating the effectiveness of the proposed method. The comment references specific works ([1,2,3]) that could be included in the comparisons, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered guidance on how to conduct these additional experiments or which specific aspects of the proposed method should be compared. Overall, the feedback is mostly helpful as it directs the authors to enhance the robustness of their experimental evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what the authors should do to address this issue. The authors are left to infer that they should expand their analysis to include a broader range of NAS approaches, but the comment lacks concrete details on how to implement this expansion. Therefore, the comment is somewhat actionable, as it points out a gap but does not fully direct the authors on how to fill it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BRP-NAS,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by pointing out that the analysis only compares against three basic alternatives and ignores other NAS approaches, such as super-net/one-shot methods. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of BRP-NAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches. However, the comment does not provide specific examples or references to support this claim, such as mentioning which other NAS approaches are relevant or how they could enhance the analysis. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the relevance of the omitted NAS approaches and their potential impact on the analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This feedback is clear and actionable, as it highlights an area where the authors could expand their analysis to provide a more comprehensive evaluation. However, the comment could be more helpful if it suggested specific NAS approaches that should be included or provided guidance on how to incorporate them into the analysis. Despite this, the comment still offers valuable insight and direction for the authors to improve their draft. Therefore, it is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to provide more information about the filtering process used to create the Arabic climate change QA dataset, specifically regarding the translation and filtering methodology. This feedback is clear and direct, giving the authors a concrete action to take: they should include detailed information about these processes to enhance the assessment of the dataset\\'s quality. The comment is highly actionable as it specifies exactly what needs to be addressed and provides a clear path for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary for assessing the dataset\\'s quality. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of these details and how they impact the dataset\\'s quality, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset\\'s quality. This feedback is clear and actionable, as it directs the authors to provide additional details that are crucial for evaluating the dataset. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects of the methodology should be detailed. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that the authors should conduct additional experiments or analyses, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors can infer that they need to conduct more experiments but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its suggestions for enhancing the experiment results, but it lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment does not provide specific examples, references, or detailed reasoning to support why these aspects are lacking or how they could be improved. The claim is somewhat verifiable as it highlights areas for potential enhancement, but it lacks the depth and evidence needed to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experiment results, suggesting that the inclusion of attacks with different strengths and an exploration of how different thresholds influence detection performance could enrich the results. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental analysis. However, the comment could be more helpful if it offered specific examples or suggestions on how to implement these enhancements. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful improvement in their draft, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more information about the performance differences resulting from using different image sizes and variations of ResNets. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add this information but are not given specific guidance on how to present it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the performance differences resulting from using different image sizes and variations of ResNets. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking for more information about the performance differences resulting from using different image sizes and variations of ResNets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors provide more information about the performance differences resulting from using different image sizes and variations of ResNets. This is a clear and actionable suggestion that could help the authors improve their draft by offering a more comprehensive understanding of the impact of these variations on performance. However, the comment could be more helpful if it provided specific guidance on how to present this information or what aspects of performance should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more detailed in its suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. While the comment implies that the authors should provide more detailed information about the algorithm, it does not specify what aspects of the algorithm need more detail or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more detail but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references or clear indications of where the algorithm is described, the authors may find it challenging to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the algorithm should be presented and described in detail to facilitate understanding of the proposed method. While this feedback is clear and identifies a specific area for improvement, it lacks depth and does not provide guidance on what aspects of the algorithm need more detail or how to present them. The comment is somewhat helpful as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether there is existing work that offers a way to approximate the contribution of FFNs, given that a linear decomposition cannot be obtained. It suggests that if no such work exists, the authors should add a statement indicating that it is an open problem. This feedback is explicit in its request for additional information and provides a clear direction for the authors to follow. The suggestion to add a line or two to address the issue is concrete, as it specifies what the authors should do to improve the readability and clarity of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and \"linear decomposition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider existing work that might offer a way around the issue of not being able to obtain a linear decomposition. The comment further recommends adding a statement to indicate that there is no solution for this problem and that it is an open issue. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, and it suggests that the authors should consider whether there is existing work that offers a way around this limitation. The comment implies that the absence of such work is a limitation of the current approach, but it does not provide specific references or detailed reasoning to support this claim. While the suggestion to add a statement about the open problem is logical, the lack of explicit evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a relevant question about the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider whether there is existing work that offers a way around this limitation, such as an approximation. If no such work exists, the comment recommends adding a statement to indicate that it is an open problem, which would improve the readability and provide a clearer overall picture to the reader. This feedback is clear and actionable, offering a specific suggestion for enhancing the paper. However, it could be more helpful if it provided examples of existing work or more detailed guidance on how to address the issue. Overall, the comment is mostly helpful, as it provides valuable insights and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the impact of the number of images on the model performance and another about the explanation of BYOL in the abstract. While the questions are clear and imply that the authors should address these points, they do not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and report on the impact of image numbers and provide a detailed explanation of BYOL. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the impact of the number of images on the model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image numbers and the explanation of BYOL, but without clear references to specific sections or parts of the paper, the authors may find it challenging to pinpoint where these issues need to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the impact of the number of images on the model performance and requests clarification on the explanation of BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions about the paper. First, it questions how the number of images impacts the model performance, which is a critical aspect of understanding the robustness and generalizability of the model. Second, it requests clarification on the explanation of BYOL in the abstract, which is a relevant point for readers who may not be familiar with the acronym. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their explanation. While it identifies areas for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the observed effects are strong, the paper lacks clarity on why the method works, particularly regarding the L_pixel component. It explicitly recommends providing stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation and justification of the method\\'s effectiveness. The comment provides a specific action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the clarity of the paper regarding the effectiveness of the method, specifically the L_pixel component. It suggests that while the observed effects are strong, the paper lacks explanation on why the method works, particularly for this component. The comment provides a clear direction for improvement by recommending stronger arguments or intuitions to explain the benefits of the particular losses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion for improvement, as it clearly outlines what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of clarity regarding why the method works, particularly for the L_pixel component. It suggests that stronger arguments or intuitions are needed to explain why these particular losses are beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the explanation of why the method works, particularly for the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance the theoretical foundation of their method by providing a deeper understanding of its components. By addressing this issue, the authors can improve the clarity and robustness of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training data for LLMs, which is in trillions of tokens, and suggests that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their dataset. The action is implicit and vague, as the authors are left to infer that they need to consider the size and diversity of their dataset but are not given specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training data for LLMs, which is in trillions of tokens, and suggests that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper discusses the training data or dataset size, making it weakly grounded. The comment is specific in detailing the concern about the dataset size and its implications, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this to the typical training data for LLMs, which is in trillions of tokens, and suggests that the dataset needs to be massive to cover varied domains. This comparison is based on common knowledge about the scale of training data required for LLMs, providing a logical basis for the claim. However, the comment could be strengthened by providing specific examples or references to studies that support the need for larger datasets. Overall, the claim is somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It compares this to the typical training data for LLMs, which is in trillions of tokens, and suggests that the dataset needs to be massive to cover varied domains. This feedback is somewhat helpful as it highlights a potential limitation in the dataset size and encourages the authors to consider the implications of their dataset on the model's performance. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending additional data sources or methods to enhance the dataset. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the baseline metric but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. While it identifies a potential issue with the baseline, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their baseline metrics. The comment lacks actionable feedback, leaving the authors with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. It implies that the authors should provide a clearer understanding of when to use SynTextBench over other metrics. While the comment explicitly suggests a comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to make a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and \"the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of SynTextBench with other metrics like MMLU and Big Bench for language generation, and the need for a clearer understanding of when to use SynTextBench over these other metrics. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. The reviewer acknowledges that some metrics may not satisfy the proposed desiderata but emphasizes the importance of comparing SynTextBench with existing metrics. This claim is somewhat verifiable as it provides a logical reasoning for the comparison, but it lacks specific examples or references to support the claim fully. The authors would need to conduct their own research to fully understand the comparison, making the comment mostly verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their SynTextBench metric with other metrics proposed in the literature, such as MMLU and Big Bench for language generation. It highlights the importance of understanding under what conditions SynTextBench should be used over other metrics. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing a gap in the evaluation of their metric. However, the comment could be more helpful if it offered examples or specific guidance on how to conduct this comparison. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consideration of ECG segments with only one label assigned, suggesting that including all reports might be more beneficial. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their approach, but it lacks concrete details on what changes should be made or how to implement them. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the rationale behind only considering ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique, as it clearly outlines the concern about the labeling approach, but it lacks grounding due to the absence of explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind only considering ECG segments with one label assigned, suggesting that including all reports might be more beneficial. However, the comment does not provide any supporting evidence, reasoning, or references to justify why including all reports would be easier or more beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the methodology used in the paper, specifically why only ECG segments with one label are considered. It suggests that including all reports might be more beneficial, implying that the current approach might be limiting. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or why including all reports would be beneficial. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements or computational complexity. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a more detailed discussion on scalability, but without specific suggestions on what aspects to focus on or how to present this information, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Limited Discussion of Scalability Bounds,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of thorough exploration of the upper limits of FedDES\\'s scalability, including no clear discussion of memory requirements or computational complexity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a thorough discussion on the scalability bounds of FedDES, specifically mentioning the absence of clear discussions on memory requirements or computational complexity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the limited discussion on scalability bounds. It highlights the lack of thorough exploration of the upper limits of FedDES\\'s scalability and the absence of clear discussions on memory requirements or computational complexity. This feedback is clear and actionable, as it directs the authors to expand their discussion on scalability, which is an important aspect of evaluating the practicality and applicability of their method. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to consider. Overall, the comment is mostly helpful as it points out a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It asks whether this means the base node affects the ordering, key nodes for attention, and ultimately the model performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or what specific aspects of the paper need clarification or improvement. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NodeSort\" and \"base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node, asking whether this affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It does not contain a claim or opinion that requires verification. It is a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of \"NodeSort\" differentially sorting nodes based on the base node. It seeks clarification on whether this affects the ordering, key nodes for attention, and ultimately the model performance. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the implications in their paper. The feedback is somewhat helpful as it prompts the authors to consider the impact of \"NodeSort\" but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i), implying that the arrow should be directed differently. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative directions for the arrow. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the direction of the arrow based on the reviewer\\'s suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in Figure 2 and suggests that it should be from the latent space to n^(i) instead of from a Gaussian space. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of an arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space. This is a logical observation that challenges the current representation in the figure. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this change is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the direction of an arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). This feedback is somewhat helpful as it prompts the authors to reconsider the representation in their figure and potentially clarify the purpose of the arrow. However, the comment lacks depth and does not provide detailed guidance on how to address the issue or why the suggested change might be beneficial. To be more helpful, the comment could include additional context or reasoning to support the suggestion. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the paper, namely that many abbreviations lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to avoid confusion. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of abbreviations lacking definition, providing a concrete example with \"AR\" in Table 5. This feedback is clear and actionable, guiding the authors on what needs to be addressed to improve the clarity of their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and cause confusion, providing a specific example with \"AR\" in Table 5. This claim is verifiable as it is supported by a concrete example, which helps the authors understand the issue and take corrective action. The mention of \"domain adaptation tasks and algorithms\" provides a clear context for the abbreviation, making the claim mostly verifiable. However, the comment could be strengthened by suggesting how the authors might address this issue, such as by providing a glossary or defining the abbreviations in the text. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that many abbreviations lack definition and cause confusion. It provides a concrete example by specifying that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it instructs the authors to define the abbreviations used in the paper to improve clarity. By addressing this issue, the authors can enhance the readability and understandability of their work. However, the comment could be more helpful if it suggested ways to present the definitions or provided additional guidance on how to handle abbreviations effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not provide any explicit guidance or suggestions for the authors to address this issue. The comment lacks concrete details on what specific considerations should be explored or how the authors might investigate this further. As a result, the authors are left without a clear understanding of what actions to take or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on what these technical considerations might be or how they could impact the analysis. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or what specific technical considerations are at play. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using \"advantage\" instead of \"q value\" in the analysis, suggesting that there might be other technical considerations for this choice. While it identifies a potential area of interest, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or explore the technical considerations further. Without actionable feedback or detailed insights, the authors are left with a vague understanding of what needs to be improved. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the performance comparison in Table 1, specifically noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This implies that the comparison may not be fair due to the differing sample weights. However, the comment does not explicitly instruct the authors to address this issue or suggest how to make the comparison fair. The action is implicit and somewhat vague, as the authors need to infer that they should ensure a fair comparison by either adjusting the sample weights or explaining the rationale behind the current setup. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance comparison, noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed to ensure a fair comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This claim is somewhat verifiable as it provides a specific reason for the perceived unfairness, namely the differing sample weights. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining how the different sample weights might impact the comparison or providing specific instances where this might lead to unfairness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS uses different sample weights (W u i) during training, while most compared baselines set all sample weights as 1. This observation highlights a potential source of unfairness in the comparison, which is a critical aspect of evaluating the effectiveness of the proposed method. By pointing out this discrepancy, the comment provides the authors with a clear direction for improvement, suggesting that they should either adjust the sample weights or provide a rationale for the current setup. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to ensure a fair comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the reply buffer being too large, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or suggestions for modifications to mitigate the problem. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the \"reply buffer\" and references a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning,\" which provides some grounding by indicating the context of the issue. However, it does not specify which part of the paper discusses the reply buffer or how the time complexity issue is addressed. The authors can infer that it relates to the methodology or results section, but the comment lacks full grounding. The comment is specific in identifying the potential issue with the time complexity of a large reply buffer, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.\" However, the comment does not provide detailed reasoning or examples to support why this would be the case, nor does it explain how the referenced paper relates to the issue. This lack of detailed justification or specific examples makes the claim somewhat verifiable, as the authors would need to delve deeper into the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could lead to high computational costs. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines or perspectives should be included or how to implement these suggestions. The action is explicit but lacks concrete details, making it somewhat actionable. The authors know they need to involve other baselines but may not be entirely sure how to execute this suggestion effectively.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. However, it does not specify which part of the paper this suggestion should be applied to, such as a specific section or table. Additionally, while it mentions specific references, it does not provide detailed guidance on how to incorporate these baselines or perspectives. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed, and not specific, as it lacks detailed guidance on implementation. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. The comment references specific references ([16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45]) but does not provide detailed reasoning or examples of how these references support the suggestion. While the references are listed, the comment lacks specific explanations or examples of how these baselines or perspectives could enhance the performance evaluation. This makes the claim somewhat verifiable, as the authors would need to infer the relevance of these references to their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives. It provides specific references to consider, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is clear and actionable, as it offers concrete suggestions for enhancing the evaluation of the paper. However, it could be more helpful if it included a brief explanation of why these baselines or perspectives are relevant or how they might improve the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or rationale.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APE-GAN may not fully demonstrate the framework\\'s capabilities. While the comment implies that this additional comparison would enhance the paper\\'s results, it does not explicitly instruct the authors to make this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this additional comparison to improve the paper\\'s meaningfulness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the current comparison with APE-GAN may not fully demonstrate the framework\\'s capabilities. However, it does not specify which part of the paper this suggestion should be addressed in, such as the results section or the discussion. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting a potential enhancement to the comparison, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that comparing the proposed framework with a method designed to defend against multiple attacks would enhance the paper\\'s results. However, the comment does not provide specific examples or references to support the claim that such a comparison would be meaningful or that the current comparison with APE-GAN is insufficient. The suggestion is based on a logical reasoning that multiple attack defenses are less common, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a rationale but lacks specific examples or references to fully support the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests an additional comparison that could enhance the paper's results by comparing the proposed framework with a method designed to defend against multiple attacks. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in order to improve the comprehensiveness and meaningfulness of their study. However, the comment could be more helpful if it included specific examples or references to methods that defend against multiple attacks, which would further guide the authors in implementing this suggestion. Overall, the comment is mostly helpful as it offers a constructive way to improve the paper, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the bounds for \\\\tau_i^l at line 111, emphasizing its importance for understanding the time-warp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it highly actionable. The authors know exactly what to do to enhance their paper, which aligns with the criteria for a highly actionable comment.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: defining the bounds for \\\\tau_i^l to understand the time-warp function. This provides clear guidance on what the authors need to revise. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to define the bounds for \\\\tau_i^l to better understand the time-warp function. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, requesting that the authors define the bounds for \\\\tau_i^l at line 111. This feedback is actionable and directly addresses a potential area of confusion in the paper, specifically regarding the time-warp function. By providing this guidance, the comment helps the authors clarify their work and improve its clarity. However, it could be more helpful if it offered additional context or explanation about why defining these bounds is important or how it might impact the understanding of the time-warp function. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the efficiency of the pairwise matching or suggestions for alternative approaches. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, suggesting that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without explicit references to sections or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or data to demonstrate the inefficiency, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency of pairwise matching, suggesting that it may be too low for practical application. However, it does not provide any specific suggestions or guidance on how the authors might improve the efficiency or address this concern. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, it does not provide specific guidance or suggestions on how the authors could improve the allocation or editing of the figure. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to address the issue. As a result, the comment is vague and does not offer a clear path for improvement, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"Figure 1\" and suggests that its allocation is too naive, implying that the authors could have edited the space of the main paper more wisely. However, it does not specify which part of the paper this figure is located in, making it weakly grounded. The comment is specific in identifying the issue with the figure\\'s allocation, but without explicit references to sections or specific elements, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. However, the comment lacks specificity and does not provide any actionable guidance or suggestions on how the authors might improve the allocation or editing of the figure. Without detailed feedback or examples, the authors are left without a clear understanding of what changes could be made to address the issue. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to re-write the first sentence of the abstract. This is a direct and clear action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it highly actionable. The authors know exactly what action to take and how to implement it, as they are told to re-write the first sentence of the abstract. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the first sentence of the abstract needs to be rewritten, but it does not specify which part of the abstract this sentence is located in. This makes it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the sentence are problematic or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be rewritten, but it does not provide any justification or explanation for this claim. There is no reasoning or evidence offered to support why the sentence is problematic or how it could be improved. Without any supporting details or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the first sentence of the abstract needs to be rewritten, which is a specific and actionable piece of feedback. However, it lacks further guidance or explanation on what aspects of the sentence are problematic or how it could be improved. Without additional context or suggestions, the authors may find it challenging to effectively address the issue. While the comment identifies a potential area for improvement, it is incomplete and does not provide enough detail to be fully helpful. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that adding a method to improve transferability is a good approach but notes that it cannot be considered a significant contribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes they should make to enhance their contribution. The comment lacks actionable details, such as suggesting alternative methods or ways to improve transferability, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the addition of a method to improve transferability, suggesting it is a good approach but not a significant contribution. However, it does not specify which part of the paper this method is added to or how it relates to other methods. The authors can infer that it might be related to the methodology section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, the comment is specific in suggesting that the contribution is not significant, but it does not provide detailed feedback on how to enhance the contribution. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method to improve transferability is good but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this approach is not considered significant. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the addition of a method to improve transferability as a good approach but questions its significance as a contribution. However, it does not provide any specific feedback or suggestions on how the authors could enhance their contribution or address the issue of significance. Without actionable guidance or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of clarity and specify the challenges. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the analysis of Adam under the (L0,L1)-smoothness condition, suggesting that the authors should clarify the challenges involved. It implies that the authors should explain the differences between their analysis and that of Zhang et al. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the explanation of challenges and differences. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the challenges when analyzing Adam under the (L0,L1)-smoothness condition, suggesting that standard analysis could be applied. The comment implies that the authors should explain the challenges and differences with Zhang et al. However, the review does not provide specific examples or references to support the claim that standard analysis is applicable or to clarify the differences with Zhang et al. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and differences based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the challenges of analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should clarify these challenges and explain the differences between their analysis and that of Zhang et al. This feedback is clear and actionable, as it directs the authors to address a particular gap in their explanation. However, the comment could be more helpful if it provided specific examples or further guidance on how to articulate these differences. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a general observation about the basis of person re-ID methods, mentioning that most are built on pedestrian detectors (two-step method) and that there are also end-to-end methods that combine detection and re-ID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the basis of person re-ID methods, mentioning that most are built on pedestrian detectors (two-step method) and that there are also end-to-end methods that combine detection and re-ID. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how this information should be addressed or integrated into the paper. As a result, the authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a factual statement about the basis of person re-ID methods, mentioning that most are built on pedestrian detectors (two-step method) and that there are also end-to-end methods that combine detection and re-ID. This statement is descriptive and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely informative and does not necessitate any justification or evidence beyond the statement itself. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point provides a general observation about the basis of person re-ID methods, noting that most are built on pedestrian detectors (two-step method) and that there are also end-to-end methods that combine detection and re-ID. While this information is factual and could be useful for the authors to consider in the context of their work, it does not offer any specific guidance or suggestions for improvement. The comment lacks depth and does not provide actionable feedback, leaving the authors without a clear understanding of how to address this information in their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests adding a first sentence to introduce Section 3.2, providing a clear and direct action for the authors to take. The comment specifies exactly what needs to be done, making it highly actionable. The authors know exactly how to apply this feedback to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2, which is a factual statement and does not contain any subjective claims or opinions. It is purely descriptive and does not require verification or justification. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the draft by recommending the addition of a first sentence to introduce Section 3.2. This feedback is specific and directly addresses a structural issue in the paper, guiding the authors on how to enhance the clarity and organization of their work. By suggesting a straightforward change, the comment is highly helpful as it empowers the authors to make a tangible improvement in their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial rationale selector being \"perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that the initial rationale selector is \"perfect,\" suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"perfect\" in the context of the initial rationale selector, suggesting that if it were perfect, no additional work would be needed. This feedback identifies a potential ambiguity or confusion in the paper and prompts the authors to clarify their rationale. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it highlights a point that needs attention, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct questions. The first question is about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. This is an implicit action, as the authors are being asked to clarify their experimental approach. However, it is not explicitly stated, and the authors may need to infer that they should provide additional information on this aspect. The second question is about the number of questions created for the zero-shot intent classifier and its accuracy. This is also an implicit action, as the authors are being asked to provide specific details about their experimental setup. Both questions are somewhat vague, as they do not provide explicit instructions on how to address them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the experimentation with domain ontologies to avoid placeholder generation and the details about the zero-shot intent classifier, such as the number of questions created and its accuracy. This provides clear guidance on what aspects of the paper require further clarification or elaboration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions: one about the use of domain ontologies and another about the specifics of the zero-shot intent classifier. Neither question contains a claim or opinion that requires verification. They are factual and seek clarification, making them \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two areas that need clarification or elaboration. First, it questions whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. This is a relevant point that could impact the comprehensiveness of the study. Second, it asks for specific details about the zero-shot intent classifier, such as the number of questions created and its accuracy. These questions are clear and actionable, providing the authors with specific areas to address in their draft. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of how domain ontologies could be used. Overall, the comment is mostly helpful as it directs the authors to important aspects of their work that require further clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing aspect in the paper, which is the lack of citations to set the work in context with other Multi-Agent Reinforcement Learning (MARL) research, specifically mentioning recent papers on self-play and population-play. The reviewer provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This feedback is clear and provides concrete guidance on how to improve the draft by including relevant citations. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to set the work in context with other MARL work, specifically referencing recent papers on self-play and population-play. It provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail allows the authors to accurately identify the parts of the paper that need revision and understand what is missing. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks citations to set it in the context of other MARL work, specifically mentioning recent papers on self-play and population-play. The reviewer provides specific examples of papers that could be cited, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which supports the claim. This level of detail provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by explaining why these specific papers are relevant or how they relate to the work being discussed. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of citations to set the work in context with other Multi-Agent Reinforcement Learning (MARL) research. It provides examples of recent papers on self-play and population-play, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which could be relevant to the work being discussed. This feedback is clear and actionable, as it guides the authors on how to enhance the context and relevance of their paper by including these citations. However, the comment could be more helpful if it explained why these specific papers are relevant or how they relate to the work being discussed. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold and how it differs from a decision threshold used by models. The comment explicitly asks the authors to clarify this aspect, providing a clear and direct action for the authors to take. The feedback is concrete, as it specifies what needs to be clarified, and it is explicit, as it directly instructs the authors to provide clarification. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the \"abstention process,\" allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it questions the basis of the abstention process, specifically whether it is based on a prediction probability threshold and how it differs from a decision threshold used by models. The comment requests clarification, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold and how it differs from a decision threshold used by models. The comment does not make a claim or judgment but rather seeks clarification, which is a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the abstention process, specifically whether it is based on a prediction probability threshold and how it differs from a decision threshold used by models. This is a clear and specific inquiry that prompts the authors to clarify their methodology, which is an important aspect of their work. By asking for clarification, the comment provides a direct and actionable suggestion for the authors to improve their draft. However, the comment could be more helpful if it offered additional context or suggestions on how to address the question. Overall, the comment is mostly helpful as it guides the authors toward a clearer explanation of their methodology, but it could be more comprehensive with further guidance or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines despite mentioning various model criticism techniques. The reviewer suggests that the authors could compare with a chain-of-thought prompting approach. This feedback is explicit and provides a concrete suggestion for improvement, indicating that the authors should consider adding more robust baselines to their comparisons. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of meaningful baselines and suggests a particular approach, such as comparing with a chain-of-thought prompting method, to enhance the comparisons. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests that the authors could compare with a chain-of-thought prompting approach. This claim is somewhat verifiable as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to consider the suggestion and potentially conduct additional comparisons to address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that despite mentioning various model criticism techniques, the authors only compare with simple naive baselines. The reviewer suggests a specific alternative, such as comparing with a chain-of-thought prompting approach, which could provide a more robust evaluation. This feedback is clear and actionable, offering the authors a concrete suggestion for enhancing the validity and depth of their comparisons. By addressing this critique, the authors can significantly improve the rigor and relevance of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. While the comment implies that the authors should clarify their pretraining approach and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or methodology description. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment is specific in its questioning, it does not provide detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and aim to gather information, making it a normal statement. Therefore, the correct label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the pretraining of the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalizability of this approach to settings without associated labels. This feedback is somewhat helpful as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address these questions or potential implications. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this potential dependency or what specific aspects of the design might be affected. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and subsequent design decisions might be hardware and software dependent. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects are hardware or software dependent. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing attention or improvement. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the paper, noting that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, context, or suggestions on how to address this dependency. Without detailed guidance or actionable feedback, the authors are left without a clear understanding of how to improve their draft. The comment highlights a potential area for consideration but lacks depth and specificity, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not provide explicit or implicit actions for the authors to take. The questions posed are more exploratory in nature, seeking clarification rather than directing the authors to make specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not specify which part of the paper these questions pertain to, such as a specific section or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment does not provide specific details on what aspects of the ground truth or the ablation study are being questioned, further reducing its specificity. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions seeking clarification on the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely descriptive and seeks information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the accuracy of the ground truth and the differences observed in the results, particularly in the context of the ablation study. It prompts the authors to consider whether the small differences are noticeable or due to noise or randomness in the training process. However, the comment lacks specificity and does not provide actionable guidance or suggestions for how the authors might address these questions or improve their analysis. Without detailed feedback or recommendations, the authors are left with a general understanding of the issues but without a clear path forward for improvement. Therefore, the comment is somewhat helpful, as it identifies areas for consideration but does not fully support the authors in making meaningful changes to their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that important experimental details are missing or relegated to the appendix, and the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback provides a clear and explicit action for the authors to take: they should include detailed explanations and interpretations of the experimental results, particularly for the PCA experiments mentioned. The comment is highly actionable as it specifies exactly what needs to be addressed and provides concrete guidance on how to improve the draft. Therefore, this comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of missing explanations and interpretations for the PCA experiments in these figures. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that important experimental details are missing or relegated to the appendix, and that the appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This claim is somewhat verifiable as it highlights a specific issue with the presentation of experimental results, but it lacks detailed examples or references to support the claim fully. The authors would need to review their appendix and experimental sections to understand the extent of the issue, making the comment mostly verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the presentation of experimental details, noting that many important details are missing or relegated to the appendix. It specifically points out that the appendix lacks explanations or interpretations, and that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback is clear and actionable, as it directs the authors to include detailed explanations and interpretations of their experimental results, particularly for the PCA experiments. By addressing this feedback, the authors can significantly improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of new evaluation metrics and the need for an in-depth exploration of the experimental results. While it identifies these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they should propose new evaluation metrics and conduct a more detailed analysis of the experimental results. However, the comment lacks concrete details on what specific new metrics should be proposed or how the experimental results should be explored in-depth. This makes the action implicit and somewhat vague, as the authors are not provided with clear steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of new evaluation metrics and the need for an in-depth exploration of the experimental results. It mentions the experimental analysis section, providing some grounding by specifying the part of the paper being addressed. However, it does not specify which specific results need further exploration or why the current evaluation metrics are insufficient. This makes the comment weakly grounded, as the authors can infer the general area but not the exact parts needing attention. The comment is specific in identifying the need for new evaluation metrics and a deeper analysis of experimental results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an in-depth exploration of the reasons for the experimental results. While the comment identifies a potential issue with the lack of new evaluation metrics, it does not provide specific examples or references to support this claim. Additionally, the suggestion for a deeper analysis of the experimental results is vague and lacks detailed guidance. Therefore, the comment is somewhat verifiable, as it provides some justification but lacks sufficient detail and examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper. First, it points out that no new evaluation metrics are proposed, and only existing metrics are linearly combined. This is a critical observation as it highlights a potential limitation in the paper's methodology. Second, it suggests that the experimental analysis section lacks an in-depth exploration of the reasons behind the experimental results. This feedback is actionable as it prompts the authors to consider proposing new evaluation metrics and to provide a more detailed analysis of their experimental findings. However, the comment could be more helpful if it provided specific examples or suggestions for new evaluation metrics or ways to enhance the experimental analysis. Overall, the comment is mostly helpful as it directs the authors to areas that need improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the notation \"K\" being used for both a known kernel function and the number of layers. However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit, as the authors need to infer that they should clarify or change the notation to avoid confusion. The comment lacks concrete details on how to implement the change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L166 and L176) where the notation \"K\" is used for different purposes, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that \"K\" is used for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to improve the clarity and consistency of the notation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation \"K\" is abused by being used for both a known kernel function and the number of layers. This claim is supported by specific line references (L166 and L176), which provide evidence of the notation\\'s misuse. The mention of specific lines allows the authors to verify the claim and understand the context of the notation\\'s use. Therefore, the comment is fully verifiable, as it provides clear and direct evidence to support the claim.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K\" being used for both a known kernel function and the number of layers. This feedback is clear and actionable, as it directs the authors to clarify or change the notation to avoid confusion. By pointing out this inconsistency, the comment helps the authors improve the clarity and consistency of their notation, which is crucial for the reader\\'s understanding. However, the comment could be more helpful if it suggested alternative notations or provided examples of how to resolve the issue. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\\' statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison. However, it does not explicitly instruct the authors to make these clarifications or provide specific guidance on how to incorporate additional citations. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' statement about the problem being fairly reductionist and the reference to \"Perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition and suggests that the authors need to clarify their claim and provide more citations for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of connections to human cognition in the context of the paper, specifically the statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR. The reviewer challenges the authors\\' claim by pointing out that the problem is described as fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that it would be surprising if a behavioral economist studying this problem would ignore these aspects and requests more citation for comparison. While the comment provides some logical reasoning and references to the authors\\' own statements, it lacks specific examples or detailed references to support the claim fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the relevance of connections to human cognition in the context of the paper. It questions the authors\\' statement that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation, which humans use. The comment suggests that the authors need to clarify their claim and provide more citations for comparison against \"previously appreciated\" effects. This feedback is somewhat helpful as it identifies a potential confusion in the paper and prompts the authors to clarify their argument. However, it could be more helpful if it provided specific suggestions on how to address the issue or offered examples of relevant literature for comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies an issue with the wording in the conclusion, specifically mentioning that it is \"overly exaggerated\" and \"flamboyant.\" The reviewer suggests that the word choice is too elaborate, providing a clear action for the authors to take: to tone down the language in the conclusion. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be changed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with the wording being \"overly exaggerated\" and \"flamboyant,\" providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant.\" However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues with the language. Without detailed evidence or examples, the claim remains vague and lacks sufficient justification, rendering it barely verifiable. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the conclusion, noting that the wording is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it directs the authors to tone down their language to make it more appropriate for academic writing. However, the comment could be more helpful if it provided specific examples of where the language is overly dramatic or suggested alternative phrasing. Despite this, the feedback is still valuable as it highlights a critical aspect of the paper that needs attention. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, along with specific criteria for the experiments. The comment is highly actionable because it specifies exactly what needs to be done and how to implement the suggested action, leaving no ambiguity for the authors. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion should be implemented in, nor does it provide details on how to conduct these experiments or what specific aspects need to be addressed. The authors can infer that this relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper by comparing the proposed method with existing ones. However, the comment lacks specific examples or references to existing works that have conducted similar comparisons, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is valuable as it identifies a specific area for improvement and offers a concrete way for the authors to enhance the comprehensiveness and rigor of their study. However, the comment could be more helpful if it provided additional context or examples of how these experiments might be conducted or what specific insights they could offer. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific information should be included or how to present it. Therefore, the comment is somewhat actionable, as it points out areas for clarification but does not fully direct the authors on how to improve their draft.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also requests clarification on how the embeddings are combined and fed into the CSCM. The comment is fully grounded as it explicitly mentions the need for clarification on the combination of embeddings and their input into the CSCM, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be clarified, providing clear guidance on how to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It also requests clarification on how embeddings are combined and fed into the CSCM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, particularly in the context of differences in sequence lengths. It highlights the need for clarification on how embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations on this aspect of their methodology. By addressing this point, the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of how similar issues have been addressed in other works. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed in the paper, and their values are not specified. This provides a clear and direct action for the authors to take: they should discuss the sensitivity of these hyper-parameters and specify their values in the paper. The comment is explicit and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion of the sensitivity of these hyper-parameters and the lack of specified values. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed in the paper. This is a factual statement that can be verified by checking the paper for any discussion or analysis of these hyper-parameters. The comment does not provide additional reasoning or evidence beyond the statement, but it is clear and straightforward, making it mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$. It highlights that their values are not specified in the paper, which is a critical aspect of experimental methodology. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors enhance the rigor and transparency of their work. However, the comment could be more helpful if it suggested ways to address this issue, such as recommending specific methods for sensitivity analysis or providing examples of how to present the results. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the lack of perturbation noise in selecting positive samples, which could impact generalization performance. The reviewer suggests conducting more experiments on different downstream tasks and across various domains to address these concerns. While the comment identifies specific areas for further investigation, it does not provide explicit instructions on how to conduct these experiments or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the similarity-aware positive sample selection and its potential impact on GNN-based encoder over-smoothing and generalization performance. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the concerns about over-smoothing and generalization performance, suggesting additional experiments on different downstream tasks and across various domains. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection and the lack of perturbation noise in selecting positive samples. The reviewer suggests that this could lead to lower generalization performance and proposes additional experiments on different downstream tasks and across various domains to address these concerns. However, the comment does not provide specific evidence, examples, or references to support the claim that the current experiments do not alleviate the concerns. The reasoning is logical but lacks detailed justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the potential over-smoothing of GNN-based encoders due to similarity-aware positive sample selection, which could lead to the loss of unique features and impact generalization performance. It also questions the lack of perturbation noise in selecting positive samples, suggesting that this might further compromise generalization. The reviewer acknowledges that the authors have experimented with transfer performance on a graph classification task but expresses concerns that these experiments do not fully address the issues. The comment provides a clear direction for further experimentation, suggesting additional tests on different downstream tasks and across various domains. This feedback is mostly helpful as it identifies specific areas for improvement and offers actionable suggestions for enhancing the robustness and generalization of the model. However, it could be more helpful if it included specific examples or detailed guidance on how to conduct these additional experiments. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether fast SMP is less expressive than SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide guidance on how to address the question or what specific aspects of the discussion should be expanded upon. The authors cannot confidently determine which part of the paper this comment addresses, and it lacks specificity regarding what needs to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or justify the need for additional discussion. Without specific examples or context, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the expressiveness of 'fast SMP' compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded upon. The comment does not offer detailed suggestions or examples, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide explicit guidance on how the authors should address this issue or what specific information should be added to clarify these aspects. The action is implicit, as the authors can infer that they need to provide more details, but it is vague because it lacks concrete steps or suggestions on how to improve the clarity. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. Without explicit references or clear indications of where the issue lies, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or how the authors should address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the types of situations or social norms discussed in the main paper are not clear, specifically mentioning physical and psychological safety. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, specifically mentioning physical and psychological safety. However, it does not provide any suggestions or guidance on how the authors might address this issue or clarify these aspects in their paper. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the inclusion of more baselines and domains to be tested, as well as stronger empirical results with different design choices. It also asks for stronger motivation for the current choices of weighting and learning density functions. This feedback provides clear and specific actions for the authors to take, such as conducting additional experiments and providing more detailed justification for their methods. The explicit nature of the request and the concrete suggestions make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for more baselines and domains to be tested, as well as stronger empirical results with different design choices. It also addresses the lack of motivation for the current choices of weighting and learning density functions. This provides clear guidance on what needs to be addressed, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks sufficient baselines and domains for comparison, and that the choices of weighting and learning density functions are not strongly motivated. The reviewer requests stronger empirical results with different design choices and more domains. While the comment highlights areas for improvement, it does not provide specific examples or references to support the claim that the current choices are inadequate. This makes the claim somewhat verifiable, as the authors would need to infer the specific issues and address them based on the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the need for more baselines to be compared and more domains to be tested. It also points out that the choices of weighting and the way of learning density functions are not strongly motivated, prompting the authors to provide stronger empirical results. This feedback is clear and actionable, as it specifies what the authors need to do to enhance the robustness and validity of their work. However, the comment could be more helpful if it provided specific suggestions or examples of additional baselines or domains that could be considered. Overall, the comment is mostly helpful, as it directs the authors toward meaningful improvements but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be revised. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not specify which results or sections of the paper are being referred to, making it difficult for the authors to identify the exact parts that need attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance or references to specific sections, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results are not comparable to existing methods, implying a lack of significance for the proposed methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing work, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying a lack of significance. However, it does not provide any specific guidance or suggestions on how the authors might improve the comparability of their results or enhance the significance of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is not helpful at all, as it lacks depth and does not offer any constructive suggestions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It notes that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering with different datasets and backbones. The comment also mentions proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies areas where the paper could be improved, it does not provide explicit guidance on how the authors should address these issues or what specific insights are needed to enhance the paper. The action is implicit and somewhat vague, as the authors are left to infer what changes are necessary without clear instructions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It mentions the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones, and notes the proposed modifications like different penalty coefficients for users and items. However, the comment lacks specific references to sections or parts of the paper where these issues are discussed, making it weakly grounded. The comment is specific in identifying the lack of insights into the unique challenges of overcorrelation in recommender systems, but without explicit references, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, suggesting it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. The reviewer provides some justification by mentioning the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim of limited novelty. While it highlights the modifications proposed, such as different penalty coefficients for users and items, it does not provide enough evidence or references to fully support the claim. Therefore, the comment is somewhat verifiable, as it provides some basis for the claim but requires more detailed justification or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a perceived lack of novelty in the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific domain. It highlights the contribution as mainly the transposition of DeCorr\\'s insights into graph collaborative filtering with different datasets and backbones. The comment also notes the proposed modifications, such as different penalty coefficients for users and items, but criticizes the paper for lacking insights into the unique challenges of overcorrelation in recommender systems. While the comment points out areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is somewhat helpful as it directs the authors to consider the novelty and depth of their contribution, but it lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, specifically the assumption that the spectrum of a kernel is sub-gaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion on how to address this limitation or whether it should be explored further. The comment lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitation of the obtained results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, whose spectrum decays polynomially. However, the comment does not specify which part of the paper discusses these assumptions or limitations, making it weakly grounded. The comment is specific in detailing the issue with the assumption and the implications for the results, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is sub-gaussian, which is acceptable for Gaussian kernels but not for other classes like Matern kernels. The reviewer provides a logical explanation by contrasting the behavior of Gaussian and Matern kernels, which supports the claim. However, the comment could be strengthened by providing specific examples or references to studies that have explored the implications of this assumption. Overall, the claim is mostly verifiable, as it offers a clear rationale but lacks detailed examples or references to fully substantiate the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that the assumption of a sub-gaussian spectrum for kernels is restrictive, as it excludes other popular classes like Matern kernels. This feedback is somewhat helpful as it highlights an area where the results might be limited, prompting the authors to consider broader applicability or discuss the implications of this assumption. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand their analysis to include other kernel types. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should consider incorporating a gender detection model into their pipeline, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is somewhat actionable, as it highlights a potential issue but does not provide detailed instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of ELM choice and its implications, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. The comment provides a logical reasoning for the potential drawback of the current approach, which is mostly verifiable. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, especially when vocal traits match speaker identity. This feedback is clear and highlights a potential drawback in the current approach, providing the authors with a specific area to consider for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as proposing methods for integrating gender detection models or discussing potential implications. Overall, the comment is mostly helpful as it identifies a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to a reference [31]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived lack of technical substance or suggestions for enhancing the paper. Without actionable advice or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, it does not specify which part of the paper this claim is based on, such as a particular section or methodology. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the paper are considered incremental or lacking in substance, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment claims that the paper is incremental and lacks technical substance, primarily consisting of adding a new loss to reference [31]. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions for improvement. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the perceived issues. The comment lacks depth and does not provide any constructive advice, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\\'s ability to capture these phenomena. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the empirical evidence or what specific aspects of the model should be tested. The action is implicit and somewhat vague, as the authors need to infer that they should conduct empirical studies to support the model\\'s applicability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the model to real-world diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, it does not specify which part of the paper discusses the model\\'s applicability or where the empirical evidence should be included. The authors can make an educated guess that it relates to the results or discussion sections, but the comment lacks full grounding. It is specific in suggesting the need for empirical evidence, but without explicit references to specific sections, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors provide empirical evidence to support this claim. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate why the current evidence is insufficient or how the proposed model might not capture real-world diffusion phenomena. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and address them in their response. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the proposed model to real-world diffusion processes. It acknowledges the interest and elegance of the problem but emphasizes the need for empirical evidence to demonstrate the model\\'s ability to capture real-world diffusion phenomena. This feedback is clear and actionable, as it directs the authors to provide empirical evidence to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on how to conduct these empirical studies or what aspects of the model should be tested. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This feedback is clear and direct, providing a concrete action for the authors to take. The suggestion is specific and actionable, as it outlines exactly what needs to be done to enhance the clarity and understanding of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the method\" and \"each layer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, providing a plot of how different weights of the model move after unlearning, and which layers are affected the most. This level of detail provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot to illustrate how different weights of the model change after unlearning, specifically focusing on which layers are affected the most. This suggestion is based on a logical reasoning that providing such a plot would enhance the understanding of the method\\'s impact on different layers. However, the comment does not provide specific examples or references to support the claim that this information is crucial or missing. Therefore, the claim is somewhat verifiable, as it lacks detailed justification or evidence to fully substantiate the need for the suggested plot.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot to illustrate how different weights of the model change after unlearning, focusing on which layers are affected the most. This feedback is clear and constructive, offering a concrete way for the authors to enhance the clarity and understanding of their results. By suggesting a visual representation of the weight changes, the comment helps the authors to better communicate the impact of their method on different layers, which is a valuable contribution to the paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or how they could enhance their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper from a methodology perspective, specifically mentioning that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue with the novelty of the paper, but without clear grounding, the authors may struggle to identify the exact parts that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. This claim is somewhat verifiable as it provides a reference to support the assertion about the ENCODE part. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the decomposition part being the only incremental contribution. The authors would need to delve deeper into the paper to understand the significance of this contribution, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in reference [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential weakness in the paper\\'s originality, it does not provide any actionable suggestions or guidance on how the authors might address this issue or enhance their contribution. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but lacks depth and actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues with the presentation: it is too equation-driven and the notation is convoluted, particularly in Chapter 3. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful. While the comment explicitly suggests adding a figure, it does not provide specific guidance on how to create an effective illustration or which key concepts should be included. The action is explicit but somewhat vague, as the authors know they need to add a figure but may not be entirely sure of the specifics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"chapter 3\" and \"section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the presentation being too equation-driven and the notation being convoluted, suggesting that an illustrative figure of the key concepts would be helpful. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation, particularly in Chapter 3, is convoluted and hard to follow. The suggestion to include an illustrative figure of key concepts in Section 3 is a logical way to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim about the equation-driven nature of the presentation or the complexity of the notation. This makes the claim somewhat verifiable, as the authors would need to infer the specific issues and how to address them based on the general feedback provided.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the presentation: it is too equation-driven and the notation, particularly in Chapter 3, is convoluted and hard to follow. The reviewer suggests that an illustrative figure of the key concepts in Section 3 would be helpful in improving clarity. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the readability and comprehensibility of the paper. By addressing these issues, the authors can significantly improve the accessibility and effectiveness of their presentation. Therefore, the comment is mostly helpful, as it offers specific guidance for improvement while being comprehensive in its suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the visual presentation of Figure 3, particularly the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide specific guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the visual presentation, but without concrete suggestions, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the visual presentation, specifically suggesting enhancements for better readability and aesthetic appeal, such as improving the subscripts. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the visual presentation of Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific examples or reasoning to support why this enhancement is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the visual presentation of Figure 3, suggesting that the subscripts could be enhanced for better readability and aesthetic appeal. While the comment highlights a potential issue, it lacks detailed guidance or suggestions on how to achieve this enhancement. Providing specific examples or recommendations would have made the feedback more actionable and helpful for the authors. As it stands, the comment offers a general direction but does not fully support the authors in making the necessary improvements. Therefore, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the differences between the two normalization methods. Without actionable suggestions or specific instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Batch Normalization\" and \"Online Normalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. The comment raises a question about the difference between the two normalization methods, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the claim or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the perceived bias in Batch Normalization and the claimed unbiased nature of Online Normalization. It highlights a potential confusion in the paper regarding the estimation of the real gradient distribution. However, the comment does not provide any specific suggestions or guidance on how the authors might clarify this point or address the confusion. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, which is a violation of the 9-page paper limit. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the formatting to meet the page limit. The comment lacks concrete details on what specific changes should be made to rectify the problem, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of reduced whitespace throughout the paper, including crammed equations and captions too close to figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9-page paper limit due to the formatting issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, which is a violation of the 9-page paper limit. However, the comment does not provide any evidence or reasoning to support this claim, such as specific examples of where the whitespace has been reduced or how it affects the page count. Without such details, the claim remains unverifiable, as the authors may not be able to understand or address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in crammed equations and captions that are too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the 9-page paper limit. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to improve the layout or suggesting alternative formatting options. Despite this, the comment effectively points out a critical area for improvement, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technical details and formulations in the paper are limited and that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion to clarify or expand on the novelty of the scheme or procedure. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited and that the main novelty lies in the scheme or procedure. However, it does not specify which part of the paper these limitations are observed in, nor does it provide details on what specific aspects of the technical details or formulations are lacking. This makes it difficult for the authors to pinpoint the exact areas that need improvement. The comment lacks both grounding and specificity, leaving the authors without clear guidance on how to address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"technical details and formulations are limited\" and suggests that the main novelty lies in the scheme or procedure. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance the technical details or clarify the novelty. Without actionable feedback or detailed advice, the authors are left without a clear path to address the identified issue. As a result, the comment is barely helpful, as it highlights a potential area for improvement but lacks the depth and specificity needed to guide the authors effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The comment implies that the authors should reconsider their claims or explore alternative methods, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not provide a clear path for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in Table 3, questioning the claim of better results and suggesting that the proposed constrained method may actually yield lower validity and diversity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion of better results in the Molecule generation experiment is incorrect, as the proposed constrained method actually yields lower validity and diversity. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the claim of better results in the Molecule generation experiment, suggesting that the proposed constrained method may actually yield lower validity and diversity. This feedback is somewhat helpful as it points out a potential issue with the paper\\'s claims, prompting the authors to reconsider their results and possibly revise their conclusions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. To be more helpful, the comment could include recommendations for alternative approaches or further analysis to validate the claims. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not specify what aspects of the environment should be described or how detailed the description should be. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting where the additional information could be included, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks a detailed description of the Starcraft environment, implying that this is a necessary addition. However, the comment does not provide specific examples or reasoning to support why this description is crucial or how it would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the paper could benefit from a more detailed description of the Starcraft environment. While it implies that this information could be included in an appendix, it does not provide specific guidance on what aspects of the environment should be described or how this would enhance the paper. The comment identifies a potential area for improvement but lacks depth and actionable suggestions, making it somewhat helpful. The authors are given a general direction but no detailed guidance on how to address the issue, limiting the comment's usefulness.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include a discussion on the prompt dataset creation and its source for the few-shot case. This is a clear and direct action for the authors to take, providing them with a specific area to address in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the prompt dataset creation and its source for the few-shot case should be included. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a discussion on the prompt dataset, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the prompt dataset creation and its source for the few-shot case should be included. However, it does not provide any reasoning, evidence, or examples to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source for the few-shot case. This is a clear and actionable suggestion that can help improve the paper by providing additional context and information about the dataset used in the study. However, the comment could be more helpful if it offered specific guidance on what aspects of the dataset creation should be discussed or how this discussion could be integrated into the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or address the perceived incremental nature of the work. Without explicit or implicit actions, the authors are left without a clear understanding of what changes they should make to their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the motivation of the paper and suggests that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is causing this difficulty or provide any details on what aspects of the motivation are unclear. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is \"very difficult to follow the motivation of this paper\" and suggests that it appears to be an incremental engineering paper. However, the comment lacks any supporting evidence, reasoning, or examples to justify why the motivation is difficult to follow or why it seems incremental. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might clarify the motivation or address the perceived incremental nature of the work. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, as it lacks the necessary depth and specificity to guide the authors in enhancing their paper.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study on the weighting method of the cross-entropy loss. It provides a specific example from the paper where the authors mention that their method underperforms in a particular scenario, suggesting that weighting might have helped improve performance. This feedback is explicit and concrete, as it clearly instructs the authors to conduct an ablation study on the weighting method and provides a rationale for why it could be beneficial. The authors know exactly what action to take and how to apply it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an ablation study on the weighting method of the cross-entropy loss and references a specific scenario mentioned in the paper where the authors note that their method underperforms due to \"repetitive background sounds\" in the Atlantis game. This provides a clear direction for the authors to consider and addresses a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion is based on, making it weakly grounded. The comment is specific in suggesting an ablation study and providing a rationale for why it could be beneficial. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an ablation study on the weighting method of the cross-entropy loss, citing a specific scenario where the authors mention underperformance due to \"repetitive background sounds\" in the Atlantis game. The reviewer implies that weighting might have helped remedy this issue, providing a logical reasoning for the suggestion. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the potential benefits of the ablation study based on the provided rationale. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting an ablation study on the weighting method of the cross-entropy loss, which could provide valuable insights into the performance of the method. It references a specific scenario mentioned in the paper where the authors note that their method underperforms due to \"repetitive background sounds\" in the Atlantis game, suggesting that weighting might have helped remedy this issue. This feedback is clear and actionable, as it identifies a potential area for improvement and provides a rationale for why it could be beneficial. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or incremental nature of the work, or how to enhance the dataset or benchmark. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it references another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the lack of novelty and incremental nature of the work, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature. It provides specific details about the work, such as addressing a particular problem of column operations in designing semantic parsers for Text-to-SQL and the use of a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. This level of detail provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to specific studies or works that demonstrate the lack of novelty, which would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and notes that the new dataset is a different train/test split of an existing dataset, SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. This feedback is somewhat helpful as it points out a significant issue with the paper's originality and suggests that the authors should consider how their work contributes to the existing literature. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Therefore, it is rated as somewhat helpful, as it provides insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be conducted on more than one game environment, implying that the authors should expand their experimental scope. However, the comment does not provide specific guidance on which additional game environments should be considered or how to conduct these experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be conducted on more than one game environment, implying that the current scope is limited. However, it does not specify which part of the paper this issue pertains to, such as the experimental section or results. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify the exact area needing revision. Additionally, the comment lacks specificity regarding which additional game environments should be considered or how the experiments should be expanded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment lacks specific reasoning or evidence to support why additional game environments are needed or how this would improve the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental scope, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point for improvement. However, the comment lacks specificity and does not provide guidance on which additional game environments should be considered or how the experiments should be expanded. This makes it somewhat helpful, as it points out a potential area for improvement but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what they need to do to improve their draft, which is to provide examples to justify the importance of this contribution. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to explain the importance of removing certain assumptions, such as bounded variance and bounded gradients, by providing solid examples. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for examples to support the claim, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this removal is significant. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors need to provide more explanation and justification for their work. It points out the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that the authors should provide solid examples to support this claim. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it offered suggestions on how to present these examples or provided additional context for the authors to consider. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, such as optimizing the implementation or discussing potential reasons for the slow performance and low accuracy. Without any guidance or direction, the authors are left without a clear understanding of how to address this issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim of implementing ImageNet for the first time, noting that it is slow and has low accuracy. It provides specific details about the time it takes to test an ImageNet picture using AlexNet and ResNet-18, as well as the accuracy achieved. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the implementation and the results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the implementation of ImageNet is slow and has low accuracy, citing specific times and accuracy rates. However, the comment does not provide any supporting evidence, such as comparisons with other methods or references to similar studies, to substantiate these claims. Without additional context or references, the authors may find it challenging to understand the basis of the critique or to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time it takes to test an ImageNet picture using AlexNet and ResNet-18, as well as the accuracy achieved. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve their implementation. While it highlights a problem, it lacks actionable feedback or constructive advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. While the comment implies that the authors should consider using labeled data for consistency training, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the potential benefit and the references provided, but it lacks direct action or detailed guidance on how to implement this suggestion. Therefore, the comment is mostly actionable, as it provides a clear direction for the authors to consider but requires them to infer the specific steps to take.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. However, the comment does not explicitly mention a specific part of the paper, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in suggesting the use of labeled data and referencing relevant literature, which provides a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefit of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, referencing specific papers for further exploration. The inclusion of references to \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation\" provides some support for the claim, as these papers are likely to discuss the use of labeled data in consistency training. However, the comment could be strengthened by providing more detailed reasoning or examples from these references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive evidence or detailed explanation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a thoughtful question about the potential benefits of using labeled data for consistency training in graph anomaly detection tasks. It suggests that labeled data could provide effective information for consistency training, which is a valuable insight for the authors to consider. The comment references specific papers, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide additional context and guidance for the authors. However, the comment could be more helpful if it provided a clearer explanation of how labeled data could be integrated into the consistency training process or offered specific suggestions for implementation. Despite this, the comment offers a valuable direction for the authors to explore, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model's performance is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a suggestion for theoretical justifications. While the comment implies that the authors should provide additional data and theoretical support, it does not explicitly instruct them to do so. The action is somewhat vague, as it does not specify exactly how the authors should report the classification accuracy or what kind of theoretical justifications are needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed classification network and expresses doubt about its classification error compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and requests theoretical justifications for the issue. However, the comment does not specify which part of the paper discusses the proposed network or where the classification accuracy should be reported. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting what needs to be addressed, such as reporting classification accuracy and providing theoretical justifications. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and requests theoretical justifications. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the proposed network might lose classification accuracy. The request for theoretical justifications is a reasonable suggestion, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, questioning whether the new model is universally better. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data, which is a specific and actionable request for additional data. Additionally, the comment requests theoretical justifications for the issue, which could provide deeper insight into the model\\'s performance. While the comment identifies a potential weakness and offers clear guidance, it could be more helpful by providing specific examples or references to support the claim. Overall, the comment is mostly helpful as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items are comprised of all items available in memory minus those seen. The reviewer questions how such an exhaustive list could be effectively implemented and tested with simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or suggestions for potential solutions, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to the recognition of lists and the implementation of recalling items based on these lists. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the feasibility of implementing an exhaustive list for recognition and testing with simulations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items are comprised of all items available in memory minus those seen. The reviewer questions how such an exhaustive list could be effectively implemented and tested with simulations. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. The reasoning is somewhat verifiable as it provides a clear explanation of the issue, but it could be strengthened with additional details or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the feasibility of implementing a system that recalls items based on lists, particularly in the context of recognition where new items are comprised of all items available in memory minus those seen. It questions how such an exhaustive list could be effectively implemented and tested with simulations. While the comment identifies a potential issue with the approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology. The feedback is somewhat helpful as it points out a weakness, but it does not provide actionable advice or detailed insights to help the authors improve their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information CD captures beyond Predictive Uncertainty. It also questions why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides specific areas for improvement, such as explaining the additional information CD captures and justifying the choice of measure. While the action is explicit, the comment could be more actionable by providing concrete examples or suggestions for alternative formulations. Overall, the comment is mostly actionable as it clearly identifies areas for improvement and provides a direction for the authors to follow.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 115\" and \"line 113,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to describe alternate formulations for Confidence Diversity (CD) and to clarify why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should describe alternate formulations for Confidence Diversity (CD) and questions the choice of entropy as a measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current formulation and suggesting an alternative perspective. However, it lacks specific examples or references to support the claim that entropy is not a good measure, which would strengthen the argument. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It also questions the current formulation, specifically asking why entropy is not considered a good measure for the \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment highlights a potential gap in the paper's explanation and offers a clear direction for improvement by asking for clarification on the additional information CD captures beyond Predictive Uncertainty. This feedback is detailed and constructive, empowering the authors to enhance their draft by addressing these specific points. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the assumption for termination states of instructions being quite strong and notes that labeling a large number of data manually can be very expensive. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods for labeling data or proposing ways to reduce the expense. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment highlights the issue of labeling a large number of data manually being expensive, but it does not provide specific guidance or suggestions on how to address this concern. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is \"quite strong\" and notes that labeling a large number of data manually can be very expensive. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the strength of the assumption or the expense of manual labeling. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a concern about the assumption for termination states of instructions being quite strong, which can be expensive to label manually. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their work. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the paper regarding the contribution related to ECE_sweep. It explains that the contribution involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. The reviewer suggests that the paper should be more upfront about this contribution. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should rephrase or present their contribution. The action is implicit and somewhat vague, as the authors know they need to clarify the contribution but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the contribution, namely that it involves using data to choose the number of bins, which is a form of autotuning a hyperparameter in the estimate. The comment further suggests that this contribution is not fundamentally different and should be more clearly described. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the nature of the contribution related to ECE_sweep is not clearly described in the text. The reviewer provides a detailed explanation of the contribution, stating that it involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. This explanation is logical and provides a clear understanding of the issue. However, the comment could be strengthened by referencing specific sections of the paper where this description is lacking or by providing examples of how the contribution is not clearly communicated. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks specific references or examples to fully substantiate the critique. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the nature of the contribution related to ECE_sweep is not clearly described. It provides a detailed explanation of the contribution, which involves using data to choose the number of bins, effectively autotuning a hyperparameter in the estimate. The reviewer suggests that this is not fundamentally different and should be more clearly communicated upfront. This feedback is clear and actionable, as it directs the authors to clarify their contribution and its significance. However, the comment could be more helpful if it offered suggestions on how to present this information more effectively. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for improving the clarity and impact of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as Reinforcement Learning (RL) methods, but none of these methods are used as a baseline. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, how to incorporate them, or what specific aspects of the RL methods should be explored. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to address this observation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This provides clear guidance on what needs to be addressed in the related work section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s methodology. However, the comment lacks specific examples or references to the RL methods mentioned, which would strengthen the justification. Providing more detailed information or examples of these methods would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a gap in the related work section by noting that it discusses other methods for training NMT models beyond Maximum Likelihood Estimation (MLE), such as RL methods, but none of these methods are used as a baseline. This feedback is somewhat helpful as it identifies an area where the paper could be improved by incorporating additional baselines or methods for comparison. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or which specific methods could be considered as baselines. While it highlights an important area for improvement, the lack of detailed advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a confusion in the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" However, it does not provide explicit guidance or suggestions on how to clarify this ambiguity in the draft. The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" but it does not offer concrete steps for the authors to take to resolve this issue. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of ambiguity regarding whether the authors are referring to a particular efficient proxy or a general category of efficient proxies. This provides clear guidance on what needs to be clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the text regarding whether the authors are referring to a specific \"efficient proxy\" or a general category of \"efficient proxies.\" The comment points out the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy,\" which suggests that the authors may be referring to a family of efficient proxies. However, the comment does not provide additional context, examples, or references to support the claim or clarify the ambiguity. As a result, the claim is somewhat verifiable, as it highlights a potential issue but lacks detailed justification or evidence to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text regarding the reference to \"efficient proxy.\" It points out the ambiguity in whether the authors are referring to a particular proxy or a general category, noting the inconsistency in the use of \"is\" and the absence of a specific proxy called \"Efficient Proxy.\" This feedback is clear and actionable, as it prompts the authors to clarify their intention and ensure consistency in their terminology. However, the comment could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of how to clarify the text. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point describes a specific methodological approach used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Group-learning setting, followed by the use of DBSCAN for clustering. However, it does not provide any explicit or implicit suggestions for improvement or changes. The comment lacks actionable guidance, such as recommending alternative methods, explaining the rationale behind the chosen approach, or suggesting how to enhance the clustering process. Without any direction or specific advice, the authors are left without a clear understanding of what they should do to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020, and the Group-learning setting, followed by the use of DBSCAN for clustering. This allows the authors to accurately identify the specific part of the paper being addressed. The comment is also specific because it details the methodological approach used, providing clear information about the methods and techniques employed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes a specific methodological approach used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Group-learning setting, followed by the use of DBSCAN for clustering. However, it does not provide any claims, opinions, or suggestions that require verification. It is purely descriptive, making it a factual statement without any subjective elements. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual description of the methodological approach used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020, and the Group-learning setting, followed by the use of DBSCAN for clustering. However, it lacks any analysis, critique, or suggestions for improvement. Without any actionable feedback or guidance, the authors are left without a clear understanding of how to enhance their work or address potential weaknesses. Therefore, the comment is not helpful at all, as it does not provide any value to the authors in terms of improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this analysis or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of different projection matrices on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an investigation into the resilience of the metric, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the variability in results due to the choice of random projection matrix and suggests that the authors should investigate the resilience of the metric to different projection matrices. The reviewer acknowledges that pathological projection matrices could skew the MFTMA capacity and width scores, but notes that this is unlikely with random projections. The comment provides a logical reasoning for the concern and suggests a potential area for further investigation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this suggestion to fully address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the variability in results due to the choice of random projection matrix. It suggests that the authors should investigate the resilience of the metric to different projection matrices, which is a reasonable and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Additionally, the mention of \"pathological projection matrices\" adds a layer of complexity that could be clarified further. Overall, the comment identifies a potential issue and offers a direction for improvement, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This implies that the authors should expand the evaluation of FGT to include its use in comparing the proposed method with other methods. However, the comment does not provide specific guidance on how to implement this change or which aspects of FGT should be evaluated. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take and may not fully understand the scope of the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This claim is somewhat verifiable as it provides a logical reasoning for the evaluation process. However, it lacks specific examples or references to support why this change is necessary or how it would improve the evaluation. The comment could be strengthened by providing more detailed justification or examples, making it mostly verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of FGT, noting that it is only used in the ablation study and suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation methodology. By addressing this point, the authors can enhance the comprehensiveness and rigor of their evaluation, which is crucial for a robust assessment of their method. However, the comment could be more helpful if it offered additional guidance on how to implement this change or suggested specific metrics or analyses to include. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their evaluation process.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model appears overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the model should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model is overly simple, both a feature and a bug. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the model are considered simple or how this simplicity affects the model. Without explicit references to sections, figures, or specific elements of the model, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model is \"overly simple,\" both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to what aspects of the model are considered overly simple, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what changes could be made to enhance their work. As a result, the comment is not helpful at all, as it lacks the necessary depth and direction to assist the authors in improving their draft.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winner-take-all property, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the novelty of their work. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions would be necessary to enhance the originality of their paper. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the paper\\'s contribution to the understanding of the winner-take-all property, questioning the novelty of the findings given the simplified settings and the fact that most findings have been reported in previous works. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks novelty in its understanding of the winner-take-all property, particularly given its simplified settings and the fact that most findings have been reported in previous works. The reviewer supports this claim by referencing previous works that have used the winner-take-all property, such as NN-based clustering algorithms. However, the comment could be strengthened by providing specific examples or references to the previous works that have reported similar findings, which would enhance the verifiability of the claim. As it stands, the comment is mostly verifiable, as it provides a logical reasoning and some supporting evidence, but it lacks detailed references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novel insights to the understanding of the winner-take-all property, given its simplified settings and the fact that most findings have been reported in previous works. This feedback is somewhat helpful as it identifies a potential weakness in the paper\\'s contribution, prompting the authors to consider how their work differs from existing literature. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their findings. To be more helpful, the comment could include recommendations for additional experiments, comparisons, or analyses that could strengthen the paper\\'s originality. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of run-times in the experiments to aid readers who might apply the method. This feedback is explicit and provides concrete actions for the authors to take, such as including a brief mention of computational cost and providing examples of run-times. The suggestions are clear and actionable, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only discussed in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of run-times in the experiments to aid readers who might apply the method. The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely, the inclusion of computational cost information and examples of run-times. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that mentioning the negligible computational cost of CHR in the main paper could help motivate the method. It also recommends providing a rough example of run-times in the experiments to aid readers. However, the comment does not provide specific examples or detailed reasoning to support why this information is crucial or how it would enhance the paper. The suggestion is logical but lacks concrete evidence or references to substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion to enhance the paper by recommending that the authors mention the negligible computational cost of CHR in the main paper. This would help motivate the method and provide readers with a clearer understanding of its practical implications. Additionally, the comment suggests including a rough example of run-times in the experiments to aid readers who might apply the method. This feedback is clear and actionable, offering specific guidance on how to improve the paper by providing additional context and examples. However, the comment could be more helpful if it included a rationale for why this information is important or how it would impact the reader\\'s understanding. Overall, the comment is mostly helpful as it provides valuable suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also provides a concrete action by recommending testing on a smaller subset of RepoEval and comparing with state-of-the-art code completion systems. This feedback is clear and provides specific guidance on what the authors need to do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing on a smaller subset of RepoEval and comparing with state-of-the-art code completion systems. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or results section where baselines are discussed. The authors can infer that this comment relates to the evaluation or comparison section. The comment is specific in suggesting the inclusion of Copilot and the importance of comparing with state-of-the-art systems. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The suggestion is based on the importance of comparing with state-of-the-art code completion systems, which is a logical and reasonable claim. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or that it is essential to compare with it. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting the inclusion of additional baselines for code completion tasks. It specifically recommends comparing with existing commercial applications like Copilot, which is a state-of-the-art code completion system. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the comprehensiveness and validity of their evaluation. By including these baselines, the authors can better position their work in the context of current commercial applications, making the comment highly helpful. However, the comment could be further improved by providing more detailed guidance on how to implement this suggestion or what specific aspects of Copilot should be compared. Overall, the comment is highly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on their selection criteria and potentially explore other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context and potentially conduct further evaluations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses the evaluation on MTEB, making it weakly grounded. The comment is specific in its request for clarification on the selection criteria and the potential for different insights from other tasks or datasets. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. The comment provides a logical reasoning for the concern about generalizability, but it lacks specific examples or references to support the claim. While the authors are directed to consider alternative datasets, the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the claim is somewhat verifiable, as it provides a basis for the concern but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the results due to the evaluation on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and potentially expand their evaluation to other datasets, which could enhance the robustness and applicability of their findings. However, the comment could be more helpful if it provided specific examples of alternative datasets or tasks that the authors might consider. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2), and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. While the comment implies that the authors should provide additional information or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question and provide the requested information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"shifted-MNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why shift=0 is better than shift~N(0,\u03c3^2) and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2), and suggests showing the performance of the model and baselines on test samples from the observational (in)distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why shift=0 is better or why this comparison is relevant. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the performance of the shifted-MNIST dataset, specifically why shift=0 is better than shift~N(0,\u03c3^2). It also suggests that it would be useful to show the performance of the model and baselines on test samples from the observational (in)distribution. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper and provides a suggestion for additional analysis. However, the comment could be more helpful if it offered specific guidance on how to address the question or provided examples of how to present the performance on test samples. Overall, the comment provides some direction for improvement but lacks depth and actionable details, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not provide specific guidance on what aspects of the experiment description need more detail or how the authors might improve the clarity. The comment refers to \"Questions\" for further details, but without elaboration, the authors are left without concrete steps to take. This makes the comment somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of detail in the experiment description, suggesting that it would benefit from increased clarity to allow readers to better understand the results. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its suggestion that the description of experimental details needs improvement, but without explicit references to specific sections or elements, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiment description lacks detail, making it difficult for readers to judge the results. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or suggestions for improvement. The comment refers to \"Questions\" for further details, but without elaboration, it remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experiment description, noting that it lacks detail, which makes it difficult for readers to understand the results. This is a critical observation that could impact the clarity and comprehensibility of the paper. However, the comment does not provide specific suggestions or guidance on how to improve the experiment description, such as what details should be included or how to present them in a more clear manner. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a key issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more explanation to clarify the expected outcomes, particularly regarding the optimization strategies and their results. It explicitly mentions the need for a discussion on the effects of minimizing both inter and intra terms in Eq 3 or only the first term. This feedback is clear and provides specific guidance on what the authors should address in their paper. The action is explicit and concrete, as it directs the authors to include a detailed discussion on the optimization strategies and their outcomes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing more explanation to clarify the expected outcomes, particularly regarding the optimization strategies and their results. The comment suggests discussing the effects of minimizing both inter and intra terms in Eq 3 or only the first term, offering concrete guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanation to clarify the expected outcomes, particularly regarding the optimization strategies and their results. It questions what would happen by minimizing both inter and intra terms in Eq 3 or only the first term. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the paper lacks sufficient explanation. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected outcomes of their work. It highlights the importance of discussing the optimization strategies and their results, particularly in relation to Eq 3. The comment also provides a concrete example of what could be discussed, such as the effects of minimizing both inter and intra terms or only the first term. This feedback is clear and actionable, offering the authors a specific direction for enhancing the clarity and comprehensiveness of their paper. However, it could be more helpful if it included additional suggestions or examples to further guide the authors. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors include a formal or intuitive definition of treewidth, as it is central to all the proofs in the paper. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment specifies the need for a definition, which gives the authors a concrete step to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or chapter. This makes it difficult for the authors to pinpoint the exact location where the definition should be added. The comment is specific in its suggestion to include a definition, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. However, the comment does not provide any reasoning or evidence to support why this definition is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including a formal or intuitive definition of treewidth would be beneficial, as it is central to all the proofs in the paper. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the clarity and comprehensibility of the paper. By addressing this suggestion, the authors can ensure that their readers, particularly those unfamiliar with the concept of treewidth, have a better understanding of the theoretical foundations of their work. However, the comment could be more helpful if it offered additional guidance on how to present the definition or its implications. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper is not self-contained and requires the supplementary material to be fully understood, which is understandable given the NIPS format. It also emphasizes the importance of reproducibility and requests the authors to release the source code of their experiments. While the comment explicitly requests the release of the source code, it does not provide specific guidance on how to ensure reproducibility or what aspects of the code should be made available. The action is explicit but somewhat vague, as it lacks detailed instructions on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper not being self-contained, which is understandable given the NIPS format. It mentions the necessity of the supplementary material for understanding large parts of the main paper and ensuring reproducibility. The reviewer also requests the authors to release the source code of their experiments to allow reproduction of their results. However, the comment does not specify which parts of the paper are not self-contained or how the supplementary material could be improved to address this issue. While it provides a clear request for the release of source code, the lack of specific guidance on the content or structure of the supplementary material makes it weakly grounded and specific. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not self-contained, which is understandable given the NIPS format, but notes that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. The reviewer also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment provides a logical explanation for the need for supplementary material and source code release, it lacks specific examples or references to support the claim that the paper is not self-contained. This makes the claim somewhat verifiable, as it provides a general rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a significant issue with the paper's self-containment, noting that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. This feedback is clear and actionable, as it identifies a critical area for improvement and provides a specific request for the authors to enhance the paper's reproducibility. However, the comment could be more helpful if it offered suggestions on how to improve the self-containment of the main paper or provided guidance on what aspects of the supplementary material are most critical for understanding. Overall, the comment is mostly helpful as it directs the authors to address a key issue and enhance the paper's reproducibility, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of using multiple INs at different speeds in the dynamics predictor and suggests that the added complexity should be evaluated. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The comment implies that the authors should consider ablation studies to determine the impact of this design choice, but it does not specify how to conduct such studies or what metrics to use. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of multiple INs at different speeds in the dynamics predictor. It questions the importance of this design choice and suggests that the added complexity should be evaluated by considering whether one IN would suffice. However, the comment does not specify which part of the paper discusses this feature, making it weakly grounded. It is specific in detailing what needs to be addressed, namely the evaluation of the added complexity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the importance of using multiple INs at different speeds in the dynamics predictor and suggests that the added complexity should be evaluated. However, it does not provide any supporting evidence, reasoning, or references to justify why this aspect is crucial or how it impacts the model\\'s performance. The comment lacks specific examples or detailed analysis, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of using multiple INs at different speeds in the dynamics predictor. It points out that this design choice has not been ablated, which is a critical aspect of evaluating the significance of the added complexity. By asking whether one IN would suffice, the comment prompts the authors to consider the necessity of this feature and potentially conduct an ablation study to determine its impact. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the importance of this novel feature. Therefore, the comment is mostly helpful, as it offers a constructive suggestion for enhancing the paper\\'s clarity and rigor.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation regarding the experiments, noting that it is not surprising the opponent is outperformed in terms of the multi-agent payoff proposed by the authors. The comment explains that the opponent does not aim to maximize this payoff, instead focusing on classical SE and AE. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this observation. It lacks guidance on how the authors might address this issue or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by explaining that the opponent does not aim to maximize the multi-agent payoff proposed by the authors, instead focusing on classical SE and AE. This provides clear guidance on what needs to be addressed in the experiments. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is not surprising the opponent is outperformed in terms of the multi-agent payoff proposed by the authors, as the opponent does not aim to maximize this payoff. The comment provides a logical explanation by stating that the opponent maximizes classical SE and AE instead. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific observation about the experiments, noting that it is not surprising the opponent is outperformed in terms of the multi-agent payoff proposed by the authors. The comment explains that the opponent does not aim to maximize this payoff, instead focusing on classical SE and AE. While this feedback highlights a potential issue with the experimental setup, it does not offer actionable suggestions or guidance on how the authors might address this observation or improve their draft. The comment lacks depth and does not provide a clear path for the authors to enhance their work. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a description of why certain choices were made, specifically why the REINFORCE algorithm was chosen over PPO. It implies that the choice might be related to the attention model paper being iterated upon, but it does not explicitly state this connection. While the action is implicit, it is concrete in suggesting that the authors should provide a rationale for their choice of algorithm. This provides a clear direction for the authors to follow, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a description of why certain choices were made, specifically the choice of the REINFORCE algorithm over PPO. It implies that this choice might be related to the attention model paper being iterated upon, but it does not specify which part of the paper this choice is discussed in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. The comment is specific in suggesting that the authors should provide a rationale for their choice of algorithm, but it is not fully grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over PPO, implying that this choice might be related to the attention model paper being iterated upon. However, the comment does not provide specific evidence or references to support why this choice was made or how it relates to the attention model paper. The suggestion is logical but lacks detailed justification or examples, making it somewhat verifiable. The authors would need to infer the reasoning behind the choice and provide additional context to fully understand and address the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over PPO. This is a clear and actionable suggestion that can help the authors improve their draft by explaining the reasoning behind their methodological decisions. By addressing this point, the authors can enhance the transparency and clarity of their work, making it more understandable for readers. However, the comment could be more helpful if it provided specific examples or references to support why the choice of REINFORCE might be relevant in the context of the attention model paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to clarify or address the confusion, making it unactionable. The authors are left without a clear understanding of what steps to take to improve their draft based on this feedback.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion regarding the statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a specific statement in Theorem 5.1, suggesting that it might imply a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance regularized problem. While the comment identifies a potential issue, it lacks depth and does not provide any actionable suggestions or guidance on how the authors might clarify or address this confusion. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area of confusion but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, which is crucial for task domain adaptation. While the comment highlights an important area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more detailed information on this aspect, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a gap in the paper but does not offer specific guidance on how to fill it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. It questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what needs to be addressed, namely the need for more information on domain adaptation and morphologic segmentation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of information on how to apply morphologic segmentation across different domains and whether it should be conducted differently for each domain. The reviewer questions the assumption of morphologic segmentation being invariant across domains, which is relevant to task domain adaptation. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of supporting evidence or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of this issue and how it relates to their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the application of morphologic segmentation across different domains. It questions whether morphologic segmentation should be conducted differently for various domains and highlights the importance of this consideration in the context of task domain adaptation. The comment points out that the paper assumes morphologic segmentation is invariant across domains, which is a critical oversight. By raising this issue, the comment provides the authors with a clear direction for improvement, encouraging them to address the lack of insight into domain adaptation and morphologic segmentation. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the feedback is mostly helpful as it directs the authors to a critical area needing further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment does not explicitly instruct the authors to make these clarifications, it implies that they should provide more detailed information to address the reviewer\\'s questions. The action is implicit but concrete, as the authors know exactly what information needs to be clarified. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without clear grounding, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the object detection based attention, specifically whether it is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the object detection based attention, specifically asking whether it is performed on the image or on a convolutional feature map. It also suggests clarifying whether rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper and prompts the authors to provide more clarity. However, it lacks depth and does not offer specific suggestions on how to address the issue or improve the clarity of the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing discussion about the Set Transformer and other related works that use summary tokens. It provides a specific reference to the Set Transformer paper, which gives the authors a clear action to take: they should include a discussion about this work and other related works in their paper. The comment is explicit and provides concrete guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a reference to the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a missing discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. By mentioning a specific reference (https://arxiv.org/abs/1810/00825), the comment provides a clear and actionable suggestion for the authors to include a discussion about these works. This feedback is valuable as it directs the authors to a relevant area that could enhance the comprehensiveness and depth of their paper. However, the comment could be more helpful if it offered additional context or suggestions on how to integrate this discussion into the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the acceleration of NTK convergence in the high-frequency range by Fourier features. It implies that the authors should provide an analysis or explanation of this aspect, as it is considered essential for the theoretical support of Fourier features. However, the comment does not explicitly instruct the authors to include this analysis or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the acceleration of NTK convergence in the high-frequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for analysis but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the acceleration of NTK convergence in the high-frequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. However, the comment does not provide any evidence, reasoning, or references to support the claim that Fourier features accelerate NTK convergence. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the acceleration of NTK convergence in the high-frequency range by Fourier features, suggesting that this is an essential theoretical support for the merits of Fourier features. While it identifies a potential gap in the analysis, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the analysis are missing. The comment lacks actionable feedback, leaving the authors with a general idea of what might be lacking but without a clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit guidance or suggestions on what the authors should do to address this issue. The comment implies that the authors should include more details about this process, but it lacks concrete instructions or examples on how to improve the draft. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the lack of details on how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the issue of fitting the residual, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the input-output mapping. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the network\\'s architecture, specifically the lack of details on how it fits the residual instead of directly learning the input-output mapping. This is a relevant observation that could help the authors clarify their methodology and improve the clarity of their paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional details could be included. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the experiment setup in Section 3.3, specifically requesting information about data augmentation methods and learning rates. This provides a clear and direct action for the authors to take, which is to provide detailed information about the experiment setup. The reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is likely intended to provide context or a relevant example, but it does not directly instruct the authors on how to address the request. Overall, the comment is explicit in its request for information but lacks detailed guidance on how to implement it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the experiment setup, including data augmentation methods and learning rates. The reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides additional context, but it is not directly related to the request for experiment setup details. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual question about the experiment setup in Section 3.3, along with a reference to a specific paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks.\" The inclusion of the reference provides context and supports the request for more information about the experiment setup. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that lacks clarity, namely the experiment setup in Section 3.3. By asking for details about data augmentation methods and learning rates, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is important for the reader to understand. Additionally, the reference to \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" could be more relevant if it were directly connected to the experiment setup being questioned. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not explicitly instruct the authors to perform such a test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider statistical significance but are not given specific instructions on how to implement this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what specific numbers are being referred to. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to consider a statistical significance test, but it lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. However, the comment does not provide any specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to justify the need for a statistical significance test. This lack of supporting information makes the claim difficult for the authors to address effectively, as they are left without clear guidance on how to evaluate the significance of the results. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the similarity of numbers when comparing the proposed method to baselines, suggesting that a statistical significance test might be necessary. This is a relevant point that could impact the interpretation of the results, and the suggestion to consider a statistical significance test is clear and actionable. However, the comment could be more helpful if it provided specific guidance on how to conduct such a test or what statistical methods might be appropriate. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that could enhance the rigor of their analysis. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. While the comment does not provide explicit instructions or suggestions for improvement, it implies that the authors should clarify this aspect of their work. The action is implicit, as the authors need to infer that they should address this gap in their paper. However, the comment is somewhat actionable because it provides a clear direction for the authors to explore and address in their draft. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for this clarification. It is a request for clarification rather than a claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the impact of non-parametric emission distributions on inference tasks in a discrete HMM, specifically asking which inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. This question highlights a potential gap in the paper\\'s explanation and suggests that the authors should clarify this aspect. By prompting the authors to address this issue, the comment provides a clear direction for improvement, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to address this gap or provided examples of inference tasks that might be affected. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, it does not explicitly instruct the authors to perform this analysis or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a deeper analysis but are not given specific steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT-3.5-turbo, suggesting that the authors should provide an analysis of the underlying reasons for this outcome. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of this analysis and how it could be improved. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the insufficient analysis of experimental results. It points out that the authors mention the poor performance of the scope prompting method on GPT-3.5-turbo but do not provide any analysis of the underlying reasons for this outcome. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of the experimental results to understand the reasons behind the observed performance. However, the comment could be more helpful if it suggested specific methods or approaches for conducting this analysis. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation for low-rank factorization in the introduction is unnecessary, given that the main result is about polytopes. It implies that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide specific guidance on how to incorporate these implications or where to discuss them in the paper. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of their results for low-rank matrix factorization, but they are not given explicit instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"motivation in the introduction\" and the \"main result,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation for low-rank factorization and suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the motivation for low-rank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer implies that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide specific examples or references to support the claim that the motivation is unnecessary or how the implications for low-rank matrix factorization should be discussed. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning and potential implications themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation presented in the introduction, suggesting that the focus on low-rank factorization may be unnecessary given the main result is about polytopes. It provides a clear and actionable suggestion to explicitly discuss any implications of the result for low-rank matrix factorization, if applicable. This feedback is valuable as it prompts the authors to clarify and potentially expand their discussion to better align with the main focus of their work. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion or provided examples of potential implications. Overall, the comment is mostly helpful, as it directs the authors to a relevant area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific method used to solve the min-min problem, asking which alternating direction method is employed. However, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable details, such as suggesting which methods should be considered or how to clarify this information in the paper. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the specific alternating direction method used to solve the min-min problem, but it does not specify which part of the paper this information is mentioned in. The authors may need to search the paper to identify the relevant section, making it weakly grounded. However, the comment is specific in its request for clarification about the method used. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the specific alternating direction method used to solve the min-min problem. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific alternating direction method used to solve the min-min problem, indicating a lack of clarity in the paper. While it identifies a potential area for improvement by pointing out the need for more detailed information, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment is somewhat helpful as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, making it incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived lack of novelty or suggest alternative approaches to enhance the novelty of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically mentioning the interpretation of deep neural networks using a linear model. However, it does not specify which part of the paper discusses this novelty or where the authors could improve it. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment lacks specificity as it does not provide detailed guidance on how to enhance the novelty or suggest alternative approaches. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically stating that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper, specifically noting that the novelty of the work is limited due to the use of a linear model for interpreting deep neural network predictions. However, the comment does not provide any actionable suggestions or guidance on how the authors might enhance the novelty of their work or address this critique. Without specific advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful at all, as it lacks actionable feedback.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to the experiments. The authors are left to infer that they need to expand their experiments and consider larger models or more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limitations of model size and restrictive baselines in both the language modeling and image classification tasks. However, it does not specify which parts of the paper these experiments are described in, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific in its critique of the experiments but lacks grounding, as it does not provide a clear reference to the sections or figures where these experiments are discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines in both the language modeling and image classification tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains somewhat verifiable, as it provides a general direction for improvement but lacks concrete support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the comprehensiveness and generality of the experiments, specifically noting that the model size is limited and the baselines are restrictive. This feedback is somewhat helpful as it points out an area for improvement, suggesting that the authors should consider expanding their experiments to include more comprehensive and general evaluations. However, the comment lacks specific guidance or suggestions on how to achieve this expansion, such as recommending additional models or baselines to include. While it provides a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML or implicit-MAML, to Table 1. While the comment implies that the authors should consider incorporating this approach, it does not provide explicit instructions on how to do so or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the potential benefits and implementation details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML or implicit-MAML, to Table 1. However, it does not specify which part of Table 1 this suggestion pertains to, nor does it provide detailed guidance on how to incorporate this approach. The authors can infer that it relates to the experimental setup or results section, but the lack of specificity and explicit references make it difficult to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, specifically mentioning MAML or implicit-MAML, to Table 1. However, the comment does not provide any reasoning, examples, or references to support why this approach would be beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, specifically mentioning MAML or implicit-MAML, to Table 1. While it provides a specific suggestion for improvement, it lacks detailed guidance on how to implement this approach or why it would be beneficial. The comment does not offer a clear rationale for why this addition would enhance the paper or provide examples of how it could be integrated. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of few-shot examples for CoT. This implies that the authors should conduct an ablation study to demonstrate the effectiveness of their prompt choice. While the comment identifies the need for an ablation study, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of few-shot examples for CoT. This implies that the authors should provide more detailed analysis or experiments to justify their prompt selection. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. The authors can make an educated guess that it relates to the methodology or results sections, but the comment lacks full grounding. It is specific in suggesting the need for an ablation study, but without explicit references to specific parts of the paper, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the use of few-shot examples for CoT. The comment suggests that an ablation study could improve performance by exploring alternative prompt strategies. However, the comment does not provide specific examples or detailed reasoning to support why an ablation study is necessary or how it would improve the paper. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of an ablation study based on the suggestion alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of an ablation study to explain the choice of prompt. It suggests that an ablation study could help clarify why the chosen prompt is effective, particularly in the context of CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\\'s methodology and analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, distinguishing them from \"temporal relationship.\" This feedback is direct and provides a clear action for the authors to take, ensuring that they use these terms accurately in their draft. The comment is explicit and concrete, offering a specific correction that the authors can apply to improve their manuscript. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the misuse of terms, such as \"causal mechanisms\" and \"causality,\" which are different from \"temporal relationship.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the use of terms \"causal mechanisms\" and \"causality,\" suggesting that they should be used carefully to distinguish them from \"temporal relationship.\" This is a factual statement asking for precision in terminology, rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, pointing out a potential confusion in the terminology used in the paper. It highlights the distinction between \"causal mechanisms\" and \"causality,\" which is different from a \"temporal relationship.\" This feedback is actionable as it provides a direct suggestion for improvement, encouraging the authors to use these terms more accurately. However, the comment could be more helpful if it offered additional context or examples to further clarify the distinction. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the strength of the claim that replacing procedure steps of XAIFOOLER with a random mechanism resulted in better performance than random. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to strengthen the demonstration of capability or what specific changes could be made to improve the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance,\" allowing the authors to accurately identify the section being addressed. It is also specific because it questions the strength of the claim that \"better than random\" is a strong demonstration of capability, providing a clear point for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the strength of the claim that replacing procedure steps of XAIFOOLER with a random mechanism resulted in better performance than random. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the strength of a claim made in the paper regarding the performance of XAIFOOLER when compared to a random mechanism. It suggests that \"better than random\" may not be a strong demonstration of capability, implying that the authors should provide more robust evidence or comparisons to substantiate their claims. However, the comment lacks specific guidance or suggestions on how the authors might improve their demonstration of capability or what additional evidence could be included. While it identifies a potential weakness, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels\". While the comment implies that the authors should address this relationship, it does not provide specific guidance on how to do so or what aspects of the results should be discussed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for a discussion on the relationship between the results and the lower bounds, but without explicit references to sections or figures, the authors may find it challenging to pinpoint where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using low-rank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a connection to existing work. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper. While it points out a relevant topic, it does not offer actionable steps for the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clear results. The reviewer questions how well the assumptions underlying PCA are met. While the comment implies that the authors should provide more information on the assumptions and their validation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their validation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, questioning the clarity of the results. It provides a logical reasoning by explaining the intuitive nature of using PCA and suggests that the authors should address how well the assumptions underlying PCA are met. However, the comment does not specify which part of the paper discusses the use of PCA or the results that are unclear. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in its request for clarification on the assumptions, but without explicit references to sections or specific results, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems incremental and lacks clear results. The reviewer provides a logical reasoning by explaining the intuitive nature of using PCA and questions how well the assumptions underlying PCA are met. However, the comment lacks specific examples or references to support the claim of incremental novelty or the lack of clear results. While the reference to Dombrowski et al. (2022) is provided, it does not directly relate to the claim being made. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the novelty and significance of using PCA to reduce interaction count, suggesting that it may seem incremental and lacks clear results. The reviewer provides a logical explanation of why PCA might be used in this context, noting that it aims to retain the maximum information in the data with reduced dimensionality, assuming certain assumptions are met. However, the comment does not offer specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their results. While it identifies a potential issue, it lacks actionable feedback, making it somewhat helpful. The authors are left with a general understanding of the critique but without detailed instructions on how to enhance their work. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the few-shot RC models considered in the paper are not state-of-the-art models and questions how their performance compares to relation extraction/generation models in few-shot settings. While the comment raises a concern and asks for a comparison, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a comparison but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the few-shot RC models considered in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparison of the models to state-of-the-art models and relation extraction/generation models in few-shot settings. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the few-shot RC models considered in the paper are not state-of-the-art models, providing references to support this claim. However, the comment lacks detailed reasoning or specific comparisons to demonstrate why these models are not state-of-the-art. The references provided are external sources, which could be useful for further investigation, but the comment does not fully substantiate the claim within the context of the paper. Therefore, the claim is mostly verifiable, as it provides some support but could be strengthened with more detailed analysis or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the few-shot RC models considered are not state-of-the-art models. It provides references to support this claim, which could help the authors understand the context better. Additionally, the comment raises a question about how the performance of these models compares to relation extraction/generation models in few-shot settings. This feedback is clear and actionable, as it prompts the authors to consider a more comprehensive evaluation of their models against current benchmarks. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is mostly helpful as it directs the authors to a relevant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide results for the discussion on using sequential MCB vs a single MCT layers for the decision head. It explicitly asks the authors to speak about what was observed, indicating a clear action for the authors to take. The comment is direct and provides a specific request for additional information, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"discussion of using sequential MCB vs a single MCT layers for the decision head,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors provide results or observations regarding this discussion, which is clear and actionable feedback. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information or clarification regarding the results of using sequential MCB vs a single MCT layer for the decision head. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for more information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a gap in the discussion by noting that the results for using sequential MCB vs a single MCT layer for the decision head are not presented. It requests that the authors provide some insight into what was observed, which is a clear and actionable suggestion for improvement. This feedback is specific and directs the authors to a particular area where additional information could enhance the paper. However, it could be more helpful if it provided guidance on how to present these results or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a missing element that could strengthen the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify or address these concerns, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or clarification regarding the choice of distribution sets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the distribution sets are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its questioning of the choice and control of distribution sets, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specificity and does not provide any suggestions or guidance on how the authors might address these questions. The feedback is somewhat helpful as it prompts the authors to consider these issues, but it does not offer actionable advice or detailed insights to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct perplexity experiments using more current language models, specifically transformer-based (masked) language models, to better align their paper with current NLP trends. This is an explicit action with concrete guidance on how to improve the draft by specifying the type of models to use. The authors know exactly what needs to be done to enhance their work, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"perplexity experiments\" and \"obsolete language models (n-gram HMM, RNN),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the use of transformer-based (masked) language models to align the paper with current NLP trends. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the perplexity experiments are conducted on outdated language models (n-gram HMM and RNN) and recommends using transformer-based models instead. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, noting that the current models are rarely used. However, the comment lacks specific examples or references to support the claim that transformer-based models are more appropriate or current in NLP trends. Providing such examples or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on outdated language models (n-gram HMM and RNN) that are no longer commonly used. It provides a clear and actionable suggestion for improvement by recommending the use of transformer-based (masked) language models to align the paper with current NLP trends. This feedback is valuable as it directs the authors to update their experiments to reflect more contemporary models, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it included additional guidance on how to implement this change or why it is important for the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of clarity regarding the estimation of \"mu,\" which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the discussion of \"muestimation\" in the paper, implying that it is related to the proportion of missing observations. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of \"mu,\" but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the estimation of \"mu,\" which is described as the proportion of missing observations. The comment highlights a lack of clarity regarding how \"mu\" can be estimated, suggesting that the authors need to provide more information or explanation on this aspect. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim of lack of clarity. This makes the claim somewhat verifiable, as the authors would need to infer the exact issue and address it themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the estimation of \"mu,\" which is described as the proportion of missing observations. It points out that the discussion lacks clarity on how \"mu\" can be estimated. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should consider providing high-probability bounds, specifically mentioning the use of ensemble methods as performed in the experiments. It also suggests adding a measure of robustness to the experiments, such as error bars or standard deviation, in addition to the mean error. These suggestions are clear and provide concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing high-probability bounds and mentions ensemble methods as a possible approach, referencing the experiments. It also suggests adding a measure of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results section. The suggestion to use ensemble methods and add robustness measures is specific, providing clear guidance on how to improve the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that only bounds in expectation are provided and asks if it would be possible to obtain high-probability bounds. It mentions ensemble methods as a potential approach and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that ensemble methods could be used to achieve high-probability bounds. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires further elaboration or evidence to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by noting that only bounds in expectation are provided, and it suggests that high-probability bounds could be beneficial. It offers a specific suggestion to use ensemble methods, as performed in the experiments, to achieve these bounds. Additionally, the comment recommends adding a measure of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to enhance their work. However, it could be more helpful if it included examples or further explanation of how to implement these suggestions. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the paper\\'s motivation for \"diversity\" but notes that the model does not enforce diversity explicitly. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might incorporate diversity into their model or what changes could be made to better align the model with the paper\\'s motivation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the paper\\'s motivation for \"diversity\" and the lack of explicit enforcement of diversity in the model. However, it does not specify which part of the paper this concern relates to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. The comment is specific in detailing the issue with the model\\'s lack of diversity enforcement, but it lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the model does not enforce diversity, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant concern regarding the paper's motivation for 'diversity' and the lack of explicit enforcement of diversity in the model. This is a critical observation that could impact the paper's validity and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. Without actionable feedback, the authors are left with a general understanding of the problem but no clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, as it specifies exactly which experiments are missing and what the authors should add. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment mentions that \"some experiments are missing,\" specifically referencing contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are missing from, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the type of experiments missing, it lacks grounding because it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that some experiments are missing, such as contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to include these experiments in their draft. However, the comment could be more helpful if it offered additional guidance on why these experiments are important or how they might enhance the paper. Despite this, the feedback is mostly helpful as it directs the authors to a clear area for expansion, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is also true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not provide explicit guidance on how to address these issues or improve the bounds. The authors are left to infer that they need to investigate and potentially revise the bounds, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is also true for the results on the adaptive adversary and the counterfactual feedback. However, the comment does not specify which part of the paper these observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issue with the bounds but lacks grounding as it does not reference specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds, specifically mentioning the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is true for the results on the adaptive adversary and the counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to invest additional effort to fully understand and address the issues raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the gap between the lower and upper bounds, particularly noting the use of \\\\sqrt(\\\\beta) instead of \\\\beta^{1/3}. It also suggests that for some graphs, the existing bound with the independence number may be better, and this is true for the results on the adaptive adversary and the counterfactual feedback. This feedback is somewhat helpful as it points out a potential area for improvement in the paper, specifically regarding the bounds and their application. However, the comment lacks depth and does not provide detailed guidance on how to address these issues or improve the bounds. While it highlights a relevant area for further exploration, it does not offer actionable steps or suggestions for the authors to take, limiting its usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer questions the logic behind this observation, asking \"Why?\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or what changes might be needed to improve the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reported ablation studies, questioning why the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the logic behind the results presented in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer asks \"Why?\" but does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a puzzling observation from the ablation studies presented in Table 2, where the complete loss function performed worse than those with some terms missing for the CUB and SOP datasets. The reviewer questions the logic behind this result, asking \"Why?\" This feedback is somewhat helpful as it points out a potential issue with the experimental results, prompting the authors to reconsider their findings and possibly explore alternative explanations or adjustments. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting an experiment where the image is occluded, which would simulate irregularities in neural/behavioral data and allow for the inspection of the model\\'s long-range inference capacity. The reviewer emphasizes that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. The comment provides a clear and specific action for the authors to take, making it highly actionable. The authors know exactly what experiments to conduct and why, giving them a clear direction for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting an experiment where the image is occluded, which is a specific suggestion for improving the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental design or results section, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data and to assess the model\\'s long-range inference capacity. The reviewer provides a logical reasoning for why this experiment would be beneficial, explaining that it would allow for the inspection of the model\\'s ability to handle irregularities. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the importance of this experiment based on the reviewer\\'s explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper by proposing an experiment where the image is occluded. This experiment is designed to simulate the irregularities present in neural/behavioral data, such as keypoint detection failures, and would allow for the evaluation of the model\\'s long-range inference capacity. The comment is clear and detailed, offering a concrete way for the authors to enhance their work. However, it could be more helpful if it included a rationale for why this experiment is crucial or how it would impact the overall understanding of the model. Despite this, the comment is mostly helpful as it provides a direct and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the statement in the abstract is unclear and suggests that it should be more high-level, avoiding technical details. This provides a clear action for the authors to take: revise the abstract to make it more accessible and less technical. The feedback is direct and concrete, offering a specific step for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract\" and the specific statement that is unclear, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear and suggests that the abstract should be more high-level, avoiding technical details. This provides clear guidance on what needs to be addressed to improve the clarity of the abstract. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a statement in the abstract is unclear and suggests that it should be more high-level. However, the comment does not provide specific examples or detailed reasoning to support why the statement is unclear or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, pointing out that a particular statement is unclear. It suggests that the abstract should be more high-level and avoid technical details. This feedback is clear and actionable, as it directs the authors to revise the abstract to improve its clarity and accessibility. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the statement or what aspects of the technical details should be avoided. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity of their abstract, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include results in other modalities, specifically mentioning language-related tasks. It also provides a nuanced comment about the relevance of expected test loss for language-related tasks, noting that out-of-distribution (OOD) performance is also important. While the comment implies that the authors should expand their results to include other modalities, it does not provide explicit instructions on how to do so or which specific modalities to consider. The suggestion is concrete in terms of the modalities to explore but lacks detailed guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, specifically mentioning language-related tasks. It also provides a nuanced comment about the relevance of expected test loss for language-related tasks, noting that out-of-distribution (OOD) performance is also important. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the results section, but without explicit references, it is challenging to pinpoint the exact part. The comment is specific in suggesting the inclusion of results in other modalities and the consideration of OOD performance, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including results in other modalities, such as language-related tasks, would be beneficial. It also notes that for language-related tasks, out-of-distribution (OOD) performance is important, which might make expected test loss less meaningful. However, the comment lacks specific examples or references to support the claim that including results in other modalities would be valuable or that OOD performance is particularly relevant for language tasks. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include results in other modalities, specifically mentioning language-related tasks. It also provides a nuanced observation about the relevance of expected test loss for language-related tasks, noting that out-of-distribution (OOD) performance is also important. This feedback is somewhat helpful as it identifies a potential area for expansion and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered guidance on how to incorporate these additional modalities or provided examples of language-related tasks that could be explored. Overall, the comment provides some direction but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the motivation of the work should be further justified, specifically in the context of few-shot learning. It highlights the need to explain how the proposed method effectively uses \"few-shot\" instances and guarantees generalizability to new tasks with limited training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to provide more justification and details but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work, specifically in the context of few-shot learning for graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"few-shot\" instances and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the authors should provide this additional justification. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified, particularly in the context of few-shot learning. It provides a logical reasoning by explaining that the paper defines a few-shot situation for graph link prediction but does not address how to effectively use \"few-shot\" instances or guarantee generalizability to new tasks. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the motivation behind the work. It highlights the importance of explaining how the proposed method effectively uses \"few-shot\" instances and guarantees generalizability to new tasks with limited training steps. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to enhance the justification or provide additional details. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of GP as \"kind of straightforward and naive,\" suggesting that it lacks depth or innovation compared to the broader GP community. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the use of GP or what specific aspects need to be addressed. Without actionable suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of GP as \"kind of straightforward and naive\" and mentions that dynamical modeling has been widely investigated in the GP community, referencing the Gaussian Process Dynamical Model from NIPs 2005. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its critique of the GP approach but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of GP is \"kind of straightforward and naive\" and references the Gaussian Process Dynamical Model from NIPs 2005 as a point of comparison. However, the comment lacks specific examples or detailed reasoning to support why the current approach is naive or how it compares to the referenced work. The mention of a specific reference provides some context, but the claim remains somewhat vague without further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claim but requires more detailed justification or examples to be fully verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the use of GP as \"kind of straightforward and naive,\" suggesting that it lacks depth or innovation compared to the broader GP community. It references the Gaussian Process Dynamical Model from NIPs 2005 as a point of comparison, implying that the current approach may not be as advanced or well-explored as it could be. However, the comment does not provide specific suggestions or guidance on how the authors might improve their use of GP or what aspects of the model could be enhanced. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the differential privacy application is not fully developed and encourages the authors to think it through more clearly. It also highlights the novelty of the online algorithm and robustness, and recommends moving the experimental results from the appendix to the main paper. While the comment provides some guidance on areas for improvement, it lacks specific instructions on how to enhance the differential privacy application or what aspects need more clarity. The action is implicit and somewhat vague, as the authors are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"given 2)-5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the differential privacy application, suggesting that it is \"half-baked\" and encouraging the authors to think it through more clearly. Additionally, it highlights the novelty of the online algorithm and robustness and recommends moving the experimental results from the appendix to the main paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the differential privacy application is \"half-baked\" and suggests that the authors should think it through more clearly. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The mention of the online algorithm and robustness being \"significantly interesting and novel\" is a positive statement but does not contribute to the verifiability of the claim about the differential privacy application. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a mixed assessment of the paper, acknowledging the novelty of the online algorithm and robustness but expressing concerns about the differential privacy application being \"half-baked.\" It encourages the authors to think through this aspect more clearly. Additionally, it suggests moving the experimental results from the appendix to the main paper, which could enhance the paper\\'s clarity and impact. However, the comment lacks specific guidance on how to improve the differential privacy application or what aspects need more attention. While it identifies areas for improvement, the feedback is somewhat helpful as it provides a general direction for enhancement but lacks detailed actionable suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what changes or clarifications are needed to resolve the ambiguity. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of methodology specificity, but without grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the specificity of the proposed methodology, suggesting that it may not be tailored to bimanual manipulation and that robotic manipulation alone could be more appropriate. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation alone would be sufficient. This feedback is somewhat helpful as it identifies a potential issue with the methodology's applicability, prompting the authors to consider whether their approach is indeed specific to bimanual manipulation. However, the comment lacks depth and does not provide specific suggestions or examples on how to address this concern or improve the methodology. While it points out an area for improvement, it does not offer actionable guidance, making it somewhat helpful but incomplete.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide METEOR results, which are also reported in recent works. This is a clear and direct action that the authors can take to improve their draft. The comment also provides additional context by mentioning recent works that report METEOR results, which gives the authors a concrete basis for their action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to provide METEOR results, which should be obvious to the authors. It also specifies what needs to be addressed by referencing recent works that report METEOR results. This provides clear guidance on what the authors should include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include METEOR results, which are also reported in recent works. However, it does not provide specific references to these recent works or explain why METEOR results are important or relevant to the paper. This lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of METEOR results and find the relevant references on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is clear and actionable, instructing the authors to include METEOR results, which are also reported in recent works. This feedback is specific and provides a concrete suggestion for improvement, allowing the authors to enhance their draft by addressing a gap in their presentation. However, the comment could be more helpful if it explained why METEOR results are important or how they relate to the broader context of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived gap in the paper regarding the potential benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. The reviewer suggests that the authors should have spent more time discussing these aspects and provides an example by asking about the biggest takeaways from the found architecture. While the comment implies that the authors should address this gap, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate this discussion into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the authors\\' discussion on the benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. However, it does not specify which part of the paper this discussion is lacking in, making it weakly grounded. The comment is specific in suggesting that the authors should have spent more time on this aspect and provides an example by asking about the biggest takeaways from the found architecture. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should have discussed the potential benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. The reviewer provides a logical reasoning by stating that this aspect is important for improving raw performances and future design. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of this aspect and how it relates to their work, which could be challenging without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the discussion of the benefits of using AutoML approaches, specifically the extraction of hints for future network architecture design. It suggests that the authors should have spent more time on this aspect and provides an example by asking about the biggest takeaways from the found architecture. This feedback is clear and actionable, as it directs the authors to expand their discussion on the potential applications and implications of their work. However, the comment could be more helpful if it offered specific suggestions on how to incorporate this discussion or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While the comment implies that the authors should make these changes, it does not provide specific guidance on how to achieve conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors can infer that they need to make these changes but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the paper is being referred to, such as a specific section or subsection, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and that empirical results should be included, but it lacks detailed guidance on how to achieve these improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, the comment lacks specific examples or detailed reasoning to support why the current content is not concise or why empirical results are necessary. Without these details, the authors may find it challenging to understand and address the feedback effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies areas for improvement, the comment lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. This makes it somewhat helpful, as the authors gain some insight into potential improvements but are left without actionable steps to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the experiments, noting that the author only tested the ReBeL performance on two typical games and suggesting that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment does not provide explicit guidance on how to address this issue or suggest specific experiments to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experimental scope but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental scope by mentioning that the author only conducted experiments on two typical games and suggests exploring the performance on more complex problems, especially those with larger depth. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental scope and the need to explore more complex problems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the author only conducted experiments on two typical games and suggests that the performance on more complex problems, especially those with larger depth, should be explored. However, the comment lacks specific examples or references to support the claim about the complexity of the games or the impact of depth on the value and policy functions. Without detailed evidence or reasoning, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental scope of the paper, noting that the author only conducted experiments on two typical games and suggesting that the performance on more complex problems, especially those with larger depth, should be explored. This feedback is somewhat helpful as it points out an area where the authors could expand their analysis to provide a more comprehensive understanding of the ReBeL\\'s performance. However, the comment lacks specific suggestions or guidance on how to conduct these additional experiments or what specific complexities should be explored. While it highlights a potential area for improvement, it does not provide detailed actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that the work is incremental. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the novelty of their work. The comment lacks actionable details, such as recommending additional experiments, discussing related work more thoroughly, or suggesting ways to enhance the novelty of the paper. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, suggesting that the improvements on different datasets are trivial and that the work is incremental. However, it does not specify which datasets or sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need attention. The comment also mentions that \"lots of previous works focus on this topic,\" but it does not provide specific examples or references to support this claim. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that it is incremental. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the paper by stating that the improvements on different datasets are trivial and that the novelty of the work is limited. It suggests that the paper is incremental, as it only adds topic entities without significant innovation. However, the comment lacks specific examples or detailed feedback on how the authors could enhance the novelty or improve the work. Without actionable suggestions or guidance, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the theoretical guarantee regarding the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it lacks concrete details on what specific aspects should be covered or how to present the discussion. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the missing discussion on theoretical guarantees, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it directs the authors to include a discussion on this theoretical aspect, which could enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what specific aspects to focus on. Overall, the comment is mostly helpful as it points out a significant gap in the paper and encourages the authors to address it, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measures to evaluate the generated VCEs, with evaluation primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is mainly performed through visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of generated VCEs lacks quantitative measures, relying mainly on visual inspection. This is a subjective opinion that requires justification, as it implies that the current evaluation method is insufficient. However, the comment does not provide specific examples or references to support why quantitative measures are necessary or how they could be implemented. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors would need to infer the importance of quantitative measures based on general knowledge of evaluation practices. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it relies heavily on visual inspection without quantitative measures. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should incorporate more robust evaluation methods to assess the quality and effectiveness of the generated VCEs. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used for evaluation. Despite this, the feedback is clear and actionable, making it mostly helpful for guiding the authors in enhancing their evaluation process. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper claims to show improvements over baselines, but the actual results are only marginally better and often within the error bar range. This suggests that the performance differences between methods are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The feedback implies that the authors should reconsider their claims or provide more detailed analysis, but it lacks concrete steps or actionable advice. As a result, the comment is vague and does not offer a clear path for the authors to follow, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the claim of marginal improvements over baselines, noting that the error range is high, which suggests that the performance differences between methods are not significant. However, it does not specify which part of the paper this claim is based on, such as a particular section or figure that presents the results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being discussed. Additionally, while the comment highlights the issue with the claim, it does not provide specific guidance on how to address it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper shows only marginal improvements over baselines, with the performance differences often within the error bar range. This claim is based on the observation that the error range is high, suggesting that the performance differences between methods are not significant. The comment provides a logical reasoning by pointing out the high error range, which supports the claim that the improvements are marginal. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is mostly verifiable, as it is supported by a clear explanation but lacks detailed examples or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out that the paper claims to show improvements over baselines, but the actual results indicate only marginal improvements, often within the error bar range. This suggests that the performance differences between methods are not significant. While the comment identifies a potential issue with the paper\\'s claims, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their results. The feedback is somewhat helpful as it highlights a weakness in the paper\\'s claims, but it lacks actionable advice or detailed analysis to help the authors improve their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights significant artifacts in the generated videos, noting that only some beach videos are convincing. It also mentions that the action recognition performance is below the current state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their results. The questions posed do not offer actionable steps for the authors to take. As a result, the comment lacks concrete details and explicit actions, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"significant artifacts\" in the generated videos and notes that only some beach videos are convincing. It also compares the action recognition performance to the current state-of-the-art on the UCF dataset, highlighting the use of more complex architectures. However, the comment does not specify which part of the paper discusses the generated videos or the action recognition performance, making it difficult for the authors to pinpoint the exact sections that need attention. The mention of specific datasets like the UCF dataset provides some context, but the lack of explicit references to sections or figures limits the grounding. The comment is specific in detailing the issues with the generated videos and the performance comparison, but it is not fully grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current state-of-the-art on the UCF dataset. However, it does not provide specific examples or detailed comparisons to support these claims. The mention of \"more complex (deeper, also processing optic flow) architectures\" suggests a basis for the claim, but without explicit references or detailed analysis, the claim remains somewhat verifiable. The authors would need to conduct further research to fully understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the presence of significant artifacts in the generated videos and the subpar action recognition performance compared to the current state-of-the-art on the UCF dataset. It highlights that only some beach videos are convincing, suggesting a lack of consistency in the results. The comment also points out the gap in performance compared to more complex architectures used in the UCF dataset. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their results. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problems but no clear path forward for improvement. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how to select representative images, indicating that this aspect of the paper is unclear. However, the comment does not provide explicit guidance or suggestions on how to address this issue. The authors are left to infer that they need to clarify or improve the selection process, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of diversity and representativeness in the new proposed evaluation set compared to the previous method. However, it does not specify which part of the paper this concern is related to, such as a specific section or figure, making it weakly grounded. The comment is specific in detailing what is unclear, namely the process of selecting representative images. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of clarity regarding how the new proposed evaluation set is more diverse and representative than the previous method. It questions the process of selecting representative images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how to select representative images, which is a critical aspect of ensuring the evaluation set is robust and effective. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a background section that introduces the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a background section to introduce the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This feedback is fully grounded as it explicitly mentions the need for a background section and the specific elements to include, allowing the authors to accurately identify the parts of the paper that need revision. The comment is also specific because it clearly specifies what needs to be addressed, providing detailed guidance on how to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks a background section to introduce the basic RL framework, which would help clarify the context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment identifies a potential issue with the paper\\'s structure, it does not provide specific examples or detailed reasoning to support why this is necessary. The suggestion is somewhat verifiable as it highlights a potential gap in the paper\\'s organization, but it lacks concrete evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting the inclusion of a background section to introduce the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy. This would help clarify the RL context being considered and make the subsequent sections easier to follow. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is specific and provides concrete guidance on how to improve the clarity and organization of the paper, making it highly helpful for the authors. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how to improve the model capacity, whether through adjustments to the model architecture, training data, or other means. Without specific suggestions or directions, the authors are left without a clear understanding of how to address this concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. However, it does not specify which part of the paper discusses the proposed method or the model capacity, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on how this limitation could be addressed or what specific aspects of the model capacity are limited. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically the issue of limited model capacity when users continuously add new languages. This is a relevant observation that could impact the scalability and applicability of the method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation. Without detailed feedback or recommendations, the authors are left with a general awareness of the issue but without a clear path forward for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it implies that the authors should clarify the connection between their work and the referenced paper, it does not provide explicit guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it references a specific paper, it does not provide any further explanation or reasoning to support the claim that the term is not relevant. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the question, rendering the comment barely verifiable. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by Doshi-Velez and Kim (2017). While it points out a potential connection that needs clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what specific steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide detailed guidance on what needs to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the similarity between the proposed method and the approach in reference [10], suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. The comment implies that the proposed method may not be novel or innovative, as it seems to be similar to an existing approach. However, the comment does not provide any specific evidence, examples, or references to support this claim, making it difficult for the authors to understand the basis of the comparison. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the proposed method by pointing out its similarity to an existing approach in reference [10]. It suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data, which implies that the proposed method may not be as novel as claimed. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or differentiate their work from the existing approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, improve the interpretation, or suggest alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the limitation of the Atari game results, noting that they are based on a single game and a single baseline, which makes interpretation challenging. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that the Atari game results are based on a single game and a single baseline, which makes it difficult to interpret. This is a clear and actionable feedback that highlights an area for improvement. However, the comment could be more helpful if it provided suggestions on how to expand the results or offer alternative approaches to enhance the interpretability of the findings. Despite this, the comment still offers valuable insight into a critical aspect of the paper, making it mostly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. While it implies that these experiments are necessary, it does not provide explicit instructions or detailed guidance on how to conduct them. The authors can infer that they need to add these experiments, but the comment lacks concrete details on what specific aspects of distributed deployment and larger models should be explored. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to identify where to incorporate these suggestions. Additionally, the comment lacks specificity regarding what aspects of distributed deployment and larger models should be explored. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. The lack of justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation section of the paper, suggesting that experiments on distributed deployment and a larger model should be included. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects of distributed deployment and larger models should be explored. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for expansion, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should provide evidence or experiments to support their claim by testing their model with larger word embedding and LSTM parameters. While the comment suggests an action\u2014testing the model with larger parameters\u2014it does not provide explicit instructions on how to conduct these tests or what specific parameters to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the authors\\' claim about achieving superior performance with fewer parameters compared to the baseline. It mentions specific aspects of the model, such as the word embedding size and LSTM size, which are directly related to the claim. The comment also specifies what needs to be addressed by asking for improvements when the proposed model uses larger word embedding and LSTM parameters. This provides clear guidance on what the authors need to consider to support their claim. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance with fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. The reviewer asks for evidence or experiments to support the claim by testing the proposed model with larger word embedding and LSTM parameters. This request for additional evidence or experiments provides a clear direction for the authors to substantiate their claim, making the comment mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment questions the authors' claim of achieving superior performance with fewer parameters compared to the baseline model. It suggests that the baseline model might have been tested with standard parameter settings, implying that the authors' claim may not be entirely accurate. The reviewer requests evidence or experiments to support the claim by testing the proposed model with larger word embedding and LSTM parameters. This feedback is clear and actionable, as it prompts the authors to provide additional evidence or experiments to substantiate their claim, which could significantly enhance the credibility of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what parameters to test. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires further investigation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the introduction of two new hyperparameters, k and \u03b7, which require fine-tuning. It notes that this fine-tuning depends on the availability of the environment or a good OPE (Online Parameter Estimation) method. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting alternative methods for fine-tuning or providing recommendations for handling the dependency on the environment or OPE method. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the introduction of two new hyperparameters, k and \u03b7, and their requirement for fine-tuning. However, it does not specify which part of the paper discusses these hyperparameters, making it weakly grounded. The comment is specific in detailing the issue with the fine-tuning requirement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two new hyperparameters, k and \u03b7, requires fine-tuning, which depends on the availability of the environment or a good OPE (Online Parameter Estimation) method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of two new hyperparameters, k and \u03b7, which require fine-tuning. It highlights the dependency on the environment or a good OPE (Online Parameter Estimation) method, which could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or further elaboration, the feedback is somewhat helpful as it points out a potential problem but does not offer a clear path for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the application of regularization between the LN model and the GLM presented by pillow et al. It suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. However, the comment does not provide explicit instructions on how to achieve this or what specific features should be replicated. The action is implicit and somewhat vague, as the authors can infer that they need to align their approach with the previous model, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the application of regularization to both LN models and GLMs, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the GLM presented by pillow et al., suggesting that the authors should try to reproduce the main features of this model to make the comparison fair. This level of specificity helps the authors understand what needs to be addressed in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should try to reproduce the main features of the previous model presented by pillow et al. to make the comparison fair. The reviewer provides a specific example of how the previous model used L1 regularization for filters and a low-rank approximation to the spatial filter, contrasting it with the current approach of cropping the stimulus. This comparison is based on logical reasoning and provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by including references to the specific work by pillow et al. or more detailed explanations of the differences in methodology. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the LN model and the GLM presented by pillow et al. It points out that the authors apply regularization in the form of a cropped stimulus to both models, whereas the previous model used L1 regularization for filters and a low-rank approximation to the spatial filter. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of the previous model. This feedback is somewhat helpful as it highlights a specific area where the authors might need to adjust their approach to ensure a fair comparison. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific features of the previous model should be replicated. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a study on inference time in the paper, suggesting that it would be valuable to compare the inference speed of the proposed pose estimation method with previous top-down and bottom-up methods. While the comment implies that the authors should conduct such a study, it does not provide explicit instructions or detailed guidance on how to carry out this comparison. The action is implicit and somewhat vague, as the authors would need to infer the specific steps to take and how to conduct the comparison. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a study on inference time, particularly in comparison to previous top-down and bottom-up pose estimation methods. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to include a comparison of inference speeds, but it lacks grounding as it does not clearly indicate where this comparison should be made. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no study on inference time in the paper, suggesting that it would be valuable to compare the inference speed of the proposed pose estimation method with previous top-down and bottom-up methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The absence of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by noting the absence of a study on inference time, which is relevant for a pose estimation method. It suggests that comparing the inference speed of the proposed method with previous top-down and bottom-up methods would be valuable. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to enhance their work. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or suggested specific metrics to use. Overall, the comment is mostly helpful, as it directs the authors to a meaningful area for further analysis and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the limitations of the claim about evolutionary dropout addressing internal covariate shift, specifically noting that it can only increase the variance of some low-variance units. It also mentions that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be explicitly discussed. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to structure the discussion or what additional information should be included. The action is explicit but somewhat vague, as the authors know they need to discuss the limitations but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the claim about evolutionary dropout,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, noting that it can only increase the variance of some low-variance units and suggesting that Batch Normalization standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some low-variance units. The reviewer contrasts this with Batch Normalization, which standardizes the variance and centers the activation. This comparison provides a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, noting that it can only increase the variance of some low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. The comment suggests that these limitations should be discussed explicitly, providing a clear and actionable direction for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to structure this discussion or what additional information should be included. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should add these elements, it does not provide explicit guidance on how to do so or which figures should be updated. The action is implicit and somewhat vague, as the authors can infer that they need to include additional attention maps but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding \"tentative attention maps\" to the qualitative figures, which implies that it is addressing the figures where attentions are discussed. However, it does not explicitly mention which figures or sections this pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of tentative attention maps, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to include \"tentative attention maps\" in the qualitative figures, alongside the retrieved and final attentions. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the understanding of the results. Without supporting evidence or explanation, the claim lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including \"tentative attention maps\" in the qualitative figures would be beneficial. This feedback is somewhat helpful as it identifies a potential enhancement to the visual presentation of the results, which could provide additional insights into the attention mechanisms. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these maps or why they would be valuable. While it points out an area for improvement, it does not offer actionable steps or detailed suggestions, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the author should add more description about the contribution of the paper. While it explicitly states an action, it lacks specific guidance on what aspects of the contribution should be elaborated or how to present them. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the author should add more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description, making it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide specific guidance on what aspects of the contribution should be elaborated. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated or how to present them. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it provides a general direction but lacks actionable details.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should include supervised baselines in their experiments. It provides a clear rationale for why this is important, noting that the scale of the datasets (~100k images) suggests that full annotation is likely available, making a supervised baseline informative for comparing self-supervised methods. The comment also highlights the value of including a fully supervised pre-trained network as a baseline. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of supervised baselines in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that including supervised baselines would be informative, especially given the scale of the datasets used. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of supervised baselines is a missing aspect in the experiments. It provides a logical reasoning by noting that datasets of scale ~100k images likely have full annotation available, making a supervised baseline informative for comparison. However, the comment could be strengthened by providing specific examples or references to studies that have used supervised baselines in similar contexts. This would enhance the verifiability of the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why including these baselines is important, especially given the scale of the datasets used, which likely have full annotation available. The comment suggests that including a fully supervised pre-trained network as a baseline would be informative for comparing self-supervised methods. This feedback is actionable and provides a clear direction for the authors to improve their draft by adding a critical comparison point. However, it could be more helpful if it offered specific suggestions on how to implement these baselines or provided examples of similar studies that have used supervised baselines. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance differences between methods are minimal, suggesting that the results may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The authors are left to infer that they should consider updating their benchmarks or exploring other methods to improve the robustness of their results. While the comment identifies areas for improvement, it lacks concrete steps or suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Performance differences between methods are minimal across evaluations,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by noting that the performance differences are less than 1 percentage point and may be due to random variation. Additionally, it points out that the benchmarks selected are outdated and likely saturated, providing a specific critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal, citing that the differences are less than 1 percentage point, which may be due to random variation. It also mentions that the benchmarks used are outdated and likely saturated, referencing a specific paper, \"LoRA Learns Less and Forgets Less\" [1]. This provides some support for the claim, as the reference to the paper suggests that the benchmarks are indeed outdated. However, the comment could be strengthened by providing more detailed analysis or examples of how the benchmarks are outdated or saturated. Therefore, the claim is mostly verifiable, as it has some justification but could be further substantiated.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal, with differences less than 1 percentage point. It suggests that these differences may be due to random variation and that the benchmarks used are outdated and likely saturated. This feedback is valuable as it highlights a potential flaw in the paper's methodology and suggests that the authors should consider updating their benchmarks or exploring other methods to improve the robustness of their results. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of more suitable benchmarks. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the method\\'s effectiveness on the Hopper environment, which has deterministic dynamics, and suggests that it might be equivalent to action-conditional masking. It also questions the absence of BEAR from the baselines and suggests evaluating the method on domains with non-deterministic dynamics to assess its empirical efficacy. While the comment implies that the authors should address these concerns, it does not provide explicit instructions or concrete steps on how to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the method\\'s benefits and consider additional domains for evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s effectiveness on the Hopper environment, which has deterministic dynamics, and suggests that it might be equivalent to action-conditional masking. It also questions the absence of BEAR from the baselines and suggests evaluating the method on domains with non-deterministic dynamics. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the discussion of the method\\'s application and evaluation. The comment is specific in detailing what needs to be addressed, such as the method\\'s efficacy on non-deterministic domains and the inclusion of BEAR in the baselines. However, the lack of explicit references to specific sections or parts of the paper makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the method\\'s effectiveness, particularly in the context of deterministic dynamics and the absence of BEAR from the baselines. While the comment provides some logical reasoning by questioning the method\\'s benefit in deterministic environments and suggesting evaluation on non-deterministic domains, it lacks specific examples or references to support these claims. The absence of detailed evidence or examples makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some rationale but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several important questions and concerns about the method\\'s effectiveness, particularly in the context of deterministic dynamics and the absence of BEAR from the baselines. It questions why the method is beneficial on Hopper, which has deterministic dynamics, and suggests that it might be equivalent to action-conditional masking. The comment also recommends evaluating the method on domains with non-deterministic dynamics to assess its empirical efficacy. Additionally, it points out the omission of BEAR from the baselines, which could be a significant oversight. While the comment identifies important areas for improvement and provides some guidance, it lacks specific suggestions on how to address these issues or expand the evaluation. Therefore, the comment is somewhat helpful, as it highlights critical areas for improvement but could be more comprehensive in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a theocratical justification for why co-training and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should provide this justification or what aspects to focus on. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging can improve results. However, it does not specify which part of the paper this justification should be included in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for a justification but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theocratical justification for why co-training and weight averaging can improve results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that such a justification is necessary or beneficial. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging can improve results. While it identifies a potential area for improvement by highlighting the importance of justifying these methods, the comment lacks specificity and does not offer detailed guidance on how to provide this justification. It does not provide examples or suggest specific aspects that should be addressed, leaving the authors with a general idea of what is needed but without actionable steps. Therefore, the comment is somewhat helpful, as it points out a gap in the paper but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds that are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their derivation. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds that are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper the derivation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by mentioning Bayesian-PAC based bounds, but without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example, \"Bayesian-PAC based bounds,\" to support this claim. However, the comment lacks detailed reasoning or references to substantiate why these bounds are not realistic or how Bayesian considerations would improve them. While the mention of Bayesian-PAC based bounds provides some context, the claim remains somewhat verifiable due to the lack of comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds that are not realistic unless Bayesian considerations are taken into account. It provides a specific example, \"Bayesian-PAC based bounds,\" which could guide the authors in understanding the limitations of their approach and potentially suggest a direction for improvement. However, the comment lacks depth and does not offer actionable advice on how the authors might address this issue or integrate Bayesian considerations into their work. While it identifies a potential weakness, the feedback is incomplete and does not fully support the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in detailing what additional information is needed, but without clear grounding, the authors may struggle to identify the exact sections that require expansion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by suggesting that more details about the proposed method should be presented. It highlights the need for clarification on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it provides specific guidance on what additional information should be included to enhance the comprehensiveness of the paper. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of similar approaches that have successfully addressed these issues. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed method\\'s ability to detect hallucinations in open-ended responses, specifically mentioning the challenge of identifying shared information for consistency checking in responses to prompts like \"introduce a sports celebrity to me.\" However, the comment does not provide explicit guidance or suggestions on how the authors might address this challenge or improve their method. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the proposed method\\'s ability to detect hallucinations in open-ended responses, particularly with prompts like \"introduce a sports celebrity to me.\" This provides full grounding as it explicitly mentions a scenario that could be challenging for the method. The comment is also specific because it details the issue of identifying shared information for consistency checking in responses to such prompts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s ability to detect hallucinations in open-ended responses, specifically mentioning the challenge of identifying shared information for consistency checking in responses to prompts like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by explaining the potential difficulty in detecting hallucinations in such scenarios. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this critique and potentially provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed method, specifically its ability to detect hallucinations in open-ended responses. It provides a specific example, \"introduce a sports celebrity to me,\" to illustrate the challenge of identifying shared information for consistency checking. This feedback is valuable as it highlights a critical area for improvement and offers a concrete scenario for the authors to consider. However, the comment could be more helpful if it suggested ways to address this challenge or provided additional guidance on how to enhance the method\\'s robustness. Overall, the comment is mostly helpful as it directs the authors\\' attention to a significant issue but could be more comprehensive with further suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of the theoretical findings in relation to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN. While the comment implies that the authors should conduct additional verification, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct further verification but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the theoretical findings in relation to real-world deep learning models, specifically mentioning the need to verify the conclusion about label noise and model size on MNIST and CNN. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a particular area for verification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the theoretical findings in relation to real-world deep learning models, specifically questioning the conclusion about label noise and model size on MNIST and CNN. The reviewer suggests verifying these conclusions, which is a logical request for further investigation. However, the comment lacks specific examples or references to support the claim that the findings are unclear or need verification. This makes the claim somewhat verifiable, as it provides a direction for further exploration but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the theoretical findings in relation to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST and CNN, which is a specific and actionable piece of feedback. By recommending verification, the comment provides a clear direction for the authors to improve their draft by ensuring that their theoretical findings are applicable and relevant to practical scenarios. However, the comment could be more helpful if it included additional guidance on how to conduct this verification or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the distribution p(y|Hf\u00af(tn)) should be chosen as Gaussian, as this is a requirement for Kalman Filtering and Smoothing and CVI. It also mentions that this assumption is later made in the ELBOs. This provides a clear and direct action for the authors to take, ensuring that the distribution is specified as Gaussian. The comment is explicit and concrete, offering specific guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distribution p(y|Hf\u00af(tn)) and the context of Kalman Filtering and Smoothing and CVI, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the requirement for the distribution to be chosen as Gaussian, which is necessary for the mentioned methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution p(y|Hf\u00af(tn)) must be chosen as Gaussian for Kalman Filtering and Smoothing and CVI to be possible. It further notes that this assumption is later made in the ELBOs. The comment provides a logical reasoning for the claim by explaining the necessity of the Gaussian distribution for the mentioned methods. However, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could benefit from additional supporting evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the choice of distribution for p(y|Hf\u00af(tn)). It points out that the distribution should be chosen as Gaussian, as this is a requirement for Kalman Filtering and Smoothing and CVI. The comment also notes that this assumption is later made in the ELBOs, which helps the authors understand the context and importance of this choice. By highlighting this requirement, the comment offers clear guidance on how to improve the draft, making it mostly helpful. However, it could be more helpful if it provided additional context or examples to further clarify the necessity of this choice. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The comment implies that the authors should consider reporting cosine similarities for larger weight decay strengths, but it does not specify how to do so or what specific changes are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the application of weight decay to all layers, the expected impact on training loss, and the absence of reported cosine similarities for large weight decay parameters. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that applying weight decay to all layers would lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. It suggests that the absence of reported cosine similarities for such large weight decay strengths is convenient, implying that the authors might be avoiding reporting suboptimal results. However, the comment lacks specific examples or references to support the claim about the expected impact of weight decay on training loss and cosine similarities. The reasoning is somewhat logical but requires more detailed evidence or examples to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal results, particularly for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that the authors might be avoiding reporting suboptimal results. This feedback is somewhat helpful as it highlights a specific area for improvement and encourages the authors to consider reporting cosine similarities for larger weight decay strengths. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional guidance on what specific changes could be made to improve the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests conducting qualitative experiments to demonstrate the validity of the conditional independence model, specifically recommending the use of a toy dataset to show the separability of inlier features and outlier features. This provides a clear and concrete action for the authors to take. The second part suggests providing visualization results or a schematic diagram to help readers understand the proposed test metric and its comparison with other metrics. While the action is explicit, the comment could be more actionable by providing specific guidance on what kind of visualization or diagram would be most helpful. Overall, the comment is mostly actionable as it provides clear directions for improvement, but with some room for further detail.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"qualitative experiments\" and \"conditional independence model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as conducting illustrative experimental results to demonstrate the validity of the model and proposing a new test metric with comparative experiments. Additionally, it suggests providing visualization results or a schematic diagram to aid understanding. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcond-i could perform better than minimizing HSIC_HOOD. The comment also points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the effectiveness of HSICcond-i or the necessity of the suggested experiments. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting that illustrative experimental results could be provided to show the effectiveness of minimizing HSICcond-i over HSIC_HOOD. This feedback is clear and actionable, guiding the authors on how to enhance the experimental section. Second, the comment notes the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, recommending the inclusion of visualization results or a schematic diagram to aid understanding. This feedback is also specific and actionable, providing a clear path for the authors to improve the clarity and comprehensiveness of their work. Overall, the comment is highly helpful as it offers detailed and constructive suggestions for enhancing the paper\\'s experimental and methodological sections.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. While the comment implies that this analysis could provide valuable insights, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this analysis further. However, the suggestion is concrete in terms of what could be analyzed, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a specific analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return. The comment also provides a theoretical explanation of how the roles between \"winners\" and \"cooperators\" might emerge based on the cost to reward the other agent. However, it does not explicitly mention which part of the paper this analysis should be added to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the impact of varying \u03b1 on reward incentives and collective return. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a theoretical explanation of how the roles between \"winners\" and \"cooperators\" might emerge based on the cost to reward the other agent. The comment also speculates that if the cost were lower, roles would be less distinguished, leading to a lower collective return. While the comment offers a logical reasoning, it lacks specific examples or references to support the claim. The authors would need to infer the exact nature of the analysis and its potential outcomes. Therefore, the comment is somewhat verifiable, as it provides a logical framework but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a valuable analysis that could be conducted to better understand the impact of the cost of incentivization on performance. It proposes examining the effect of varying the value of \u03b1 on the reward incentives and collective return, which could provide insights into how roles between \"winners\" and \"cooperators\" emerge. The comment also offers a theoretical explanation of how the cost affects these roles and the collective return. While the suggestion is clear and actionable, it could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a potential area for improvement and offers a direction for further exploration, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to revise the approach description in \u00a73, indicating that it is partially difficult to follow. It also provides a specific suggestion to use the additional page of the camera-ready version to extend the approach description, rather than adding more experiments. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"\u00a7 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach description being partially difficult to follow and suggests revising it. Additionally, it provides a concrete suggestion to use the additional page of the camera-ready version to extend the approach description rather than adding more experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in \u00a73 is partially difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support why the description is difficult to follow. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or detailed justification to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description in \u00a73, noting that it is partially difficult to follow. It provides a clear and actionable suggestion to revise the description, recommending the use of the additional page in the camera-ready version to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete solution, making it mostly helpful. However, the comment could be more helpful if it included additional guidance on how to enhance the clarity of the description. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights to explain why the proposed gyro-structures outperform existing methods. Second, it notes that the paper lacks comparisons with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach's performance relative to simpler or more commonly used techniques. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues, such as suggesting specific methods to compare or how to incorporate interpretive insights. The actions are implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments part\" and the \"related discussion,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the lack of interpretive insights and the omission of comparisons with other state-of-the-art methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related discussion lacks interpretive insights to explain why the proposed gyro-structures outperform existing methods. It also notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance. The comment provides a logical reasoning for the claim by highlighting the need for interpretive insights and comparisons with other methods. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the experiments section of the paper. First, it points out the lack of interpretive insights in the discussion, which would help explain why the proposed gyro-structures outperform existing methods. Second, it notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, which could provide a clearer understanding of the proposed approach\\'s performance relative to simpler or more commonly used techniques. This feedback is clear and actionable, as it directs the authors to enhance the interpretability of their results and broaden the scope of their comparisons. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what kind of evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more evidence but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment identifies a specific area for improvement, it does not provide detailed guidance on what kind of evidence or analysis is needed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper lacks evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the specific areas that require more evidence or analysis. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the need for more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential use-cases of LMGQS compared to other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be most beneficial or how to present it effectively. Despite this, the comment provides a valuable direction for the authors to enhance their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential impact of regularization effects on the improvements observed in the paper, rather than the distillation process itself. It suggests that the fine-tuning on GLUE without early-stopping could lead to high variances, and proposes that proper ablation studies are needed to verify the claims. While the comment implies that the authors should conduct additional studies to address this concern, it does not provide explicit instructions on how to perform these studies or what specific analyses are needed. The action is implicit and somewhat vague, as the authors can infer the need for additional studies but may not know exactly how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific aspect of the paper being addressed, namely the case where the student distills knowledge to the teacher and the potential impact of regularization effects. It also specifies the issue by pointing out the lack of early-stopping during fine-tuning on GLUE, which could lead to high variances. The comment suggests that proper ablation studies are needed to verify the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern that the improvements observed in the paper could be due to regularization effects rather than distillation. It provides a logical reasoning by pointing out that fine-tuning on GLUE without early-stopping can lead to high variances, which could mask the true effects of distillation. The comment suggests that proper ablation studies are needed to verify the claims. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the impact of regularization effects. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical point about the potential impact of regularization effects on the observed improvements in the paper, rather than the distillation process itself. It suggests that the fine-tuning on GLUE without early-stopping could lead to high variances, which might mask the true effects of distillation. The comment provides a clear and actionable suggestion for the authors to conduct proper ablation studies to verify their claims. This feedback is valuable as it highlights a potential flaw in the paper\\'s methodology and offers a specific direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to design these ablation studies or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively identifies a critical area for improvement and offers a constructive suggestion for further research.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. These suggestions are clear and concrete, providing the authors with specific actions to take to improve their draft. The use of specific examples, such as the MUSE paper, further enhances the actionability of the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions for improvement, such as adding performance metrics on word similarity and sentence translation tasks, and including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. These suggestions are clear and detailed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests two improvements for the experiments: (i) adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages. The first suggestion is supported by referencing the MUSE paper, which provides a clear basis for the recommendation. The second suggestion is also logical and aligns with common practices in language evaluation. However, the comment could be strengthened by providing specific examples or references for the second point. Overall, the claim is mostly verifiable, as it provides a solid basis for the first suggestion and logical reasoning for the second, but lacks detailed examples for the latter. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two specific suggestions for improving the experiments, which is valuable feedback for the authors. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to those in the MUSE paper, to enhance the credibility of the framework. This is a clear and actionable suggestion that can help the authors demonstrate the robustness and effectiveness of their framework. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, in the experiments. This is a minor point but still offers a direction for further exploration. The comment is mostly helpful as it provides actionable feedback that can guide the authors in enhancing their experimental setup and results. However, it could be more helpful if it included additional context or examples to support the suggestions. Therefore, the comment aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: one about the applicability of node importance in a 1-shot scenario and another about the absence of a 1-shot setting in the experiment section, despite related works like RALE having it. While the comment identifies areas of confusion and potential gaps in the paper, it does not provide explicit or implicit actions for the authors to take. The questions are more exploratory in nature, seeking clarification rather than suggesting specific changes or improvements. As a result, the comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address these issues. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the consideration of node importance among nodes with the same label in the support set, particularly in the context of a 1-shot scenario. It also points out the absence of a 1-shot setting in the experiment section, contrasting it with related works like RALE that include such a setting. However, the comment does not specify which part of the paper discusses the 1-shot scenario or the experiment section, making it difficult for the authors to pinpoint the exact areas needing attention. While the authors can infer that these issues relate to the methodology or results sections, the lack of explicit references limits the comment\\'s grounding. The comment is specific in its questioning of the applicability and the absence of a specific setting, but the lack of grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the applicability of node importance in a 1-shot scenario and notes the absence of a 1-shot setting in the experiment section, contrasting it with related works like RALE that include such a setting. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and how they might address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two distinct questions about the paper. First, it questions the applicability of node importance in a 1-shot scenario, which could be a critical aspect of the methodology. Second, it points out the absence of a 1-shot setting in the experiment section, contrasting it with related works like RALE that include such a setting. While the comment identifies potential gaps and areas for clarification, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights important aspects of the paper that need further exploration or clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to conduct these discussions or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but may not know exactly how to approach it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion for additional discussion but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussion about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these problems. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional insights and analysis. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach these discussions. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of insight into why self-supervised learning is necessary for 360 video data with spatial audio. It implies that the authors should provide more justification or explanation for this choice. However, the comment does not explicitly instruct the authors to add this information or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to add an explanation but are not given specific instructions on how to do it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results section, specifically questioning the need for self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more insight into why this approach is valuable. However, the comment does not explicitly mention which part of the experimental results section it is referring to, making it weakly grounded. The comment is specific in its request for additional insight into the necessity of self-supervised learning on this type of data. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of self-supervised learning on 360 video data with spatial audio, suggesting that the paper lacks insight into why this approach is valuable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, it lacks insight into why self-supervised learning is necessary for this type of data. This observation highlights a critical area for improvement, as it prompts the authors to provide a more detailed explanation of the rationale behind their approach. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing potential explanations or examples to include. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, providing them with a specific step to improve their draft. The comment is concrete in its guidance, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests averaging results over multiple runs to determine statistical significance, but it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. Without explicit references to sections or figures, the authors may find it challenging to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the results should be averaged or how this would impact the determination of statistical significance. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that results should be averaged over multiple runs to determine statistical significance. This is a common practice in experimental design to ensure the reliability of results. However, the comment does not provide specific examples or references to support why this is necessary or how it would impact the analysis. While the suggestion is based on a logical reasoning, it lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their findings. By averaging results over multiple runs, the authors can better understand the variability and significance of their results, which is crucial for the validity of their conclusions. However, the comment could be more helpful if it provided additional context or examples of how this should be implemented or why it is important for the specific study. Despite this, the feedback is mostly helpful as it offers a concrete step for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should highlight the observations and conclusions made in the experimental section, as this would be beneficial for understanding the trade-offs between annotation effort and training performance. While the comment implies that the authors should make these observations more prominent, it does not provide specific guidance on how to do so, such as suggesting where to place this information or how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to make the observations more visible but may not know exactly how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the trade-offs between annotation effort and training performance. However, it does not specify which part of the experimental section these observations and conclusions are located in, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in its suggestion to highlight these observations and conclusions but lacks full grounding due to the lack of explicit references to specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the trade-offs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are important or how they relate to the trade-offs. Without additional context or evidence, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the trade-offs between annotation effort and training performance. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity and accessibility of the paper. However, it could be more helpful if it offered specific guidance on where or how to highlight these observations and conclusions. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It also references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this comparison without specific guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to \"Remark 1,\" which suggests that the authors can identify the specific part of the paper being addressed. However, it does not explicitly mention the section or page number, making it weakly grounded. The comment is specific in suggesting a comparison of performance on datasets with a decision space beyond binary, which could help the authors address a potential limitation of their approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the KDE approach when the classifier space is beyond binary, referencing a specific work by Zhang et al. The comment suggests comparing the performance on datasets with a decision space beyond binary, which is a logical suggestion for further exploration. However, the comment does not provide detailed reasoning or examples to support the claim that this comparison is necessary or beneficial. While it points out a potential area for investigation, the lack of specific evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance of the KDE approach when the classifier space is beyond binary, noting that this might be a problem. It references another approach by Zhang et al. and suggests comparing the performance on datasets with a decision space beyond binary. This feedback is somewhat helpful as it identifies a potential area for improvement and suggests a specific comparison that could be made to enhance the paper. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment offers a clear direction for further exploration but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two separate concerns: the impact of the SR model\\'s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide explicit or implicit actions for the authors to take. There are no suggestions on how to address these issues, such as conducting additional experiments or analyzing the artifacts. The lack of guidance or specific instructions leaves the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two separate concerns: the impact of the SR model\\'s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what is meant by \"unexpected artifacts\" or how they relate to the pipelining method. Without clear guidance on where to address these issues, the comment is not grounded and lacks specificity. Therefore, this comment is categorized as not grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises two separate concerns: the impact of the SR model\\'s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issues. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two distinct concerns: the impact of the SR model\\'s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. However, it does not provide any specific guidance or suggestions on how the authors might address these issues. Without actionable feedback or detailed analysis, the authors are left without a clear understanding of what needs to be improved or how to improve it. This lack of direction makes the comment unhelpful, as it does not offer any meaningful insights or steps for the authors to take to enhance their draft. Therefore, the comment is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these experiments to enhance the paper. The comment is specific and concrete, as it outlines exactly what experiments are missing and what the authors should focus on. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the parts of the paper that need improvement. The comment is also specific because it clearly specifies what is missing, providing a clear direction for the authors to enhance their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or reasoning to support why these experiments are necessary or how they would enhance the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work to improve its comprehensiveness and robustness. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or provided examples of similar studies that have included such analyses. Despite this, the comment is mostly helpful as it directs the authors to important areas for improvement, making it a valuable feedback for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the experimental results, noting that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models learned based on each dataset, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the experimental setup or provide additional context to justify the use of prior knowledge. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method has no advantage over the state-of-the-art without prior information and that the comparison is unfair due to the added complexity and cost of using two representation models. The comment provides a clear critique of the experimental setup and suggests that the authors should consider these factors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information, but shows an advantage when using prior knowledge. The reviewer argues that this comparison is unfair due to the added complexity and cost of using two representation models. While the comment provides a logical reasoning for the unfairness of the comparison, it lacks specific examples or references to support the claim about the SOTA or the proposed method. This makes the claim somewhat verifiable, as the authors would need to delve deeper into the literature or their own results to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the proposed method has no advantage over the state-of-the-art (SOTA) without prior information. It highlights that the advantage only appears when using prior knowledge, which could be considered unfair due to the added complexity and cost of using two representation models. This feedback is somewhat helpful as it points out a critical aspect of the experimental setup that needs attention. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve the comparison. To be more helpful, the comment could provide recommendations on how to adjust the experimental design or analysis to better evaluate the proposed method. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is an explicit suggestion, as it clearly indicates what the authors should do to improve their draft. However, the comment does not provide specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a suggestion for improvement rather than a claim that requires verification. It does not express an opinion, judgment, or subjective statement that needs justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This is a valuable suggestion as it could provide a more comprehensive understanding of the methods' performance in different scenarios. However, the comment lacks specific guidance on how to implement this suggestion, such as which types of collaborative games to include or how to design the experiments. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of experimental settings for Figures 1 to 9, which makes them difficult to be convincing. However, it does not provide explicit guidance on what specific information should be included in the experimental settings or how the authors should present it. The action is implicit, as the authors need to infer that they should add the missing information, but it is vague because it lacks concrete details on what exactly should be included. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of missing experimental settings, which makes it difficult for the figures to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes them hard to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically noting that the experimental settings for Figures 1 to 9 are missing. This is a critical piece of information that is essential for understanding and evaluating the results presented in the figures. By pointing out this omission, the comment provides the authors with clear and actionable feedback that can help them improve the clarity and credibility of their work. However, the comment could be more helpful if it suggested specific ways to include the experimental settings or provided examples of how to present them effectively. Overall, the comment is mostly helpful as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the ambiguity in the proposed method\\'s ability to avoid impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\\' approach. However, the comment does not provide explicit guidance on how the authors should clarify this issue or what specific steps they should take to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to clarify the method\\'s impact on learning new task knowledge. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It mentions the proposed pathway protection method based on sparsity in activation channels and notes that some parameter isolation methods are tailored to leverage this sparsity. However, the comment highlights the ambiguity in how the proposed method avoids impeding the learning of new task knowledge. While the authors can infer that this relates to the methodology or results sections, the comment does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing the issue of ambiguity regarding the method\\'s impact on learning new task knowledge. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the rationale behind the work is unclear regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\\' approach. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to delve deeper into the literature or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s rationale, specifically the ambiguity surrounding how the proposed pathway protection method avoids impeding the learning of new task knowledge. It highlights a relevant issue by noting that some parameter isolation methods are tailored to leverage sparsity, which could be relevant to the authors\\' approach. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this issue or address the concern. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider this aspect but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the ad-hoc nature of the regularization term and suggests that it lacks theoretical support. It implies that the authors should consider alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. While the comment provides a specific suggestion, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization term, providing a specific critique about its ad-hoc nature and lack of theoretical support. It suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This feedback is specific in detailing what aspect of the regularization needs improvement and provides a concrete suggestion for alternative methods. However, it does not explicitly mention which part of the paper discusses the regularization term, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the regularization term is ad-hoc and lacks theoretical support, despite the author providing an intuitive explanation. The reviewer suggests using alternative statistics, such as the median, which is less sensitive to outliers, to replace the mean and standard deviation in the regularization. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the median is a better choice. The comment could be strengthened by providing more detailed reasoning or examples, making it mostly verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the ad-hoc nature of the regularization term and its lack of theoretical support. It suggests that the authors consider alternative statistics, such as the median, which is less sensitive to outliers, as a replacement for the mean and standard deviation in the regularization. This feedback is clear and actionable, providing the authors with a specific direction for improving their work by exploring alternative methods that could enhance the robustness of their regularization approach. However, the comment could be more helpful if it included examples or further explanation of how the median could be used effectively. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by specifying the need to integrate benchmark comparisons against state-of-the-art fairness algorithms. This would enhance the paper by offering tangible evidence of the proposed method's performance and positioning the ManyFairHPO framework within the existing FairML research landscape. The comment provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for comparisons with existing fairness algorithms and suggests integrating benchmark comparisons against state-of-the-art fairness algorithms. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper by providing evidence of the proposed method\\'s performance. The comment logically reasons that such comparisons are necessary for positioning the ManyFairHPO framework within the existing FairML research landscape. However, it does not provide specific examples of existing fairness algorithms or detailed reasoning on why these comparisons are crucial. While the claim is mostly verifiable, it could be strengthened with more detailed justification or references to specific algorithms. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section of the paper, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would enhance the paper by offering tangible evidence of the proposed method\\'s performance. This feedback is highly valuable as it guides the authors on how to strengthen their experimental section and position their work within the existing research landscape. The comment is specific and actionable, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the supervised pretraining method based on the prediction of the homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to homo, lumo, and gap. The comment also questions the claim of the paper being a \"general-purpose neural network model\" in light of this observation. While the comment identifies a potential issue and provides an example, it does not explicitly instruct the authors to address this concern or suggest specific changes to improve the paper. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and address the potential negative transfer issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"prediction of homo-lumo gap\" and references the \"QM9\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the potential issue of negative transfer and provides an example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to homo, lumo, and gap. This specificity helps the authors understand what needs to be addressed in their paper, particularly regarding the claim of being a \"general-purpose neural network model.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of the homo-lumo gap may lead to negative transfer, citing an example from the QM9 dataset where Transformer-M performs poorly on most tasks except those related to homo, lumo, and gap. This claim is somewhat verifiable as it provides a specific example to support the assertion of negative transfer. However, the comment lacks detailed reasoning or references to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the supervised pretraining method based on the prediction of the homo-lumo gap, suggesting that it may lead to negative transfer. It provides an example from the QM9 dataset, where Transformer-M performs poorly on most tasks except those related to homo, lumo, and gap. This observation challenges the claim of the paper being a \"general-purpose neural network model.\" The comment is helpful as it highlights a specific area of concern and provides a concrete example to support the claim, allowing the authors to consider this issue in their work. However, it could be more helpful if it offered suggestions on how to address the negative transfer issue or improve the generalizability of the model. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a detailed explanation of why this term might be misleading, noting that it implies the total variation between test and train distributions of the network's outputs vanishing to zero, which may not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide specific guidance on how to rephrase it. While the authors can infer that they should reconsider the term, the action is not explicitly stated, and the feedback lacks concrete details on how to implement the suggested change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the term \"distributional generalization\" used in the paper, suggesting that it might be too strong to describe the empirical phenomenon presented. It provides a detailed explanation of why this term might be misleading, noting that it implies the total variation between test and train distributions of the network\\'s outputs vanishing to zero, which may not be the case. However, the comment does not specify which part of the paper uses this term, making it weakly grounded. The comment is specific in detailing the issue with the term, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the term \"distributional generalization\" might be too strong to capture the empirical phenomenon presented, as it implies the total variation between test and train distributions of the network\\'s outputs vanishing to zero, which may not be the case. The reviewer provides a logical explanation for this concern, noting that the conclusion is based on a few test functions where the outputs match. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific critique of the term \"distributional generalization\" used in the paper, suggesting that it might be too strong to describe the empirical phenomenon presented. The reviewer offers a detailed explanation of why this term might be misleading, noting that it implies the total variation between test and train distributions of the network\\'s outputs vanishing to zero, which may not be the case. This feedback is clear and actionable, as it prompts the authors to reconsider the terminology used in their paper. However, the comment could be more helpful if it suggested alternative terms or provided examples of how the term could be rephrased to better align with the empirical findings. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a subjective opinion about the theoretical contribution being \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to strengthen the theoretical contribution, improve the bound, or enhance the mathematical novelty of the proof. Without actionable advice or suggestions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not specify which part of the paper this assessment is based on, such as a particular section or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which aspects of the paper are being addressed or what specific improvements are needed. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that the bound is weak and unpractical. It also mentions that the proof lacks mathematical novelty. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a subjective assessment of the theoretical contribution, stating that it is \"ok but not particularly strong\" compared to existing results. It also mentions that the bound is weak and unpractical and that the proof lacks mathematical novelty. However, the comment does not offer any specific suggestions or guidance on how the authors might improve their theoretical contribution or address the perceived weaknesses. Without actionable feedback or constructive advice, the authors are left without a clear path for enhancing their draft. Therefore, the comment is not helpful at all, as it does not provide any meaningful insights or direction for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. While the comment implies that the authors should provide clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the exact change needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the phrase \"is sufficient\" and provides a possible interpretation of what the authors might mean by it, suggesting that they should clarify the context. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the phrase \"is sufficient\" at lines 240 and 428, suggesting that the authors should clarify what they mean by it. The reviewer provides a possible interpretation, indicating that the authors might want to express that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. However, the comment does not provide any evidence or references to support the claim that this interpretation is necessary or accurate. The lack of supporting information makes the claim somewhat verifiable, as the authors would need to infer the necessity of clarification based on the reviewer\\'s suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the text, questioning the phrase \"is sufficient\" at lines 240 and 428. It provides a possible interpretation of what the authors might mean by this phrase, suggesting that they should clarify that the sum of \"optimistic\" hoped-for rewards is close to the expected actual rewards. This feedback is clear and actionable, as it directs the authors to clarify a potentially ambiguous statement in their draft. However, the comment could be more helpful if it offered additional guidance on how to rephrase the sentence for clarity. Overall, the comment is mostly helpful, as it provides a specific area for improvement and offers a constructive suggestion for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the theoretical discussions could be improved, specifically mentioning that the current theorems follow directly from the algorithm design and the property of mutual information to \u0394_DP. It implies that the authors should consider adding sample complexity-type results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. While the comment identifies an area for improvement, it does not provide explicit guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore sample complexity results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical discussions in the paper, suggesting improvements by mentioning the direct relationship between the current theorems and the algorithm design, as well as the property of mutual information to \u0394_DP. It implies that the authors should consider adding sample complexity-type results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the theoretical discussions. The comment is specific in suggesting the type of results that could be added, but it lacks full grounding as it does not specify the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could be improved by providing sample complexity-type results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. The reviewer provides a logical reasoning by mentioning the direct relationship between the current theorems and the algorithm design, as well as the property of mutual information to \u0394_DP. However, the comment lacks specific examples or references to support the claim that such results are necessary or would significantly enhance the paper. While the reasoning is clear, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions of the paper. It suggests that the current theorems could be enhanced by incorporating sample complexity-type results, such as determining the sufficient amount of training data points that would not return NSF, given confidence levels. This feedback is clear and actionable, as it provides a concrete direction for the authors to consider in expanding their theoretical analysis. However, the comment could be more helpful if it offered specific examples or references to guide the authors in implementing these suggestions. Overall, the comment is mostly helpful, as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the description of the VAD (Voice Activity Detection) in the paper, suggesting that it is misleadingly referred to as a VAD. The reviewer argues that the method described is not a true VAD, as it discards TF bins with a magnitude less than epsilon, which is equivalent to discarding TF bins with zero magnitude to avoid division by zero. The reviewer provides a clear critique of the method and its naming, but does not offer specific guidance or suggestions for improvement. While the comment highlights a potential issue with the paper, it lacks actionable advice on how the authors might address this concern. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the \"VAD description\" in the paper, allowing the authors to accurately identify the part being discussed. It is also specific because it clearly specifies the issue with the VAD description, pointing out that the method described is not a true VAD and that it discards TF bins with zero magnitude, which is not typical for VAD. The comment provides a detailed critique of the method and its naming, offering a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the VAD (Voice Activity Detection) description in the paper is puzzling and suggests that it is not accurately described as a VAD. The reviewer provides a logical explanation by pointing out that the method described discards TF bins with a magnitude less than epsilon, which is equivalent to discarding TF bins with zero magnitude to avoid division by zero. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by referencing specific literature or common practices in VAD to further substantiate the claim. Overall, the comment is mostly verifiable, as it provides a logical argument but lacks detailed references or examples to fully support the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the description of Voice Activity Detection (VAD) in the paper. It points out that the method described, which discards TF bins with a magnitude less than epsilon, is not accurately represented as a VAD. The reviewer explains that a true VAD should look for the presence of speech, not just energy, and is typically defined over time, not frequency. This feedback is clear and provides a specific critique of the paper\\'s methodology, allowing the authors to understand and address the issue. However, the comment could be more helpful if it offered suggestions on how to improve the VAD description or provided examples of how to better align it with the definition of VAD. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is difficult to follow and lacks a clear intuition for how the components fit together, which affects the experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their paper. There is no explicit or implicit action for the authors to take, such as revising the presentation or adding more context to the experiments. Without actionable advice, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general critique that the paper is not easy to follow, lacking a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of clarity is most pronounced. The authors might infer that it relates to the experimental sections or the overall structure, but this is not explicitly stated. The comment is not specific about what needs to be addressed or how the authors might improve the clarity. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the components fit together. This feedback highlights a critical area for improvement, as it affects the overall understanding and impact of the experiments. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as restructuring the presentation or adding more context to the experiments. While it points out a key weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should address the fairness of the comparison and provide additional metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed comparisons and metrics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously, and requests the inclusion of KID/FID metrics for the teacher network. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional metrics, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the comparison might not be fair or why the requested metrics are necessary. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It questions whether this simultaneous training affects the performance of the teacher network and suggests that the authors provide KID/FID metrics for the teacher network. This feedback is clear and actionable, as it prompts the authors to consider the implications of their training approach and to provide additional metrics that could help assess the fairness of the comparison. However, the comment could be more helpful if it provided specific guidance on how to address the fairness issue or suggested alternative methods for comparison. Overall, the comment is mostly helpful, as it directs the authors to a critical area that requires further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the refined region vector, specifically whether it effectively scales the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight. While the comment implies that the authors should explore this aspect further, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement or test the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning its effectiveness and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the refined region vector, specifically whether it effectively scales the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight. While the comment provides a logical reasoning about the potential effect of the refined vector, it lacks specific examples or references to support the claim. The suggestion for a scaling variable is an inference based on the provided information, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the refined region vector, questioning its effectiveness in scaling the most important regions by a factor of two before global pooling. It also suggests considering the introduction of a scaling variable before the attention weight, which could potentially improve the model. This feedback is clear and actionable, providing the authors with a specific area to explore and a potential solution to enhance their work. However, the comment could be more helpful if it included additional context or examples to further clarify the issue and the suggested improvement. Overall, the comment is mostly helpful, as it directs the authors to a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, namely that failures on the ALFRED benchmark are often due to goal misspecification. It explains that the LLM does not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the goal specification or how to handle ambiguities in human language. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of goal misspecification in the context of the ALFRED benchmark, specifically mentioning the LLM\\'s inability to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, it does not specify which part of the paper discusses the ALFRED benchmark or the LLM\\'s performance, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\\'s performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, specifically mentioning the LLM\\'s inability to accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is somewhat verifiable as it provides a logical explanation of the issue, but it lacks specific examples or references to support the assertion. The comment does not provide detailed evidence or examples of how goal misspecification leads to failures on the ALFRED benchmark, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the problem of goal misspecification in the context of the ALFRED benchmark. It explains that the LLM\\'s failure to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language, contributes to the failures on the benchmark. This feedback is somewhat helpful as it highlights a critical area for improvement, but it lacks actionable suggestions or guidance on how the authors might address this issue. While it provides insight into a potential weakness, it does not offer specific steps or strategies for enhancing the goal specification or handling ambiguities in human language. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the improvement of the method over state-of-the-art (SOTA) methods like IGEV, suggesting that the effect may not be significantly improved due to the nature of iterative optimization schemes. The reviewer explicitly suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to understand why the improvement is not significant. Additionally, the reviewer questions whether it is difficult for Sampling-Gaussian to significantly improve SOTA schemes, which are mostly iterative frameworks similar to IGEV. These suggestions provide clear and concrete actions for the authors to take, such as conducting an analysis and addressing the concern about the difficulty of improving SOTA schemes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises concerns about the improvement of the method over state-of-the-art (SOTA) methods like IGEV and suggests analyzing the distribution of disparities produced by IGEV compared to other baselines. However, it does not explicitly mention which part of the paper this concern relates to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as analyzing the distribution of disparities and questioning the difficulty of improving SOTA schemes. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the limited improvement of the method over state-of-the-art (SOTA) methods like IGEV, suggesting that this might indicate the absence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a logical reasoning by questioning the significance of the improvement and suggesting an analysis of the distribution of disparities produced by IGEV compared to other baselines. This provides a clear direction for the authors to explore and address the concern. However, the comment could be strengthened by providing specific examples or references to support the claim. Overall, the claim is mostly verifiable, as it offers a logical framework for further investigation but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the limited improvement of the proposed method over state-of-the-art (SOTA) methods like IGEV, suggesting that this might indicate the absence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a clear and actionable suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the comment questions whether it is difficult for the Sampling-Gaussian method to significantly improve SOTA schemes, which are mostly iterative frameworks similar to IGEV. This feedback is valuable as it prompts the authors to explore the reasons behind the limited improvement and consider the potential challenges in enhancing SOTA schemes. However, the comment could be more helpful if it offered specific guidance on how to conduct the analysis or address the challenges. Overall, the comment is mostly helpful, as it provides clear direction for further investigation and improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It explicitly recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback provides a clear and concrete action for the authors to take, as it specifies what additional analysis or presentation could be included to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, it implies that this analysis could be integrated into the results or discussion sections. The authors can infer that this suggestion relates to the evaluation or comparison of different models, making the comment weakly grounded. However, it is specific in detailing what additional analysis could be included to enhance the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper investigation into how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a logical suggestion for enhancing the paper, it lacks specific examples or references to support the claim that such an investigation would add nuance to the conclusions. The suggestion is somewhat verifiable as it provides a clear direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more nuanced analysis by investigating how specific models, such as GPT-4o and InternVL2, behave differently when ReGuide is applied. It recommends presenting the differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper by adding depth to the analysis. However, it could be more helpful if it included examples or further guidance on how to conduct this analysis. Overall, the comment is mostly helpful, as it offers a valuable suggestion for improving the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment is specific and concrete, as it directly instructs the authors to address a particular aspect of their explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. However, it does not specify which part of the paper this clarification is needed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where the clarification is required. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a logical suggestion to improve the clarity of the paper, but it does not contain a claim that requires verification. It is a request for clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests clarifying whether the Fourier modes are real or complex numbers when discussing them as numbers. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their explanation. By addressing this point, the authors can enhance the understanding of their work for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the overall interpretation of the paper. Overall, the comment is mostly helpful as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ appear without explanation, specifically questioning their input and output domains. It also mentions that the notation $\\\\delta$ has some brief description, implying that the issue is more with the lack of explanation for $h, g$. While the comment identifies a problem, it does not provide explicit guidance on how to address it, such as suggesting where to include the necessary explanations or how to clarify the domains. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the notations $h, g$ and $\\\\delta$, questioning their input and output domains. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the sections where these notations are introduced. The comment is specific in pointing out the lack of explanation for these notations, particularly noting that $\\\\delta$ has some brief description, implying that $h, g$ should also be clarified. However, the comment could be more specific by suggesting where this clarification should be included. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the appearance of notations $h, g$ without explanation, specifically asking about their input and output domains. It also mentions that $\\\\delta$ has some brief description, implying that the issue is more with the lack of explanation for $h, g$. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this lack of explanation is problematic or how it affects the paper. Without additional context or justification, the claim remains unverifiable, as it does not offer a clear basis for the authors to address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation $h, g$ appearing without explanation, particularly regarding their input and output domains. It also notes that $\\\\delta$ has some brief description, suggesting that the lack of explanation for $h, g$ is a similar issue. This feedback is somewhat helpful as it points out a potential area for clarification in the paper, which could improve the reader's understanding. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending where to include the necessary explanations or how to clarify the domains. Overall, the comment offers some guidance but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks ablations, specifically mentioning the need to include results using the GCPG model without pre-trained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what additional results should be included to address the concern. The comment is highly actionable because it gives the authors a direct and detailed instruction on how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ablations\" and \"results using the GCPG model without pre-trained initializations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing from the results, namely, the performance gain due to the task formulation versus pre-trained language models. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results are unclear regarding the performance gain due to the task formulation versus pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to clarify this. The comment provides a logical reasoning for the claim by identifying a specific gap in the results that needs to be addressed. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to infer the exact nature of the missing ablations and how they would impact the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s results, namely the lack of ablations to distinguish between the performance gain due to the task formulation and the use of pre-trained language models. It provides a clear and actionable suggestion by recommending the inclusion of results using the GCPG model without pre-trained initializations. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their results, allowing them to better understand and communicate the contributions of their work. However, the comment could be more helpful if it offered additional context or examples of how these ablations might be conducted or interpreted. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to clarify or label the axes, leaving the authors without a clear path for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement describing a difficulty in understanding Figure 1, specifically the axes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 1, noting that it is hard to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to clarify or label the axes to improve the figure\\'s interpretability. However, the comment could be more helpful if it provided suggestions on how to achieve this clarity, such as recommending specific labels or explanations. Despite this, the feedback is mostly helpful as it points out a critical area for improvement, prompting the authors to enhance the figure\\'s readability. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. It also provides a clear reason for this requirement, noting that the proposed method is based on implicit differentiation, which typically incurs additional computational costs. This feedback is direct and provides a concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of \"2 Direct runtime comparisons with existing methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014direct runtime comparisons\u2014and provides a reason for this omission, noting that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed method is based on implicit differentiation, which typically requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are necessary. However, the comment could be strengthened by providing specific examples of existing methods or references to studies that have made such comparisons. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed references or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It provides a clear rationale for why these comparisons are necessary, noting that the proposed approach is based on implicit differentiation, which typically incurs additional computational costs. This feedback is actionable and constructive, as it guides the authors on a specific area where they need to improve their draft to demonstrate the efficiency of their approach. By highlighting the importance of runtime comparisons, the comment empowers the authors to make a meaningful enhancement to their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and questions the technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the framework or what specific aspects need improvement. Without actionable suggestions or feedback, the authors are left without a clear path for revision. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed framework as a simple combination of meta-learning and federated learning, questioning its technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the framework are considered simple or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, questioning its technical contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the technical contribution of the proposed framework, suggesting that it is a simple combination of meta-learning and federated learning. However, it does not provide any specific feedback or suggestions on how the authors might enhance the framework or address the perceived lack of technical contribution. Without actionable guidance or detailed critique, the comment offers little value to the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss case studies and error studies to demonstrate the effectiveness of each proposed component. It provides an example of how this could be done by mentioning a specific case study related to graph pre-training for AMR parsing and generation. While the comment implies that the authors should include case studies, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides a specific example of what could be included, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to demonstrate the effectiveness of each proposed component, specifically mentioning the Element-level Graph Pre-training. It provides an example of a case study related to graph pre-training for AMR parsing and generation. This feedback is specific as it identifies a particular aspect of the paper that could be improved and provides a concrete example of how to address it. However, it is not fully grounded because it does not explicitly mention the section where this discussion should be included, leaving the authors to infer the relevant part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies would enhance the paper\\'s effectiveness. It provides a specific example of a case study related to graph pre-training for AMR parsing and generation, which supports the claim. However, the comment could be strengthened by explaining why case studies are necessary or how they would improve the paper\\'s impact. The suggestion is mostly verifiable as it provides a concrete example, but it lacks detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the paper could be strengthened by including case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of how this could be done, referencing a case study related to graph pre-training for AMR parsing and generation. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the paper\\'s credibility and impact. However, the comment could be more helpful if it provided additional guidance on how to conduct these case studies or integrate them into the paper. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It questions the need for additional evaluation of these aspects and requests clarification on the motivation for considering them. While the comment implies that the authors should clarify their approach, it does not provide explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification without detailed instructions on how to achieve it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"traditional DCI framework,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific details about the evaluation of disentanglement (D) and the potential entanglement between DCI and ES, which helps the authors understand what needs to be clarified. The comment requests clarification on the motivation for considering explicitness (E) and size (S) as extra evaluation, further specifying the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. The reviewer provides examples to support the claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the entanglement between DCI and ES. While the examples provide some support, the lack of comprehensive evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered within it. It provides examples to support this claim, such as the need for a fixed capacity of probing (f) and latent size to evaluate disentanglement (D). The comment also points out the potential entanglement between DCI and ES, which could impact the evaluation. However, it lacks specific suggestions or guidance on how the authors might address these concerns or clarify the motivation for considering explicitness and size as extra evaluations. While the comment identifies an important issue, it does not provide actionable feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. However, the comment does not provide explicit guidance on how to address this issue or suggest specific alternatives. The action is implicit and somewhat vague, as the authors are left to infer that they should explore automated disentangling methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically. However, the comment does not specify which part of the paper discusses the disentangling process or the choice of the semantic segmentation network, making it weakly grounded. The comment is specific in detailing the issue with manual disentangling, but without explicit references to sections or modules, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning the choice of the semantic segmentation network as the first module. The reviewer suggests that it would be more interesting if everything were learned automatically. However, the comment lacks specific reasoning or evidence to support why manual disentangling is a problem or why an automated approach would be preferable. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the manual disentangling process, and questions the choice of the semantic segmentation network as the first module. It suggests that it would be more interesting if everything were learned automatically, implying that the authors should consider an alternative approach. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or explore automated disentangling methods. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the connection between the theoretical analysis and the proposed method. It suggests that the method appears to simply adopt the self-attention mechanism from transformers without explaining how it enhances generalization for distant nodes. However, the comment does not provide explicit guidance or suggestions on how the authors could improve this aspect of their paper. The feedback is vague and lacks actionable steps, leaving the authors uncertain about what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not explicitly mention which part of the paper discusses the theoretical analysis or the proposed method, making it weakly grounded. The comment is specific in detailing the issue with the connection between the theoretical analysis and the proposed method, but without explicit references, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not clearly demonstrate how it enhances generalization for distant nodes, suggesting that it merely adopts the self-attention mechanism from transformers without providing a strong connection to the theoretical analysis. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references to relevant literature makes the claim somewhat verifiable, as it provides a general critique but does not fully substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's explanation regarding the connection between the theoretical analysis and the proposed method. It points out that the method appears to simply adopt the self-attention mechanism from transformers without clarifying how it enhances generalization for distant nodes. This feedback highlights a critical area for improvement, as it suggests that the authors need to provide a more detailed explanation of how their method integrates with the theoretical analysis and enhances generalization. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this gap. Overall, the comment is somewhat helpful as it directs the authors' attention to a significant weakness in their draft, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide explicit guidance on how the authors should address this issue or improve the clarity of the presentation. The comment implies that the authors should clarify or provide more context about the existing methods being used, but it does not specify how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (12),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the presentation of existing methods is vague and can only be understood by checking the original paper. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. This lack of supporting information makes the claim difficult for the authors to address effectively, rendering it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some sections are using existing methods without providing clear explanations. It highlights that the presentation of these methods is vague and can only be understood by referencing the original paper. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors should clarify the use of existing methods and provide more detailed explanations. However, the comment could be more helpful if it offered specific suggestions on how to improve the clarity or provided examples of how to present the methods more effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the stability definition needs better justification, specifically addressing the issue that the left side can be arbitrarily small under certain constructions of \\\\tilde{g}. It implies that the authors should make the stability definition lower bounded, providing a concrete action to improve the draft. However, the comment does not explicitly instruct the authors to make this change, leaving it to be inferred. While the action is clear, the lack of explicit instruction makes the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the stability definition, suggesting that it needs better justification, particularly regarding the left side being arbitrarily small under certain constructions of \\\\tilde{g}. It implies that the definition should be made lower bounded. However, the comment does not specify which part of the paper discusses the stability definition, making it weakly grounded. The authors can infer that it relates to the theoretical or methodological sections, but the exact location is not clearly identified. The comment is specific in suggesting a change to the stability definition, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification, specifically addressing the issue that the left side can be arbitrarily small under certain constructions of \\\\tilde{g}. The reviewer suggests making the stability definition lower bounded as a more reasonable treatment. This claim is somewhat verifiable as it provides a logical reasoning for the need for better justification and suggests a potential solution. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under certain constructions of \\\\tilde{g}. It suggests that a more reasonable approach would be to make the stability definition lower bounded. This feedback is clear and actionable, providing the authors with a specific area for improvement in their theoretical framework. By addressing this issue, the authors can strengthen the foundation of their work. However, the comment could be more helpful if it offered additional guidance on how to implement the suggested change or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. It also mentions that issues should be addressed and implies that the work should be considered for a more application-oriented venue. However, the comment does not provide specific guidance on how to conduct the comparison or address the issues, leaving the authors with a vague understanding of the actions needed. While the suggestion to compare against existing methods is explicit, the lack of concrete details on how to execute this makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"notations issues,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests comparing the effectiveness of the methodology against existing methods, such as contrastive decoding, and implies that the paper should be considered for a more application-oriented venue if the issues are not addressed. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, specifically mentioning contrastive decoding. However, it does not provide specific examples or references to support why this comparison is necessary or how it would improve the paper. The claim is somewhat verifiable as it highlights a potential area for improvement but lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding. This is a clear and actionable suggestion that could enhance the paper\\'s contribution and relevance. Additionally, the comment mentions \"issues mentioned above\" that should be addressed, implying that the reviewer has previously pointed out specific problems that need to be resolved. However, the comment does not elaborate on what these issues are, which limits its helpfulness. Overall, the feedback is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the algorithm\\'s effectiveness and problem, specifically its requirement for access to the entire training dataset. It questions how the algorithm would operate effectively when the training dataset is not fully perceptible. Additionally, it critiques the comprehensiveness of the related validation experiments, the analysis of time complexity and efficiency, and suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be done. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several aspects of the paper, including the algorithm\\'s effectiveness, the problem of requiring access to the entire training dataset, the comprehensiveness of validation experiments, and the analysis of time complexity and efficiency. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. While the comment provides specific feedback on the content, it lacks grounding as it does not explicitly mention specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims, including the effectiveness and problem of the algorithm requiring access to the entire training dataset, the lack of comprehensive validation experiments, and the need for a clearer analysis of time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to fully substantiate them.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the algorithm\\'s requirement for access to the entire training dataset, the lack of comprehensive validation experiments, and the need for a clearer analysis of time complexity and efficiency. It also suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the comment highlights important issues, it lacks specific guidance or suggestions on how the authors might address these concerns. The feedback is somewhat helpful as it points out areas for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed method is not well-positioned in the literature and recommends a thorough literature review to better understand its novelty. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific concept of representing the marginal score as the expectation of scores of distributions conditioned on inputs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out that this concept is not novel and has been used in other works, such as denoising score matching and score-interpolation. It provides examples and suggests that the authors conduct a thorough literature review to better understand the context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. The reviewer supports this claim by referencing specific works, such as denoising score matching and score-interpolation, which use similar concepts. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, suggesting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is not novel. It provides specific examples from the literature, such as denoising score matching and score-interpolation, to support this claim. The comment also recommends a thorough literature review to better understand the context and potential prior work. This feedback is clear and actionable, as it directs the authors to conduct a more comprehensive literature review to position their work effectively. However, the comment could be more helpful if it offered suggestions on how to integrate this literature review into the paper or how to differentiate the proposed method from existing work. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example to support this claim. The reviewer explicitly states that it is necessary to provide a gradient comparison between KL and PCC, which is a clear and direct action for the authors to take. This feedback is highly actionable as it specifies exactly what needs to be done to address the concern, providing a concrete step for the authors to follow. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, providing a clear explanation and suggesting a specific action to address this concern by comparing the gradients of KL and PCC. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence is not convincing. It provides a logical explanation by comparing the gradient distributions of KL divergence and MSE loss, suggesting that the constraint strength of a loss function is defined by its gradient distribution. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific assumption made in the paper regarding the Pearson correlation coefficient (PCC) and its comparison to KL divergence. It provides a logical explanation by discussing the gradient distribution of loss functions, such as KL divergence and MSE loss, to challenge the assumption that PCC is a more relaxed constraint. The comment suggests that the authors should provide a gradient comparison between KL and PCC to substantiate their claim. This feedback is clear and actionable, offering a specific direction for the authors to improve their argument and provide more robust evidence. However, it could be more helpful if it included examples or references to further support the reasoning. Overall, the comment is mostly helpful, as it provides valuable guidance for enhancing the paper\\'s argumentation and evidence, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions why the distribution cannot have changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or conduct the experiments. The authors are left to infer that they need to clarify the resolution of the debate and potentially conduct additional experiments, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and asking about the disentanglement of changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and asks if experiments have disentangled changes in distribution from the removal of information. However, the comment does not provide specific examples or references to support the claim that the resolution is careless or that the experiments are insufficient. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the resolution of a debate that was previously left open in the paper. It questions the assumption that the distribution has not changed and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s argument and encourages the authors to clarify or address this issue. However, the comment could be more helpful if it provided specific suggestions or examples on how to conduct these experiments or clarify the debate. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should reproduce the results of the comparison methods using the same setting as the proposed method, specifically with AdamW and cosine learning rate, to ensure a fair comparison. This is a clear and direct action for the authors to take. Additionally, the comment provides a concrete suggestion by mentioning that most recent methods have their code released, which can be used for reproduction. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific method used for training, \"AdamW with cosine lr,\" and the comparison methods, \"adam with fixed lr.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the unfairness of the comparison and suggests that the authors should reproduce the results using the same setting to ensure a fair comparison. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between the proposed method and other methods is unfair due to the use of different optimizers and learning rates. The reviewer suggests that the authors should reproduce the results using the same setting as the comparison methods to ensure a fair comparison. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action to address it. However, the comment lacks specific references or examples of the comparison methods or their codes, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the comparison methods use Adam with fixed learning rate. The reviewer suggests that the authors should reproduce the results using the same setting as the comparison methods to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific step to take to improve the validity of their comparisons. However, the comment could be more helpful if it included additional guidance on how to access the code of the comparison methods or suggestions on how to implement the suggested changes. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the plots are \"terrible\" due to several issues, including their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are crucial for presenting experimental results and should be clearer. This feedback provides a direct and concrete action for the authors to improve their draft by revising the plots to make them more readable and informative. The comment specifies the issues and suggests that the authors should address these problems to enhance the clarity of their presentation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the plots, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" due to several issues, including their small size, hard-to-distinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the lack of clear labeling of the axes. This detailed critique provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by suggesting specific improvements or alternatives for enhancing the plots. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, including the small size of the plots, difficulty in distinguishing between colors, poorly labeled axes, and visually similar labels. By highlighting these problems, the comment helps the authors understand what needs to be improved to enhance the clarity and effectiveness of their presentation. The feedback is detailed and provides clear guidance on how to address these issues, making it highly helpful for the authors to improve their draft. Therefore, the comment is rated as highly helpful, consistent with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that Table 1 lacks standard deviations and suggests that the experiments could be more extensive to strengthen the submission. However, it does not provide explicit guidance on how to address the issue of missing standard deviations or how to make the experiments more extensive. The comment implies that the authors should consider adding standard deviations to Table 1 and potentially expanding their experiments, but it does not offer concrete steps or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of standard deviations in the table. Additionally, the comment suggests that the experiments could be more extensive, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 lacks standard deviations and suggests that more extensive experiments would strengthen the submission. However, the comment does not provide specific examples or references to support the claim that the experiments are insufficient or how the inclusion of standard deviations would improve the submission. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it lacks standard deviations. This is a clear and actionable piece of feedback that the authors can use to improve their draft. Additionally, the comment suggests that the experiments could be more extensive, which provides a direction for further improvement. However, the comment could be more helpful if it offered specific suggestions on how to expand the experiments or provided examples of what additional data or analyses could be included. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several actions to improve the paper\\'s clarity and structure. It explicitly recommends rearranging the sections to improve the flow (introduction->method->experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. Additionally, it suggests improving the visualization of Figs. 7 and 8. These suggestions are clear and provide concrete steps for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests improving the structure of the paper by rearranging the sections (introduction->method->experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. It also suggests improving the visualization of Figs. 7 and 8. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the overall structure and content of the paper. The suggestion to focus on the IEM in Fig. 3 provides some specificity, but the comment lacks detailed guidance on how to improve the visualization of Figs. 7 and 8. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is \"a bit hard to follow\" and suggests improvements to the structure and focus on specific figures. However, it does not provide specific examples or detailed reasoning to support these claims. The suggestion to improve the structure and focus on the IEM in Fig. 3 is vague and lacks concrete evidence or references to substantiate the need for these changes. As a result, the comment is considered unverifiable, as it does not provide sufficient justification or evidence to support the claims made.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including its structure and clarity. It suggests rearranging the sections to improve the flow (introduction->method->experiments) and emphasizes the importance of focusing on the IEM in Fig. 3, which is considered the main figure. Additionally, it recommends improving the visualization of Figs. 7 and 8. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the readability and impact of their work. However, the comment could be more helpful if it included specific examples or detailed feedback on how to improve the visualization of the figures. Overall, the comment is mostly helpful as it offers constructive feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which architectures or tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but may not know exactly how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper this suggestion pertains to, such as the experimental section or the results. This makes it difficult for the authors to pinpoint the exact area that needs revision. The comment is specific in suggesting additional experiments, but it lacks grounding, as it does not clearly identify the sections or elements being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a subjective opinion or suggestion, as it implies that the current scope of experiments is limited and that exploring other architectures and tasks could provide valuable insights. However, the comment does not provide specific examples or references to support why these additional experiments would be beneficial or how they might impact the results. Without detailed justification or evidence, the claim remains somewhat verifiable, as the authors would need to infer the potential value of these additional experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it identifies a potential limitation in the scope of the experiments and encourages the authors to consider broader applicability. However, the comment lacks specific guidance on which architectures or tasks to explore, which could be beneficial for the authors in planning their next steps. While it provides a direction for improvement, it does not offer detailed actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the use of a transformer free of locality bias, suggesting that the neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment implies that the authors should address this concern, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the use of a transformer free of locality bias, suggesting that neighborhood agents should have more impact on each other due to the limited speed of information propagation. However, it does not specify which part of the paper this concern is related to, such as a particular section or figure discussing the transformer architecture. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment specifies the issue with the transformer\\'s no-locality, it does not provide detailed guidance on how the authors might address this concern. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses skepticism about the use of a transformer free of locality bias, suggesting that neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. While the comment raises a valid point, it lacks specific examples or references to support the claim that the neighborhood agents should have more impact. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the use of a transformer free of locality bias, suggesting that neighborhood agents should have more impact on each other due to the limited speed of information propagation. The reviewer questions the rationale behind this choice and requests that the authors provide more explanation on why the lack of locality in the transformer does not pose a concern. This feedback is somewhat helpful as it identifies a potential issue with the methodology and prompts the authors to clarify their reasoning. However, it could be more helpful if it provided specific suggestions or examples on how to address this concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or evaluate the trade-offs. The comment implies that the authors should consider the potential impact of these strategies on the model's utility, but it lacks concrete steps or recommendations for improvement. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the impact of mitigation strategies on the overall performance of the model, suggesting a potential trade-off between reducing a particular behavior and maintaining high performance. However, it does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on the model\\'s utility, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting a potential trade-off between reducing a particular behavior and maintaining high performance. The comment logically reasons that if these strategies significantly impair the model\\'s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct additional analysis to fully understand the impact of these strategies. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential impact of mitigation strategies on the overall performance of the model. It highlights the trade-off between reducing a particular behavior and maintaining high performance, which is an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or evaluate the trade-offs. While it identifies a relevant area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, suggesting that it is unclear why this method is required for the problem at hand. However, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment implies that the authors should justify the use of cross-validation, but it does not specify what kind of justification or evidence would be sufficient. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of 6-fold cross-validation for every dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of cross-validation, noting that other papers in the comparison did not use it. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, suggesting that it is unclear why this method is required for the problem at hand. The reviewer provides a logical reasoning by comparing the current work to other papers that did not use cross-validation, implying that the justification for its use is lacking. However, the comment could be strengthened by providing specific examples or references to support the claim that other papers did not use cross-validation. This would make the claim more verifiable. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks detailed evidence.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a valid concern about the use of 6-fold cross-validation in the paper, questioning the necessity of this method given that other papers in the comparison did not use cross-validation. This feedback is somewhat helpful as it prompts the authors to justify the choice of cross-validation, which could lead to a clearer understanding of the methodology and its implications. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or explain the rationale behind their choice. Overall, the comment identifies a potential area for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to clarify the impact of these components. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the incorporation of combinatorial and heuristic aspects and suggests that the authors clarify the impact of these components. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. It suggests that the authors clarify the impact of these heuristic components. However, the comment does not provide specific examples or detailed reasoning to support the claim about the effectiveness of the method or the impact of the heuristic components. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of clarifying these aspects based on the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable suggestion for improving the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to address the issue. Overall, the feedback is somewhat helpful as it identifies an area for improvement and offers a direction for further clarification, but it lacks depth and actionable details. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their method. The comment implies that the authors should clarify or address this issue, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the feasibility of the proposed method without camera information, specifically addressing the \"knowledge of CAD model correspondences\" and the process of ray marching. The comment clearly specifies the issue, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the feasibility of the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer provides a logical reasoning by pointing out the need for camera information to determine the origin of the ray, which is a critical aspect of the method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this critique and provide additional information or clarification to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It points out the importance of knowing the viewpoint for performing ray marching and highlights a potential issue with the method. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their method. While it identifies a potential weakness, it does not provide actionable feedback, leaving the authors with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is somewhat helpful, as it prompts the authors to consider this critical aspect but does not fully support them in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern that the presented method, while using ODA as a method for solving the MOIP problem, does not clearly demonstrate how it improves performance and computation speed over just using ODA. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should clarify the improvements made by their method, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the use of ODA as a method for solving the MOIP problem and questions how the presented method improves performance and computation speed over just using ODA. However, it does not specify which part of the paper discusses ODA or the presented method, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue of lacking clarity on improvements over ODA. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presented method, ODA, has learned to imitate the problem-solving method but does not clearly demonstrate how it improves performance and computation speed over just using ODA. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of concrete evidence or references makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and provide additional information to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the lack of clarity in how the presented method improves performance and computation speed over using ODA alone. It suggests that the method has learned to imitate the problem-solving method but does not provide specific details on how it achieves better results. While the comment identifies a potential weakness in the paper, it lacks actionable guidance or suggestions on how the authors might address this issue. Without specific recommendations or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not provide detailed guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the low-resource regime. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to conduct additional experiments on various datasets and to include results from the full dataset. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the low-resource regime. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where experimental results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its suggestion, it is not grounded, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of just the low-resource regime. However, the comment does not provide any specific reasoning or evidence to support why additional datasets or full dataset experiments are necessary. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also encourages experiments on the full dataset instead of just the low-resource regime. This feedback is clear and actionable, as it provides the authors with a concrete direction for enhancing the robustness and comprehensiveness of their experimental results. However, the comment could be more helpful if it included specific suggestions on which datasets to use or how to analyze the results. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\\' claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their work. The feedback lacks actionable details, such as recommending specific changes to the experimental setup or providing examples of how to clarify the tasks. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the generic argument task and the random argument task in proving the authors\\' claims. It also describes the dataset transformation and experimental setup as \"cumbersome\" and \"not very clear.\" However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of explicit references to sections, figures, or specific elements of the paper results in weak grounding. While the comment is specific in detailing the issues with the tasks and setup, it does not provide enough context for the authors to identify the exact parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task do not clearly prove the authors\\' claims, and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of clarity in the generic argument task and the random argument task, questioning how they support the authors' claims. It also describes the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights areas that need improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed recommendations, the authors are left with a general understanding of the problems but no clear path forward for improvement. Therefore, the comment is somewhat helpful, as it points out weaknesses but does not provide sufficient detail to be fully actionable.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be interesting to see how the model works for tabular data, although it notes that this is not necessary. The comment implies that the authors could consider exploring the application of their model to tabular data, but it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider this extension without clear instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the model to tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the discussion of multi-modal data, but this inference is not direct. The comment is specific in suggesting an area for exploration but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to see how the model works for tabular data, noting that this is not necessary. However, the comment does not provide any reasoning, evidence, or examples to support why exploring tabular data would be beneficial or how it relates to the current work. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests exploring the application of the model to tabular data, which is a specific area of interest. While it acknowledges that this is not necessary, it provides a direction for potential extension or application of the model. However, the comment lacks depth and does not offer specific guidance on how to approach this exploration or what aspects of the model might be relevant for tabular data. The feedback is somewhat helpful as it identifies a potential area for further work, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should add more analysis on the alignment of entity representations, particularly focusing on multilingual alignment and visualizations or case studies for different language types. It also expresses interest in whether entities from low-resourced languages are well aligned with those from high-resourced languages. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the language-agnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting additional analysis on the alignment of entity representations, particularly focusing on multilingual alignment and the inclusion of visualizations or case studies for different languages. Additionally, it expresses interest in the alignment of entities from low-resourced languages with those from high-resourced languages. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has a weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It suggests adding more analysis on multilingual alignment and proposes visualizations or case studies for different languages. The comment also expresses interest in whether entities from low-resourced languages are well aligned with those from high-resourced languages. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim of a weak analysis. The suggestion for additional analysis and visualizations is logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the analysis of the alignment of entity representations, particularly for language-agnostic characters. It suggests that the authors should add more analysis on multilingual alignment and provide visualizations or case studies for different languages. Additionally, the comment expresses interest in whether entities from low-resourced languages are well aligned with those from high-resourced languages. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and presentation. However, the comment could be more helpful if it offered specific examples or methods for conducting these analyses. Overall, the comment is mostly helpful as it guides the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not provide explicit instructions on how to address these issues, such as suggesting ways to remove duplicates or indicating how to verify the publication information. The actions are implicit and somewhat vague, as the authors can infer that they need to check and correct the references list but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. However, it does not specify which part of the paper the references list is located in, making it weakly grounded. The comment is specific in detailing what is wrong with the references, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. This is a factual observation that can be verified by checking the references list. The comment does not require any additional evidence or reasoning beyond the observation itself, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years for many papers. This feedback is clear and actionable, as it provides the authors with concrete areas to address in order to improve the quality and accuracy of their references. By pointing out these issues, the comment helps the authors ensure that their references are properly formatted and complete, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it suggested ways to resolve the duplicates or provided examples of how to verify the publication information. Overall, the comment is mostly helpful as it directs the authors to important aspects of their references that need attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It also provides a clear action for the authors to take: \"The authors need to analyze and compare the theoretical results to other comparable methods.\" This feedback is direct and provides a concrete step for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound, and suggests that the authors should analyze and compare the theoretical results to other comparable methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear and weak. It highlights the lack of clarity regarding the error bound, which is a critical aspect of the theoretical results. The comment also provides a clear suggestion for improvement by recommending that the authors analyze and compare their theoretical results with other comparable methods. This feedback is actionable and provides a specific direction for the authors to enhance the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it offered additional guidance on how to improve the clarity of the error bound or suggested specific methods for comparison. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving a critical aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a request for clarification. Second, it points out the absence of the pseudo-code for the proposed method, which is a clear and explicit action for the authors to take. The inclusion of specific references to relevant literature, such as [1] and [2], provides concrete guidance on how to address the second issue. However, the first part of the comment, while important, is more of a question than a directive, making it less actionable. Overall, the comment is mostly actionable because it provides a clear action for the authors to take regarding the pseudo-code, but it could be more actionable if it included specific guidance on how to address the first question. Therefore, this comment aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which is a general observation and does not specify where in the paper this is discussed. This part of the comment is not grounded as it does not refer to a specific section or part of the paper. Second, it points out the absence of the pseudo-code for the proposed method, which is a specific issue that could be addressed by adding the missing code. However, the comment does not specify where the pseudo-code should be included, making it weakly grounded. The comment is specific in identifying the missing pseudo-code, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two distinct claims. The first claim questions why explicit methods perform better than implicit methods on locomotion tasks, but it does not provide any supporting evidence or reasoning to substantiate this claim. The second claim points out the absence of the pseudo-code for the proposed method, which is a factual observation that requires no justification. However, the comment includes references to relevant literature, such as [1] and [2], which could provide context for the first claim. Overall, the comment is mostly verifiable due to the inclusion of references, but the lack of detailed reasoning or examples for the first claim makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two distinct issues. First, it questions the performance difference between explicit and implicit methods on locomotion tasks, which is a valid point for further clarification or explanation. Second, it points out the absence of the pseudo-code for the proposed method, which is a critical piece of information that should be included for clarity and reproducibility. The inclusion of references to relevant literature, such as [1] and [2], provides context and suggests that the authors should consider these works in their explanation. However, the comment could be more helpful if it offered specific suggestions on how to address the performance difference or provided more detailed guidance on what aspects of the pseudo-code are missing. Overall, the comment is mostly helpful as it identifies important areas for improvement and provides some guidance, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. While the comment implies that the authors should provide a justification or explanation for this limitation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This implies that the comment is addressing the section where the authors discuss the performance of their model on different types of noise. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in its request for a justification or explanation for the limited scope of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors about the reason for only showing results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This is a logical observation that prompts the authors to provide a justification for the limited scope of their results. However, the comment does not provide any specific evidence, examples, or references to support the claim that the model should perform well on other types of noise. The lack of detailed reasoning or supporting information makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why the authors only show results on images corrupted using Gaussian noise, despite mentioning that their model can work well for a variety of image noise. This feedback prompts the authors to consider expanding their evaluation to include other types of noise, which could enhance the comprehensiveness and robustness of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional noise types to test or suggesting ways to incorporate them into the analysis. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should visualize the effect of the existing PU learning methods\\' performance decline as the dimensionality of the data increases. This is a clear and explicit action that the authors need to take to enhance their draft. The comment provides a specific suggestion on how to improve the paper, which is to include visualizations to support the research motivation. This makes the comment highly actionable, as the authors know exactly what step to take to address the feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the performance decline of existing PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial, particularly since it is the research motivation of the paper. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. It is specific in suggesting the need for visualization to support the research motivation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors assert a decline in performance of existing PU learning methods as data dimensionality increases. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as data dimensionality increases. It suggests that visualizing this effect would be beneficial, particularly since it is the research motivation of the paper. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the draft by including visualizations to support the research motivation. However, the comment could be more helpful if it offered additional guidance on how to effectively visualize this effect or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a need to simplify the description of results, specifically mentioning an example of convoluted language. It provides suggestions for improvement by referencing related work and suggesting a check on whether useful communication is happening, given the differences in figures seem too small. The comment also references specific papers for further context. While the suggestions are explicit and provide concrete references, the action is mostly actionable because it gives the authors a clear direction on how to simplify their results description and improve their analysis, but it could be more detailed in terms of specific changes to make. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"result description\" and provides specific examples of convoluted language, allowing the authors to accurately identify the parts of the paper being addressed. It also suggests related work and references specific papers, which further grounds the comment. The comment is specific because it details what is wrong with the result description, provides suggestions for improvement, and references relevant literature. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the result description is needlessly convoluted and suggests simplifying it. It provides specific examples of convoluted language and references related work, such as [1] and [2], to support the suggestion. The references to [1] and [2] offer a basis for the claim that the authors should check for useful communication and consider the differences in figures. However, the comment could be strengthened by providing more detailed reasoning or examples of how the convoluted language affects the clarity of the results. Overall, the claim is mostly verifiable, as it provides some support but could benefit from more detailed justification. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the result description, noting that it is needlessly convoluted. It provides a concrete example of the language used, which helps the authors understand the problem. The comment also offers suggestions for improvement by referencing related work and suggesting a check on whether useful communication is happening, given the differences in figures seem too small. Additionally, it references specific papers ([1] and [2]) for further context, which can guide the authors in refining their analysis and presentation. This feedback is clear, actionable, and provides valuable insights for improving the clarity and effectiveness of the results section, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the approximation error is defined as the gap between objective values, which is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization to clarify this definition. While the comment implies that the authors should include a mathematical characterization, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit, as the authors need to infer the specific action from the feedback. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the definition of approximation error, suggesting that it is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization. However, the comment does not specify which part of the paper discusses the approximation error, making it weakly grounded. The authors can infer that it relates to a section or table where the error is discussed, but they cannot pinpoint the exact location. The comment is specific in suggesting a way to improve the clarity of the definition, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the definition of approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not offer any specific examples, references, or detailed reasoning to support why the current definition is ambiguous or how a mathematical characterization would improve clarity. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique and develop their own understanding of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous without seeing the values in the table. It suggests that providing a mathematical characterization would improve clarity. This feedback is somewhat helpful as it points out a specific area for improvement and offers a constructive suggestion. However, it lacks depth and does not provide detailed guidance on how to implement the mathematical characterization or what specific aspects of the definition need clarification. While it gives the authors a direction to improve their draft, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the proposed model: first, it notes that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. Second, it points out that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to improve the model or suggest alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the proposed model, such as the reassignment probability and the evolution model. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, leading to slow dynamics. It also notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment provides a logical explanation for the slow dynamics, it lacks specific examples or references to support the claim about the simplicity of the evolution model. This makes the claim somewhat verifiable, as it requires further evidence or detailed reasoning to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the proposed model. First, it points out that the model's reassignment probability of 1/n results in only one node changing cluster per time step on average, leading to slow dynamics. Second, it notes that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment highlights these weaknesses, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve their model. The feedback is somewhat helpful as it directs the authors' attention to areas needing improvement, but it lacks depth and specific advice, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that there are missing details about the division of the dataset into training and test sets, including numbers and the method used for division. It suggests that these details should be added. The comment provides a clear and concrete action for the authors to take, which is to include these details in their draft. This makes the comment highly actionable, as the authors know exactly what needs to be done to improve their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details about the division, numbers, and the method used (e.g., random or other considerations). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division of the dataset into training and test sets, including numbers and the method used for division. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing information. The comment lacks detailed reasoning or evidence, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the division of the dataset into training and test sets. It highlights the importance of including numbers and the method used for division, such as whether it was done randomly or with other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or why it is crucial for the paper. Overall, the comment is mostly helpful, as it directs the authors to a critical aspect of their methodology that needs clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the challenges of building text descriptions for each task, which requires human labor, and notes the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with long-text input. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these challenges or improve the scalability of the framework. Without actionable suggestions or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the challenges of building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with long-text input. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights specific challenges, it does not provide detailed guidance on how to address them. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with long-text input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights two main concerns: the need for human labor in building text descriptions for each task and the variability in optimal textual formats for policy learning. It also mentions the potential scalability issue with long-text input. While the comment identifies important challenges and limitations in the framework, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problems but without a clear path forward for improvement. Therefore, the comment is somewhat helpful, as it provides insight into areas needing attention but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how to address the lack of theoretical results or suggestions for potential improvements. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, it does not specify which part of the paper this claim is based on, nor does it provide details on what theoretical results are expected or missing. This makes it difficult for the authors to identify the exact sections that need attention or improvement. The comment lacks both grounding and specificity, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work does not provide any new theoretical results, despite the use of a new type of loss in the setting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the work does not provide any new theoretical results, despite the introduction of a new type of loss in the setting. This feedback is somewhat helpful as it highlights a potential gap in the paper, suggesting that the authors should focus on developing theoretical contributions to enhance the work. However, the comment lacks specificity and does not provide actionable guidance on how to address this issue or what specific theoretical results could be explored. While it identifies a weakness, it does not offer detailed suggestions for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a hypothesis regarding the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to conduct the analysis or what evidence to provide. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. However, the comment does not explicitly mention which part of the paper this hypothesis is based on, making it weakly grounded. The authors can infer that it relates to the discussion of the dataset or experimental results, but this inference is not direct. The comment is specific in suggesting a hypothesis and asking for evidence, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. However, the comment lacks specific examples or references to support the hypothesis, making it somewhat verifiable. The authors would need to infer the reasoning and provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a hypothesis about the characteristics of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with simple, consistent, or typical object poses, while the impossible part includes images with ambiguous labels, atypical poses, or positions. The reviewer suggests that human test results might support this hypothesis and asks the authors to provide more evidence to either prove or disprove it. This feedback is somewhat helpful as it offers a potential explanation for the observed phenomena and prompts the authors to explore this hypothesis further. However, the comment could be more helpful if it provided specific guidance on how to test or validate the hypothesis, such as suggesting particular experiments or analyses. Overall, the comment provides a useful direction for the authors to consider, but it lacks depth and actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. While the comment implies that the authors should expand their testing to include other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should test the model on other tasks but are not provided with specific guidance on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, it does not specify which part of the paper this question pertains to, such as a specific section or results section where the testing results are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment raises a valid point about the scope of testing, it does not provide specific guidance on what the authors should do to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the scope of the model\\'s testing, specifically asking if it was only tested on the single supporting fact dataset (Task 1 of bAbI) and whether other tasks were considered. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\\'s validity. Without additional context or justification, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the scope of the model\\'s testing, specifically noting that it was only tested on the single supporting fact dataset (Task 1 of bAbI) and asking if other tasks were considered. While this comment identifies a potential limitation in the testing scope, it does not provide specific guidance or suggestions on how the authors might address this issue or expand their testing to include other tasks. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 is difficult to follow and recommends improving it by providing more illustrations and examples. While the comment implies that the authors should enhance the clarity of this section, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly how to improve the section or what kind of illustrations and examples would be beneficial. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it is hard to follow and suggesting improvements by providing more illustrations and examples. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 3.2 is difficult to follow and suggests improving it with more illustrations and examples. However, the comment does not provide any specific reasons or examples of why the section is hard to follow, nor does it offer detailed guidance on what kind of illustrations or examples would be beneficial. This lack of detailed justification or evidence makes the claim difficult for the authors to address effectively, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the authors improve the section with more illustrations and examples. This feedback is valuable as it directs the authors to a specific area of their draft that needs enhancement, offering a concrete step to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on what kind of illustrations or examples would be most beneficial. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the repeated calculation of the hypervolume for promising region selection. It also suggests that this computation could be time-consuming for problems with many objectives. While the comment implies that the authors should address the time complexity issue, it does not provide explicit guidance on how to do so. The authors are left to infer that they need to analyze or discuss the time complexity of their algorithm, but without specific instructions or examples, the action remains somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of time complexity and the potential impracticality of the algorithm for problems with many objectives. The comment provides a detailed analysis of the problem, suggesting that the repeated calculation of the hypervolume could be time-consuming and potentially impractical for certain types of problems. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It suggests that this computation could be time-consuming, especially for problems with many objectives. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\\'s efficiency, but it lacks specific examples or references to support the claim. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically the repeated calculation of the hypervolume for promising region selection. It highlights a potential issue that could impact the practicality of the algorithm for problems with many objectives. This feedback is valuable as it prompts the authors to consider and address a significant computational challenge that could affect the usability of their method. However, the comment could be more helpful if it provided suggestions or examples on how to mitigate this issue or offered guidance on how to analyze or discuss the time complexity. Despite this, the comment is mostly helpful as it directs the authors to a critical area that needs attention, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be conducted on medium or large datasets, such as ImageNet, to make the results more convincing. However, it labels this as a \"minor issue\" and notes that it will not affect the overall quality of the paper. While the comment implies that the authors should consider using larger datasets, it does not provide explicit guidance on how to implement this suggestion or why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer the importance and method of addressing this issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset size used in the experiments, suggesting that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting the use of larger datasets, but it lacks detailed guidance on how to implement this suggestion or why it would improve the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of small datasets in the experiments makes the results less convincing and recommends using medium or large datasets like ImageNet. However, the comment does not provide specific examples or detailed reasoning to support why larger datasets would be more convincing or how they would impact the results. The suggestion is based on a general assumption about the importance of dataset size, but it lacks concrete evidence or references to substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper, noting that the datasets used in the experiments are very small. It suggests that including results on medium or large datasets, such as ImageNet, would make the findings more convincing. However, the comment labels this as a minor issue and does not provide specific guidance on how to address it or why it would be beneficial to include larger datasets. While the comment highlights a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. The authors are given a general direction but no detailed steps to enhance their work. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. It suggests that they should delve deeper into the limitations of evolutionary methods, specifically regarding leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, particularly regarding the title, which is deemed too generic and vague. Additionally, the reviewer questions the meaning of \"brittle convergence properties\" and suggests that DeepRL methods are widely adopted, encouraging the authors to consider the landscape 10 years ago. These suggestions are explicit and provide concrete guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for a more precise critique, allowing the authors to identify the relevant parts of the paper. It also addresses the title, suggesting it is too generic and vague, and questions the meaning of \"brittle convergence properties.\" Additionally, the comment provides specific suggestions for improvement, such as exploring state, reactiveness, and learning during an episode, and referencing the adoption of DeepRL methods. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of multiple claims and suggestions, but it lacks specific evidence or references to support these claims. The comment suggests that the authors should delve deeper into the limitations of evolutionary methods, particularly regarding state, reactiveness, and learning during an episode. It also critiques the title as too generic and vague, and questions the meaning of \"brittle convergence properties.\" However, without additional context or references, the claims are not fully verifiable. The suggestion to consider the landscape 10 years ago is a vague reference to historical context without specific examples or evidence. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claims but lacks detailed support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It suggests that the authors should delve deeper into the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. This feedback is actionable and provides a clear direction for enhancing the paper. Additionally, the comment critiques the title as too generic and vague, advising the authors to be more precise in their critique. The reviewer also questions the meaning of \"brittle convergence properties\" and suggests that DeepRL methods are widely adopted, encouraging the authors to consider the landscape 10 years ago. These suggestions are specific and constructive, offering valuable insights for the authors to improve their draft. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these questions. The actions are implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing clarification. The comment is specific in detailing what needs to be addressed, but it is not grounded as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. These are factual questions that require the authors to provide more information or clarification, rather than subjective claims or opinions. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity, such as the synthesis of the focal stack, the forward model using a defocus map and an image, and how edges with depth discontinuities are handled. By raising these questions, the comment provides the authors with clear guidance on what aspects of their work need further explanation or elaboration. However, the comment could be more helpful if it offered suggestions or examples on how to address these gaps in the paper. Despite this, the feedback is mostly helpful as it directs the authors to areas that require more detailed explanation, allowing them to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors include a comparison of their approach, GCG, with other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit action that provides a clear direction for the authors to enhance their draft. Additionally, the comment mentions a minor point about the jailbreaking percentage being low for certain LLMs, which could be a potential area for further exploration or clarification. The feedback is concrete and provides specific guidance on how to improve the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included, namely a comparison of the approach with other LLMs, and mentions a minor point about the jailbreaking percentage. This level of detail provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors showed their approach, GCG, could be transferred to other LLMs and that it could craft adversarial prompts and transfer them to other LLMs. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The mention of a \"minor point\" about the jailbreaking percentage being low for certain LLMs is also not substantiated with evidence or detailed reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable, as it lacks sufficient detail and evidence to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors include a comparison of their approach, GCG, with other LLMs. This is a clear and actionable piece of feedback that could enhance the paper by demonstrating the versatility and applicability of GCG. Additionally, the comment points out a minor issue regarding the jailbreaking percentage being low for certain LLMs, which could be an area for further exploration or clarification. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects of the jailbreaking percentage should be addressed. Overall, the comment is mostly helpful as it offers constructive feedback that can guide the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it does not explicitly instruct the authors to provide a detailed explanation, it implies that the authors should clarify this point to improve the understanding of their work. The action is implicit, as the authors need to infer that they should provide more detailed information. However, the comment is somewhat actionable because it provides a clear direction for improvement, even if it does not specify exactly how to address the issue. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difference between similarity and exit times, providing a clear direction for the authors to clarify this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the authors\\' approach to unsupervised feature selection from a diffusion perspective and expresses confusion about the difference between similarity and exit times. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of novelty or the confusion about the concepts. Without additional context or explanation, the authors may find it challenging to understand the basis of the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area of confusion in the paper, specifically the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to understand the distinction. This feedback is somewhat helpful as it points out a specific area where the authors could improve the clarity of their work. However, it lacks depth and does not provide specific suggestions on how to address the issue or enhance the explanation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not explicitly instruct them to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these limitations further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not make a claim or provide any evidence to support the need for further exploration of these limitations. The comment is more of a query than a claim, and without any supporting reasoning or examples, it is difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While it identifies a potential area for further exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment highlights a potential gap in the framework but does not offer actionable advice or insights to help the authors improve their work. Therefore, the comment is somewhat helpful, as it provides a direction for further investigation but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It suggests that the authors could consider using the Kialo dataset instead, which is cleaner and more established. However, the comment does not explicitly instruct the authors to use the Kialo dataset or provide specific guidance on how to integrate it into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using the Kialo dataset but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the creation of the dataset and the use of the Kialo dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the optional nature of creating the dataset and suggests using the Kialo dataset, which is well-studied in the community, as it provides pairs of short claims and their counters. The comment further notes that the Kialo dataset is cleaner since it does not rely on automatic processes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the creation of the dataset is optional and suggests using the Kialo dataset instead. It provides a logical reasoning by stating that the Kialo dataset is well-studied and cleaner, as it does not rely on automatic processes. However, the comment lacks specific examples or references to support the claim about the Kialo dataset being \"cleaner\" or the benefits of using it. This makes the claim somewhat verifiable, as it provides a general rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential improvement in the paper by suggesting that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It highlights the benefits of using the Kialo dataset, noting that it is well-studied and cleaner since it does not rely on automatic processes. This feedback is clear and actionable, as it provides the authors with an alternative dataset to consider, which could enhance the quality and relevance of their work. However, the comment could be more helpful if it included specific guidance on how to integrate the Kialo dataset into the paper or discussed potential implications of using it. Overall, the comment is mostly helpful, as it offers a valuable suggestion for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the number of tasks in the experiments is considered limited and suggests that the authors should include several tasks (at least 10) and sequential results in terms of tasks learned rather than epochs. The comment also includes a question for the authors to address their comments on weaknesses. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft, which is to expand the number of tasks and present results in a different format. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically mentioning the limited number of tasks and the desire to see several tasks and sequential results. However, it does not specify which part of the experiments section this feedback pertains to, such as a particular figure or table. The authors can infer that it relates to the experimental setup or results section, but this inference is not as direct as it could be. The comment is specific in detailing what the authors should address, namely the number of tasks and the presentation of results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of tasks in the experiments is limited and suggests that the authors should include several tasks (at least 10) and present results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning or evidence to support why 10 tasks are considered sufficient or why the current presentation is inadequate. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the number of tasks considered in the experiments, suggesting that the authors should include more tasks (at least 10) and present results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental setup and presentation. However, the comment could be more helpful if it offered additional guidance on how to select or design these additional tasks or how to present the results effectively. Despite this, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their experimental section. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not provide any explicit guidance or suggestions on how to address this issue. The comment lacks concrete details or actionable steps for the authors to follow, leaving them without a clear understanding of what needs to be done to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the parameter S, indicating that its setting remains a problem. However, it does not specify which part of the paper discusses this parameter or where the issue arises. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of setting the parameter S are problematic or how it could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the parameter S, stating that its setting remains a problem. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is an issue or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the parameter S, noting that its setting remains a problem. However, it does not provide any guidance or suggestions on how to address this issue or improve the draft. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to resolve the problem. This lack of specificity and guidance makes the comment barely helpful, as it highlights a potential issue but does not offer any meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a human evaluation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the section discussing caption generation or evaluation metrics. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the human evaluation should be considered or how it would improve the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. This claim is somewhat verifiable as it provides a logical reasoning for why human evaluation might be more convincing. However, the comment lacks specific examples or references to support the claim that automatic metrics are misleading, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a reasonable basis for the claim but could be improved with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is somewhat helpful as it identifies a potential weakness in the evaluation methodology and suggests an alternative approach that could provide more robust insights. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the human evaluation or what aspects should be evaluated. While it points out a potential area for improvement, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental setup should be clarified regarding the semi-real nature of the multi-node seed cascades, which are artificially created by merging single-node seed cascades. This provides a direct and clear action for the authors to take, which is to include this clarification in their draft. The comment is specific and concrete, as it clearly instructs the authors on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setup is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This provides clear guidance on what needs to be clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This claim is supported by the mention of a specific reference ([2]), which provides a basis for the assertion. However, the comment could be strengthened by explaining why this artificial creation affects the realism of the setup or how it impacts the results. Despite this, the reference to [2] provides a clear starting point for the authors to understand and address the issue. Therefore, the claim is mostly verifiable, as it provides a solid foundation for further investigation but could benefit from additional explanation.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that the multi-node seed cascades are artificially created by merging single-node seed cascades, making the setup only semi-real. This is a clear and actionable feedback that the authors should address by clarifying this aspect in their paper. By pointing out this potential limitation, the comment helps the authors improve the transparency and validity of their experimental setup. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered additional context for understanding the implications of this artificial creation. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the datasets and models used, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or what specific datasets or models should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their analysis to include more diverse datasets and models, but they are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper in terms of datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also points out the absence of assessments on state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what is missing, such as assessments of other biases and datasets, and the inclusion of state-of-the-art generative models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has limited datasets and models, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also notes the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights a limitation, it does not provide specific examples or references to support the claim about the absence of other biases or datasets. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to conduct further research to fully understand the scope of the limitation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation in the paper, specifically noting that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not considered. It also points out the absence of assessments on state-of-the-art generative models like GPT. This feedback is clear and actionable, as it highlights areas where the authors can expand their analysis to provide a more comprehensive evaluation of biases and models. However, the comment could be more helpful if it suggested specific datasets or models that should be included or provided guidance on how to incorporate these assessments. Despite this, the comment provides valuable insights that can guide the authors in improving their draft, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the sensitivity of the method to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a suitable value for $\\\\alpha$. While the comment identifies an issue, it does not provide explicit guidance on how to conduct this search or what specific steps the authors should take to address the sensitivity. The action is implicit and somewhat vague, as the authors can infer that they need to perform hyperparameter tuning but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the method to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a proper $\\\\alpha$. However, it does not specify which part of the paper discusses the method or the hyperparameters, making it weakly grounded. The comment is specific in detailing the issue of sensitivity and the need for hyperparameter search, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a proper $\\\\alpha$. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or comparisons to other methods that might be less sensitive to hyperparameters. Without additional evidence or context, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method\\'s sensitivity to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a suitable value for $\\\\alpha$. This feedback is somewhat helpful as it highlights a critical aspect of the method\\'s applicability and suggests a specific area for improvement. However, the comment lacks depth and does not provide detailed guidance on how to conduct this hyperparameter search or what specific parameters might be most influential. While it points out a relevant issue, it does not offer actionable steps for the authors to address it effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with Figure 3, stating that it is challenging to understand due to unclear workflow and captions, as well as confusing representation of communication modes on the left side. This provides a clear and direct action for the authors to take: improving the clarity of Figure 3 by enhancing the workflow and captions, and clarifying the representation of communication modes. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, including the unclear workflow and captions, and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be improved in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusing representation of communication modes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it difficult to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as a confusing representation of communication modes. This feedback is clear and actionable, as it provides a direct area for improvement that the authors can address to enhance the clarity and effectiveness of their figure. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the figure or provided examples of better practices. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. While it identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this point in their draft. The action is implicit, as the authors need to infer that they should provide a clearer explanation of this term. However, the comment lacks concrete details on how to address the issue, making it somewhat actionable. The authors know they need to clarify the term but may not be entirely sure how to do so without further guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where the clarification is needed. The comment is specific in identifying the issue with the term \"learned [MASK] embedding,\" but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage. However, it does not provide any supporting evidence, reasoning, or references to clarify why this term is unclear or how it could be improved. The comment lacks specific details or examples that would help the authors understand the issue or suggest how to address it. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to make improvements. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage. This is a clear and actionable feedback that the authors can use to clarify their work. By addressing this point, the authors can improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it provided additional guidance on how to clarify the term or suggested potential sources of confusion. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the reported results appear to be partially derivative, as they extend to hyper-networks results already presented in the literature for standard networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue, such as suggesting ways to differentiate the results or provide additional context. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, as they extend to hyper-networks results already presented in the literature for standard networks. However, it does not specify which part of the paper these results are presented in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the results are derivative or how they relate to the literature. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the reported results are \"partially derivative,\" suggesting that they extend results already presented in the literature for standard networks to hyper-networks. However, the comment lacks specific references or detailed explanations to support this claim. Without additional context or examples, it is challenging for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the reported results seem to be partially derivative, as they extend results already presented in the literature for standard networks to hyper-networks. However, it does not provide any specific examples or references to support this claim, nor does it offer suggestions on how the authors might differentiate their results or address this issue. Without actionable feedback or detailed guidance, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as not helpful at all.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The comment indicates that Figure 3 is difficult to read, but it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might enhance the readability of the figure, such as suggesting changes to the font size, color scheme, or layout. Without actionable advice, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by stating that the figure is \"very hard to read,\" which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why the figure is difficult to read. Without additional context or explanation, the claim remains unsubstantiated, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any suggestions or guidance on how the authors might improve the figure\\'s readability. Without actionable advice or specific feedback on what changes could be made to enhance the figure, the comment provides limited value to the authors. It highlights a problem but does not offer a path forward for resolution, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first part, \"The GAT is trained with the whole model?\" is a question that implies the need for clarification or confirmation regarding the training process of the GAT. However, it does not provide explicit guidance on how to address this issue. The second part, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" suggests that the text should be reviewed by a native English speaker and that some sentences need rewriting for clarity. While this provides a general direction, it lacks specific guidance on which sentences need rewriting or how to improve clarity. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper discusses the GAT or where the need for a native English speaker\\'s review is mentioned. However, it is specific in suggesting that the GAT is trained with the whole model and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, even if the authors cannot pinpoint the exact sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim, \"The GAT is trained with the whole model?\" is a question that seeks clarification and does not contain an opinion or judgment that requires verification. The second claim, \"Needs to be reviewed by a English native speaker and some sentences need to be rewriting for improving the clarity,\" is a suggestion for improvement but lacks specific examples or reasoning to support why a native speaker\\'s review is necessary or which sentences need rewriting. This makes the comment barely verifiable, as it does not provide sufficient evidence or justification for the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two separate issues. First, it questions whether the GAT is trained with the whole model, which could be a critical aspect of the methodology that needs clarification. Second, it suggests that the text should be reviewed by a native English speaker to improve clarity, indicating that some sentences may be unclear or poorly phrased. While the comment highlights important areas for improvement, it lacks specific guidance on how to address the first issue or which sentences need rewriting for clarity. This makes the feedback somewhat helpful, as it points out potential weaknesses but does not provide detailed actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate observations. The first part suggests replacing a specific mathematical expression with an arbitrary parameter, which implies that the authors should consider using a more general or flexible approach. However, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The second part questions the choice of a specific learning rate value, suggesting that the authors should provide a justification for this choice. While the comment identifies areas for improvement, it lacks concrete details on how to address these issues, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119-121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with replacing a mathematical expression with an arbitrary parameter and questions the choice of a specific learning rate value, suggesting that the authors should provide a justification for this choice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim questions the replacement of a mathematical expression with an arbitrary parameter, but it does not provide any reasoning or justification for why this change might be problematic. The second claim questions the choice of a specific learning rate value, noting that it differs from the Adam default value, but it does not offer any explanation or evidence to support why this choice is inappropriate. Without additional context or reasoning, the claims are difficult for the authors to address, making them unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, suggesting that this change might not be justified. Second, it questions the choice of a specific learning rate value, noting that it differs from the Adam default value and lacks a clear justification. While the comment highlights areas that need clarification or justification, it does not provide detailed guidance on how the authors might address these issues or why these changes are problematic. The feedback is somewhat helpful as it directs the authors to areas that require further explanation, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to conduct error analysis in the paper and provide detailed explanations of the model\\'s performance under different scenarios. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the draft. The comment also provides a rationale for why this is important, stating that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting error analysis and providing detailed explanations of the model\\'s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where error analysis could be included. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its request for error analysis, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not provide specific examples or references to support why error analysis is necessary or how it would aid in guiding subsequent improvements. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of error analysis based on general knowledge. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would provide more detailed guidance for the authors. Overall, the comment is mostly helpful as it directs the authors toward a significant improvement in their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests analyzing the domain gap and discussing the differences between datasets. It implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. Additionally, it suggests that if the method can fine-tune a pre-trained model on synthetic data, it would enhance the value of the approach. While the comment provides a clear direction for analysis and discussion, it does not specify how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap and discussing the differences between datasets, which implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. It also mentions the potential value of the approach if it can fine-tune a pre-trained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, such as discussing the domain gap and the potential for fine-tuning on synthetic data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap and discusses the potential value of the approach if it can fine-tune a pre-trained model on synthetic data. However, the comment lacks specific examples or references to support the claim about the domain gap or the benefits of fine-tuning on synthetic data. This makes it difficult for the authors to fully understand and address the feedback. The lack of detailed reasoning or evidence renders the claim somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests analyzing the domain gap and discussing the differences between datasets. It implies that the authors should consider the proximity of datasets to each other and how this affects the adaptation process. Additionally, it highlights the potential value of the approach if it can fine-tune a pre-trained model on synthetic data. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a direction for further analysis. However, it lacks detailed guidance on how to conduct this analysis or what specific aspects to focus on, which limits its comprehensiveness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This comment provides a clear and explicit action for the authors to take, which is to include an NCE-based method in their comparison. The reference to a specific study provides concrete guidance on how to implement this suggestion, making the action highly actionable. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a study that shows the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion should be made in, nor does it provide detailed guidance on how to incorporate this comparison. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This claim is somewhat verifiable as it provides a reference to a study that supports the feasibility of the suggestion. However, the comment lacks specific details or examples of how this comparison would enhance the paper, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include at least one NCE-based method for comparison, referencing a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing a specific suggestion for enhancing the paper by broadening the scope of comparisons. However, the comment could be more helpful if it offered additional guidance on how to incorporate this comparison or why it is important for the paper. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests two improvements for the experiment section: conducting a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment explicitly states these actions, it does not provide detailed guidance on how to conduct the significance test or which specific LLMs should be compared. The authors are given a clear direction but lack specific instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements for the \"experiment section,\" which provides some grounding as it indicates a specific part of the paper. However, it does not specify which part of the experiment section needs improvement, such as the methodology, results, or discussion. The comment is specific in suggesting the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). However, the lack of explicit references to sections or specific elements of the experiment makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests improvements for the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with recent Large Language Models (LLMs). While the comment provides a logical suggestion for enhancing the experiment, it lacks specific examples or references to support why these changes are necessary or beneficial. The claim is somewhat verifiable as it offers a direction for improvement but requires more detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experiment section, suggesting that a significance test should be conducted on human evaluation results and that the proposed method should be compared with recent Large Language Models (LLMs). These suggestions are clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experiment. However, the comment could be more helpful if it included specific examples of LLMs to compare with or detailed guidance on conducting the significance test. Overall, the feedback is mostly helpful as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a specific previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" published in ICML2019, and to illustrate the relationship between this work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' claim about the lack of research on joint error for UDA and references a specific previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" published in ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the authors should discuss the relationship between their work and the mentioned previous work, and explain why their method is better. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' assertion about the lack of research on joint error for UDA is incorrect, as it has been studied in previous works like \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" in ICML2019. The reviewer provides a specific reference to support the claim, which is a clear and robust form of evidence. This makes the claim fully verifiable, as it is well-supported by a direct reference to existing literature. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' claim that there is no research focusing on the joint error for UDA. It points out that this problem has already been studied in a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" published in ICML2019. The comment provides a specific reference and suggests that the authors should discuss this work and explain the relationship between it and their proposed method, as well as why their method is better. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by addressing the gap in their claim and providing a more comprehensive discussion of related work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, suggesting that the performance of the paper may be unfairly attributed to the use of a newly collected large dataset (209M) compared to the smaller datasets used by existing methods. The reviewer implies that the superior performance of the proposed method could be due to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should consider the impact of dataset size on the results and potentially adjust their analysis or comparisons accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a newly collected 209M dataset versus smaller datasets used by existing methods like GEM, which employs only 20M unlabeled data. This provides a clear context for the issue, allowing the authors to identify the part of the paper being discussed as the section comparing the proposed method with SOTA methods. However, the comment does not specify what needs to be addressed or how the authors should adjust their comparison to make it more fair. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods may be unfair due to the use of a newly collected large dataset (209M) compared to smaller datasets used by existing methods. The reviewer provides a specific example of GEM using only 20M unlabeled data, which supports the claim that the scale of datasets can significantly impact accuracy. This reasoning is logical and provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed comparisons or references to specific studies to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of the comparison with state-of-the-art (SOTA) methods. It points out that the performance of the paper is based on a newly collected large dataset (209M), while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be due to the larger dataset rather than the method itself. This feedback is clear and actionable, as it prompts the authors to consider the impact of dataset size on their results and potentially adjust their analysis or comparisons to ensure a fair evaluation. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending the use of a common dataset for comparison or suggesting additional experiments. Overall, the comment is mostly helpful, as it directs the authors to a critical aspect of their evaluation that needs attention.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that powerful pre-trained language models, such as BERT and XLNet, should be used as the base encoder for all methods to overcome the domain-shift problem. It implies that the authors should compare the efficacy of the transfer parts rather than using the simplest n-gram features. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specific guidance on integrating these models or how to compare the efficacy of the transfer parts. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods to address the domain-shift problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the use of these models, but it is not grounded, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that powerful pre-trained language models like BERT and XLNet can help overcome the domain-shift problem in NLP. It implies that using these models as the base encoder could improve the efficacy of the transfer parts compared to using n-gram features. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The suggestion is based on general knowledge about the capabilities of these models, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a suggestion for improving the approach to domain adaptation in the NLP field. It recommends using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, which could help overcome the domain-shift problem. This is a clear and actionable piece of feedback that could significantly enhance the draft by suggesting a more effective approach. However, the comment could be more helpful if it included additional guidance on how to integrate these models or compare their efficacy with the current n-gram features. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the complexity of the proposed method, noting that it has several complicated modules and more parameters than the baselines. It questions whether the performance gain is due to a specific module or simply because of the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue and implies that the authors should conduct a more comprehensive ablation study to clarify the source of the performance gain, it does not explicitly instruct the authors to perform such a study. The action is implicit and somewhat vague, as the authors can infer the need for a more detailed ablation study but may not know exactly how to conduct it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed method\" and \"the current version of the ablation study,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of complexity and the need for a more definitive ablation study to determine whether the performance gain is due to a particular module or the increased number of parameters. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the complexity of the proposed method and questions whether the performance gain is due to a specific module or the increased number of parameters. The comment highlights the lack of clarity in the ablation study, which is a valid observation. However, it does not provide specific examples or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to conduct a more thorough analysis to address the concern, but the comment itself lacks the depth needed to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, noting its complexity and the potential for the performance gain to be attributed to the increased number of parameters rather than specific modules. It highlights the lack of clarity in the ablation study, which is essential for understanding the contributions of individual components. This feedback is valuable as it points out a specific area where the authors need to provide more detailed analysis or experiments to substantiate their claims. However, the comment could be more helpful if it suggested specific ways to conduct the ablation study or provided examples of how to address the complexity issue. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the explanation of a specific section (lines 196-197) and suggests that more detail is needed to understand why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide explicit guidance on how to address this issue or what specific information should be added. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more explanation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 196-197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for more explanation regarding the difference between the two quantities and how they capture the difference in learning settings. The comment also includes a personal opinion about the acceptance of the paper, but this does not detract from the specificity of the feedback regarding the explanation needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the explanation of a specific section (lines 196-197) and suggests that more detail is needed to understand the difference between the two quantities and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would improve the paper. The claim is based on a subjective opinion and lacks verifiable evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires more explanation, namely the difference between two quantities discussed in lines 196-197. It questions why these quantities are different and how they capture the difference in learning settings. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment also includes a personal opinion about the acceptance of the paper, which, while interesting, does not directly contribute to improving the draft. Overall, the comment is somewhat helpful as it points out a need for clarification but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and direct, providing the authors with a specific action to take. The comment also specifies what needs to be addressed, which is the sensitivity of these parameters. Therefore, the comment is highly actionable, as it gives the authors precise guidance on how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to \"4.]\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed: the sensitivity of fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should address in their response. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information or discussion, rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific in its request for the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is actionable and provides a clear direction for the authors to enhance their draft by addressing a specific aspect of their methodology. By highlighting this area, the comment helps the authors to improve the comprehensiveness and robustness of their work. Therefore, the comment is rated as highly helpful, as it offers valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests an interesting direction for further exploration, which is to test the proposed framework with different policy gradient approaches. However, it does not provide explicit guidance on how to conduct this exploration or what specific approaches should be considered. The second part asks a question about the number of random seeds used for learning policies, which is an explicit request for clarification. While the first part is vague, the second part is clear and actionable. Overall, the comment is mostly actionable because it provides a concrete request for clarification but lacks detailed guidance on the first suggestion.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The second part of the comment asks about the number of random seeds used for learning policies, which is specific but still does not provide clear grounding as it does not specify the exact section or context where this information is discussed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts: a suggestion to explore the proposed framework with different policy gradient approaches and a question about the number of random seeds used for learning policies. The first part is a suggestion and does not contain a claim that requires verification. The second part is a factual question seeking clarification, which is not a claim. Therefore, the entire comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct points. The first part suggests an interesting direction for further exploration by asking if the proposed framework works with different policy gradient approaches. This is a valuable suggestion that could enhance the paper\\'s scope and applicability. However, it lacks specific guidance on how to conduct this exploration or which approaches to consider, making it somewhat helpful. The second part is a factual question about the number of random seeds used for learning policies, which is clear and actionable. While the comment offers some useful insights, it could be more helpful if it provided more detailed guidance on the first suggestion. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper\\'s evaluation is limited to a single dataset and task, and that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. While the comment implies that the authors should expand their evaluation to multiple datasets and tasks, it does not provide specific guidance on which datasets or tasks to consider or how to implement this expansion. The action is implicit and somewhat vague, as the authors can infer the need for broader evaluation but may not know exactly how to achieve it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s evaluation is limited to a single dataset and task, implying that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify which additional datasets or tasks should be considered. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper\\'s evaluation is limited to a single dataset and task, suggesting that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This claim is somewhat verifiable as it provides a logical reasoning for why the evaluation should be expanded. However, the comment lacks specific examples or references to datasets or tasks that could be used for a more comprehensive evaluation, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper\\'s evaluation, noting that it is restricted to a single dataset and task. It suggests that the results and conclusions would be strengthened by applying the analysis to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on which additional datasets or tasks might be relevant or provided guidance on how to integrate these into the analysis. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While the comment implies that the authors should explore this connection, it does not provide explicit instructions or concrete steps on how to incorporate this idea into the paper. The action is implicit and somewhat vague, leaving the authors to infer that they should consider this connection but without clear guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the paper\\'s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the paper\\'s content. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the paper\\'s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address or evaluate the suggestion effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the paper\\'s considerations to kernel (ridge) regression and suggests presenting the work in the \"language of kernel interpolation/smoothing.\" While this comment identifies a potential connection that could enhance the paper\\'s relevance and scope, it lacks specific guidance or actionable suggestions on how to incorporate this idea or explore its implications. The feedback is somewhat helpful as it prompts the authors to consider a broader application of their work, but it does not provide detailed instructions or examples to facilitate this exploration. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 55-64, where it mentions four critical factors affecting the performance of chain-of-thought prompting. The comment implies that the authors should include references to existing studies that have discussed these factors. While the action is explicit, it lacks concrete guidance on which specific studies to reference or how to integrate them into the paper. The authors know they need to add references but may not be entirely sure how to do so effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 55-64, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the need to add supportive references for claims that may be inspired by existing studies. The comment provides a clear example of the factors discussed in the paper and notes that most of these factors have been discussed in existing studies, giving the authors a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides a specific example by referencing lines 55-64, where it mentions four critical factors affecting the performance of chain-of-thought prompting. The comment implies that these factors have been discussed in existing studies, but it does not provide specific references or examples to support this claim. While the suggestion to add references is logical, the lack of detailed evidence or references makes the claim somewhat verifiable. The authors would need to conduct additional research to verify the claim, making it a borderline case.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, suggesting that some claims may be inspired by existing studies and recommends adding supportive references. It provides a specific example by referencing lines 55-64, where it mentions four critical factors affecting the performance of chain-of-thought prompting. By pointing out the need for references, the comment offers a clear and actionable suggestion for improving the paper. However, it could be more helpful if it included specific references to existing studies that have discussed these factors, which would provide the authors with a more detailed path for improvement. Overall, the comment is mostly helpful as it directs the authors to enhance the paper\\'s credibility by providing necessary references.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the tasks presented are somewhat standard, it would be beneficial to include more unique tasks that showcase the diversity of the dataset. The reviewer specifically mentions the possibility of creating interleaved image-text tasks, such as Question Answering from images. This feedback provides a clear direction for the authors to consider adding more diverse tasks to their study, but it does not specify which specific tasks or how to implement them. The action is explicit but somewhat vague, as it lacks detailed guidance on how to create these unique tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the tasks presented in the paper, specifically mentioning \"Figure captioning\" and \"matching figures/sub-figures to appropriate captions.\" It suggests that the tasks are somewhat standard and could be enhanced by including more unique tasks that showcase the diversity of the images or plots. The reviewer provides a specific example of an interleaved image-text task, such as Question Answering from images. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the task descriptions or methodology sections. The comment is specific in suggesting the inclusion of more diverse tasks, but it lacks full grounding as it does not explicitly mention the sections where these tasks are discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks presented in the paper are somewhat standard and could be enhanced by including more unique tasks that showcase the diversity of the images or plots. The reviewer provides a specific example of an interleaved image-text task, such as Question Answering from images, which could be considered. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim that the current tasks are not diverse enough. While the suggestion for additional tasks is clear, the lack of supporting examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by noting that the tasks presented are somewhat standard and could be enhanced by including more unique tasks that showcase the diversity of the images or plots. It provides a specific suggestion for adding an interleaved image-text task, such as Question Answering from images, which could add diversity to the study. This feedback is clear and actionable, offering the authors a concrete direction for improving their work. However, it could be more helpful if it included additional guidance on how to implement these unique tasks or why they are important. Overall, the comment is mostly helpful as it provides valuable insights for enhancing the paper, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relevance of the framework to specific problems, such as non-convex losses and non-norm type defenses. It also asks whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant. Additionally, it questions whether the framework could still provide intuitions on the risk upperbound. The comment does not provide explicit instructions or suggestions for the authors to address these questions or concerns. While it implies that the authors should consider these issues, the lack of concrete guidance or actionable steps makes it difficult for the authors to know exactly how to respond. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.3\" and \"binary classification,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the relevance of the framework to specific problems, such as non-convex losses and non-norm type defenses, and asks whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant. Additionally, it questions whether the framework could still provide intuitions on the risk upperbound. This level of detail provides clear guidance on what aspects of the paper need further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework to specific problems, such as non-convex losses and non-norm type defenses. It questions whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant and whether it could still provide intuitions on the risk upperbound. The comment also asks if the true mean is known through an oracle, whether one could use the covariance or other statistics to design a better defense. While the comment raises valid questions, it lacks specific evidence, examples, or references to support the claims or provide a clear rationale for the questions being asked. This makes the claim somewhat verifiable, as the authors would need to delve deeper into the literature or their own work to fully understand and address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the relevance of the framework to specific problems, such as non-convex losses and non-norm type defenses. It questions whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints would make the algorithm irrelevant and whether it could still provide intuitions on the risk upperbound. Additionally, it asks if the true mean is known through an oracle, whether one could use the covariance or other statistics to design a better defense. These questions prompt the authors to consider the applicability and limitations of their framework, which is valuable for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions or concerns. Overall, the comment is somewhat helpful as it identifies areas for further exploration and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an experiment where the trained models are sparsified to reduce the number of selected features and compared to the proposed model in terms of accuracy. This is an explicit action with concrete details on how to implement it, as it provides a specific experiment to conduct. The authors know exactly what they need to do to address this suggestion, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an experiment where the trained models are sparsified to reduce the number of selected features and compares the accuracy to the proposed model. This provides clear guidance on what the authors could do to enhance their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a suggestion for an additional experiment, asking the authors to consider sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. This suggestion is not a claim or opinion but rather a request for further exploration. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests an additional experiment that could enhance the paper by exploring the effect of sparsifying the trained models on the number of selected features and comparing the accuracy to the proposed model. This feedback is clear and actionable, providing the authors with a specific direction for further analysis that could strengthen their work. However, the comment could be more helpful if it included a rationale for why this experiment would be beneficial or how it might impact the overall understanding of the results. Despite this, the suggestion is valuable and aligns with a score of 4, as it offers a constructive way to improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the extraction of landmark features, and the generation of landmarks on the edge. The reviewer also questions the number of landmarks used, the type of image features, and the fixed radius with different scales. Additionally, they ask about achieving shape invariance. While the comment identifies several areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail about the techniques, specifically the sparsification process, extraction of landmark features, and generation of landmarks on the edge. It also raises questions about the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This provides clear guidance on what aspects of the paper need more detail and explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It raises several specific questions about the sparsification process, landmark feature extraction, and other aspects of the methodology. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. The lack of detailed reasoning or specific examples makes it challenging for the authors to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail about the techniques used, which makes it difficult to reproduce the results. It raises several specific questions about the sparsification process, landmark feature extraction, and other aspects of the methodology. This feedback is clear and actionable, as it provides the authors with a list of areas where they need to provide more detailed explanations to improve the reproducibility and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what additional information could be included. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment does not offer explicit guidance or suggestions on how to address this issue or mitigate the potential biases. The authors are left to infer that they should consider alternative approaches or additional factors to improve the eviction decisions, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies a potential problem but does not provide specific steps for resolution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach to determining chunk significance in FIITED, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The comment is specific in detailing the potential issue of biases introduced by basing eviction decisions solely on utility scores and provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for recent chunks to gain a temporary high utility, leading to premature evictions of other valuable chunks. This claim is somewhat verifiable as it provides a logical reasoning about the potential bias in the utility-based approach. However, the comment lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the utility-based approach to determining chunk significance in FIITED, suggesting that it might introduce biases. It provides a specific example of how recent chunks could gain a temporary high utility, leading to premature evictions of other valuable chunks. This feedback is somewhat helpful as it highlights a potential weakness in the approach and encourages the authors to consider alternative methods or additional factors to mitigate these biases. However, the comment could be more helpful if it offered suggestions or examples of how to address this issue or improve the eviction decisions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contributions to the final result. It suggests that the authors should include quantitative experiments and comparisons between algorithms to provide a clearer understanding of the framework\\'s performance. The comment also implies the need for more detailed explanations of the presented results. While the action is implicit, it is concrete in suggesting specific improvements, such as conducting quantitative experiments and comparisons. The authors can infer that they need to enhance the experimental section to address the reviewer\\'s concerns. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"result section\" and the need for \"quantitative experiments and comparison between selection of algorithms\" or \"a more detailed explanation\" of the presented results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the result section, namely quantitative experiments and comparisons, and the need for detailed explanations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of different parts of the framework and their contributions to the final result are unclear. It suggests that the lack of quantitative experiments and comparisons between algorithms, as well as detailed explanations of the presented results, contributes to this uncertainty. The comment provides a logical reasoning by highlighting the absence of specific details that would clarify the framework\\'s performance. However, it does not provide specific examples or references to support the claim, which limits its verifiability. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the clarity of the framework\\'s performance and contributions. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments and comparisons between algorithms, as well as detailed explanations of the presented results. This feedback is clear and actionable, as it provides specific suggestions for improvement, such as conducting quantitative experiments and comparisons, and offering more detailed explanations. By addressing these points, the authors can enhance the comprehensiveness and clarity of their results section, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the paper need to be clarified or improved. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the model\\'s capabilities are unclear or how they could be clarified. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. As a result, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors present a simplified version of Theorem 2 for a general audience, similar to Theorem 1. This implies that the authors should work on making Theorem 2 more accessible by simplifying it. However, the comment does not provide specific guidance on how to simplify the theorem or what aspects to focus on. The action is explicit but vague, as the authors know they need to simplify Theorem 2 but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests simplifying Theorem 2 for a general audience, similar to Theorem 1, and mentions that Definition 2 and Theorem 2 are hard to digest on their own. This provides specific guidance on what needs to be addressed, which is the clarity and accessibility of Theorem 2. However, it does not explicitly mention which part of the paper these theorems and definition are located in, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that Theorem 2 is difficult for a general audience to understand and proposes simplifying it, similar to Theorem 1. However, the comment does not provide specific examples or detailed reasoning to support why Theorem 2 is hard to digest or how it could be simplified. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the specific issues and potential solutions based on the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors present a simplified version of Theorem 2, similar to Theorem 1, to make it more accessible to a general audience. This feedback is clear and actionable, as it identifies a specific area where the authors can improve the clarity and readability of their work. By simplifying Theorem 2, the authors can enhance the understanding of their results for a broader audience. However, the comment could be more helpful if it provided specific guidance on how to simplify the theorem or what aspects to focus on. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting experiments with a larger image resolution to see how it affects performance. While the comment implies that the authors should consider this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what larger resolutions to use. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"1, All the experiments are conducted using images under 224*224 resolution,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the interest in seeing how performance would be affected by using a larger resolution. This provides clear guidance on what the authors should consider adding or exploring in their experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be interesting to see how performance changes with a larger image resolution. However, it does not provide any reasoning, evidence, or references to support why this would be beneficial or how it might impact the results. The comment lacks specific examples or logical reasoning to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting direction for further experimentation by proposing the use of larger image resolutions to evaluate performance. This feedback is somewhat helpful as it provides a potential area for exploration that could enhance the comprehensiveness of the study. However, it lacks specific guidance on how to conduct these experiments or what specific resolutions to consider, which limits its actionable value. To be more helpful, the comment could include suggestions on how to implement this suggestion or what benefits might be expected from such an experiment. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the KeyQN section, specifically asking for clarification on the keypoint mask averaged feature vector. It implies that the authors should provide a detailed explanation or justification for this aspect of their work. However, the comment does not explicitly instruct the authors to make any changes or provide specific guidance on how to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should clarify this part of their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"keypoint mask averaged feature vector\" and suggests that it might be a simple multiplication of each feature map element-wise by H_psi. This provides clear guidance on what needs to be addressed in the KeyQN section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the KeyQN section, specifically regarding the keypoint mask averaged feature vector. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the KeyQN section, asking for clarification on the keypoint mask averaged feature vector. It suggests that the feature vector might be obtained by multiplying each feature map element-wise by H_psi. While the comment identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the concept in their paper. The feedback is somewhat helpful as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is an explicit action that provides clear guidance on what the authors should add to their draft. The comment is specific and concrete, as it directly instructs the authors to include this information, leaving no ambiguity about how to implement the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention that the algorithms follow the sampled policy for a while. However, it does not provide any reasoning or evidence to support why this information is important or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should mention that the algorithms follow the sampled policy for a while. This is a specific and actionable piece of feedback that could enhance the clarity and completeness of the paper. By addressing this suggestion, the authors can provide additional context and depth to their explanation, which could improve the reader\\'s understanding of the methodology. However, the comment could be more helpful if it provided further context or explanation of why this information is important or how it relates to the overall discussion. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what changes might be necessary to improve the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of lower bounds for round complexity in batched ranking problems, specifically mentioning the exploitation of an easy reduction from the problem of collaborative ranking. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment provides some specificity by explaining the relationship between the two problems, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the paper exploits an easy reduction from the problem of collaborative ranking, which leads to lower bound results as an easy corollary. This observation highlights a potential simplification or shortcut in the paper\\'s approach, suggesting that the authors may have overlooked the complexity of the problem or the significance of their results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). The reviewer implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not provide explicit guidance on how to improve the prompting technique or suggest specific methods for curating prompts. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the prompting technique used in the study, labeling it as \"very basic\" and suggesting that it fails to fully leverage the potential of Large Language Models (LLMs). However, it does not specify which part of the paper discusses the prompting technique, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the prompting technique but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is \"very basic\" and fails to leverage the full potential of Large Language Models (LLMs). However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the study, namely the use of a \"very basic\" prompting technique that fails to fully leverage the potential of Large Language Models (LLMs). It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks depth and does not provide specific guidance or examples on how to improve the prompting technique or what constitutes \"carefully curated prompts.\" While it highlights an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it provides a general direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory. It points out the specific differences, such as the use of CLIPseg and OTSU segmentation instead of cross-attention. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the novelty of their approach. The feedback is implicit and lacks concrete details on what actions the authors should take to enhance the novelty of their work. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"video storyboarding\" and \"frame-wise SDSA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the perceived lack of novelty in the proposed approach, comparing it to ConsiStory and highlighting the differences in mask sources. This provides clear guidance on what aspects of the paper need to be addressed or improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the innovation of the proposed video storyboarding approach is limited, specifically noting that it mirrors the approach used in ConsiStory. The comment provides a detailed comparison by highlighting the differences in mask sources, such as the use of CLIPseg and OTSU segmentation instead of cross-attention. This level of detail provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections of the paper or providing more context about why these differences are significant. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory. It highlights the differences in mask sources, such as the use of CLIPseg and OTSU segmentation, which is a clear and actionable point for the authors to address. By pointing out these differences, the comment provides the authors with a direction to enhance the novelty of their approach. However, the comment could be more helpful if it offered suggestions on how to further differentiate the approach or improve its originality. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the zero-shot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walker-run\" and \"walker-walk,\" and the manipulation scenario with 3-prong and 4-prong tasks. The reviewer implies that the paper should clarify these points to avoid misleading the reader. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to make these clarifications. The action is implicit and somewhat vague, as the authors need to infer that they should address these points in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the zero-shot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between \"walker-run\" and \"walker-walk,\" and the manipulation scenario with 3-prong and 4-prong tasks. However, the comment does not explicitly mention which part of the paper these examples are based on, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the transferability and the difficulty of tasks. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between \"walker-run\" and \"walker-walk,\" and the manipulation scenario with 3-prong and 4-prong tasks, to support their claim. However, the comment lacks detailed reasoning or references to substantiate the claim fully. While the examples provide some insight, the lack of comprehensive justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the zero-shot nature of the experiment and the transferability of the policy. It provides specific examples, such as the difference between \"walker-run\" and \"walker-walk,\" and the manipulation scenario with 3-prong and 4-prong tasks, to support the claim that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer suggests that the paper should clarify these points to avoid misleading the reader. This feedback is clear and actionable, as it identifies specific areas that need clarification and provides examples to guide the authors in improving their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or provided additional context. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the authors might need to consider additional datasets or adjustments to their evaluation approach, but it does not specify what specific actions should be taken. The authors are left to infer that they might need to expand their dataset selection or adjust their evaluation methodology, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, it does not specify which datasets are being referred to or how they relate to the tasks mentioned. The authors can infer that the comment is related to the sections discussing the datasets and their use in the evaluation, but without explicit references, it remains weakly grounded. The comment is specific in its concern about the adequacy of the datasets for evaluation, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The addition of a thank you note and an update on the authors\\' response does not address the original claim. Without detailed justification or evidence, the claim remains unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the evaluation process. The addition of a thank you note and an update on the authors\\' response does not enhance the helpfulness of the comment, as it does not offer actionable feedback for the authors to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit and vague, as the authors are left to infer what needs to be done without clear instructions on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about how the proposed method addresses sparse reward problems and suggests that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment does not specify which part of the paper discusses the sparse reward problems or the experiments, making it weakly grounded. The comment is specific in its critique of the method\\'s ability to address sparse reward problems, but without clear references to specific sections or experiments, the authors may struggle to identify the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the proposed method in addressing sparse reward problems, suggesting that the experiments do not provide sufficient support for this claim. It also implies that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim. The lack of concrete evidence or detailed analysis makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical question about the effectiveness of the proposed method in addressing sparse reward problems. It points out that the experiments do not provide sufficient support for this claim and suggests that the method might not be significantly different from existing approaches like Qmix, which could solve sparse-reward tasks with a dense reward signal. This feedback is somewhat helpful as it identifies a potential weakness in the paper and prompts the authors to consider how their method compares to existing solutions. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the paper. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, have access to this data for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the dataset usage. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the curated AH36M dataset, specifically whether it is used for training and whether other methods like HMR and SPIN have access to it. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset usage and comparison with other methods. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the AH36M dataset, specifically whether it is used for training and whether other methods like HMR and SPIN have access to it for a fair comparison. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry seeking clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the use of the curated AH36M dataset, specifically whether it is used for training and whether other methods, such as HMR and SPIN, have access to it. This is an important point for ensuring a fair comparison among methods. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the dataset usage in their paper. While it identifies a potential area of concern, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear question to address but without specific guidance on how to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pre-trained model is being compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to clarify the motivation, improve the comparison, or address the model size issue. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several concerns about the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pre-trained model is being compared with other models. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, while the comment identifies specific issues, it lacks detailed guidance on how to address them. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises several claims, including that the motivation for using an adversarial network is unclear and that the comparison of experimental results is unfair. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the assertion that the comparison is unfair or how the addition of CAT and GAN affects the model size. Without such support, the claims remain vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies several issues with the paper, including the unclear motivation for using an adversarial network and the unfair comparison of experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, and that a pre-trained model is being compared with other models. However, the comment lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending specific methods for hyperparameter tuning or providing examples of how to analyze the variability. The action is implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and questions the variability in optimal hyperparameters due to sample-by-sample optimization. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the issue with hyperparameter tuning but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and questions the variability in optimal hyperparameters due to sample-by-sample optimization. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the potential variation in optimal hyperparameters. This makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, specifically the need to tune multiple hyperparameters (step size, N, and \\\\(\\\\delta t\\\\)) and the potential variability in optimal hyperparameters due to sample-by-sample optimization. This is a critical observation that could impact the robustness and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending methods for hyperparameter tuning or providing examples of how to analyze the variability. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully support the authors in resolving it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited comparison of performance with few methods and notes that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison of performance with few methods and the inconsistency of the proposed method being better than others. It suggests that analysis should be provided for inferior results that contradict the motivation. However, it does not specify which sections of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for analysis of inferior results, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results, as they contradict the motivation. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to provide analysis is logical, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the limited comparison of performance with only a few methods. It points out that the proposed method is not consistently better than others, which contradicts the motivation. The reviewer suggests that analysis should be provided for inferior results to address this discrepancy. This feedback is clear and actionable, as it directs the authors to a specific area needing improvement and provides a clear path forward. However, the comment could be more helpful if it offered suggestions on how to conduct the analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the robustness of their results and addressing a critical critique. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison between the author\\'s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The comment implies that the authors should conduct additional experiments to demonstrate the superiority of their method over the baseline and Mid Vision Feedback. However, it does not provide explicit instructions on how to conduct these experiments or what specific comparisons should be made. While the action is implicit, it is somewhat concrete in suggesting the need for additional experimental comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the author\\'s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely, a comparison with the image classification result of Mid Vision Feedback (MVF). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison between the author\\'s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as the lack of comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by explaining that without these comparisons, it is not possible to prove that the schema searched by ELF is better than the schema in Mid Vision Feedback (MVF). This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the paper\\'s contribution points. It points out that the paper lacks a comparison between the author\\'s method (ELF) and the baseline without Mid Vision Feedback (MVF), as well as a comparison with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it highlights a critical area for improvement that could strengthen the paper\\'s claims and demonstrate the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what additional experiments could be included. Overall, the comment is mostly helpful as it directs the authors to a key area for enhancing the experimental section of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". This is an explicit action that provides a clear direction for the authors to improve their draft by changing the notation. The comment is specific and concrete, as it directly instructs the authors on how to address the issue of confusion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using different notation to avoid confusion between the dimensionality of points and the dilation factor, both represented by \"D\". However, it does not specify which part of the paper this notation is used in, making it weakly grounded. The comment is specific in suggesting a change to avoid confusion, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the notation \"D\" is used for both dimensionality of points and dilation factor, which could lead to confusion. The reviewer recommends using different notation to avoid this confusion. However, the comment does not provide specific examples or references to support why this confusion exists or how it affects the paper. The suggestion is logical but lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper, where the notation \"D\" is used for both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific examples or suggestions for alternative notations. Despite this, the feedback is still somewhat helpful as it directs the authors to a specific area that needs clarification, allowing them to improve the clarity and readability of their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions\" in the paper. It suggests that more elaboration is needed to clarify this concept. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address the issue or what specific information should be added. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 186-line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether \"elements\" is equivalent to \"states\" or \"actions,\" indicating what needs to be clarified. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the concept of state is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the concept of \"state\" and its relationship to \"elements\" and \"actions.\" It provides a clear question about the equivalence of \"elements\" to \"states\" or \"actions,\" which prompts the authors to clarify this aspect of their work. By asking for more elaboration, the comment encourages the authors to provide a clearer explanation, which can enhance the understanding and clarity of their paper. However, the comment could be more helpful if it offered suggestions on how to clarify the concept or provided examples of similar contexts where the distinction is made. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspect should be detailed. However, it does not provide explicit guidance on what specific details should be included or how the authors should elaborate on the innovative aspects. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed FRM, which is a specific part of the paper. However, it does not specify which part of the paper discusses the FRM, making it weakly grounded. The comment suggests that the innovative aspect should be detailed, but it does not provide specific guidance on what details are missing or how they should be elaborated. This lack of specificity makes it difficult for the authors to understand what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspect should be detailed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovative aspect should be detailed. While this feedback identifies a potential area for improvement by highlighting the need for more detailed explanation of the innovative aspects, it lacks specific guidance or suggestions on how the authors might elaborate on these points. The comment provides some insight into what the authors could focus on, but it does not offer actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests rearranging the content of Sections 3 and 4 to reduce redundancy. It explicitly proposes moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, ensuring they know exactly how to implement the suggested change. The comment is explicit and detailed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides a specific suggestion for rearranging the content to reduce redundancy, specifying which paragraphs should be moved. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Sections 3 and 4 are slightly redundant and proposes a rearrangement to improve clarity. However, it does not provide any specific examples or detailed reasoning to support the claim of redundancy or the suggested rearrangement. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with redundancy between Sections 3 and 4, suggesting a rearrangement to improve clarity. It provides a specific and actionable suggestion by proposing the movement of certain paragraphs to reduce redundancy. This feedback is clear and offers a concrete way for the authors to enhance the organization and coherence of their draft. However, the comment could be more helpful if it further explained why the current arrangement is problematic or how the suggested rearrangement would improve the paper. Overall, the comment is mostly helpful as it provides a constructive suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors. While the comment implies that the authors should conduct these analyses, it does not provide specific guidance on how to approach these analyses or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include theoretical analyses or extensive experiments to understand why certain approaches outperform others. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what aspects need further analysis, such as the comparison between simple greedy selection and more principled acquisition functions, and the performance of deterministic MLP predictors versus probabilistic predictors. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include theoretical analyses or extensive experiments to understand why certain approaches outperform others. The reviewer questions the empirical results and suggests that a more novel contribution could be found by exploring these aspects. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current empirical results are strong or that the suggested analyses are necessary. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks concrete evidence or detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for further exploration and improvement in the paper. It suggests that the authors conduct theoretical analyses or extensive experiments to understand why certain approaches, such as the simple greedy selection method and deterministic MLP predictors, outperform more principled acquisition functions and robust probabilistic predictors, respectively. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by addressing the gap in understanding the reasons behind these empirical results. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or experiments. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful area of investigation that could significantly improve the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to provide a citation for the discussion of the \"k-max problem\" elsewhere, implying that the authors should include this information in their draft. This request is clear and direct, providing the authors with a specific action to take. The comment is highly actionable as it gives a concrete instruction on what needs to be done to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment requests information about where else the \"k-max problem\" was discussed and asks for a citation. However, it does not specify which part of the paper this discussion is located in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a citation but lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification, asking for a citation regarding the discussion of the \"k-max problem.\" It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests additional information about the discussion of the \"k-max problem\" by asking for a citation. While it identifies a potential gap in the paper, it does not provide any context or explanation about why this information is important or how it might impact the paper. The feedback lacks depth and does not offer actionable suggestions for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies two issues: forward referencing in the paper and the need for clearer explanations of contributions in the Introduction. It suggests that the material supporting the main contributions should be included in the main sections rather than the appendix. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues, such as specifying which sections should be revised or how to reorganize the content. The actions are implicit and somewhat vague, leaving the authors to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as forward referencing and the need for clearer explanations of contributions, and suggests that material supporting the main contributions should be included in the main sections rather than the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in subsequent sections. It also suggests that the main contributions need to be written more clearly in the Introduction and that material supporting these contributions is in the appendix rather than the main sections. While the comment identifies specific issues, it lacks detailed examples or references to support the claims, making it somewhat verifiable. The authors would need to infer the exact points that need clarification or reorganization based on the general feedback provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: forward referencing and the need for clearer explanations of contributions in the Introduction. It points out that material is introduced without proper explanation and is later explained in subsequent sections, such as Figure 1. The comment also notes that the material supporting the main contributions is in the appendix rather than the main sections, specifically mentioning the deep-rag algorithm and discussion on high concurrency. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper by clarifying the introduction and ensuring that key contributions are explained in the main sections. However, the comment could be more helpful if it offered suggestions on how to reorganize the content or provide additional context to support the main contributions. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance the clarity and organization of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have not analyzed the security (or protection of privacy) of the proposed framework. This is a clear and direct action for the authors to take, as it identifies a specific area that needs to be addressed in the draft. However, the comment does not provide guidance on how to conduct this analysis or what aspects of security should be considered. While the action is explicit, the lack of concrete details on how to implement it makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out that the authors have not analyzed the security or protection of privacy of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. Without explicit references or clear indications of where this analysis is lacking, the authors may find it challenging to identify the exact areas needing attention. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is not specific because it does not provide detailed guidance on what aspects of security or privacy should be analyzed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors have not analyzed the security or protection of privacy of the proposed framework. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis on the security and protection of privacy of the proposed framework. This is a critical area that authors should address to ensure the robustness and reliability of their work. However, the comment does not provide specific guidance or suggestions on how the authors might conduct this analysis or what aspects of security and privacy should be considered. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors to a critical area but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, but the article does not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at the PPP maps. This feedback is explicit and provides a clear action for the authors to take, which is to provide a detailed explanation of the PPP maps and their implications. The action is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the authors\\' statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It questions the lack of explicit explanation or understanding provided in the article regarding the type of understanding one reaches by looking at PPP maps. However, the comment does not specify which part of the paper discusses PPP metrics or maps, making it weakly grounded. The authors can infer that it relates to the sections discussing PPP effects, but the exact location is not clearly identified. The comment is specific in its request for an explicit explanation, but the lack of grounding limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks, noting that the article does not provide an explicit explanation or understanding of this concept. The reviewer asks for clarification on what type of understanding is reached by looking at PPP maps. While the comment raises a valid point about the lack of explanation, it does not provide specific examples or references to support the claim that the explanation is missing. The reasoning is somewhat logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper regarding the explanation of PPP metrics and their importance for understanding PPP effects in different tasks. It points out that while the authors mention the importance of these metrics, the article lacks an explicit explanation or understanding of what type of insight is gained by examining PPP maps. This feedback is somewhat helpful as it highlights a specific area where the authors need to provide more clarity and detail. However, it does not offer specific suggestions or guidance on how to address this gap, leaving the authors with a general direction but without detailed steps to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their training process. The suggestion to provide a stronger baseline is implicit and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide clear instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of ignoring rewardless actions that could provide useful supervision and suggests that this could be a significant factor in the better performance of FP + RBI compared to RBI alone. The comment further suggests that the authors should provide a stronger baseline to prove the usefulness of FP. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer provides a specific example from Task 3, \"No, the answer is Timothy Dalton,\" which is a rewardless action that could offer useful feedback. The comment logically infers that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. However, the claim lacks specific references or detailed analysis to fully substantiate the reasoning. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the better performance of FP + RBI compared to RBI alone. This is a valuable observation that could help the authors improve their understanding of their model's performance. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how to incorporate rewardless actions into the training process. Additionally, the suggestion to provide a stronger baseline is vague and lacks detail. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the multi-scale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. It implies that the only benefit of the slow RNN is the reduction of the gradient path. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the multi-scale statement but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"multi-scale statement\" in the paper, implying that it is related to the use of slow and fast RNNs. However, it does not specify which section or part of the paper this statement is located in, making it weakly grounded. The comment is specific in its critique, explaining that the slow and fast RNNs operate on a logical time scale rather than a physical one, and that the only benefit is the reduction of the gradient path by the slow RNN. This provides clear guidance on what needs to be addressed, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical explanation for why this might be the case, noting that the RNNs are sequentialized in the graph, which supports the claim. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Overall, the claim is somewhat verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the critique. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the multi-scale statement in the paper, suggesting that it might be misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, which could lead to confusion. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify their statement. However, the comment lacks depth and does not provide actionable suggestions on how to address this issue or improve the clarity of the statement. While it highlights a potential problem, it does not offer detailed guidance for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a distinction in the formulation of the paper regarding the decision maker\\'s interest in the true objective function versus the stochastic noisy function. It suggests that the authors should make this distinction clearer upfront. While the comment implies that the authors should clarify this point, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed to improve the clarity of the distinction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper\\'s formulation regarding the decision maker\\'s interest in the true objective function versus the stochastic noisy function. It suggests that the authors should make this distinction clearer upfront. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the formulation or methodology section. The comment is specific in detailing what needs to be clarified, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the expected performance under observation noise is typically used for evaluation because the decision-maker is interested in the true objective function, and the noise is assumed to be misleading. It contrasts this with the formulation in the paper, where the decision maker is interested in the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current formulation is misleading. This makes the claim somewhat verifiable, as it requires further elaboration to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential misunderstanding in the paper's formulation regarding the decision maker's interest in the true objective function versus the stochastic noisy function. It suggests that the authors should clarify this distinction upfront, which is a valuable observation that could improve the clarity and accuracy of the paper. However, the comment could be more helpful if it provided specific suggestions on how to make this distinction clearer, such as proposing alternative formulations or examples. Despite this, the feedback is mostly helpful as it directs the authors' attention to an important aspect of their work that needs clarification. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. However, the comment does not provide explicit guidance or suggestions for the authors to address these issues in their draft. While it points out areas for consideration, it lacks actionable steps or concrete recommendations for improvement. As a result, the authors are left with a general understanding of the potential problems but without clear direction on how to address them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential issues. It also suggests that oversmoothing could be another factor, referencing a specific paper for further context. However, the comment does not specify which part of the paper discusses DGNs or their modeling abilities, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issues with DGNs, such as oversquashing and oversmoothing, and provides a reference for further exploration. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs could be due to oversquashing and vanishing/exploding gradients, and also suggests that oversmoothing could be another factor. The comment references a specific paper, \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning, In AAAI'18,\" which provides a basis for the claim about oversmoothing. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim about oversquashing and vanishing/exploding gradients. While the reference to the paper adds some verifiability, the lack of detailed explanation or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another contributing factor, referencing a specific paper for further context. This feedback is somewhat helpful as it points out a specific area for improvement and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on incorporating the referenced paper into the discussion. Overall, the comment provides some insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not provide specific guidance or suggestions on how to clarify the formulation. The authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. Without explicit instructions or concrete examples, the authors cannot effectively address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the problem formulation is unclear in both the statement and introduction examples. However, it does not specify which specific examples or sections of the paper are causing the confusion. This makes it difficult for the authors to pinpoint the exact parts that need clarification. The comment lacks grounding as it does not identify a specific part of the paper, and it is also not specific about what aspects of the formulation are unclear. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the clarity of the problem formulation in both the statement and introduction examples. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity. Without actionable feedback or examples, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment barely helpful, as it highlights a problem but does not offer any direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\\'s applicability and generalizability. This feedback is clear and provides specific models to consider, giving the authors a concrete action to take. The suggestion is direct and actionable, as it specifies exactly what experiments should be conducted to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\\'s applicability and generalizability. However, it does not specify which part of the paper this suggestion should be implemented in, making it weakly grounded. The comment is specific in suggesting the types of experiments that could be conducted, but without clear grounding, the authors may struggle to determine where to incorporate this feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. The claim is based on the assumption that conducting such experiments would provide valuable insights into the method\\'s applicability and generalizability. However, the comment does not provide specific examples or references to support why these experiments are necessary or how they would enhance the paper. The reasoning is somewhat logical but lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper lacks experiments on different LLM families, such as OPT, BLOOM, or other alternatives. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by exploring the method\\'s applicability and generalizability across various LLM families. By conducting these experiments, the authors can gain valuable insights that could strengthen their findings and contribute to a more comprehensive understanding of their method. However, the comment could be more helpful if it offered additional guidance on how to design or interpret these experiments. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful area for expansion, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or whether it is a problem that needs to be resolved. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or context being addressed. The comment lacks specificity as it does not provide details on why this limitation is a concern or how it could be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation of the method, suggesting that it only works for generative models that can be fine-tuned as in/outpainting models. However, it does not provide any further context, examples, or suggestions on how this limitation could be addressed or whether it is a significant issue. Without additional guidance or actionable feedback, the authors are left with a vague understanding of the problem and no clear path for improvement. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer suggests that the connection between these two parts is weak and that their initial expectation of the approach was not met. However, the comment does not provide explicit guidance or suggestions on how the authors could strengthen the connection between these parts or clarify their approach. The feedback lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connection between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. However, it does not specify which sections or parts of the paper these topics are discussed in, making it weakly grounded. The comment is specific in detailing the reviewer\\'s initial expectation and how it was not met, providing some guidance on what might be missing or unclear. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the connections between the curve finding and FGE parts of the paper are weak. The reviewer provides a personal interpretation of what they expected the approach to be, which differs from the actual content. However, the comment lacks specific evidence or detailed reasoning to support the claim that the connections are weak. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a perceived disconnect between the first part of the paper, which deals with curve finding, and the second part, which involves FGE. The reviewer shares their initial expectation of the approach, which was not met, and notes that the connection between these parts is weak. However, the comment lacks specificity and actionable guidance on how the authors could strengthen this connection or clarify their approach. Without detailed suggestions or examples, the authors are left with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that while the proposed method is grounded in neuroscience, some of its general ideas are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods. This feedback is explicit in its request for the authors to discuss their work in the context of existing literature, providing a clear action for the authors to take. However, it does not specify which specific aspects of the existing methods should be discussed or how the authors should integrate this discussion into their paper. While the action is clear, the lack of detailed guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and references specific methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM, which are discussed in the graph-based SLAM appendix section. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: a discussion of the proposed method in relation to these existing methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some general ideas in the proposed method are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer provides specific examples, like the use of pose graphs in SLAM and loop closure, and mentions curiosity-driven exploration. This provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to the specific literature or methods being compared, which would further support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality of the proposed method, noting that some of its general ideas are already present in other methods, such as those using generalized Voronoi graphs or semantic maps for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could help clarify its contributions and novelty. This feedback is somewhat helpful as it points out a gap in the paper\\'s discussion and provides a direction for improvement. However, it could be more helpful if it offered specific suggestions on how to integrate this discussion or highlighted particular aspects of the existing methods that should be addressed. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests moving some experimental setup details back into the main text and relocating some background information from Section 2 to the appendix. This provides explicit guidance on what actions the authors should take to improve the clarity and organization of their paper. The suggestion is concrete, as it specifies which elements should be moved and where, giving the authors a clear understanding of how to implement the changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, tasks, and other details being moved to the appendix, which makes it difficult to interpret the paper. It suggests moving some of these details back into the main text and relocating some background information from Section 2 to the appendix instead. This provides specific guidance on what needs to be addressed, but it does not explicitly mention which sections or parts of the paper are being referred to. While the authors can infer that it relates to the experimental setup and Section 2, the comment is not fully grounded as it lacks explicit references to these sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret the paper. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to move some details back into the main text and relocate background information from Section 2 to the appendix is not substantiated with evidence or examples, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the organization of the paper, noting that the experimental setup, tasks, and other details are moved to the appendix, which makes it hard to interpret. It provides a clear and actionable suggestion to move some of these details back into the main text and relocate some background information from Section 2 to the appendix instead. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and accessibility of their paper. However, the comment could be more helpful if it explained why this reorganization would be beneficial or provided additional context. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in the paper\\'s structure and readability.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point points out that \"Memb\" is mentioned as the previous state-of-the-art but lacks any reference. This implies that the authors should include a reference to support the claim about \"Memb\" being the previous state-of-the-art. However, the comment does not explicitly instruct the authors to add a reference, leaving it to be inferred. The action is concrete in terms of what needs to be done (adding a reference), but it is implicit in the instruction. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment mentions \"Memb\" as the previous state-of-the-art but notes the absence of any reference. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion or references section where such claims are typically made. However, the comment lacks specificity as it does not detail what kind of reference is missing or why it is important. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"Memb\" is the previous state-of-the-art but notes the absence of any reference. This claim is somewhat verifiable as it points out a potential oversight in the paper, but it lacks specific details or references to support the assertion that \"Memb\" is indeed the previous state-of-the-art. The comment does not provide enough information for the authors to fully understand the context or the basis of the claim, making it difficult for them to address the issue effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a significant omission in the paper, noting that \"Memb\" is mentioned as the previous state-of-the-art but without any reference. This is a critical issue because it undermines the credibility of the claim and the authors' argument. However, the comment does not provide any guidance on how to address this issue or suggest potential references that could be included. While it highlights a crucial weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes on performance and provides an example of how the performance varies with different ratios of unseen classes. This feedback is explicit and concrete, as it clearly instructs the authors to investigate a specific aspect of their work and provides a concrete example of what to consider. The authors know exactly what action to take and how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes on performance and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion should be addressed in, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a particular area for investigation, but without clear grounding, it is challenging for the authors to know where to make the changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the impact of the ratio of unseen classes on performance should be studied. It provides an example of how performance varies with different ratios of unseen classes, which is a logical and specific suggestion. However, the comment lacks detailed reasoning or references to support why this aspect is important or how it relates to the broader context of the paper. While the suggestion is clear, the lack of additional justification or evidence makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific area for further investigation, namely the impact of the ratio of unseen classes on performance. It provides a concrete example of how the performance varies with different ratios of unseen classes, which is a valuable suggestion for enhancing the depth and comprehensiveness of the study. This feedback is actionable and offers a clear direction for the authors to explore, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to approach this investigation or potential implications of the findings. Therefore, the comment aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, it does not provide explicit guidance or suggestions on how the authors should clarify or address this point in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the use of epsilon-greedy exploration. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" in the context of the proposed strategy, indicating that the authors should clarify whether it is used in addition to the proposed strategy. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"epsilon-greedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. However, the comment does not provide any supporting evidence, reasoning, or references to clarify this point. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of the proposed strategy, suggesting that it might be used in addition to the proposed strategy. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be addressed. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the critique or suggestions for improvement. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure, making it difficult for the authors to identify the exact area needing revision. The comment also lacks specificity regarding what aspects of the method are considered \"not new\" or how the authors could improve the novelty of their approach. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations of why this combination is not novel or how it differs from existing work. Without such support, the claim remains unverifiable, as the authors would need to infer or investigate the claim themselves. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with the transformed distribution being a Gaussian mixture distribution. However, it does not provide any specific feedback or suggestions on how the authors could improve their work or address the critique. The comment lacks actionable guidance or constructive feedback, leaving the authors without a clear understanding of what changes are needed to enhance their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential area for improvement in the proposed invariant learning module, specifically suggesting that the feature selection could be enhanced by considering representation learning. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The authors are left to infer that they should explore incorporating representation learning into the feature selection process, but without concrete steps or examples, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the feature selection in Section 4.2 could be improved by considering representation learning, as discussed in the appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the feature selection in Section 4.2 could be improved by considering representation learning. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the appendix suggests that there is some discussion related to representation learning, but without further elaboration, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the proposed invariant learning module, specifically focusing on the feature selection aspect. It points out that the current framework seems not limited to raw-level selection and suggests that representation learning could be considered to enhance the feature selection. This feedback is clear and actionable, as it directs the authors to explore a specific aspect of their work that could lead to a more comprehensive and robust approach. However, the comment could be more helpful if it provided additional guidance or examples on how to incorporate representation learning into the feature selection process. Overall, the comment is mostly helpful, as it offers a valuable direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details are missing, specifically mentioning that the design of rewards is not fully understandable. However, it does not provide explicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors to infer that they need to provide more information about the reward design. Since the action is implicit and vague, the authors may struggle to determine exactly what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions that \"some details are missing,\" specifically referencing the design of rewards, which is not fully understandable. However, it does not specify which part of the paper discusses the reward design, making it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in identifying the missing details but lacks grounding as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any specific details or examples of what is missing or how the design of rewards is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable as it lacks sufficient evidence or justification to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where details are missing, namely the design of rewards. It highlights a particular aspect that needs clarification, which is the design of rewards. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific details are missing. Without actionable advice or examples, the authors are left with a general understanding of what needs improvement but without a clear path forward. Therefore, the comment is barely helpful, as it identifies a weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for ML-based emulators. This is an explicit action, as it clearly instructs the authors to include a specific discussion about the runtime. The comment provides a concrete suggestion on what aspect of the paper should be addressed, making it clear to the authors how to implement the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications where computational cheapness is a selling point for ML-based emulators. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of the model\\'s performance or limitations. The comment is specific in suggesting that the runtime should be discussed as a limitation, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count, which might be a limitation for applications where computational cheapness is a selling point for ML-based emulators. This claim is somewhat verifiable as it provides a logical reasoning based on the characteristics of the model. However, it lacks specific examples or references to support the assertion about the runtime being a limitation. Providing more detailed evidence or examples would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the ML-based emulator Prithvi WxC, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications where computational efficiency is a key advantage. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. By highlighting this potential limitation, the comment helps the authors to enhance the comprehensiveness and accuracy of their work. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the quality of paraphrases generated for the training data, specifically questioning how different these paraphrases are from the original sentences. It emphasizes the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment suggests that if the paraphrases are not significantly different from the originals, the quality of the final training data will be low, leading to a limited number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it, such as suggesting methods to evaluate or improve the paraphrasing process. The action is implicit and somewhat vague, as the authors are left to infer that they need to assess and potentially improve the paraphrasing quality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of paraphrasing for the training data, specifically questioning how different the paraphrases are from the original sentences. It highlights the importance of this aspect for the subsequent steps in the process. However, it does not specify which part of the paper discusses the paraphrasing process, making it weakly grounded. The comment is specific in detailing the concern about the quality of paraphrases and their impact on the final training data. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases generated for the training data, suggesting that if the paraphrases are not significantly different from the original sentences, the quality of the final training data will be low. The comment logically connects the quality of paraphrases to the impact on the training data, providing a clear rationale for the claim. However, it lacks specific examples or references to support the assertion about the impact of paraphrase quality on the training data. This makes the claim somewhat verifiable, as it requires further evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paraphrasing process for the training data, specifically questioning the difference between the paraphrases and the original sentences. It highlights the importance of this aspect, as it impacts the quality of the subsequent steps in the process. The comment logically explains that if the paraphrases are not significantly different, the quality of the final training data will be low, leading to a limited number of pairs being added to the new training data. This feedback is clear and actionable, as it prompts the authors to evaluate and potentially improve the paraphrasing process to ensure the quality of their training data. However, it could be more helpful if it provided specific suggestions or examples on how to assess or enhance the paraphrasing quality. Overall, the comment is mostly helpful, as it directs the authors to a crucial area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing could be improved, as it took the reviewer a significant amount of effort to understand the main idea and the theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The comment lacks concrete details or suggestions for the authors to follow, leaving them without a clear understanding of what changes to make. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing could be improved, as it took the reviewer a lot of effort to understand the main idea and the theoretical analysis. However, it does not specify which parts of the paper are unclear or need improvement, nor does it provide any guidance on how to address these issues. The authors may have difficulty determining which sections of the paper are problematic, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what aspects of the writing need improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the writing could be improved, as it took the reviewer a lot of effort to understand the main idea and the theoretical analysis. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to identify and address the issues. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the writing could be improved, as it took the reviewer a significant amount of effort to understand the main idea and the theoretical analysis. However, it does not provide specific guidance or suggestions on how to improve the clarity or structure of the paper. Without actionable feedback or detailed recommendations, the authors are left without a clear understanding of what changes to make to enhance their draft. Therefore, the comment is not helpful at all, as it lacks the necessary depth and specificity to guide the authors in improving their work.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the unfairness of comparing the domain-specific model trained on Pix3D to zero-shot single-image 3D reconstruction models, also tested on Pix3D. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of unfair comparisons or suggestions for alternative experiments or methodologies. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the domain-specific model\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the unfair comparisons to zero-shot single-image 3D reconstruction models, even though they are also tested on Pix3D. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparisons to zero-shot single-image 3D reconstruction models are unfair because both the domain-specific model and the models being compared are trained and tested on Pix3D. This claim is based on a logical observation about the unfairness of the comparison, as it suggests that the models are not being tested under different conditions. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider the reasoning and potentially conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparisons made in the paper, specifically noting that the domain-specific model is trained and tested on Pix3D, while the comparisons are to zero-shot single-image 3D reconstruction models also tested on Pix3D. This observation highlights a potential flaw in the experimental setup, which could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the comment implies that such experiments would be beneficial, it does not explicitly instruct the authors to perform them. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments to strengthen their work. However, the suggestion is concrete in terms of the specific datasets to use, which provides some guidance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments would be beneficial or how they would enhance the support for C2D. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. However, the comment does not provide any reasoning or evidence to support why these specific datasets would be beneficial or how they would enhance the support for C2D. Without such justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper\\'s support for the C2D method. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D method would benefit from them. While it offers a direction for improvement, it does not fully address the authors\\' needs for actionable feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or simplify the tasks. The action is implicit and vague, as the authors are left to infer that they should consider alternative approaches but are not given concrete steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the reviewer is addressing, such as a particular section or experiment. It also lacks specificity because it does not provide detailed feedback on what aspects of the abstract visual reasoning tasks are confusing or how they could be improved. The authors cannot confidently determine which parts of the paper need revision, and the comment does not offer clear guidance on how to address the issues raised. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. The reviewer questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. However, the comment lacks specific examples or references to support the claim that the tasks are overly difficult or confusing. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the abstract visual reasoning tasks, finding them unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler visual reasoning tasks might be more effective. The reviewer also expresses confusion about the multiple rows and changing factors between frames, which they believe could lead to difficulties in interpreting the models\\' learning patterns. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or simplify the tasks. While it identifies a potential issue, it does not provide actionable feedback, making it somewhat helpful. The authors are left with a general understanding of the problem but without detailed advice on how to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of essential visualization of intermediate processes and comparisons, but it does not provide specific guidance on how to address this issue. It does not suggest what kind of visualizations should be included or how the comparisons should be presented. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors may infer that it relates to the methodology or results sections, but without explicit mention, it is difficult to pinpoint the exact area needing attention. The comment is specific in identifying the need for visualization and comparisons but lacks grounding due to the lack of specific references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance their draft by including visualizations that could help readers better understand the intermediate steps and comparisons. However, the comment could be more helpful if it provided suggestions on what specific visualizations or comparisons would be most beneficial or how they could be effectively integrated into the paper. Despite this, the comment offers a valuable direction for improvement, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the expected counterfactual violating a condition stated in the definition. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual violating a condition stated in Definition 1. This feedback is clear and actionable, as it points out a potential problem that needs to be addressed in the paper. However, the comment lacks further guidance or suggestions on how the authors might resolve this issue or what implications it might have for the overall analysis. While it highlights a critical area for improvement, the lack of additional context or direction limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for the authors to focus on but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the importance of the result and provides a comparison with existing work, specifically [15], which claims that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer suggests that the decentralized algorithm's ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the reviewer notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer what changes might be necessary without clear direction. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the importance of the result, provides a comparison with existing work ([15]), and notes the change in iteration complexity in Theorem 3. This level of detail helps the authors understand what needs to be addressed in their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the importance of the result presented in the paper, comparing it to existing work ([15]) that claims perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer suggests that the decentralized algorithm\\'s ability to escape saddle points in polynomial time is not surprising given this context. Additionally, the comment notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. While the comment provides a logical comparison and references existing work, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to delve deeper into the literature and the specific results to fully understand the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the importance of the result presented in the paper, suggesting that it is not surprising given existing work on perturbed gradient descent. The reviewer provides a specific reference to [15] and notes a change in the iteration complexity in Theorem 3, which is no longer dimension-free. While the comment identifies a potential issue with the novelty of the result, it does not offer specific suggestions or guidance on how the authors might address this concern or improve their work. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice or detailed analysis to fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search of the learning rate is done on the validation set. While it implies that the authors should clarify this aspect, the comment does not provide explicit guidance on how to address the issue or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to clarify this point but are not given concrete instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the grid search of the learning rate is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential area of confusion, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify this point or address any potential issues related to the grid search. The comment is somewhat helpful as it prompts the authors to consider this aspect, but it does not offer actionable advice or detailed feedback to improve the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, particularly marginalized ones. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to address these issues or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the diversity of the sample, particularly regarding racial and economic diversity, and how well the results might generalize to other groups, especially marginalized ones. This provides clear guidance on what aspect of the paper needs further consideration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, especially marginalized ones. However, it does not provide any evidence, reasoning, or references to support the claim that the sample lacks diversity or that the results may not generalize. Without additional context or justification, the authors may find it challenging to address this concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the diversity of the sample, specifically asking about racial and economic diversity and how well the results might generalize to other groups, especially marginalized ones. This is a critical consideration for ensuring the applicability and relevance of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the diversity of their sample. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear area for improvement but without detailed guidance on how to achieve it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the small number of images (20) in the VioT dataset, which the reviewer feels is insufficient to validate the approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should collect more data, how to increase the dataset size, or any other potential solutions. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images (20) in each of the 4 categories, which the reviewer feels is insufficient to validate the approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the small number of images (20) in the VioT dataset, questioning its sufficiency for validating the approach. However, the comment lacks specific reasoning or evidence to support why 20 images are insufficient or how this impacts the validity of the approach. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset size, specifically noting that only 20 images are provided for each of the 4 categories in the VioT dataset. The reviewer expresses a concern that this small number of images may not be sufficient to validate the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional data collection or providing examples of how to improve the dataset. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the difficulty in following the mathematical derivations, the need for more intuitive explanations, and the lack of figure captions and legends. It specifically mentions that Figure 1 and 2 did not contribute much to the understanding and suggests that the text had to be read multiple times. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more intuitive explanations, add figure captions, and clarify the legends. However, the lack of specific guidance on how to enhance the explanations or improve the figures makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Fig. 1 and Fig. 2) and figure captions, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for more intuitive explanations of mathematical derivations and the lack of figure legends, particularly regarding the colors in Fig. 2. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions and legends, specifically mentioning that Figure 1 and 2 did not contribute much to the understanding. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references to similar works or standards further limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the difficulty in following the mathematical derivations and the need for more intuitive explanations. It also points out the lack of figure captions and legends, specifically mentioning that Figure 1 and 2 did not contribute much to the understanding. The comment provides specific examples, such as the need to explain the colors in Figure 2, which gives the authors clear guidance on how to improve the clarity and accessibility of their work. However, the comment could be more helpful if it offered suggestions on how to enhance the explanations or provided examples of how to improve the figure captions and legends. Overall, the feedback is mostly helpful as it highlights important areas for improvement and provides some actionable suggestions, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing that incorrect choices could negate any potential improvements from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a sensitivity analysis or provide more information on hyperparameter choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sensitivity of empirical results to hyperparameter choices, which is an important issue for the paper. However, it does not specify which part of the paper this concern relates to, such as specific sections or results that need to be addressed. The authors can infer that it might relate to the experimental setup or results sections, but this is not explicitly stated. The comment is specific in its request for information on sensitivity to hyperparameter choices, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\\'s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The suggestion to investigate this issue is logical, but without further elaboration, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical concern about the sensitivity of empirical results to hyperparameter choices, emphasizing that incorrect choices could negate any potential improvements from the method. This is a significant issue that the authors need to address to ensure the robustness and reliability of their findings. The comment is clear and actionable, as it provides a specific area for improvement and suggests that resolving this issue could lead to a reconsideration of the reviewer\\'s rating. However, the comment could be more helpful if it offered suggestions on how to conduct the sensitivity analysis or what specific hyperparameters to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation behind the cross-encoder architecture, stating that it does not \"ignore cross-entity comparison\" as claimed. However, it acknowledges that the architecture \"attends to all candidates at once\" to obtain final matching scores. The comment highlights a potential issue with the motivation but does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their motivation, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the motivation behind the cross-encoder architecture, specifically addressing the claim that it \"ignores cross-entity comparison.\" However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where this claim is made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides some specificity by detailing the issue with the motivation, it does not offer detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the cross-encoder architecture does not \"ignore cross-entity comparison\" as stated, but instead \"attends to all candidates at once\" to obtain final matching scores. This claim is based on a logical analysis of the architecture\\'s functionality, which provides a clear and straightforward reasoning. However, the comment could be strengthened by providing specific examples or references to support the claim, which would make it more fully verifiable. As it stands, the comment is mostly verifiable, as it provides a logical basis for the critique but lacks detailed evidence or references. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the motivation behind the cross-encoder architecture, pointing out that it does not \"ignore cross-entity comparison\" as claimed. Instead, it \"attends to all candidates at once\" to obtain final matching scores. This feedback highlights a potential misrepresentation of the architecture\\'s functionality, which is an important issue for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or improve their motivation. While it identifies a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out an issue but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement, such as recommending more modern alternatives or suggesting ways to update the methods. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment criticizes the use of an \"antiquated\" GNN model and method, stating that it impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the models or methods are considered antiquated or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an \"antiquated\" GNN model and method, which negatively impacts the performance of the framework. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the use of an antiquated GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is not helpful at all, as it does not offer any constructive feedback or direction for enhancing the draft.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a concern with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the experiment. The reviewer suggests that the experiment could be strengthened in two ways, but does not specify what these ways are. While the comment implies that the authors should address the issues related to the use of pseudo feature importance and the perturbation value, it lacks explicit guidance on how to do so. The action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"One experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of pseudo feature importance and the reliance on Proposition 3.2 and a large enough perturbation value, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment using pseudo feature importance is problematic due to its reliance on Proposition 3.2 and the choice of a large enough perturbation value. However, the comment does not provide specific details or examples to support this claim, such as how the pseudo feature importance affects the experiment or how the perturbation value impacts the results. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the potential issues and address them on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment that estimates the quality of uncertainty estimates, noting that it uses pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and the choice of a large enough perturbation value, which makes it difficult to trust the experiment. The reviewer suggests that the experiment could be strengthened in two ways, implying that the authors should address these concerns. However, the comment does not provide detailed guidance on how to strengthen the experiment or what specific changes would be beneficial. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental settings are not properly mentioned, which is crucial for result reproducibility. It also mentions that the code is not provided. This feedback is clear and direct, providing the authors with specific actions to take: they need to properly document the experimental settings and provide the code. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experimental settings and the lack of code, which are critical for result reproducibility. However, it does not specify which part of the paper discusses the experimental settings or where the code is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the experimental settings and the absence of code, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not properly mentioned, which is critical for result reproducibility. It also mentions that the code is not provided. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings, noting that they are not properly mentioned, which affects result reproducibility. It also points out the absence of code, which is essential for reproducibility. This feedback is clear and actionable, as it highlights specific areas that need improvement to enhance the credibility and reliability of the research. However, the comment could be more helpful if it provided suggestions on how to properly document the experimental settings or offered guidance on making the code available. Despite this, the comment is mostly helpful as it directs the authors to important aspects of their draft that require attention. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of lexical and syntactic diversity in teacher feedback, suggesting that the feedback might be auto-generated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make the feedback more realistic. While the comment suggests an action, it does not provide specific guidance on how to implement these suggestions, such as which types of feedback to generate or how to ensure diversity. The action is explicit but somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of lexical and syntactic diversity in teacher feedback, suggesting that the feedback might be auto-generated. It implies that the authors should consider using human evaluators (Turk) or generating different types of feedback to make the feedback more realistic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment where teacher feedback is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting ways to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in teacher feedback, suggesting that it might be auto-generated. The reviewer questions whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make the feedback more realistic. This claim is somewhat verifiable as it provides a logical reasoning for the potential issue with auto-generated feedback. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the lack of lexical and syntactic diversity in teacher feedback, suggesting that it might be auto-generated. It raises a question about whether the authors intend to use human evaluators (Turk) or generate different types of feedback to make the feedback more realistic. This feedback is somewhat helpful as it points out a potential weakness in the methodology and encourages the authors to consider improving the diversity of teacher feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how to achieve this diversity. Overall, the feedback is clear and actionable, aligning with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not provide explicit instructions on how to achieve this clarification or what specific aspects of the results should be summarized. The action is implicit and somewhat vague, as the authors can infer that they need to add a summary of the supplementary experiments but are not given detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. However, it does not specify which part of the paper this should be addressed in, such as a particular section or figure. The authors can infer that it relates to the experimental section, but this is not explicitly stated. The comment is specific in suggesting the need for a summary of the supplementary experiments, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not provide any specific examples, reasoning, or references to support why this clarification is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the main text should be clarified to indicate the presence of additional experiments in the supplement and that these results should be summarized. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it included specific guidance on how to present these additional experiments or what aspects of the results should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point recommends comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" While the comment explicitly suggests a comparison, it does not provide detailed guidance on how to conduct this comparison or what specific aspects should be evaluated. The action is explicit but somewhat vague, as the authors know they need to compare their work with these studies but may not be entirely clear on the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" However, it does not specify which part of the paper this comparison should be made in, such as the results section or the discussion. This lack of explicit reference makes it difficult for the authors to pinpoint where the suggested comparison should be integrated. The comment is specific in suggesting the studies to be compared, but it is not fully grounded as it does not clearly indicate the part of the paper where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the performance of the current work with two specific studies: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer.\" However, the comment does not provide any reasoning or justification for why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these studies or how to incorporate them into their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison with two studies, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer,\" which could provide valuable insights into the performance of the current work. This feedback is clear and actionable, as it directs the authors to consider these studies for comparison, potentially enhancing the robustness and relevance of their findings. However, the comment could be more helpful if it provided additional context or guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a concrete suggestion for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer asks if the approach can be extended to more general settings. While the comment implies that the authors should consider broadening the applicability of their approach, it does not provide explicit guidance or suggestions on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more general settings but without clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the setting, but it lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer asks if the approach can be extended to more general settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it could be addressed. The lack of detailed explanation or examples makes the claim difficult for the authors to understand and address, rendering it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the specificity of the setting used in the paper, noting that it requires knowledge of a specific model or access to a generative model, an episodic problem, and a reward given only at the end of a task. The reviewer questions whether this approach can be extended to more general settings, which is a relevant and important consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might broaden the applicability of their approach or what specific changes could be made to achieve this. While it identifies a potential limitation, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the dimensionality of each region and the feature extractor used, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on how to address the question or what information should be added to the draft. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the dimensionality of each region and the feature extractor used, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is a clear and actionable point for the authors to address. By asking for clarification on this aspect, the comment provides a direct way for the authors to improve their draft by ensuring that the information is accurate and complete. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context. Overall, the comment is mostly helpful as it identifies a specific area for improvement and guides the authors toward enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which aspects of the computation, algorithm, or implementation should be detailed or how these details should be presented. The action is implicit and somewhat vague, as the authors are left to infer what specific information is needed and how to present it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what specific details are missing or how they should be presented. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks depth and justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what specific details should be included or how they should be presented. This makes it somewhat helpful, as the authors gain insight into a potential enhancement but are left without detailed instructions on how to implement it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLM-based paraphrasing. It provides specific references to support the suggestion for comparison, such as [1] and [2]. While the comment implies that the authors should conduct a more comprehensive analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Lack of Analysis\" and refers to the insufficient analysis of the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, which provides clear guidance on what needs to be addressed. The comment is specific in detailing the areas that need improvement and provides references for further comparison, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods like EDA or LLM-based paraphrasing. The comment provides references to external works, such as [1] and [2], which supports the suggestion for comparison. However, the claim about the lack of analysis is not fully substantiated with specific examples or detailed reasoning, making it somewhat verifiable. The authors would need to consult the referenced works to fully understand the context and implications of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the analysis of the paper, specifically the lack of evaluation of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, would help clarify the unique advantages of the method. The comment provides specific references to external works that could serve as a basis for comparison, offering a clear and actionable path for the authors to enhance their analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting an ablation study to understand the net effect of each component, particularly in the context of learning with MMD. It provides specific examples of experiments that could be performed, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is explicit and concrete, as it clearly outlines the actions the authors should take to improve their draft. The authors know exactly what experiments to conduct to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the section on \"learning with MMD\" and suggests conducting an ablation study to understand the net effect of each component. It provides specific examples of experiments that could be performed, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This makes the comment fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an ablation study is necessary to understand the net effect of each component in the learning process with MMD. It provides specific examples of experiments that could be conducted, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is logical and provides a clear rationale for why an ablation study is needed. However, it lacks specific references or detailed explanations of how these experiments would contribute to the understanding of the MMD learning process. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but could be strengthened with additional details or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that an ablation study is necessary to understand the net effect of each component in the learning process with MMD. It provides specific examples of experiments that could be conducted, such as learning the proposed model with a typical knowledge distillation loss or distilling a Hydra architecture with an MMD loss. This feedback is clear and actionable, offering the authors concrete steps to take to improve their draft by providing a more comprehensive understanding of the components involved. However, the comment could be more helpful if it explained why an ablation study is crucial or how it would impact the overall understanding of the paper. Nonetheless, the suggestion is mostly helpful as it guides the authors toward a specific improvement. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider or investigate this aspect, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario, but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance are being questioned or how this might relate to the broader discussion. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the performance of a specific model configuration. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting aspect of the model's behavior, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate it into their analysis. The comment identifies a potential area of exploration but does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a lack of quantitative analysis on computational gains, specifically mentioning the need for specific measurements or comparisons to substantiate the claimed benefits. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements in DQ V2. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014specific measurements or comparisons to substantiate the claimed computational benefits. The comment suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements in DQ V2. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks specific measurements or comparisons to substantiate the claimed computational benefits of replacing the MAE model with a CNN-based data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. This claim is somewhat verifiable as it highlights a gap in the paper\\'s analysis but lacks specific examples or references to support the need for such quantitative analysis. The authors would need to consider this feedback and potentially include additional data or comparisons to strengthen their claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights the need for specific measurements or comparisons to substantiate the claimed benefits of replacing the MAE model with a CNN-based data augmentation strategy. The comment provides a clear and actionable suggestion by recommending a quantitative analysis, such as GPU hours, memory usage, or training time, to demonstrate the efficiency improvements in DQ V2. This feedback is highly helpful as it directs the authors to a specific area that requires improvement, providing them with a clear path to enhance the rigor and credibility of their claims. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time for COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or comparisons. The action is implicit and somewhat vague, as it lacks specific instructions on how to address the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the time for COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, which would impact its efficiency for certain scenes. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how to address the issue of efficiency. The authors may infer that it relates to the experimental results or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the time for COLMAP and scene-by-scene fine-tuning should be considered when comparing the method, which would render it less efficient for certain scenes. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the method, suggesting that the time for COLMAP and scene-by-scene fine-tuning should be considered. This is a relevant point that could impact the efficiency of the method for certain scenes. However, the comment lacks specificity and does not provide detailed guidance on how the authors should incorporate this consideration into their analysis or comparisons. Without actionable suggestions or examples, the feedback is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical part of the technique. It asks if the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger input and output channels. These questions imply that the authors should provide more discussion, analysis, or experimental results regarding FMN. While the comment does not explicitly instruct the authors to conduct specific experiments or analyses, it provides a clear direction for what needs to be addressed. The authors can infer that they need to provide more detailed information about FMN, its scalability, and potential experiments. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks specific instructions on how to implement the suggested actions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), which is a specific part of the technique discussed in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises several questions and concerns about the FMN, such as the lack of discussion or analysis, the use of other architectures, the scaling of adaptive convolutions, and the scalability of FMN with larger input and output channels. These specific questions provide clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which is a critical part of the technique. It questions the lack of discussion or analysis on FMN, the use of other architectures for FMN, and the scalability of adaptive convolutions with the number of filter parameters. While the comment highlights areas that need further exploration or clarification, it does not provide specific evidence, examples, or references to support these claims. The lack of detailed justification or examples makes the claims somewhat verifiable, as the authors would need to infer the importance of these questions and address them in their response. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is a crucial part of the technique. It raises several questions, including whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with larger input and output channels. These questions highlight important areas that need further exploration and clarification in the paper. By addressing these questions, the authors can provide a more comprehensive understanding of their technique and its potential applications. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the feedback is mostly helpful as it directs the authors to important areas for improvement, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should investigate the individual contributions of two factors: noise and the exponential moving average. It explicitly recommends comparing the performance of the proposed model with and without each factor to understand their separate impacts. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should investigate the individual contributions of two factors: noise and the exponential moving average. It provides a specific suggestion for analysis, which is to compare the performance of the proposed model with and without each factor. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The authors can infer that it relates to the experimental or results sections, but the exact location is not explicitly mentioned. The comment is specific in its suggestion, so it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and the exponential moving average. It recommends analyzing how much each factor contributes individually. The comment provides a logical reasoning by suggesting a specific analysis to understand the impact of each factor, which is a reasonable request for improvement. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct the suggested analysis to fully understand the claim, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the paper. It identifies two factors that contribute to the proposed model\\'s performance\u2014noise and the exponential moving average\u2014and recommends analyzing how much each factor contributes individually. This feedback is clear and offers a concrete direction for the authors to explore, which could lead to a deeper understanding of the model\\'s components and their relative importance. By addressing this suggestion, the authors can enhance the comprehensiveness and clarity of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the timing of the results presentation, suggesting that the authors should also report on the agent\\'s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. The reviewer wonders if the CNN can perform reasonably well with less data. While the comment implies that the authors should consider reporting on the agent\\'s behavior during learning, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors would need to infer that they should include additional analysis or results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the timing of the results presentation, suggesting that the authors should also report on the agent\\'s behavior during the learning process. It speculates that the model parameters might be \"garbage\" early in training and that the planning component could potentially harm the performance. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or results that should be included. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its suggestion to report on the agent\\'s behavior during learning, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the timing of the results presentation in the paper, suggesting that the authors should also report on the agent\\'s behavior during the learning process. The reviewer speculates that early in training, the model parameters might be \"garbage\" and that the planning component could potentially harm the performance. However, the comment acknowledges that this is \"pure speculation\" and does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the timing of the results presentation in the paper, suggesting that the authors should also report on the agent\\'s behavior during the learning process. It speculates that early in training, the model parameters might be \"garbage\" and that the planning component could potentially harm the performance. This feedback is somewhat helpful as it prompts the authors to consider additional aspects of their results, such as the agent\\'s behavior during learning. However, the comment lacks specific guidance on how to address this issue or what specific aspects of the results should be reported. While it identifies a potential area for improvement, it does not provide detailed actionable steps, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors handle concepts in DocRED, specifically whether they consider documents as entire sentences and how they deal with multiple entity mentions referring to the same entity. The comment highlights that this information is currently missing from the manuscript. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this gap in their manuscript. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how the authors handle concepts in DocRED, specifically whether they consider documents as entire sentences and how they deal with multiple entity mentions referring to the same entity. However, it does not specify which part of the manuscript this issue is discussed in, making it weakly grounded. The comment is specific in detailing what information is missing, which is the handling of concepts in DocRED. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the handling of concepts in DocRED, specifically whether the documents are considered as entire sentences and how multiple entity mentions referring to the same entity are dealt with. The comment points out that this information is currently missing from the manuscript. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that this information is necessary or how it would impact the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the handling of concepts in DocRED, particularly whether the documents are considered as entire sentences and how multiple entity mentions referring to the same entity are dealt with. It points out that this information is currently missing from the manuscript, which is a relevant observation that could help the authors clarify their methodology and improve the clarity of their work. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue or what specific aspects of the methodology need further explanation. Overall, the comment is somewhat helpful as it identifies a gap in the manuscript and prompts the authors to address it, but it could be more comprehensive with further guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a subjective opinion that the contribution is marginal, suggesting that the methods used are well-designed and demonstrated. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to enhance the contribution or what specific aspects need improvement. The comment lacks actionable advice, leaving the authors without a clear path for revision. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, suggesting that it is marginal because the methods used are well-designed and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as a particular section or methodology. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment does not provide specific details on what aspects of the contribution are considered marginal or how they could be improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal, suggesting that the methods used are well-designed and demonstrated, and that adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the judgment. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. However, it does not provide any specific feedback or suggestions on how the authors might enhance their contribution or address the perceived lack of significance. Without actionable guidance or detailed critique, the comment offers little value to the authors in terms of improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment highlights a potential area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the additional experiments should be emphasized or clarified. As a result, the comment lacks actionability and provides no direction for the authors to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. This provides some specificity about the part of the paper that the reviewer did not fully engage with, but it does not specify what aspects of the additional experiments need attention or improvement. The comment is weakly grounded because it does not explicitly mention which section of the paper the additional experiments are located in, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a factual statement expressing appreciation for the comprehensive Appendix and acknowledging the reviewer\\'s inability to thoroughly read the additional experiments due to time constraints. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment acknowledges the comprehensive Appendix as a valuable addition to the paper, providing additional detail about certain aspects. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, specifically mentioning the Brusselator. While the comment appreciates the effort to provide more detail, it lacks actionable feedback or suggestions for improvement. It does not guide the authors on how to address the issue of incomplete reading or what specific aspects of the additional experiments might need further clarification or emphasis. As a result, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to fully demonstrate the scalability of LFF, the authors should conduct experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This is an explicit action that provides a clear direction for the authors to improve their draft. The comment specifies the type of tasks that should be included, offering concrete guidance on how to enhance the demonstration of LFF\\'s scalability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper should include these experiments or provide guidance on how to integrate this suggestion. The authors can infer that it relates to the experimental section, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate the scalability of LFF by conducting experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, which is based on the common practice of evaluating continuous control experiments on simple tasks. However, the comment lacks specific examples or references to support the claim that these tasks are more challenging or would better demonstrate LFF\\'s scalability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that to fully demonstrate the scalability of LFF, the authors should conduct experiments on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides specific examples of tasks that could help demonstrate the scalability of LFF. By suggesting these additional experiments, the comment offers a concrete way for the authors to enhance the comprehensiveness and impact of their work. However, the comment could be more helpful if it included additional guidance on how to approach these experiments or what specific aspects of LFF\\'s performance should be highlighted. Overall, the comment is mostly helpful, as it provides valuable direction for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for considering MULT as the only deep learning-based baseline that considers cross-sensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or suggest alternative baselines. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific papers (\"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020,\" \"M2FNet: Multi-modal Fusion Network for Emotion Recognition in Conversation, CVPR workshop 2022,\" and \"MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations, ICASSP 2022\") and the paper \"MULT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with considering MULT as the only deep learning-based baseline, noting its outdated nature. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but notes that MULT was proposed in 2019 and is \"out of fashion.\" This claim is somewhat verifiable as it provides a logical reasoning for why MULT might not be considered a current or relevant baseline. However, the comment lacks specific examples or references to support the claim that MULT is outdated or not considered in the field anymore. Providing more detailed evidence or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the paper for considering MULT as the only deep learning-based baseline that considers cross-sensory interaction, noting that it was proposed in 2019 and is \"out of fashion.\" This feedback highlights a potential weakness in the paper\\'s selection of baselines, suggesting that the authors may have overlooked more recent or relevant works. However, the comment does not provide specific suggestions or alternatives for the authors to consider, nor does it offer guidance on how to address this issue. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that certain terms, such as W1, W2, and W, are not defined in the paper. The reviewer suggests that these terms might denote specific components like the Encoder and Decoder network, but this is only an inference. The comment does not provide explicit guidance on how to define these terms or where they should be introduced in the paper. While the authors can infer that they need to define these terms, the action is not explicitly stated, and the lack of concrete guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections and equations (p.3, A4, eq.3) where terms like W1, W2, and W are not defined. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies what is missing\u2014definitions for these terms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements regarding the absence of definitions for specific terms (W1, W2, and W) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of definitions for terms W1, W2, and W. It provides clear guidance by specifying the sections where these terms are mentioned, allowing the authors to accurately locate and address the issue. However, the comment could be more helpful if it suggested how to define these terms or provided examples of how they should be explained. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs clarification, enabling them to improve the clarity and comprehensibility of their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during the training process. It also inquires whether this alternating process could improve performance. While the comment identifies a potential area of confusion or improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the process and its impact on performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during the training process. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its inquiry about the process and its potential impact on performance, but it is not grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the process of generating negative chips from a lightweight RPN and whether this process is fixed or updated during training. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during the training process. It also inquires whether this alternating process could help improve performance. While the comment identifies a potential area of confusion or improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore its impact on performance. The feedback is somewhat helpful as it prompts the authors to clarify their process, but it does not provide actionable steps or detailed advice for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for this evaluation but may not know exactly how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The suggestion is specific in terms of the evaluation needed, but the lack of grounding makes it challenging for the authors to pinpoint the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the applicability of the proposed approach to patients who are first-time visitors without historical reports. It suggests that the authors should evaluate their approach on both new and old patients, which is a logical and actionable step to ensure the robustness of the method. However, the comment lacks depth and does not provide specific guidance on how to conduct this evaluation or what aspects to focus on. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, limiting its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide an in-depth analysis to explain why inverse scaling happens over compute. This is an explicit action, as it clearly instructs the authors to conduct additional analysis. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, leaving the authors with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an in-depth analysis of why inverse scaling occurs over compute. It implies that the authors should provide an explanation for this phenomenon, which would strengthen the paper. However, the comment does not specify which part of the paper discusses the inverse scaling or where the analysis is lacking. This makes it difficult for the authors to pinpoint the exact section that needs improvement. The comment is specific in its request for additional analysis but lacks grounding, as it does not identify the specific part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an in-depth analysis of why inverse scaling occurs over compute. It suggests that providing such analysis would strengthen the paper. However, the comment does not offer any specific reasoning, examples, or references to support the claim that an in-depth analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of in-depth analysis regarding why inverse scaling occurs over compute. It suggests that providing such analysis would enhance the paper\\'s solidity. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. This limits the comment\\'s usefulness, as it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions: one about additional insights into modest performance gains on the Clothing1M dataset and another about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. While the questions imply that the authors should provide more information or insights, they do not explicitly instruct the authors to do so. The lack of explicit guidance and the vague nature of the questions make it difficult for the authors to know exactly what actions to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the performance of the algorithm on specific datasets, such as Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its request for additional insights and performance data but lacks grounding, as it does not reference specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions seeking additional insights into the performance of the algorithm on specific datasets. It does not contain any claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the performance of the algorithm on specific datasets, such as Clothing1M and WebVision, evaluated by DivideMix. While it does not provide specific suggestions for improvement, it prompts the authors to consider additional insights or data that could enhance their work. This feedback is somewhat helpful as it encourages the authors to explore and provide more comprehensive information about their algorithm\\'s performance on various datasets. However, it lacks depth and does not offer actionable guidance on how to address the questions raised. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks information on the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback provides clear and concrete actions for the authors to take, such as including the hyperparameters used and explaining their derivation, and conducting an evaluation that optimizes hyperparameters against the attack. The comment is explicit and provides detailed guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of description regarding hyperparameters used by each defense and how they are derived. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it provides clear guidance on what needs to be addressed, such as describing the hyperparameters and their derivation, and suggests a maximally charitable evaluation approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. The comment provides a logical reasoning for the claim by suggesting a specific approach for evaluation, which is a common practice in the field. However, it does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of hyperparameter optimization and the suggested evaluation approach to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their evaluation methodology. By addressing this issue, the authors can improve the comprehensiveness and rigor of their study. However, the comment could be more helpful if it offered additional suggestions or examples on how to optimize hyperparameters or present the results. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical results' lack of immediate practical implications but suggests that the authors could provide more take-away points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but notes that it is unclear if this is a novel finding in the paper. While the comment provides a concrete suggestion, it lacks guidance on how to present these take-away points or whether this suggestion is indeed novel. The action is mostly actionable because it offers a specific idea but lacks detailed instructions on how to implement it. Therefore, this comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and their practical implications, suggesting that the authors provide more take-away points for practitioners. It mentions a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. However, the comment does not specify which part of the paper discusses these theoretical results or where the suggestion is made, making it weakly grounded. The comment is specific in suggesting a potential take-away point and questioning its novelty, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results lack immediate practical implications, which is understandable given the novelty of the work. However, the reviewer suggests that more take-away points for practitioners would be beneficial. The comment also highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment provides some reasoning, it lacks specific examples or references to support the claim that this suggestion is not novel. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to further investigate the novelty of the suggestion to address the comment effectively.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the theoretical nature of the results and suggests that the authors provide more practical take-away points for practitioners. It highlights a specific suggestion, \"query a cluster proportionally to the square root of its size,\" but questions whether this is a novel finding in the paper. While the comment identifies a potential area for improvement by suggesting practical applications, it lacks depth and does not provide detailed guidance on how to incorporate these take-away points or whether the suggested approach is indeed novel. The feedback is somewhat helpful as it points out a potential area for enhancement but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the introduction of separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the introduction of separators and asking for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This is a request for clarification rather than a claim, as it does not express an opinion or judgment. It is factual and descriptive, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the introduction of separators in section 4. It questions the rationale behind their inclusion and asks for clarification on what additional information they provide beyond T/I/O. This feedback is clear and actionable, as it prompts the authors to provide a justification for the introduction of separators, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to effectively explain the role of separators. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on which alternative strategies to consider or how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies, providing a clear direction for the authors to explore alternative methods. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any supporting evidence, reasoning, or references to justify why mean pooling might not be the best choice or to suggest alternative strategies. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for exploration, it lacks depth and does not provide specific guidance or examples of alternative pooling strategies that could be used. This limits the usefulness of the feedback, as the authors are left without a clear understanding of how to address the issue or what specific alternatives to consider. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about missing training details, specifically whether the VQGAN is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but are not given specific guidance on how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about missing training details, specifically whether the VQGAN is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or experimental setup sections where training details are typically discussed. The comment is specific in its request for clarification on the training process, providing clear guidance on what information is missing. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about missing training details, specifically whether the VQGAN is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual inquiry that seeks clarification rather than an opinion or judgment. It does not contain any subjective claims or suggestions, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about missing training details, inquiring whether the VQGAN is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. This feedback is clear and actionable, as it prompts the authors to provide necessary information about the training process. By addressing this question, the authors can enhance the transparency and comprehensiveness of their methodology section. However, the comment could be more helpful if it suggested why this information is important or how it might impact the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include and compare their work with existing task-oriented recommendation works, such as the ones mentioned by Li et al. and He et al. It also recommends discussing how their work differs from other chatbox research works. While the comment implies that the authors should include these comparisons and discussions, it does not provide explicit instructions on how to conduct these comparisons or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including and comparing the work with existing task-oriented recommendation works, such as those by Li et al. and He et al. It provides specific references to these works, which helps the authors identify the parts of the paper that need attention. However, it does not explicitly mention which sections of the paper should include these comparisons or discussions, making it weakly grounded. The comment is specific in its suggestion to include comparisons and discussions, but the lack of explicit grounding limits its clarity. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that works such as Li et al. and He et al. are important to include and compare with, as they relate to task-oriented recommendation. The comment provides specific references to these works, which supports the claim by offering a clear basis for comparison. However, the comment could be strengthened by explaining why these works are particularly relevant or how they differ from the current work. Despite this, the inclusion of references provides a solid foundation for the claim, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should include and compare their work with existing task-oriented recommendation works, such as those by Li et al. and He et al. This feedback is valuable as it highlights the importance of contextualizing the current work within the broader literature, which can help readers understand the novelty and contributions of the research. Additionally, the comment recommends discussing how the current work differs from other chatbox research works, which can provide a clearer understanding of the paper\\'s originality and relevance. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the feedback is mostly helpful as it offers actionable suggestions for improving the paper\\'s context and relevance, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed methods, DualIS and DualDIS, do not perform well on some cross-model retrieval tasks, specifically mentioning minor improvements in the MSVD task as shown in Table 3. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the performance of the methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MSVD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed methods, DualIS and DualDIS, by pointing out that they do not perform well on some cross-model retrieval tasks, specifically mentioning minor improvements in the MSVD task. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, citing the performance in MSVD (Table 3) as an example. However, the comment lacks specific details or references to support this claim, such as comparisons with other methods or a detailed analysis of the results. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some cross-model retrieval tasks, as evidenced by minor improvements in the MSVD task. This feedback is somewhat helpful as it identifies a potential weakness in the paper, prompting the authors to consider the limitations of their methods and possibly explore ways to improve their performance on specific tasks. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting additional experiments. Therefore, while it highlights an area for improvement, it is not fully comprehensive, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental strengths of the proposed approach, suggesting that running a descent procedure for 40 different networks from the training phase may not be necessary. The reviewer proposes an alternative method, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient, as at least one of these restarts would likely reach the global minimum. This comment provides a clear and explicit suggestion for improvement, offering a concrete alternative to the authors. However, it does not fully explain why the current approach is not effective or how the proposed alternative would improve the results. Despite this, the action is explicit and provides a clear direction for the authors to consider. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not specify which part of the paper discusses the experimental setup or the descent procedure, making it weakly grounded. The comment is specific in detailing the alternative approach and the reasoning behind it, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental strengths of the proposed approach are not convincing and suggests an alternative method. The reviewer provides a logical reasoning by comparing the proposed algorithm with vanilla Adam, explaining that running a descent procedure for 40 different networks may not be necessary. However, the comment lacks specific examples or references to support the claim that running vanilla Adam with 40 random initial points would be sufficient. This makes the claim somewhat verifiable, as it provides a logical argument but requires further evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, proposing to run vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is somewhat helpful as it identifies a potential weakness in the experimental design and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided additional context or explanation for why the current approach might not be effective or how the proposed alternative would improve the results. Overall, the comment provides a clear direction for the authors to consider but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of FedSP in Tables 1 and 2, noting that it is not the best performer on some datasets. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting improvements to FedSP or how to present the results differently. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to Tables 1 and 2, providing some grounding as it specifies the parts of the paper being addressed. However, it does not specify what needs to be addressed or why the performance of FedSP is not the best, leaving the authors without clear guidance on how to improve their draft. The comment lacks specificity, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data to justify the assertion, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a discrepancy in the performance of FedSP in Tables 1 and 2, noting that it is not the best performer on some datasets. However, it does not provide any further analysis, suggestions, or context to help the authors understand the implications of this observation or how to address it. Without additional guidance or actionable feedback, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit guidance or suggestions on how the authors should explore this dataset further. The action is implicit, as the authors need to infer that they should delve deeper into the dataset, but it lacks concrete details on what specific aspects to focus on or how to enhance the exploration. As a result, the comment is vague and barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this relates to, such as a specific section or analysis where the dataset is discussed. Without explicit references or detailed guidance, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the dataset could be explored further. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance on how the authors might explore the dataset further. It does not offer actionable suggestions or details on what aspects of the dataset should be examined or how this exploration could enhance the paper. As a result, the comment is barely helpful, as it points out a potential area for improvement but does not provide sufficient direction for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states a general observation about the limitations of pruning work, specifically mentioning that efficiency gains on GPU are not yet possible. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or what steps they could take to improve the efficiency of their work on GPU. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general observation about the limitations of pruning work, specifically mentioning that efficiency gains on GPU are not yet possible. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on how this limitation affects the current work. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might improve the efficiency of their work on GPU. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a general statement about the limitations of pruning work in achieving efficiency gains on GPU. However, it lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a general observation about the limitations of pruning work in achieving efficiency gains on GPU. However, it lacks specificity and does not offer any actionable advice or suggestions for the authors to improve their work. Without detailed guidance or examples, the comment does not provide the authors with a clear path for addressing the issue or enhancing their draft. As a result, the comment is not helpful at all, as it does not contribute to the authors\\' understanding of how to improve their paper.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the cost implications of the method for men and women, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this question or what specific information should be included in the paper to answer it. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the cost implications of the method for men and women but does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or context about what the authors should do to address this question. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on the cost implications of the method for men and women. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the cost implications of the method for men and women, which is an important aspect of the paper\\'s impact and applicability. However, it does not provide any guidance or suggestions on how the authors might address this question or what specific information should be included in the paper to answer it. Without actionable feedback or direction, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area of interest but lacks depth and guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides an example reference, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which could serve as a basis for the clarification. While the action is explicit, the comment could be more actionable by providing specific guidance on how to make this clarification, such as suggesting particular aspects to focus on or how to structure the explanation. Nonetheless, the comment is mostly actionable as it clearly identifies an area for improvement and provides a reference for further clarification.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, namely the difference between meta solvers and centralized RL where agents share weights. The reference to Foester et al. provides additional context and guidance for the clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between these and centralized RL where agents share weights. The comment provides a reference to Foester et al., \"Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which supports the claim by offering a relevant example of a similar concept. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the nature of the meta solvers, suggesting that they might be centralized controllers. It provides a specific reference to Foester et al., \"Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which could serve as a basis for clarifying the difference between meta solvers and centralized RL where agents share weights. This feedback is clear and actionable, as it directs the authors to a relevant reference that could help them better articulate their approach. However, the comment could be more helpful if it included a more detailed explanation of how the reference might be applied or what specific aspects of the paper need clarification. Overall, the comment is mostly helpful, as it provides a valuable direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper\\'s categorization of papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not explicitly instruct the authors to make any changes or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the availability of papers on arXiv when categorizing them, but they are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of how the paper categorizes papers based on their publication years on the ACL anthology, noting that many papers are available on arXiv earlier than their publication in the ACL anthology. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or table, making it weakly grounded. The comment is specific in detailing the issue with the categorization, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s categorization of papers based on their publication years on the ACL anthology is incorrect, as many papers are available on arXiv earlier than their publication in the ACL anthology. The reviewer provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This example supports the claim by providing a concrete instance of the issue, making the comment mostly verifiable. However, the comment could be strengthened by further elaboration or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment points out a potential issue with the paper\\'s categorization of papers based on their publication years on the ACL anthology. It highlights that many papers are available on arXiv earlier than their publication in the ACL anthology, using the BERT paper as an example. This feedback is somewhat helpful as it identifies a specific area where the paper\\'s categorization might be inaccurate. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their categorization method. To be more helpful, the comment could provide recommendations or examples of how to handle papers that are available on arXiv before their ACL publication. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part questions the authors\\' decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. While the comment implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"QRS and RS,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between QRS and RS and the need for clarification on a specific value of u that would cause them to behave differently. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the authors\\' decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. However, it does not provide any supporting evidence or reasoning to justify why importance sampling should have been used or why the current approach is inferior. The second part raises a question about the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific but still lacks detailed reasoning or examples to fully substantiate the claim. Overall, the comment lacks sufficient evidence and reasoning to be considered fully verifiable, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two distinct points. The first part questions the authors\\' decision to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, suggesting that importance sampling could have been used directly. This feedback is somewhat helpful as it prompts the authors to reconsider their approach and potentially improve it. However, it lacks specific guidance on how to address this issue or why importance sampling might be more appropriate. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and requests clarification on a specific value of u that would cause them to behave differently. This part is more specific and actionable, as it provides a clear direction for the authors to improve their explanation. Overall, the comment provides some helpful insights but could be more comprehensive and detailed in its suggestions, aligning with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It implies that the performance is similar to IRM, which may be due to the issues mentioned earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to improve the experimental design or analysis to better validate their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results, specifically mentioning the last two datasets. However, it does not specify which datasets these are, making it weakly grounded. The comment provides some specificity by questioning the validity of the results and suggesting a possible cause, but it lacks detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of \"problems mentioned above\" suggests that there might be underlying issues, but without elaboration, the claim remains vague. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or detailed justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the experimental results, specifically noting that the performance on the last two datasets is similar to IRM, which may indicate a lack of effectiveness in validating the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the experimental results. It lacks actionable feedback, such as recommending additional experiments, modifications to the methodology, or alternative analyses to better validate the proposed method. Without detailed guidance, the authors are left without a clear path for improvement, making the comment barely helpful.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of detecting both entities in the example of Figure 2, questioning the added value of identifying both entities compared to just knowing the longer one. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or improve their draft in response. As a result, the authors are left without a clear understanding of what steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting both entities and just knowing the longer one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of detecting both entities in the example of Figure 2, suggesting that knowing the longer one might be sufficient. However, the comment does not provide any supporting evidence, reasoning, or references to justify why detecting both entities is unnecessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in the example presented in Figure 2, questioning the added value of identifying both entities compared to just knowing the longer one. While it highlights a potential area of confusion or lack of clarity in the paper, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This comment implies that the authors should clarify the distinction between sequential and non-sequential information, particularly regarding the term \"chunk.\" However, it does not provide explicit guidance on how to address this issue or clarify the confusion. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"non-sequential information such as chunks\" and asks if \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the terminology used in the paper, specifically the phrase \"non-sequential information such as chunks.\" It raises a logical inquiry about whether \"chunk\" is considered sequential information, which is a reasonable question given the context. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim or clarify the confusion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the terminology used in the paper, specifically the phrase \"non-sequential information such as chunks.\" It points out a potential confusion regarding whether \"chunk\" is considered sequential information, which could be a critical clarification for the authors to make. However, the comment does not provide any suggestions or guidance on how to address this issue or clarify the terminology. While it identifies a potential area of confusion, it lacks depth and actionable feedback, making it somewhat helpful. The authors are left with a clear question to address but without specific guidance on how to resolve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that needs explanation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to address the exception but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the upper bound when there is a separate node with 0 neighbors, which is a clear and specific concern. The comment raises a logical question about the exception and asks for an explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this exception is problematic or how it affects the theorem. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the question, rendering the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges the correctness of the theorem but points out an exception that seems counterintuitive, asking for an explanation. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this exception or clarify the theorem. The feedback is somewhat helpful as it prompts the authors to consider this specific case, but it lacks depth and actionable advice, making it less comprehensive than it could be. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the analysis regarding the detection of rumors generated by GPT and natural rumors. It suggests that further analysis or solutions could be proposed to address this issue. However, the comment does not provide explicit guidance on what specific analysis or solutions should be explored. While it identifies an area for improvement, the lack of concrete details or actionable steps makes it somewhat vague. The authors are left with a general idea of what needs to be addressed but without a clear path forward. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"The handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking analysis on why GPT-generated rumors are as difficult to detect as natural rumors, and it points out the inconsistency in the experimental results. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks analysis on why GPT-generated rumors are as difficult to detect as natural rumors. It suggests that since both are written by humans, they should be equally difficult to detect. The comment provides a logical reasoning by pointing out the inconsistency in the experimental results, where natural rumors are easier to detect than GPT-generated rumors. However, it does not provide specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a clear rationale but lacks additional evidence or references to make it fully verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the analysis of rumors generated by GPT. It points out that the paper highlights the challenges of detecting GPT-generated rumors but does not provide further analysis or solutions. The comment also questions the reasoning behind why GPT-generated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to explore this gap in their analysis and provide a more comprehensive understanding of the issue. However, it could be more helpful if it offered specific suggestions or examples of how to address this gap. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution is limited, specifically stating that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Section 4, stating that it is more about heuristics than a formal and principled solution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically stating that Section 4 is more about heuristics than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the technical contribution of the paper, noting that Section 4 is more about heuristics than a formal and principled solution. This feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and does not provide actionable suggestions for improvement. The authors are left with a general understanding of the issue but without specific guidance on how to enhance the technical contribution or address the critique. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses regret that the probability mass function is not fully utilized in the paper, specifically mentioning that it is set to a quasi-uniform distribution that depends on only one parameter. The reviewer suggests that considering various probability mass functions could have added depth to the experimental setting. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific alternatives to the quasi-uniform distribution. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the quasi-uniform distribution being used and suggests that considering various probability mass functions could have added depth to the experimental setting. The comment provides a clear direction for improvement by questioning the choice of the quasi-uniform distribution and suggesting an alternative approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses regret that the probability mass function is not fully utilized in the paper, specifically mentioning that it is set to a quasi-uniform distribution. The reviewer suggests that considering various probability mass functions could have added depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that other probability mass functions would be beneficial. The reasoning is somewhat logical, but it is not fully developed, making the claim somewhat verifiable. The authors would need to infer the potential benefits of exploring different probability mass functions, which adds to the complexity of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by noting that the probability mass function is not fully utilized in the paper. It points out that the quasi-uniform distribution used in MixBoost depends on only one parameter, suggesting that considering various probability mass functions could have added depth to the experimental setting. The reviewer questions the choice of the quasi-uniform distribution and implies that exploring different distributions could be beneficial. However, the comment lacks specific suggestions or examples of alternative distributions that could be considered, which would make it more actionable for the authors. While it provides some insight into a potential area for enhancement, the feedback is incomplete and could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in comparisons or what specific steps to consider. As a result, the authors are left without any actionable information to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not provide details on what aspects of the comparison are unfair or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of comparing the accuracies of different models, specifically noting that ChatGPT shows a higher percentage of abstention. While it identifies a potential issue with the comparison, it lacks depth and does not provide any specific guidance or suggestions on how the authors might address this concern. The comment does not offer actionable advice or insights that could help the authors improve their draft. Therefore, it is barely helpful, as it highlights a potential issue but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss connections with a specific reference, [a], which is relevant to their topic. It provides a clear action for the authors to take, which is to discuss the connections between their work and the reference. The comment also specifies the reference and its relevance, providing concrete guidance on how to implement the suggested action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references that are relevant to the topic, allowing the authors to accurately identify the parts of the paper that need attention. It also specifies what needs to be addressed, which is the discussion of connections with the reference [a], particularly its use of supervised learning in QBF solving and its generalization of SMT. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain references are relevant to the topic and suggests discussing connections with one of them, specifically [a]. However, the comment does not provide a detailed explanation of why these references are relevant or how they relate to the paper. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic, particularly reference [a]. It suggests that the authors should discuss connections with this reference, which uses supervised learning in QBF solving and generalizes SMT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by exploring connections with existing work. However, the comment could be more helpful if it included a brief explanation of why these references are important or how they relate to the authors\\' work. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the mono-tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration without detailed instructions on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"When training, a mono tonic relationship is imposed between the degree of a single-task predictor participation and the weight of the corresponding task loss,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely whether the mono-tonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. The reference to a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" adds further specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the mono-tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. The comment references a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" which provides a basis for the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve into the referenced work to fully understand the implications and potential alternatives, which adds to the complexity of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the mono-tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that this relationship could be replaced by others. It also references a specific paper, \"Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with Hypernetworks[C]//International Conference on Learning Representations. 2020,\" which provides a potential direction for exploration. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to explore alternative relationships or how to incorporate the referenced work into the paper. While it identifies a potential area for improvement, the feedback is somewhat vague and lacks actionable steps, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of computation cost and running time, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects of computation cost or running time should be compared or how this comparison should be presented. Without any actionable steps or suggestions, the authors are left without a clear understanding of what changes or additions are needed to address this point. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of computation cost and running time but does not specify which part of the paper this comparison should be made in. It lacks grounding as it does not identify a specific section, table, or figure where this comparison is discussed. Additionally, it is not specific about what aspects of computation cost or running time should be compared. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for a comparison in terms of computation cost and running time, which does not contain any claims or opinions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of computation cost and running time, which is a relevant aspect of the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what specific comparisons should be made. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. While it highlights potential issues, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these concerns or improve their draft. The lack of actionable advice makes the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not reference any specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using federated learning for traffic signal control. It challenges the authors to justify why their approach is more privacy-preserving and whether privacy is indeed an issue in this context. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it highlights potential weaknesses, it does not provide actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph, which clarifies the description. This feedback is explicit and provides a clear action for the authors to take, which is to reorder the content to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the difficulty in understanding the description of the neural network, and suggests a solution by recommending that the final paragraph of the section be moved to the beginning. This provides clear guidance on how to improve the clarity of the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand but acknowledges that the final paragraph of the section clarifies it. The suggestion to start the section with the final paragraph is based on logical reasoning, as it implies that the clarity of the description improves as the section progresses. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact issues with the description and how rearranging the content would improve clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand but becomes clearer in the final paragraph of the section. It provides a constructive suggestion to improve the clarity by recommending that the section start with the final paragraph, which clarifies the description. This feedback is actionable and offers a clear path for the authors to enhance the readability of their draft. However, it could be more helpful if it included additional suggestions or examples on how to further improve the clarity of the description. Overall, the comment is mostly helpful as it provides a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model is limited to CTC loss and asks if it would be possible to train it towards attention-based enc-dec training. While the comment implies that the authors should consider alternative training methods, it does not provide explicit guidance on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors would need to infer that they should explore alternative training methods and figure out how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the model is limited to CTC loss and asks if it could be trained towards attention-based enc-dec training. However, it does not specify which part of the paper discusses the model or its limitations, making it weakly grounded. The comment is specific in suggesting an alternative training method, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model is limited to CTC loss and asks if it could be trained towards attention-based enc-dec training. However, the comment does not provide any reasoning, evidence, or references to support the claim that the model is limited to CTC loss or why attention-based enc-dec training would be beneficial. Without such support, the claim remains unverifiable, as the authors would need to infer the basis of the suggestion themselves. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the model, suggesting that it is currently limited to CTC loss and asks if it could be trained towards attention-based enc-dec training. This feedback is somewhat helpful as it points out a specific area for improvement and suggests an alternative approach. However, the comment lacks depth and does not provide detailed guidance on how to implement this change or what specific benefits might be expected from such a shift. While it offers a direction for improvement, it does not fully support the authors in making the necessary adjustments. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address the question or what changes might be necessary. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggests that one type (the column header) should suffice. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). However, it does not provide any supporting evidence, reasoning, or examples to justify why the division is unnecessary or how it could be improved. The comment lacks specific details or references that would help the authors understand the basis of the question or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the need for one type (the column header). While it identifies a potential area of confusion or redundancy, it does not provide any actionable suggestions or guidance on how the authors might address this issue or clarify the purpose of the different types of tables. The comment lacks depth and does not offer any constructive feedback that would help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the attack methods used in the paper, labeling them as \"naive\" and suggesting that other classical attack methods in NLP should be considered. The reviewer provides an example of papers that could be referenced for alternative methods. While the comment implies that the authors should consider using more sophisticated attack methods, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the specific methods to consider, but it lacks directness in its instruction. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but does not explicitly tell the authors what to do.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment critiques the attack methods used in the paper, specifically mentioning that they are \"naive\" and suggesting the use of more classical attack methods in NLP. It provides an example of papers that could be referenced for alternative methods. However, the comment does not specify which part of the paper discusses the attack methods, making it weakly grounded. The suggestion to consider other attack methods is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are \"naive\" and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example of papers that could be referenced for alternative methods, which supports the claim. However, the comment lacks detailed reasoning or examples of why the current attack methods are considered naive, making it somewhat verifiable. The authors would need to delve deeper into the literature to fully understand the critique and potential improvements. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper by labeling the attack methods as \"naive\" and suggesting that more classical attack methods in NLP should be considered. It provides a specific example of papers that could be referenced for alternative methods, which is a clear and actionable suggestion for the authors to improve their draft. However, the comment could be more helpful if it provided a detailed explanation of why the current attack methods are considered naive or how the suggested methods could enhance the paper. Despite this, the feedback is mostly helpful as it directs the authors to consider more robust attack methods, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pre-trained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how to address these concerns or suggest specific actions for the authors to take. The action is implicit and vague, as the authors are left to infer that they should consider the potential impact of prior knowledge on fairness and take steps to mitigate it, but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment provides a specific concern about the potential for the pre-trained visual model and target dataset to leak additional information, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pre-trained visual model and target dataset might leak additional information, skewing results and leading to issues of unfairness. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider the potential impact of prior knowledge on fairness and explore ways to mitigate it, but the comment does not provide detailed guidance or evidence to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue with the pre-trained visual model and target dataset leaking additional information, which could skew results and lead to unfairness. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or ensure fairness in their comparisons. While it identifies an important issue, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not fully support the authors in resolving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for improvement, clarification, or further analysis. The comment is purely observational and lacks any actionable guidance, leaving the authors without a clear understanding of what they should do in response. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the observation that function words dominate content words in a Japanese sentence, which is a clear and detailed observation that the authors can address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks depth and does not offer any context or examples to substantiate the observation, making it difficult for the authors to understand the basis of the surprise. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as observed in Figure 1. However, it does not provide any further analysis, explanation, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance for the authors to address the issue or enhance their understanding of the data. As a result, the comment is not helpful at all, as it does not provide any meaningful insights or suggestions for improvement.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests using the minimal k-means objective over multiple seeds as a baseline instead of the average of k-means objectives. This is a specific and explicit suggestion, providing a clear action for the authors to take. The comment also includes references to support the suggestion, which adds to the actionability by providing a concrete basis for the recommendation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to using the average of k-means objectives with multiple seeds as a baseline, recommending the use of the minimal k-means objective instead. It provides references to support this suggestion, which adds specificity to the comment. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using the minimal k-means objective over multiple seeds as a baseline instead of the average of k-means objectives. It provides references to support this claim, citing two studies: \"Local maxima in the likelihood of gaussian mixture models\" by Jin et al. and \"K-means properties on six clustering benchmark datasets\" by Fr\u00e4nti and Sieranoja. These references offer a solid foundation for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced studies to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a minor suggestion regarding the choice of baseline for k-means objectives. It recommends using the minimal k-means objective over multiple seeds instead of the average, citing references to support this claim. While the suggestion is specific and actionable, it could be more helpful if it included a detailed explanation of why the minimal k-means objective is more reasonable or how it might impact the results. Additionally, the comment could benefit from a clearer connection to the paper's specific context or how this change would improve the draft. Overall, the comment offers some guidance but lacks depth and context, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an important reference related to the idea of unrolling, specifically mentioning \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss its relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add the reference and discuss its context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the reference \"Lista\" and provides a link to the paper by Yann LeCun, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely a discussion of the similarities and differences between the proposed work and \"Lista,\" and the importance of placing the paper in context. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically mentioning \"Lista\" by Yann LeCun. It provides a link to the paper, which is a clear and specific reference. The comment also explains the relevance of discussing the similarities and differences between the proposed work and \"Lista\" to provide context. This level of detail and reference makes the claim fully verifiable, as it provides a clear basis for the authors to understand and address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper, namely the lack of reference to the concept of unrolling, first proposed in \"Lista\" by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and \"Lista\" to provide context. This feedback is clear and actionable, as it directs the authors to include a relevant reference and to discuss its relevance to their work. By addressing this gap, the authors can enhance the paper\\'s context and relevance, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the reviewer suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the steps to take to clarify the definition and provide evidence. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The comment also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the sparsity of the residual term is discussed. The comment is specific in detailing what needs to be addressed, such as providing evidence for the sparsity assumption and comparing it with existing methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. The reviewer also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies areas for clarification and improvement, it lacks specific examples or references to support the claim about the sparsity assumption or the advantages of the proposed method. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the clarity of the sparsity definition of the residual term in the paper. It questions whether the residual term includes many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the reviewer suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. This feedback is clear and actionable, as it directs the authors to clarify the definition and provide evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to present this evidence or compare the assumptions with existing methods. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance or suggestions on how the authors should address this issue or what alternative terminology or explanations could be used. The action is explicit but lacks concrete details on how to implement the change, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the term \"connectivity,\" namely, that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this term is misleading or how it deviates from the intended meaning. Without additional context or explanation, the claim remains unverifiable, as the authors would need more information to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not refer to the structural connections between the brain and body. This feedback is somewhat helpful as it points out a specific area where the terminology might be confusing. However, the comment lacks depth and does not provide suggestions on how to address this issue or what alternative terminology could be used. While it highlights a potential problem, it does not offer actionable guidance for improvement, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers the authors to another section for more information, but without explicit instructions or concrete suggestions, the authors are left without a clear path forward. This makes the comment vague and unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that the paper is not polished and lacks details in several areas, including related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details or provide specific examples of what is lacking. The comment refers the authors to another section, \"Clarity, Quality, Novelty And Reproducibility,\" for more information, but this does not help the authors identify the exact issues in their current draft. As a result, the comment is not grounded and lacks specificity, making it difficult for the authors to determine what needs to be addressed. Therefore, this comment aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, making it difficult for the authors to understand and address the issues. The comment refers to another section for more information, but this does not enhance the verifiability of the claim. Without detailed justification or examples, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the paper lacks polish and details in several areas, including related work, experiments, and writing. However, it does not provide specific examples or suggestions on how to address these issues, leaving the authors without actionable feedback. The comment refers to another section for more information, but this does not help the authors identify the exact weaknesses or improvements needed. As a result, the comment is not helpful at all, as it does not offer any constructive guidance for enhancing the draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific steps in the process and suggests that the authors should focus on studying the essentialness of using an orthogonal matrix, particularly in Step 3. It implies that the authors should investigate the impact of using an orthogonal matrix versus other forms, but it does not provide explicit guidance on how to conduct this investigation or what specific aspects to examine. While the comment identifies an area for further study, it lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed in these steps, particularly the importance of studying the use of an orthogonal matrix in Step 3. The comment provides clear guidance on what aspect of the paper requires further investigation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of an orthogonal matrix is essential for a specific step in the process, but it does not provide detailed reasoning or evidence to support this claim. The comment suggests that the authors should study the importance of using an orthogonal matrix, but it lacks specific examples or references to substantiate the claim. This makes the comment somewhat verifiable, as it provides a direction for further investigation but lacks sufficient justification or evidence to fully support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the steps involved in the process, particularly highlighting the importance of using an orthogonal matrix in Step 3. It suggests that the authors should study the essentialness of using an orthogonal matrix rather than just following a form that connects local and beyond local windows. This feedback is clear and actionable, as it directs the authors to a specific area that requires further investigation and validation. However, the comment could be more helpful if it provided additional guidance on how to conduct this study or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the models and datasets used are too toy-like and recommends using more challenging datasets such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. The reviewer also asks if there is a foreseeable challenge to experiment on language tasks. While the comment provides specific suggestions for improving the models and datasets, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should consider using more challenging datasets and address the question about language tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the models and datasets used in the paper, suggesting that they are too toy-like and recommending the use of more challenging datasets such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. However, it does not specify which part of the paper discusses these models and datasets, making it weakly grounded. The comment is specific in suggesting alternative datasets and models, providing clear guidance on how to improve the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the models and datasets used are \"too toy-like\" and suggests using more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. The reviewer provides specific examples of datasets and models that could be used, which supports the claim. However, the comment lacks detailed reasoning or references to justify why these specific datasets and models are more challenging or beneficial. While the suggestion is clear, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the models and datasets used in the paper, labeling them as \"too toy-like.\" It provides actionable feedback by suggesting the use of more challenging datasets such as CIFAR100, ResNet 34 or 50, and ViT-tiny or small. This guidance is clear and could help the authors improve the robustness and relevance of their experiments. Additionally, the comment raises a question about the feasibility of experimenting on language tasks, which could prompt the authors to consider this aspect. However, the comment could be more helpful if it included a detailed explanation of why these specific datasets and models are recommended or how they would enhance the study. Overall, the comment is mostly helpful as it provides specific suggestions for improvement, but it could be more comprehensive with additional context or reasoning.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This implies that the authors should conduct these studies to provide a more comprehensive understanding of their work. However, the comment does not explicitly instruct the authors to conduct these studies or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for additional studies but may not know exactly how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some natural ablation studies are missing, specifically asking about the performance of scratchGAN when pretraining is used. This implies that the authors should conduct these studies to provide a more comprehensive understanding of their work. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. It is specific in suggesting the need for these ablation studies, particularly regarding the central argument against pretraining. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This claim is somewhat verifiable as it provides a clear suggestion for additional studies that could strengthen the paper. However, the comment lacks specific examples or references to support the importance of these ablation studies, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides a logical suggestion but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting that some natural ablation studies are missing, specifically asking how scratchGAN performs when pretraining is used. This is a valuable observation that could help the authors strengthen their work by providing additional insights into the effectiveness of their approach. However, the comment could be more helpful if it offered specific guidance on how to conduct these ablation studies or what aspects to focus on. Despite this, the feedback is clear and actionable, making it mostly helpful for the authors. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of a comparison against baselines in the paper, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. The comment suggests that this is a common practice in binary analysis applications and that many papers have developed architecture-agnostic similarity comparisons or reported similar tasks. While the comment implies that the authors should include baselines for comparison, it does not explicitly instruct them to do so or provide specific guidance on which baselines to use. The action is implicit and somewhat vague, as the authors can infer the need for baselines but may not know exactly which ones to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the lack of baselines in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not comparing against baselines and references a common practice in binary analysis applications. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, specifically in the context of a functionality similarity comparison study. The reviewer supports this claim by noting that many papers in the field have developed architecture-agnostic similarity comparisons or reported similar tasks. However, the comment does not provide specific examples or references to these papers, which would strengthen the argument. The claim is somewhat verifiable as it provides a general context but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against baselines. It highlights that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering any baselines. This feedback is valuable as it prompts the authors to include baseline comparisons, which is a common practice in binary analysis applications. The comment also references the broader context of architecture-agnostic similarity comparisons and codesearch, providing a context for the authors to understand the importance of including baselines. However, the comment could be more helpful if it suggested specific baselines or methods for comparison. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a specific mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is concrete in its guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention a specific difference in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This claim is based on a logical observation and does not require external references or detailed reasoning. The suggestion is clear and straightforward, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improvement. It directs the authors to include a mention in SI 6.5 regarding the differences in evaluation, despite the preprocessing being identical to that in Mnih et al. [7]. This feedback is clear and concrete, offering the authors a precise way to enhance their draft by highlighting a relevant distinction. By addressing this point, the authors can provide a more comprehensive understanding of their work and its context. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors' claims of efficiency advantages over previous work and the lack of metrics in the paper to support these claims. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include metrics to demonstrate the efficiency of their proposed method, but the comment lacks concrete details on what specific metrics should be used or how to present them. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper not reporting any metrics to demonstrate the efficiency of the proposed method, despite claims of advantages over previous work. However, it does not specify which part of the paper discusses these advantages or where the metrics should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the lack of metrics but lacks grounding, as it does not provide a clear reference to the specific sections or parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide metrics to support the claim of efficiency advantages over previous work. This is a subjective opinion that requires justification, as it challenges the authors\\' assertion of efficiency. However, the comment does not provide specific examples or references to previous work that the authors could use to address the claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique or to respond effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically that it claims advantages over previous work in terms of efficiency but lacks any metrics to support these claims. This is a significant gap in the paper, as it undermines the credibility of the authors\\' assertions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending which metrics to include or how to present them. While it highlights a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a key weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks specific suggestions or guidance on how to enhance the contribution or address the limitations mentioned. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically mentioning the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in identifying the issue with the contribution, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contribution of the paper is not sufficient, specifically addressing the overfitting problem of training GANs with limited data and proposing differentiable augmentation. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the sufficiency of the paper\\'s contribution, specifically mentioning the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not provide any specific suggestions or guidance on how the authors might enhance their contribution or address the limitations mentioned. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details at line 81, specifically asking about the nature of the state-space (finite or continuous), the actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be more precise to provide explicit details. This feedback is clear and direct, giving the authors a concrete action to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: providing more details about the state-space, actions, and the space in which theta lies. The reviewer suggests that while they can infer the answers, it would be more precise to be explicit. This level of detail provides clear guidance for the authors on what needs to be clarified in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking for more details about the state-space, actions, and the space in which theta lies. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a factual request for additional information, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the authors could provide more clarity and detail. By asking about the nature of the state-space, actions, and the space in which theta lies, the reviewer highlights a potential source of confusion in the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address these questions, such as recommending specific sections to expand or examples to include. While it points out an area for improvement, it lacks depth and actionable guidance, making it somewhat helpful but not fully comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or improve their proof technique. The action is implicit and vague, as the authors are left to infer that they need to clarify or address the contradiction in their proof. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity, and references Section 3 for further context. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that this is mentioned in Section 3, where the authors discuss the inapplicability of Theorem 1 due to normalization. However, the comment does not provide further explanation or evidence to support why this is a concern or how it affects the validity of the proof. The lack of detailed reasoning or references makes the claim somewhat verifiable, as the authors would need to delve deeper into the paper to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that this is mentioned in Section 3, where the authors discuss the inapplicability of Theorem 1 due to normalization. This feedback is somewhat helpful as it points out a potential weakness in the proof technique, but it lacks depth and does not provide suggestions on how the authors might address this issue or improve their proof. While it highlights an area for improvement, the comment could be more helpful with additional guidance or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a personal belief that LiDAR-based segmentation is the best choice for the downstream task, contrasting with the authors\\' use of object detection. It also provides a rationale for this belief, suggesting that colorization-based pre-training focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment does not provide explicit guidance or suggestions for the authors to consider alternative methods or address the potential limitations of their current approach. The action is implicit and vague, as the authors are left to infer that they should consider LiDAR-based segmentation but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the choice of downstream task, specifically mentioning object detection and suggesting LiDAR-based segmentation as a better option. It provides a rationale for this suggestion, noting that colorization-based pre-training focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream task or where this issue is addressed, making it weakly grounded. The comment is specific in detailing the potential issue with the current approach and suggesting an alternative, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a subjective opinion that LiDAR-based segmentation is a better choice than object detection for the downstream task. The reviewer provides a rationale by suggesting that colorization-based pre-training focuses on semantics, which may not be sufficient for object detection tasks that require accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment lacks specific examples or references to support the claim that LiDAR-based segmentation is superior. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a subjective opinion about the choice of downstream task, suggesting that LiDAR-based segmentation might be a better option than object detection. It offers a rationale for this belief, noting that colorization-based pre-training focuses on semantics, which may not be sufficient for tasks requiring accurate locations and poses, especially in benchmarks like KITTI and Waymo. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore alternative methods. While it highlights a potential weakness in the current approach, it does not provide actionable feedback for improvement. Therefore, the comment is somewhat helpful, as it offers insight but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential contradiction between the objective of Eq (12) and the IPO (Initial Point Optimality), but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion for how to resolve the contradiction or what changes might be necessary to align the objective with IPO. Without actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (12),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential contradiction with IPO, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the objective of Eq (12) is in contradiction with IPO (Initial Point Optimality). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the objective of Eq (12) in relation to IPO (Initial Point Optimality). However, it does not provide any further explanation or context about what this contradiction entails or how it might impact the paper. Without additional guidance or suggestions on how to address this issue, the authors are left without a clear understanding of what needs to be improved or how to resolve the contradiction. This lack of depth and actionable feedback makes the comment somewhat helpful, as it highlights a potential problem but does not offer a path forward for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, questioning whether the image encoder can produce meaningful embeddings for these concepts. It highlights a potential issue with concepts where the class label is more semantically related than geometrically. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they should investigate or discuss the limitations of their approach in relation to semantic concepts. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts. It provides a nuanced analysis by distinguishing between geometrically distinctive concepts and those where class labels are more semantically related. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The authors can infer that it relates to the discussion of the visual memory or adaptation capacity, but the exact location is not clearly specified. The comment is specific in detailing the concern about the adaptation capacity, particularly for concepts with semantic rather than geometric correlations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory, questioning whether it can accommodate new concepts, especially those where class labels are more semantically related than geometrically. The reviewer provides a logical reasoning by distinguishing between geometrically distinctive concepts and those with semantic correlations, suggesting that the adaptation capacity might be less effective for the latter. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to consider this critique and potentially provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a thoughtful question about the adaptation capacity of the proposed visual memory, specifically in relation to accommodating new concepts. It highlights a potential concern by distinguishing between geometrically distinctive concepts and those where class labels are more semantically related. This observation prompts the authors to consider the limitations of their approach in handling concepts with semantic rather than geometric correlations. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their adaptation capacity. While it identifies a relevant area for further exploration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should add a comparison against state-of-the-art loss functions widely used in face/iris verification, specifically mentioning Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This provides a clear and concrete action for the authors to take, as it specifies the exact comparison that should be included. The comment is highly actionable because it gives the authors a direct and detailed instruction on how to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, specifically mentioning Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be included in, such as the methodology or results section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the types of loss functions to be compared, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, specifically mentioning Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This claim is somewhat verifiable as it provides a clear suggestion for improvement by referencing specific loss functions. However, the comment lacks detailed reasoning or examples of how these loss functions should be compared or integrated into the paper. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions widely used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that the authors could compare their work against. By incorporating this comparison, the authors can better position their work within the existing literature and provide a more comprehensive evaluation of their approach. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or why these specific loss functions are relevant. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, implying that the authors should clarify or justify the purpose of this section. However, it does not provide explicit guidance on how to address this issue or what specific information should be included to clarify the intent. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context or explanation but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the intent of this section, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the intent of Section 5.2, rather than a claim or opinion that requires verification. It does not contain any subjective opinions, judgments, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, indicating that the authors should clarify the purpose or meaning of this section. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors need to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. It also recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed white-box access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"threat model\" and suggests that the authors define it more explicitly, specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This provides clear guidance on what needs to be addressed. Additionally, the comment is specific in suggesting that this information be included in a dedicated section, particularly regarding the assumed white-box access to the victim model. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification, specifically regarding the attacker\\'s level of access, capabilities, and the defender\\'s available resources. The comment provides a clear and logical reasoning for why this clarification is necessary, particularly in the context of white-box access to the victim model. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides actionable feedback by suggesting that the authors define the assumed threat model more explicitly, specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it recommends including this information in a dedicated section to enhance clarity, particularly regarding the assumed white-box access to the victim model. This feedback is clear and constructive, offering the authors a direct path to improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as highly helpful, as it effectively guides the authors in enhancing the quality and clarity of their work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the chat-GPT baseline, labeling it as \"very rudimentary\" and suggesting that a few-shot approach is not tested. It also offers a potential improvement by suggesting the inclusion of discourse relation information in the prompts, possibly using a Chain-of-Thought style approach. While the comment implies that these suggestions could enhance the paper\\'s evaluation, it does not explicitly instruct the authors to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these suggestions for improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-GPT baseline, describing it as \"very rudimentary\" and suggesting that a few-shot approach is not tested. It also proposes including discourse relation information in the prompts, possibly using a Chain-of-Thought style approach, which could enhance the paper\\'s evaluation. However, the comment does not specify which part of the paper discusses the chat-GPT baseline or where the suggestions for improvement should be implemented. While the authors can infer that it relates to the experimental setup or methodology section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-GPT baseline is \"very rudimentary\" and suggests that a few-shot approach is not tested. It also proposes including discourse relation information in the prompts, which could potentially yield better results. However, the comment lacks specific evidence or references to support these claims, such as comparisons with other baselines or detailed explanations of how the few-shot approach could be implemented. The suggestion to include discourse relation information is based on a logical inference but lacks concrete examples or references to substantiate its potential effectiveness. Therefore, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a weakness in the paper by labeling the chat-GPT baseline as \"very rudimentary\" and noting that a few-shot approach is not tested. It also suggests a potential improvement by proposing the inclusion of discourse relation information in the prompts, possibly using a Chain-of-Thought style approach. This feedback is actionable as it provides a specific direction for enhancing the paper\\'s evaluation. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of similar approaches in the literature. Overall, the comment is mostly helpful as it offers clear and actionable feedback, but it could be more comprehensive with further elaboration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs (at least 10) with error-bars. It also emphasizes the importance of providing statistics, especially since the models are small. This feedback is clear and provides specific guidance on what the authors need to do to improve their draft. The action is explicit and concrete, leaving no ambiguity about how to implement the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"results comparing standard- vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: presenting the results as a mean over many runs (at least 10) with error-bars, and justifying the need for statistics given the small size of the models. This provides clear guidance on how to improve the presentation of the results. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs with error-bars, as the plotted curves are likely from single runs and may be subject to significant fluctuations. This claim is supported by logical reasoning, as the use of multiple runs and error-bars would provide a more accurate representation of the results. However, the comment could be strengthened by providing specific examples or references to support the importance of using multiple runs and error-bars, especially for small models. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback regarding the presentation of results. It suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error-bars, which would help to mitigate the impact of fluctuations. This is a clear and constructive suggestion that can significantly improve the clarity and reliability of the results. By addressing this feedback, the authors can enhance the robustness and credibility of their findings. Therefore, the comment is highly helpful, as it offers detailed guidance that can lead to substantial improvements in the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA version and the PyTorch version. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this information is important, explaining its potential impact on training and inference speeds. Therefore, the comment is highly actionable, as it provides a specific and concrete action for the authors to follow.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically referencing the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment and its potential impact on training and inference speeds. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the logical reasoning that different versions of the experimental environment can affect training and inference speeds. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the importance of this detail and how it might impact their results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about the experimental environment, such as the CUDA and PyTorch versions. This feedback is clear and actionable, as it highlights a potential source of variability in the results that could impact training and inference speeds. By addressing this point, the authors can enhance the reproducibility and robustness of their study. However, the comment could be more helpful if it provided additional context or examples of how different versions might affect the results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. It also references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to provide context. This feedback is explicit and provides a clear action for the authors to take, which is to include the evaluation metric in the specified lines. The reference to the external work adds concrete guidance on how to implement the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 078-079 / Line 08,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. Additionally, it references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020), providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. It references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to provide context. This reference supports the claim by offering a relevant example, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric impacts the results. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be mentioned to clarify the scale of improvement and enhance comparability. It references a specific expression used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020) to provide context, which is helpful for the authors to understand the results and their implications. This feedback is clear and constructive, offering a direct way for the authors to improve their draft by including the evaluation metric. However, the comment could be more helpful if it provided additional guidance on how to incorporate this information or why it is crucial for the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the draft. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounds and their implications for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not specify which part of the paper discusses these bounds, making it weakly grounded. The comment is specific in detailing the concern about the limitations of the approach but lacks grounding, as the authors cannot confidently determine which section or part of the paper this comment pertains to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support the claim that the bounds would seriously limit the applications. Without additional context or evidence, the authors may find it challenging to understand the full extent of the issue or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs, suggesting that this might limit the applications of the approach. However, it does not provide specific guidance or suggestions on how the authors might address this issue or explore alternative applications. The comment highlights a potential limitation but lacks actionable feedback, leaving the authors with a general understanding of the problem but without a clear path for improvement. Therefore, the comment is barely helpful, as it identifies a weakness but does not offer sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the target of the paper or where to make the necessary changes. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not specify which part of the paper should be revised to address this issue, nor does it provide detailed guidance on how to clarify the target. The authors can infer that the issue is related to the introduction or methodology sections, but the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries and notes that this clarification is not clear until the conclusion. However, it does not provide any supporting evidence, reasoning, or references to justify why this confusion exists or how it impacts the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the confusion or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the paper's focus on single-token or multi-token cloze queries. It highlights that the clarification is not clear until the conclusion, suggesting that the authors should provide a clearer distinction or explanation earlier in the paper. However, the comment does not offer specific suggestions or guidance on how to address this issue or where to make the necessary changes. While it points out a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. The authors are given some insight into a potential weakness but are left without detailed guidance on how to resolve it. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the major contributions of the paper and suggests that analyzing previous work is not considered a contribution. However, it does not provide explicit guidance or suggestions on how the authors might clarify their contributions or what specific aspects of the paper could be improved to address this issue. The action is implicit and vague, leaving the authors without a clear understanding of what steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the major contributions of the paper, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the contributions, but without clear grounding, it is challenging for the authors to know where to focus their revisions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that analyzing previous work does not constitute a contribution, which is a subjective opinion. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that analyzing previous work is not considered a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify their contributions or what aspects of the paper could be strengthened to address this issue. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. The authors are given some insight into a critical area but are left without detailed guidance on how to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. This is an explicit suggestion with concrete details on how to implement the action, providing the authors with a clear direction on what to do to improve their draft. The comment is highly actionable as it gives specific guidance on how to enhance the protected feature, allowing the authors to make a direct and concrete change to their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, it does not specify which part of the paper discusses feature A, making it weakly grounded. The comment is specific in suggesting a potential enhancement, but without clear grounding, the authors may find it challenging to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically mentioning that it could represent multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a potential enhancement to the protected feature A by proposing its extension to a vector form, which could represent multiple attributes. This is a clear and actionable suggestion that could improve the comprehensiveness and applicability of the feature. However, the comment lacks further elaboration or examples of how this extension could be implemented or what benefits it might bring. While it provides a direction for improvement, it could be more helpful with additional guidance or context. Therefore, the comment is rated as mostly helpful, as it offers a valuable suggestion but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies that the technical contribution of the paper is limited. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived similarity or how to enhance the technical contribution. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies a limitation in the technical contribution of the paper. However, it does not specify which part of the paper this similarity is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the similarity are problematic or how it affects the paper\\'s contribution. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that $kNN-ECD$ is very similar to $kNN-MT$, which implies a limitation in the technical contribution of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed comparisons, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical contribution of the paper is limited due to the similarity between $kNN-ECD$ and $kNN-MT$. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this issue or enhance their contribution. Without actionable feedback or guidance, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. While the comment implies that the authors should add these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional visual aids and examples. However, the suggestion is concrete in terms of what needs to be added, making it mostly actionable. Therefore, the comment aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this explanation is needed. Without explicit references or context, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in suggesting the inclusion of an example and a figure, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this would be beneficial or how it would improve the clarity of the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including an example and a figure would be beneficial in explaining the definition of uniform shattering. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and comprehensibility of the paper. By incorporating examples and visual aids, the authors can enhance the reader\\'s understanding of the concept, making the comment highly helpful. However, the comment could be more helpful if it offered additional guidance on how to create these examples or figures, such as specific details to include or how to present them. Overall, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the novelty of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect being addressed. The comment lacks specificity as it does not provide detailed reasoning or examples to support the claim of lack of novelty. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. However, the comment lacks specific references or detailed explanations to support this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the reviewer\\'s assertion. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment expresses a belief that the proposed transductive method is not novel, suggesting it is related to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the perceived lack of novelty or enhance the originality of their method. Without detailed feedback or constructive advice, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. While the comment identifies a potential issue with the assumption, it does not provide explicit guidance on how to address it or improve the draft. The authors are left to infer that they should focus on the optimization and theoretical aspects, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the assumption among classes, noting that it is not practical and that the formulation or definition is somewhat trivial. However, it highlights the value of the paper in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment does not specify which part of the paper discusses these assumptions or how they relate to the optimization and theoretical aspects. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the assumption among classes is not practical and notes that the formulation or definition is somewhat trivial. However, it suggests that the value of the paper lies in its optimization and theoretical property analysis, from which conclusions or insights can be gained. The comment provides a logical reasoning by distinguishing between the practicality of the assumption and the potential value of the paper in other areas. While the claim is somewhat supported by the explanation, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is considered somewhat verifiable, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the assumption among classes is not practical but notes that the formulation or definition is somewhat trivial. It highlights the value of the paper in its optimization and theoretical property analysis, suggesting that this is where the paper gains its significance. However, the comment does not provide specific guidance or suggestions on how the authors might address the issue of impractical assumptions or enhance the optimization and theoretical aspects. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It suggests that without a more detailed analysis of the differences and similarities between these views, it is challenging to draw solid conclusions. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the analysis should be expanded upon. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It also mentions a specific empirical example involving the word \"slip,\" allowing the authors to accurately identify the part of the paper being discussed. The comment is specific in detailing what is missing, namely a more detailed analysis of the differences and similarities between the views, and how this affects the conclusions drawn about the different views. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. The reviewer points out that the paraphrase similarity view performs significantly better than other views and their combination, and suggests that without a more detailed analysis of the differences and similarities between these views, it is challenging to draw solid conclusions. This claim is somewhat verifiable as it provides a logical reasoning about the need for further analysis, but it lacks specific examples or references to support the assertion that the other views are not useful. The comment highlights a gap in the analysis but does not fully substantiate the claim with detailed evidence or examples, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of views other than the paraphrase similarity view. It points out that the paraphrase similarity view performs significantly better than other views and their combination, and suggests that without a more detailed analysis of the differences and similarities between these views, it is challenging to draw solid conclusions. This feedback is somewhat helpful as it identifies a gap in the analysis and encourages the authors to provide a more comprehensive evaluation of the different views. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This implies that the authors should conduct or present additional experiments to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to conduct these experiments or provide specific guidance on how to present the results. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know exactly how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the experimental results or methodology section, but this inference is not direct. The comment is specific in suggesting the need for detailed results on model size, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that increasing model size should not hurt performance, as recent work by Ni et al. shows that the scaling law applies to dense retrieval models. The reviewer suggests that the authors should provide preliminary experimental results on Wikipedia regarding model size. While the claim is based on a reference to recent work, it lacks specific details or examples from the referenced paper to fully substantiate the claim. The authors would need to look up the work by Ni et al. to understand the context fully. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional effort from the authors to fully understand and verify it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that increasing model size hurts performance, suggesting that this contradicts recent findings by Ni et al. regarding the scaling law in dense retrieval models. It provides a specific reference to support the claim, indicating that the authors should provide detailed experimental results on Wikipedia regarding model size. This feedback is clear and actionable, as it directs the authors to address a specific concern and provides a basis for their response. However, it could be more helpful if it offered suggestions on how to present the results or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors to improve their draft by addressing a critical point and providing a reference for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. However, it does not provide explicit guidance or suggestions on how the authors should conduct these experiments or what specific aspects they should focus on. The action is implicit and vague, leaving the authors to infer that they need to conduct additional experiments but without clear instructions on how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"conclusion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the request for related experiments that the information axis tool can help with, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. However, it does not provide any specific claims, opinions, or suggestions that require verification. It is a factual statement asking for additional information, which aligns with the label \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses curiosity about seeing related experiments that the information axis tool can help with, as mentioned in the conclusion. While it identifies a potential area for further exploration, it lacks specificity and does not provide actionable guidance on how the authors might conduct these experiments or what specific aspects they should focus on. The comment highlights a potential direction for future work but does not offer detailed suggestions or insights to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides a general direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might address this question or incorporate it into their draft. As a result, the comment lacks actionability and does not offer any direction for the authors to improve their work. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups struggle with Greek, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or suggestions on how to address this question or what implications it might have for the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification on whether other multilingual pretraining setups struggle with Greek. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses interest in knowing whether other multilingual pretraining setups also struggle with Greek. While it raises a relevant question, it does not provide any specific suggestions or guidance on how the authors might address this issue or incorporate it into their draft. The comment lacks actionable feedback or insights that could help the authors improve their work. As a result, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific section of the text (lines 293-295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer suggests that this makes the point less clear for readers, implying that the authors should clarify or rephrase this section to improve understanding. However, the comment does not provide explicit guidance on how to rephrase or clarify the section, leaving the authors to infer that they need to make the language more precise or detailed. The action is implicit and somewhat vague, as the authors know they need to improve clarity but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 293-295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point less clear for readers. The comment suggests that the phrase \"we manually observed the generated examples and find the results acceptable\" is unclear and could be improved. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 makes the point less clear for readers. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the text (lines 293-295) where the authors mention manually observing generated examples and finding the results acceptable. The reviewer points out that this makes the point less clear for readers, suggesting that it would be difficult for them to understand and evaluate. This feedback is somewhat helpful as it highlights a potential area of confusion in the paper and encourages the authors to clarify their explanation. However, the comment could be more helpful if it provided specific suggestions on how to rephrase or improve the clarity of the section. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the organization and clarity of the proof, specifically mentioning that many proofs lack clean logic and are difficult to follow. It also raises a specific question about the applicability of Lemma 3 to any polynomial function. While the comment identifies a problem and poses a question, it does not provide explicit guidance on how to improve the organization or clarity of the proofs. The authors are left to infer that they need to reorganize and clarify their proofs, but without specific instructions on how to achieve this, the action remains somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proof, noting that it is not well-organized and lacks clean logic, making it difficult to follow. Additionally, it raises a specific question about the applicability of the result to any polynomial function, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and lacks clean logic, making it difficult to rigorously check the correctness of the proof. The reviewer provides a specific example by questioning the applicability of Lemma 3 to any polynomial function. This claim is somewhat verifiable as it highlights a potential issue with the proof\\'s organization and logic, but it lacks detailed examples or references to support the claim fully. The authors would need to investigate the proof\\'s structure and logic to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proof, noting that many proofs lack clean logic and are difficult to follow. It specifically questions the applicability of Lemma 3 to any polynomial function, which is a clear and actionable point for the authors to address. By highlighting these issues, the comment provides the authors with specific areas to focus on for improving the rigor and clarity of their proof. However, the comment could be more helpful if it offered suggestions on how to reorganize the proofs or provide additional examples to clarify the logic. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This is an explicit action that provides a clear direction for the authors to improve their draft. However, the comment does not specify which real-world datasets should be used or how the experiments should be conducted, leaving some aspects of the action vague. Therefore, the comment is mostly actionable, as it gives a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify what aspects of the synthetic datasets are problematic or how real-world datasets would better address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This claim is based on the assumption that real-world datasets are more representative of realistic scenarios than synthetic ones. However, the comment lacks specific reasoning or references to support why synthetic datasets are insufficient for the out-of-distribution setting. Without detailed justification or examples, the claim remains somewhat verifiable, as it provides a general suggestion but lacks concrete evidence or reasoning to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the paper by aligning the experiments with more realistic scenarios. However, the comment could be more helpful if it included suggestions on which real-world datasets to use or how to adapt the experiments to better reflect real-world conditions. Despite this, the comment offers a valuable insight that can guide the authors in enhancing the relevance and applicability of their work. Therefore, it is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is an explicit action with clear guidance on what needs to be done to enhance the clarity of the figures. The suggestion is concrete, as it specifies which figures should include the smoothed GT shapes, providing the authors with a direct and actionable step to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure. 3 and Figure. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is showing the smoothed GT shapes in these figures to improve the understanding of the reconstruction quality. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a suggestion for improvement rather than a claim or opinion that requires verification. It does not contain subjective opinions, judgments, or suggestions that need justification, making it a factual statement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It recommends showing the smoothed GT shapes in Figures 3 and 5, which would help readers better understand the quality of the reconstruction. This feedback is clear and provides a concrete step for the authors to enhance the visual representation of their results. However, the comment could be more helpful if it explained why this suggestion is important or how it would impact the reader\\'s understanding. Overall, the comment is mostly helpful as it offers a direct and actionable improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the notation usage in Section 2, noting that the notations of \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way. However, it does not provide any explicit guidance or suggestions on how to resolve this issue or clarify the notation usage. The comment lacks concrete details on what specific changes should be made or how the authors should address the inconsistency. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of mixed notation usage between \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\), providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way in Section 2. However, it does not provide any supporting evidence, examples, or reasoning to justify why this mixed usage is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation usage in Section 2, noting that \\\\(\\\\hat{Y}\\\\) and \\\\(Y\\\\) are used in a mixed way. This feedback is clear and actionable, as it directs the authors to clarify and standardize the notation usage in the section. However, the comment could be more helpful if it provided suggestions on how to resolve the issue or offered examples of consistent notation usage. Despite this, the comment still provides valuable guidance for improving the clarity and consistency of the paper, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include important references for domain adaptation and to cite and discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a straightforward path for the authors to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or which parts of the paper should include these references. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its request for additional references but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should include them. However, the comment does not specify which references are missing or why they are important, making it difficult for the authors to understand the basis of the claim. Without specific examples or detailed reasoning, the claim is not fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it highlights a critical area for improvement and offers a specific step for the authors to take. However, the comment could be more helpful if it specified which references are missing or why they are important. Despite this, the feedback is mostly helpful as it directs the authors to a key area for enhancement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their hyperparameter tuning. The suggestion to consider the distance to the next best model is vague and lacks concrete steps for implementation. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide clear instructions on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about hyperparameter tuning and the distance to the next best model, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. However, the comment lacks specific evidence or references to support this claim, such as detailed comparisons of hyperparameters or results from other models. Without this additional information, the claim remains somewhat verifiable, as it provides a logical reasoning but lacks concrete evidence to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the SCNN model getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range, which could explain the large distance to the next best model. This is a valid point that could indicate a potential issue with the model\\'s performance. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or improve their hyperparameter tuning. While it identifies a potential weakness, it does not provide actionable feedback to help the authors resolve the issue. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific guidance on what aspects are unclear or how the authors might clarify them. The comment implies that the authors should address these issues, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or figures. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing clarification. The comment is specific in identifying the issue with the experimental setup but lacks grounding, as it does not provide a clear indication of where in the paper these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific examples or details to support this claim, making it difficult for the authors to understand and address the issues. The lack of concrete evidence or references leaves the claim somewhat verifiable, as the authors would need to infer the specific areas of concern based on the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not provide detailed guidance or suggestions on how the authors might clarify or improve these aspects. The comment lacks actionable feedback, such as recommending specific changes or providing examples of how to better motivate the experimental setup. As a result, the authors are left without a clear path for improvement, making the comment barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and providing details about the size of each hourglass module. While the comment does not explicitly instruct the authors to include this information, it implies that the authors should provide a detailed comparison and specify the size of each hourglass module. The action is implicit but concrete, as the authors know exactly what information is needed to address the comment. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the model architecture is described. The comment is specific in its request for additional information about the model size and its comparison to others. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, the label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the size of the model, specifically asking for a comparison with competing approaches and seeking details about the size of each hourglass module. This feedback is valuable as it prompts the authors to provide a more comprehensive understanding of their model's architecture and its relation to existing work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar models are structured. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not provide explicit guidance or suggestions on how the authors might improve this aspect of their work. The action is implicit and vague, as the authors are left without clear instructions on what changes to make or how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the metric learning theory in the paper, suggesting it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it weakly grounded. The authors can infer that it relates to the theoretical sections, but this inference is not direct. The comment is specific in its critique of the metric learning theory, but without explicit references to sections or specific elements, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It suggests that the part of the paper related to metric learning does not seem to work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or comparisons to previous work, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the metric learning theory presented in the paper, suggesting that it does not provide better results compared to previous theoretical results. It implies that the part of the paper related to metric learning does not seem to work. However, the comment lacks specific details or suggestions on how the authors might improve this aspect of their work. Without actionable guidance or examples, the feedback is limited in its usefulness to the authors. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential source of confusion in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit guidance or suggestions on how to resolve this issue. The comment lacks concrete details on how to address the confusion, such as recommending alternative notation or suggesting a clearer distinction between the two types of risks. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of confusion caused by the dual use of \"r\" and suggests that this notation is problematic. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is problematic or how it might cause confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, where \"r\" is used to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable feedback that can help the authors clarify their notation and avoid potential confusion in their readers. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending alternative notation or explaining the context in which each use of \"r\" is appropriate. Despite this, the comment is still somewhat helpful as it directs the authors to a specific area that needs attention, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. While the comment implies that the authors should consider this scenario and its implications, it does not provide explicit guidance on how to address it or what specific actions to take. The action is implicit and somewhat vague, as the authors would need to infer that they should explore this scenario and its detection capabilities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. The mention of \"Figure 8\" provides full grounding, as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of detecting crucial differences in test examples and the potential impact of using the wrong corpus. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the potential impact of not knowing that a test example is crucially different, specifically in the context of using the American corpus to explain a patient labeled as \"British\" in Figure 8. It asks if this scenario can be detected using the corpus residual value. This question prompts the authors to consider a potential limitation or challenge in their approach and encourages them to explore how their method might handle such scenarios. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the draft. While it highlights an important consideration, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of dataset, specifically suggesting the use of the WebQuestions benchmark set instead of WebQuestionsSP. It provides a rationale for this suggestion, stating that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. While the comment does not explicitly instruct the authors to make a change, it clearly implies that using WebQuestions would be a more appropriate choice. The suggestion is concrete, as it provides a specific dataset to consider and a logical explanation for the recommendation. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"choice of dataset\" and references \"WebQuestionsSP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the \"most popular WebQuestions (Berant et al., 2013) benchmark set\" instead of WebQuestionsSP, providing a clear rationale for the suggestion. The comment explains that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of dataset, suggesting the use of the WebQuestions benchmark set instead of WebQuestionsSP. The reviewer provides a logical reasoning for this suggestion, stating that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. This reasoning is based on common knowledge about the characteristics of the datasets and the requirements of the NSM model. However, the comment could be strengthened by providing specific examples or references to support the claim that WebQuestions is more suitable. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a question about the choice of dataset, specifically suggesting the use of the WebQuestions benchmark set instead of WebQuestionsSP. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for NSM, which only requires weak supervision, and would facilitate direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\\'s relevance and comparability. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits need to be demonstrated. It implies that the authors should provide evidence or examples to support their claims, particularly regarding the impact of sparsity on training speed and cost savings. However, the comment does not explicitly instruct the authors to conduct specific experiments or analyses to address these concerns. The action is implicit and somewhat vague, as the authors can infer that they need to provide evidence but are not given clear guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the necessity of claims about sparsity in training and suggests that any potential benefits need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment provides some specificity by mentioning the need to demonstrate the benefits of sparsity and the potential impact on training speed and cost savings. However, without explicit references to specific sections or elements of the paper, the comment is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of claims about the desirability of sparsity in training, suggesting that any potential benefits need to be demonstrated. The reviewer provides a logical reasoning by pointing out that a larger network that cannot fit into memory without sparsity may perform better, but this needs to be demonstrated. Additionally, the reviewer questions the relevance of reduced FLOPs in the age of parallelized computation, suggesting that actual cost savings should be shown. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened with specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment questions the necessity of claims about the desirability of sparsity in training, suggesting that these claims are not obvious and need to be substantiated. It provides a logical critique by pointing out that a larger network that cannot fit into memory without sparsity may perform better, and that any hypothetical training speed increases due to reduced FLOPs are meaningless without demonstrating actual cost savings. This feedback is somewhat helpful as it prompts the authors to reconsider their claims and provide evidence to support them. However, it lacks specific suggestions or guidance on how to address these concerns, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors provide a plot of the model illustration, pseudo-code table, or code repository to clarify the model design and learning details. It also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a well-known method. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2 Unclear model design,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the model architecture and learning details are fragmented or missing, and suggests providing a plot of the model illustration, pseudo-code table, or code repository to facilitate reproducibility. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details. It suggests providing a plot of the model illustration, pseudo-code table, or code repository to facilitate reproducibility, especially since Neurochaos Learning is not a well-known method. The comment provides a logical reasoning for the need to clarify the model design and learning details, which is a common practice in scientific publications. However, it lacks specific examples or references to support the claim that the current presentation is unclear. While the suggestion is reasonable, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides specific suggestions for improvement, such as including a plot of the model illustration, pseudo-code table, or code repository. This feedback is actionable and constructive, as it offers concrete steps for the authors to take to enhance the clarity and reproducibility of their work, particularly given the novelty of the Neurochaos Learning method. By addressing these suggestions, the authors can significantly improve the comprehensibility and usability of their draft. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for clearer clarification of the generalization to specific TSP instances, particularly in the context of the fine-tuning step in DIMES. It suggests that the paper should clearly explain how DIMES\\'s advantages, such as direct RL training for large-scale problems and meta fine-tuning, address the generalization gaps. Additionally, the reviewer suggests comparing DIMES with other methods on TSP100, both with and without meta-learning, to further demonstrate its effectiveness. While the comment provides a clear direction for improvement, it does not specify exactly how the authors should present the comparison or what specific aspects of the comparison are most important. The action is mostly actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"generalization to the specific TSP instances (the fine-tuning step in DIMES),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the advantages of DIMES in overcoming generalization gaps and the need for a comparison with other methods on TSP100 with and without meta-learning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should clarify the generalization to specific TSP instances, particularly in the context of the fine-tuning step in DIMES. It acknowledges DIMES\\'s advantages in addressing generalization gaps but emphasizes the need for clearer clarification. The comment also suggests a comparison of DIMES with other methods on TSP100, both with and without meta-learning. While the comment provides a logical reasoning for the need for clarification and suggests a potential comparison, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for clearer clarification of the generalization to specific TSP instances, particularly in the context of the fine-tuning step in DIMES. It acknowledges the advantages of DIMES in addressing generalization gaps but emphasizes the importance of clearly articulating these differences in the paper. Additionally, the comment suggests a comparison of DIMES with other methods on TSP100, both with and without meta-learning, to further demonstrate its effectiveness. This feedback is mostly helpful as it provides clear and actionable suggestions for enhancing the clarity and comprehensiveness of the paper. However, it could be more helpful if it offered specific guidance on how to present the comparison or what aspects to focus on. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim made in the paper regarding the relationship between dataset readability and question difficulty, suggesting that this relationship may depend on the method or features used for answer detection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The comment implies that the authors should consider the impact of different methods or features on their findings, but it lacks concrete steps or recommendations for action. As a result, the comment is vague and does not provide clear direction for the authors, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It questions the dependency of this relationship on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in detailing the issue with the claim, as it provides a clear critique of the dependency on specific methods or features. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that \"dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty.\" It suggests that this claim depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the dependency on these features. As a result, the claim is somewhat verifiable, as it highlights a potential issue but lacks sufficient detail or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment questions a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that this relationship may depend on the method or features used for answer detection, such as POS or dependency parse features. This feedback is somewhat helpful as it points out a potential limitation or assumption in the analysis, prompting the authors to consider the impact of different methods or features on their findings. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or conduct further analysis. While it identifies a potential area for improvement, it does not offer detailed suggestions or actionable steps, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. While the comment implies that the authors should conduct an analysis to support the claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform an analysis to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the morphfitting results in a more meaningful space. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry is meaningful, such as demonstrating that certain operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the current geometry is not meaningful. This lack of evidence makes the claim somewhat verifiable, as the authors would need to infer the need for additional analysis or evidence to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence that the geometry of the space is meaningful, such as demonstrating that specific operations (e.g., \"looking\" - \"look\" + \"walk\" = \"walking\") yield a more meaningful space. This feedback is clear and actionable, as it prompts the authors to conduct an analysis that could significantly enhance the understanding and interpretation of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and offers a direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or which specific aspects of the related work should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the writing and expand the related work section but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space explaining basic memory networks and the forward model. It also points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper need improvement or where the related work section is lacking. The authors can infer that the writing quality and related work sections are the areas of concern, but the comment lacks full grounding as it does not explicitly mention these sections. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same amount of space on explaining basic memory networks and the forward model. It also notes a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of concrete evidence or references makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two areas for improvement in the paper: the writing quality and the related work section. It suggests that the authors should improve the writing quality by ensuring that the space allocated to explaining basic memory networks and the forward model is utilized more effectively. Additionally, it points out a gap in the related work section regarding more reinforcement learning tasks in the literature. However, the comment lacks specific guidance or examples on how to enhance the writing quality or which reinforcement learning tasks should be included in the related work section. While it provides some direction, the feedback is incomplete and could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on what the authors should do with this information or how it might impact their work. As a result, the comment is unactionable, as it does not offer any direction for improvement or clarification.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the number of different kinds of physical interaction that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure, making it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of physical interaction are being questioned or how this might impact the simulation. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the number of different kinds of physical interaction that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the number of different kinds of physical interaction that can be included in one simulation. While it highlights an area of interest, it lacks specificity and does not provide any guidance or suggestions for improvement. The authors are left without actionable feedback on how to address this question or its relevance to their work. As a result, the comment is barely helpful, as it identifies a potential area of interest but does not offer any meaningful direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the model comparison section of the paper. It points out that the selection of datasets is inadequate because only one dataset has categorical features, while the others have exclusively numerical features. This is considered a limitation because categorical features are generally more challenging for deep learning models. Additionally, the authors are criticized for not using one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should consider a more diverse set of datasets and potentially adjust their methodology for handling categorical features. However, the lack of explicit instructions on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"model comparison\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, while others have exclusively numerical features. This is a critical point because categorical features are generally considered more challenging for deep learning models. The comment further specifies that the authors do not employ one-hot encoding for the dataset with categorical features, which could negatively affect performance for some models. This level of detail provides clear guidance on what needs to be addressed in the model comparison section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model comparison is inadequate due to the selection of datasets, specifically noting that only one dataset has categorical features, while others have numerical features. It suggests that this omission may affect conclusions because categorical features are generally more challenging for deep learning models. The comment also points out that the authors do not use one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. This reasoning is logical and based on common knowledge about the challenges of deep learning with categorical features. However, the comment could be strengthened by providing specific examples or references to support the claim about the impact of categorical features on model performance. Overall, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or examples. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the model comparison section of the paper, specifically noting that the selection of datasets is inadequate. It points out that only one dataset has categorical features, while the others are numerical, which could affect the conclusions drawn from the comparison. Additionally, the comment highlights that the authors do not use one-hot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific areas for improvement, such as considering a more diverse set of datasets and adjusting the methodology for handling categorical features. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of datasets that could be used for a more comprehensive comparison. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the robustness and validity of their model comparison.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with pruning in large networks, specifically mentioning the need to consider global top Q values of the metric over the average of gradients. It suggests that this could break acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate this consideration into their work. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore this aspect further but are not given concrete instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pruning majorly works with large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on finding global top Q values of the metric over the average of gradients, which could potentially break acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that pruning primarily works with large networks, which are typically trained in distributed settings, and suggests that the authors should consider the global top Q values of the metric over the average of gradients. The comment further implies that this consideration could break acceleration techniques like quantization and sparsification. However, the review does not provide specific examples, references, or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the importance of this consideration and its potential impact on acceleration techniques. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of pruning in large networks, specifically highlighting the need to consider global top Q values of the metric over the average of gradients. It suggests that this consideration could break acceleration techniques like quantization and sparsification. While the comment points out a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or incorporate the necessary considerations into their work. The feedback is somewhat helpful as it prompts the authors to explore this aspect further, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it implies that the authors should verify this, it does not provide explicit instructions on how to check or correct the figures. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially correct the figures. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also clearly specifies the issue by questioning whether some subfigures have been swapped by mistake. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking whether some subfigures in Figs 1 and 2 have been swapped by mistake. It does not contain any claims, opinions, or suggestions that require verification. It is purely a factual inquiry seeking clarification. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the potential swapping of subfigures in Figs 1 and 2. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might verify or address this concern. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this potential drawback. While the comment highlights an important consideration, it does not provide explicit guidance on how to incorporate this discussion into the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the trade-off between sensitivity and false positives, but without specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the improvement in sensitivity and the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, implying that the authors should address this trade-off. While the comment highlights a valid concern, it lacks specific examples or detailed reasoning to fully substantiate the claim about the risk of false positives. This makes the claim somewhat verifiable, as it provides a general direction for the authors to consider but requires more detailed justification or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the improvement in sensitivity provided by the dropout probe, noting its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is valuable as it highlights a potential trade-off in the methodology and encourages the authors to address this issue in their discussion. While the comment identifies an important consideration, it could be more helpful by providing specific suggestions on how to discuss this trade-off or potential mitigations. Overall, the comment is somewhat helpful as it points out a critical aspect of the methodology that needs further exploration, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors\\' claim about the regret bound for the proposed mini-batch method, as it could not be found in the supplementary material. While the comment highlights a potential issue with the paper\\'s claims, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to verify the claim and potentially revise their paper to include the missing information. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable. The authors know they need to verify the claim and possibly add the missing information, but they may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed mini-batch method and its absence in the supplementary material. It also provides a specific reference to a relevant work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which supports the claim. This allows the authors to accurately identify the part of the paper being addressed and understand the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have made a statement about the regret bound for the proposed mini-batch method, which is not supported by evidence in the supplementary material. The reviewer references a specific work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which suggests that the claim is based on a comparison with existing literature. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to investigate the claim further to understand its basis and address it appropriately. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely that the authors claim the regret bound for the proposed mini-batch method is in the appendix, but it cannot be found there. This is a critical observation that could impact the validity of the paper\\'s claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. It lacks actionable feedback, leaving the authors with a clear problem to resolve but without direction on how to do so. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include a discussion and comparison of these methods, but it lacks concrete details on how to execute this action. The authors can infer that they need to add a section discussing these methods, but the comment does not specify which methods to include or how to compare them. Therefore, the comment is somewhat actionable, as it provides an implicit action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the issue with the paper\\'s coverage of exploration methods, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence renders the claim somewhat verifiable, as the authors would need to infer the relevance of these methods and their potential impact on the paper\\'s soundness. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors should include a discussion and comparison of these methods to enhance the paper's soundness. However, the comment lacks specific guidance on how to incorporate these methods or which aspects to focus on, which limits its helpfulness. To be more helpful, the comment could provide examples or suggestions on how to integrate these methods into the paper. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the clarity and completeness of the paper. It questions whether inference is slowed down and whether there is a way to only do inference, and it asks for the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, it points out the lack of hyperparameter details, which could impact the confidence in the results of the ablation studies. The comment also critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to improve the clarity and completeness of their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about the clarity and completeness of the paper, specifically regarding the inference process, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. It also critiques the writing style, stating that it often impedes understanding. While the comment does not explicitly mention specific sections or lines, the authors can infer that it relates to the methodology or results sections, where these issues might be discussed. The comment is specific in detailing what needs to be addressed, such as the coefficient value and the need for hyperparameter details. However, it lacks full grounding as it does not explicitly mention the sections or lines where these issues are discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the clarity and completeness of the paper, including the impact of inference on the model, the coefficient of the p(L, E | X) term, and the lack of hyperparameter details. While the comment identifies potential issues, it does not provide specific evidence or references to support these claims. The questions posed are logical and reasonable, but without additional context or examples, the claims remain somewhat verifiable. The comment lacks detailed reasoning or references to substantiate the concerns, making it difficult for the authors to fully address the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points that could help the authors improve their draft. It questions the impact of inference on the model, specifically whether it slows down drastically and if there's a way to only do inference. It also asks for clarification on the coefficient of the p(L, E | X) term in line 307 and why it is 1. Additionally, the comment points out the lack of hyperparameter details, which could affect the confidence in the results of the ablation studies. Furthermore, it critiques the writing style, stating that it often impedes understanding. While the comment identifies several areas for improvement, it could be more helpful by providing specific suggestions on how to address these issues or by offering examples of how to improve the clarity of the writing. Overall, the comment is somewhat helpful as it highlights important areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this weakness or improve their method. Without guidance on potential solutions or areas for further investigation, the authors are left without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper this observation is based on, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact location where this issue should be addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the authors might address this weakness. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as a main weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a clear and actionable piece of feedback that highlights a critical area for improvement. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this weakness or improve their method. While it points out a significant issue, it does not offer actionable steps for the authors to take, limiting its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data (~20 different types) and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. While the comment implies that the authors should explore these analyses further, it does not provide explicit guidance on how to conduct these analyses or what specific observations to look for. The action is implicit and somewhat vague, as the authors can infer that they need to delve deeper into the analysis but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"language/nationality\" and provides specific examples of languages/nationalities included in the data, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the potential for interesting observations by comparing biases towards different languages/nationalities. This level of detail provides clear guidance on what the authors should focus on to improve their analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" aspect. It highlights the diversity of languages/nationalities included in the data and expresses curiosity about potential interesting observations by comparing biases towards different languages/nationalities. However, the comment lacks specific examples or references to support the claim that these analyses could be more detailed or that biases vary significantly. The suggestion is somewhat verifiable as it provides a general direction for further analysis, but it requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that some analyses could be more detailed, specifically highlighting the \"language/nationality\" aspect. It points out that the data includes a diverse range of languages/nationalities and notes that biases towards different languages/nationalities may vary. The reviewer expresses curiosity about potential interesting observations that could be made by comparing these biases. This feedback is somewhat helpful as it identifies a specific area for further analysis and suggests a potential direction for exploration. However, it lacks detailed guidance on how to conduct these analyses or what specific observations to look for, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the learning algorithm F^\\dagger in terms of preserving certain mathematical properties, such as mass or charge conservation, when solving continuous PDEs using discrete methods. It suggests that the authors should investigate whether it is possible to train the algorithm to maintain these properties and provides a specific example of Hamiltonian systems. While the comment implies that the authors should explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks detailed guidance on how to conduct the investigation or what specific properties to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Many solvers' algorithms\" and \"learning F^\\dagger,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of preserving mathematical properties, such as mass or charge conservation, and suggests exploring the behavior of the learning algorithm in this regard. The comment further provides examples, such as symplectic integrators, and asks for numerical illustrations of conservation properties in Hamiltonian systems. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the behavior of the learning algorithm F^\\dagger in terms of preserving certain mathematical properties, such as mass or charge conservation, when solving continuous PDEs using discrete methods. It suggests that the authors should investigate whether it is possible to train the algorithm to maintain these properties and provides an example of Hamiltonian systems. However, the comment does not provide any specific evidence, examples, or references to support the claim or guide the authors on how to address it. The lack of detailed reasoning or supporting information makes the claim difficult for the authors to verify or address effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the behavior of the learning algorithm F^\\dagger in terms of preserving mathematical properties, such as mass or charge conservation, when solving continuous PDEs using discrete methods. It suggests that the authors should investigate whether it is possible to train the algorithm to maintain these properties and provides a specific example of Hamiltonian systems. The comment also asks for numerical illustrations of conservation properties, which could help the authors better understand and address the issue. This feedback is clear and actionable, as it identifies a potential area for improvement and provides specific guidance on how to explore it. However, it could be more helpful if it included more detailed suggestions or examples of how to approach the investigation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an expectation for the paper to include a variety of tasks beyond link prediction where PE (Positional Encoding) is important. However, it does not provide any explicit or implicit guidance on how the authors should address this expectation. There is no suggestion of specific tasks that should be included or how the authors might demonstrate the importance of PE in these tasks. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. However, it does not specify which part of the paper this expectation relates to, nor does it provide details on what specific tasks should be included or how PE is currently being used. This makes it difficult for the authors to identify the exact section that needs attention or to understand the nature of the suggested improvements. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is expected to see a variety of tasks beyond link prediction where Positional Encoding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or references to justify this expectation. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a variety of tasks beyond link prediction where Positional Encoding (PE) is important. While it identifies a potential area for expansion, it lacks specificity and does not provide guidance on which tasks should be included or how to demonstrate the importance of PE in these tasks. The comment does not offer actionable advice or detailed suggestions for improvement, leaving the authors with a general idea but no clear path forward. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative approach for evaluating the quality of \\\\overline{\\\\Pi} by using the performance in the worst MDP instead of the summation over all MDPs in S_{test}. The reviewer provides a clear rationale for this suggestion, explaining that the summation might mask the poor performance of policies in certain MDPs. This feedback is explicit and provides a concrete action for the authors to consider, making it highly actionable. The authors know exactly what they need to do to address the issue, which is to evaluate the quality of \\\\overline{\\\\Pi} using the performance in the worst MDP. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"intuitive goal\" and the evaluation of \\\\overline{\\\\Pi} with the performance in the worst MDP, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, suggesting an alternative method using the \\\\min over S_{test} instead of the summation. This provides clear guidance on how to improve the evaluation of \\\\overline{\\\\Pi}. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach for evaluating the quality of \\\\overline{\\\\Pi} by using the performance in the worst MDP instead of the summation over all MDPs in S_{test}. The reviewer provides a logical explanation for this suggestion, noting that the summation might mask poor performance in certain MDPs. This reasoning is clear and provides a rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for evaluating the quality of \\\\overline{\\\\Pi}. It suggests using the performance in the worst MDP instead of the summation over all MDPs in S_{test}, which could help identify potential issues with the current approach. The comment explains the reasoning behind this suggestion, noting that the summation might mask poor performance in certain MDPs. This feedback is clear and provides a concrete direction for the authors to improve their evaluation methodology. However, it could be more helpful if it included additional context or examples to further illustrate the potential benefits of the suggested approach. Overall, the comment is mostly helpful, as it offers a valuable insight that can guide the authors in enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should reduce the use of footnotes in the paper, as they are \"very distracting.\" It provides a specific example by mentioning that details around parameter settings could be moved into the appendix, such as the example given at L468. This feedback is clear and actionable, as it directs the authors to make a specific change to improve the readability and structure of their paper. The suggestion to move important content into the main body and details into the appendix provides concrete guidance on how to implement the change. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the excessive use of footnotes, which allows the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions on how to address this issue, such as moving important content into the main body and details into the appendix, with a reference to line 468. This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the extensive use of footnotes is distracting and suggests moving important content into the main body and details into the appendix. However, the comment lacks specific examples or detailed reasoning to support why the current use of footnotes is problematic or how moving content would improve the paper. Without additional evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the excessive use of footnotes in the paper, which it finds distracting. It provides a clear suggestion to move important content into the main body of the paper and details into the appendix, such as parameter settings. This feedback is actionable and offers a concrete way for the authors to improve the readability and structure of their draft. By specifying the example at line 468, the comment provides a clear direction for revision, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a set of few-shot demonstrations would be beneficial and that a discussion about this would be appreciated. It also questions the inclusion of zero-shot generation results, suggesting that it might be unnecessary. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The suggestions are implicit and somewhat vague, leaving the authors to infer that they should consider including few-shot demonstrations and discussing their relevance. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, making it difficult for the authors to pinpoint the exact area being addressed. However, it is specific in its suggestion to include a set of few-shot demonstrations and discusses the inclusion of zero-shot generation results, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the inclusion of zero-shot generation results is \"a bit strange\" and questions their relevance. However, the comment does not provide specific reasoning or evidence to support this claim, such as why the results are unnecessary or how they might be misleading. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting the inclusion of a set of few-shot demonstrations, which could enhance the paper\\'s discussion. It also questions the inclusion of zero-shot generation results, suggesting that they might not be necessary. However, the comment lacks specificity and does not provide detailed guidance on how to implement the suggested few-shot demonstrations or why the zero-shot results are unnecessary. While it points out areas for consideration, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" While the comment implies that the authors should include these older works, it does not specify which specific works should be acknowledged or how to integrate them into the related works section. The action is implicit and somewhat vague, as the authors need to infer which works are being referred to and how to incorporate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This provides clear guidance on what needs to be addressed in the related works section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" However, the comment does not provide specific examples or references to these older works, making it difficult for the authors to understand which works are being referred to. This lack of detailed support or examples makes the claim somewhat verifiable, as the authors would need to infer which works are being suggested for inclusion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge older works in addition to the mentioned \"long line of work that use supervised, multilingual systems.\" This feedback is clear and actionable, as it provides a specific direction for enhancing the related works section by including historical references. However, the comment could be more helpful if it specified which older works should be included or why they are relevant. Despite this, the suggestion is mostly helpful as it guides the authors toward a meaningful improvement in their draft. Therefore, the comment aligns with a score of 4: Mostly Helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights concerns about the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how to improve the time complexity or suggests specific modifications that could be made. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the potential sources of high time complexity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method seems high, providing three reasons: the use of an item-oriented autoencoder, the elementwise function being expensive, and the large number of hidden units compared to typical matrix factorization-based methods. While the comment highlights potential issues, it lacks specific examples, detailed reasoning, or references to support these claims. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the time complexity of the proposed method, providing specific reasons such as the use of an item-oriented autoencoder, the elementwise function being expensive, and the large number of hidden units compared to typical matrix factorization-based methods. This feedback is somewhat helpful as it highlights areas where the authors might need to optimize their approach to improve efficiency. However, the comment lacks actionable suggestions or guidance on how to address these issues, which would make it more helpful. The authors are left with a general understanding of the problem but without specific steps to take to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a direct and concrete action for the authors to take, which is to modify the figure labels to include this clarification. The suggestion is explicit and clear, giving the authors a precise step to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many of the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the clarity of the figures by specifying \"pre-trained solution encoders & solution decoders,\" which would help differentiate between multiple types of autoencoders. This feedback is actionable and provides a clear direction for the authors to enhance their figures. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is based on a logical reasoning that specifying the type of encoders and decoders would enhance clarity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact changes required to improve the figures based on the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pre-trained solution encoders & solution decoders.\" This feedback is actionable and clear, as it identifies a particular area where the figures could be enhanced, allowing the authors to make targeted improvements. However, the comment could be more helpful if it explained why this specification is important or how it would impact the reader\\'s understanding. Despite this, the suggestion is valuable and provides a concrete step for the authors to enhance their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to incorporate these comparisons or whether the occlusion experiment should be removed or modified. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e, which provides some specificity. However, it does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The authors can infer that it relates to the experimental or results sections, but this inference is not direct. Additionally, the comment questions the relevance of the occlusion experiment, but it does not specify how this relates to the rest of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks comparison with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, stating that the method does not propose anything specific to occlusion. While the comment provides some context by mentioning specific methods, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion for comparison is logical, but the critique of the occlusion experiment could be strengthened with more explanation or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting comparisons with NeRF-based methods, specifically mentioning Zero-1-to-3 and point-e. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment highlights areas for improvement, it lacks detailed guidance on how to incorporate these comparisons or whether the occlusion experiment should be removed or modified. The feedback is somewhat helpful as it points out potential weaknesses, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extraction of parts of sentences and documents, as well as the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis, which provides a clear action for the authors to take. However, the comment does not specify how the authors should conduct this analysis or what specific details should be included. While the action is explicit, the lack of concrete guidance on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. The comment requests a more detailed analysis, providing clear guidance on what the authors should focus on. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and additional information about the extraction process and its impact on the experiment. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the extraction process, specifically asking how parts of sentences and documents are extracted and whether the rules of extraction have any effect on the experiment. It also requests a more detailed analysis, which is a clear and actionable suggestion for the authors to improve their draft. However, the comment could be more helpful if it provided specific guidance on what aspects of the extraction process should be detailed or how the authors might approach this analysis. Despite this, the feedback is mostly helpful as it directs the authors to a critical area that needs further clarification and analysis. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled manner and if so, when it is applied. The comment explicitly asks for more discussion on this aspect and requests information about the epoch at which the meta sampler is started. This provides clear and specific guidance for the authors to address the issue by providing additional discussion and details. The action is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"meta sampler\" and its application, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for more discussion on the decoupled application of the meta sampler and requests information about when the authors start applying it, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the application of the meta sampler, specifically whether it is used in a decoupled manner and when it is applied. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler, inquiring whether it is used in a decoupled manner and when it is applied. This prompts the authors to provide more discussion on this aspect, which could enhance the clarity and comprehensiveness of their paper. By asking for additional information about the epoch at which the meta sampler is started, the comment offers a clear and actionable suggestion for improvement. However, it could be more helpful if it provided further context or examples to guide the authors in addressing this issue. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and expansion, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take. First, it suggests that the authors should conduct more experiments using fairness-aware metrics like Equality odds (EO) in addition to their own defined vanilla metric. Second, it encourages the authors to conduct experiments on more datasets, specifically mentioning COMPAS and Drug Consumption, and recommends following the AAAI paper \"Exacerbating Algorithmic Bias through Fairness Attacks\" for guidance. Both actions are concrete and provide specific guidance on what the authors should do to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a \"vanilla metric\" and the lack of related fairness-aware metrics like Equality odds (EO), allowing the authors to identify the specific part of the paper being addressed. It also provides a clear suggestion to conduct more experiments on datasets like COMPAS and Drug Consumption, and references a specific AAAI paper for guidance. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct experiments on more datasets, such as COMPAS and Drug Consumption. The comment provides a specific reference to an AAAI paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which supports the suggestion for additional experiments. However, the comment does not fully explain why these metrics or datasets are necessary or how they would improve the paper. While the reference to the AAAI paper provides some justification, the lack of detailed reasoning or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of fairness-aware metrics like Equality odds (EO) alongside the authors' defined vanilla metric. It provides a clear suggestion for the authors to conduct more experiments on datasets like COMPAS and Drug Consumption, and references a relevant AAAI paper for guidance. This feedback is actionable and offers a concrete direction for enhancing the paper by incorporating additional metrics and datasets. However, the comment could be more helpful if it provided a detailed explanation of why these metrics and datasets are important or how they would contribute to the paper\\'s findings. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional context or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to rephrase a section of the paper (L107-114) that is deemed speculative or overly opinionated. It suggests that this content should be presented as a remark or aside in the Discussion section or removed altogether. This feedback provides clear and direct guidance on what action to take, making it highly actionable. The authors know exactly what needs to be done to address the issue, and the comment offers concrete steps to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with this section, stating that it seems speculative or overly opinionated and suggesting that it should be rephrased as a remark or aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a specific section of the paper (L107-114) is \"speculative or overly opinionated.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (L107-114) as being speculative or overly opinionated. It provides clear guidance by suggesting that this content should be rephrased as a remark or aside in the Discussion section or removed altogether. This feedback is actionable and offers a concrete way for the authors to improve the clarity and focus of their draft. By addressing this issue, the authors can enhance the credibility and effectiveness of their argument. Therefore, the comment is rated as highly helpful, as it provides specific and constructive feedback that can significantly improve the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement claimed in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should add these baselines to their evaluation. However, the suggestion is concrete in terms of what baselines to consider, which makes it somewhat actionable. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement claimed in the paper. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting the inclusion of these baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement claimed in the paper. However, the comment does not provide any reasoning or evidence to support why these specific baselines should be considered or how they would impact the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors consider additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement claimed in the paper. This feedback is clear and actionable, as it provides specific suggestions for enhancing the evaluation of the paper. By considering these baselines, the authors can better substantiate their claims and provide a more comprehensive assessment of their work. However, the comment could be more helpful if it explained why these specific baselines are relevant or how they might impact the evaluation. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies two missing elements in the paper: the value of neighborhood size \"h\" and an analysis of its influence on the model\\'s performance. It also mentions the use of different hyperparameter sets per dataset, which is not ideal. The comment provides a clear action for the authors to take, which is to provide insights into how performance varies with a constant set of parameters. Additionally, it suggests analyzing the influence of the neighborhood size \"h\" on the model\\'s performance. The feedback is explicit and provides concrete guidance on what the authors need to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the missing elements of the paper, such as the value of neighborhood size \"h\" and the analysis of its influence on the model\\'s performance. It also addresses the use of different hyperparameter sets per dataset, providing clear guidance on what needs to be addressed. The comment is specific in detailing what is missing and why it is important, offering actionable feedback for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an analysis of the neighborhood size \"h\" and its influence on the model\\'s performance, as well as the use of different hyperparameter sets per dataset. The reviewer suggests that providing insights into how performance varies with a constant set of parameters is essential. While the comment highlights important aspects missing from the paper, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these elements and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two critical areas for improvement in the paper: the lack of analysis on the neighborhood size \"h\" and its influence on the model\\'s performance, and the use of different hyperparameter sets per dataset. It emphasizes the importance of providing readers with intuitive knowledge of the value of \"h\" and its robustness across different neighborhood sizes. Additionally, the comment suggests that using a constant set of parameters would be more ideal. This feedback is clear and actionable, as it directs the authors to conduct further analysis and provide insights into the performance variations with different parameters. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which parameters to focus on. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the paper, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and address the potential effects of missing data on their model. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to address this concern. The comment is specific in its inquiry but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It is a request for clarification rather than a claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the robustness of the model when dealing with imperfect multimodal data, specifically when certain modalities are missing. It seeks clarification on whether the model can leverage additional modalities to infer missing ones and whether missing data leads to compounding effects on the polynomial tensors being constructed. This feedback is valuable as it highlights a potential weakness in the model's performance and encourages the authors to consider and address this issue. However, the comment could be more helpful if it provided specific suggestions or examples on how to investigate or mitigate these effects. Overall, the comment is somewhat helpful as it prompts the authors to consider an important aspect of their model's robustness, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question and suggests a specific analysis that could be conducted using the SST dataset. It explicitly asks for statistics on the frequency of negation or intensity words, such as \"nothing,\" and their impact on polarity. This provides a clear and concrete action for the authors to take, as it specifies what data analysis should be included in the general discussion. The authors know exactly what they need to do to address this feedback, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for analysis, asking for statistics on the frequency of negation or intensity words, such as \"nothing,\" and their impact on polarity. This level of detail guides the authors on what specific data analysis should be included in the general discussion, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for additional analysis and statistics regarding the SST dataset, specifically asking for the frequency of negation or intensity words and their impact on polarity. This is a factual request for clarification or additional data, rather than a subjective claim or opinion. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the general discussion section of the paper. It questions the effectiveness of the SST dataset by suggesting that the authors should analyze the frequency of negation or intensity words, such as \"nothing,\" and their impact on the context. This feedback is clear and constructive, as it guides the authors on how to enhance their analysis and presentation of results. By addressing this suggestion, the authors can provide a more comprehensive understanding of their findings and improve the overall quality of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of verification of the stability of the OGE-Aug on OOD benchmarks, specifically mentioning the DrugOOD dataset. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"OGE-Aug\" and the \"DrugOOD\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not verifying the stability of OGE-Aug on OOD benchmarks, such as DrugOOD, and references SPE [2] for validation on this dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not verify the stability of the OGE-Aug on OOD benchmarks, specifically mentioning the DrugOOD dataset. The comment references SPE [2] as a validation on this dataset, implying that the authors should have done the same for OGE-Aug. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out a potential gap in the paper, the lack of detailed justification or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of verification of the stability of the OGE-Aug on OOD benchmarks, such as the DrugOOD dataset. It references SPE [2] as a validation on this dataset, suggesting that the authors should have done the same for OGE-Aug. This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide additional validation to strengthen their work. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct this validation. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests considering alternative methods, such as freezing some layers of the model while training a few layers or using parameter-efficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these methods, it does not explicitly instruct them to do so. The suggestion is concrete, as it provides specific alternatives to consider, but it is implicit in the sense that the authors need to infer the action from the suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests exploring alternative methods, such as freezing some layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. However, it does not specify which part of the paper this suggestion should be applied to, making it weakly grounded. The comment is specific in suggesting alternative methods for experimental comparison, which provides clear guidance on what the authors could consider. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering alternative methods, such as freezing some layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. The comment provides a logical reasoning by suggesting that these methods are \"natural to think about\" and could offer a valuable basis for comparison. However, it lacks specific examples or references to support the claim that these methods are particularly relevant or effective in the context of the paper. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests exploring alternative methods, such as freezing some layers of the model or using parameter-efficient methods like LoRA, for experimental comparison. This feedback is valuable as it provides the authors with specific and actionable suggestions for improving their work. By considering these methods, the authors can potentially enhance the robustness and efficiency of their model, which could lead to more comprehensive and meaningful results. However, the comment could be more helpful if it included a brief explanation of why these methods are relevant or how they might impact the results. Overall, the comment is mostly helpful as it offers clear guidance for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a precise direction for enhancement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is specific and directs the authors to a particular area where they can enhance their draft by providing a more comprehensive comparison. However, the comment could be more helpful if it included specific examples of strong baselines or suggested how to effectively integrate these comparisons into the related work section. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, making it a 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors conduct multiple seed experiments to provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve the robustness of their evaluation. The comment provides concrete guidance on how to enhance the experimental setup, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of single seed experiments, which is a specific aspect of the paper\\'s methodology. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is somewhat verifiable as it logically reasons that multiple seed experiments would offer a more comprehensive assessment of the model\\'s performance and the impact of the proposed loss. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper\\'s experimental setup, specifically the use of single seed experiments. It highlights the importance of conducting multiple seed experiments to provide a more robust evaluation of the performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and actionable, as it directly suggests a method to enhance the robustness of the evaluation. However, the comment could be more helpful if it provided additional guidance on how to implement multiple seed experiments or discussed potential challenges or considerations. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, stating that the motivation behind this choice is unclear. While the comment raises a valid question, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the motivation. The action is implicit and vague, as the authors are left to infer that they need to provide a clearer explanation of their choice of distributions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice of distributions, which is a clear and actionable point. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, stating that the motivation behind this choice is unclear. However, the comment does not provide any reasoning, examples, or references to support why this choice might be problematic or how it could be improved. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It points out that the motivation behind this choice is unclear, which is a relevant concern that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify the motivation or alternative approaches they could consider. While it identifies a potential weakness, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, noting that it requires a multi-GPU setup for optimizations, which may limit its accessibility to many potential users. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or suggest alternatives that could make the method more accessible. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the accessibility of the proposed method, specifically mentioning the requirement for a multi-GPU setup for optimizations. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. The authors can infer that it relates to the methodology or experimental setup sections, but the comment lacks full grounding. It is specific in highlighting the accessibility issue but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires a multi-GPU setup for optimizations, which makes it inaccessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential limitation of the proposed method, noting that it requires a multi-GPU setup for optimizations, which may limit its accessibility to many potential users. This feedback is somewhat helpful as it identifies a specific issue that could impact the practicality and usability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or make the method more accessible. Without actionable advice or potential solutions, the authors are left with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It further suggests using Ref-[2] as a strong baseline for comparison. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare their system with others that capture semantics and use Ref-[2] as a baseline. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It also mentions Ref-[2] as a potential strong baseline for comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, while the suggestion to compare with Ref-[2] is specific, the comment does not provide detailed guidance on how to implement this comparison or what aspects to focus on. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It further recommends using Ref-[2] as a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It further recommends using Ref-[2] as a strong baseline for comparison. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\\'s evaluation. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. Additionally, it does not address any specific weaknesses or limitations in the current system, leaving the authors with a general direction but limited actionable steps. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the model\\'s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to improve their draft. The questions are implicit and lack concrete details on how to execute the suggested actions. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the model\\'s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its questioning of the model\\'s performance and potential assumptions or learning difficulties, but without clear references to specific sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the model\\'s performance on the triangle dataset, specifically asking why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the questions. Without additional context or justification, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s performance on the triangle dataset, specifically why it does not fully succeed in identifying true sources. It prompts the authors to consider whether one of the assumptions is not satisfied or if there are learning difficulties. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this problem or improve their model. The feedback is somewhat helpful as it points out a weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the applicability of the metrics used for evaluating continual learning in certain scenarios, such as when task boundaries are unknown or not clearly defined. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for alternative metrics or approaches that could be more suitable. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the issue with the applicability of these metrics in certain scenarios. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in scenarios where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the \"loss after switch\" and \"recovery time after switch.\" It points out that these metrics might not be applicable in scenarios where task boundaries are unknown or not clearly defined. This feedback is somewhat helpful as it highlights a potential weakness in the evaluation approach, prompting the authors to consider alternative metrics or methods that could be more suitable for their dataset. However, the comment lacks specific suggestions or guidance on how to address this issue, which limits its helpfulness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the user decoder\\'s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors need to infer that they should clarify or justify the current approach, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the user decoder\\'s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its questioning of the methodology but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the user decoder\\'s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the overall performance or understanding of the model. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the user decoder\\'s reliance on information only up to time step t from the agent decoder, rather than using information from all time steps. This is a valid point that could help the authors clarify their methodology and potentially improve the understanding of their model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what implications it might have for their results. While it identifies a potential area for improvement, the feedback is somewhat helpful as it prompts the authors to consider this aspect but does not fully support them in making improvements. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment explicitly suggests the need for a controlled baseline, it does not provide specific guidance on how to implement this or what specific locations should be tested. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of induction heads and FV heads appearing at different locations within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. It implies that a controlled baseline should be included to ablate heads at different locations in the model. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include a controlled baseline is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the \"location\" of induction heads and FV heads within the model could be a confounding factor affecting the performance difference when ablating these heads. The reviewer implies that a controlled baseline should be included to ablate heads at different locations in the model. While the comment provides a logical reasoning for the potential confounding factor, it lacks specific examples or references to support the claim. The suggestion for a controlled baseline is a reasonable one, but the comment could be strengthened by providing more detailed reasoning or examples. Therefore, the claim is somewhat verifiable, as it requires additional evidence or elaboration to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confounding factor in the experiment, specifically the location of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline should be included to ablate heads at different locations in the model. This feedback is clear and actionable, as it provides a specific direction for improving the experimental design to better understand the results. However, the comment could be more helpful if it offered additional guidance on how to implement this controlled baseline or what specific locations should be tested. Overall, the comment is mostly helpful as it offers a valuable suggestion for enhancing the robustness of the experimental results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a missing section on synonym identification under similarity measurement, which is crucial for describing how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, which is to add this section to their draft. The comment is explicit and concrete, as it specifies exactly what needs to be included, making it highly actionable. Therefore, the comment is rated as a 5 on the actionability scale.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions a missing section on synonym identification under similarity measurement, which allows the authors to accurately identify the part of the paper being addressed. It specifies what is missing, namely a description of how the multiple-choice task is approached, providing clear guidance on what needs to be added. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under similarity measurement, which is necessary for describing how the multiple-choice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is crucial or how its absence affects the paper. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the absence of a section on synonym identification under similarity measurement. This is a clear and actionable feedback that the authors can use to improve their draft by adding this section. The comment provides a direct suggestion for enhancing the paper\\'s content, which is valuable for the authors. However, it could be more helpful if it offered additional guidance on what should be included in this section or how it should be structured. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. However, it does not specify what this overview should include or how it should be presented. The action is implicit, as the authors need to infer that they should add an overview section, but it is vague because it lacks concrete details on what this overview should cover. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. However, it does not specify which part of the paper this overview should be included in, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity regarding what aspects of the workflow and model should be included in the overview. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment suggests that an overview of the workflow and the model would be beneficial for providing a comprehensive understanding of the work. This is a valid point, as such an overview could help readers grasp the entire scope and context of the research. However, the comment lacks specificity and does not provide guidance on what aspects of the workflow and model should be included in this overview. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not offer actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with debiasing the sketch, noting that it requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods to mitigate the bias. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the bias issue but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It implies that this information cannot be computed accurately without a significant runtime, potentially introducing bias. The comment also mentions a similar issue with computing the surrogate sketch. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the problem with debiasing and the potential bias, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that debiasing the sketch requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. The reviewer supports this claim by explaining the computational challenge and the potential impact on the approach. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the paper to understand the exact context and implications of this issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the debiasing of the sketch, noting that it requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without a significant runtime similar to solving the ridge regression problem. This implies that the approach may introduce bias, potentially undermining its purpose. The comment also mentions a similar issue with computing the surrogate sketch. While the comment highlights a critical weakness in the approach, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the bias. The feedback is somewhat helpful as it points out a significant problem but lacks actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what aspects of the setup need attention. The comment implies that the authors should address the questions raised, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the ablation experiments, suggesting that they deserve a better setup. However, it does not specify which part of the paper discusses these ablations or what specific issues need to be addressed. The authors might infer that it relates to the experimental section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, the comment is not specific about what aspects of the setup need improvement or what questions arise. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the ablation experiments, suggesting that they deserve a better setup due to the questions that arise. However, the comment does not provide specific examples of these questions or elaborate on why the current setup is inadequate. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better setup due to the questions that arise. However, it does not provide specific guidance or suggestions on how to improve the setup or address the questions. The comment lacks depth and actionable feedback, leaving the authors with a general idea of what might be problematic but without a clear path for improvement. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct more empirical work but are not given concrete steps on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should explore this aspect further, which implies that the comment is related to the discussion or results sections where such claims are typically made. However, the comment does not explicitly mention these sections, making it weakly grounded. It is specific in detailing what is missing, namely empirical evidence to test the hypothesis. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed models are useful for learning representations of low-frequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request for additional evidence. However, the comment does not provide specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to infer the specific areas where evidence is lacking and how to address it, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations of low-frequency words. It suggests that the authors should explore this aspect further, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what types of evidence would be most relevant. Additionally, it mentions that the explanation of improvements is not clear, which is another area for improvement. While the comment highlights important areas for enhancement, it lacks detailed guidance, making it somewhat helpful. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the error analysis on the movie dataset is missing, which is a clear action for the authors to take. It also provides a concrete suggestion by specifying that the authors need to identify the cases where the model fails. This level of detail gives the authors a direct and actionable path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"error analysis on the movie dataset,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the absence of error analysis, which is crucial for other researchers to continue working on the task. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it would benefit the research. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of error analysis on the movie dataset. This is a critical aspect for other researchers to build upon the work, as it provides insight into the model\\'s limitations and areas for improvement. The comment is clear and actionable, as it explicitly states what is missing and why it is important. However, it could be more helpful if it suggested specific methods or approaches for conducting the error analysis. Overall, the comment is mostly helpful, as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any explicit or implicit guidance on what specific details are missing or how the authors should address this issue. The comment lacks actionable advice or suggestions, leaving the authors without a clear understanding of what needs to be done to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that \"some details of the proposed method are missing,\" but it does not specify which details are missing or where in the paper these details should be included. It also references a \"questions section below,\" which is not explicitly mentioned in the provided text, making it difficult for the authors to identify the exact part of the paper being addressed. Without specific guidance or references to particular sections or elements of the paper, the authors cannot effectively address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or evidence to support this claim. Without detailed information on what details are missing, the authors may find it challenging to address the issue. The comment lacks verifiable evidence or reasoning, making it difficult for the authors to understand and respond to the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any specific details or suggestions on what these missing details are or how they could be addressed. Without actionable guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance their draft. This lack of specificity and guidance makes the comment unhelpful, as it does not provide any meaningful direction for improvement. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to conduct an ablation analysis, but the comment lacks concrete details on how to implement this or what specific components should be analyzed. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for ablation analysis, but without grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. This is a valid observation, as ablation analysis is a common method used to understand the contribution of individual components to the overall performance. However, the comment does not provide specific examples or references to support why the lack of ablation analysis is problematic or how it affects the interpretation of the results. While the claim is logical, it lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of ablation analysis, which makes it difficult to determine the source of the small performance gain. This is a critical observation that highlights a key area for improvement in the draft. By pointing out the absence of ablation analysis, the comment provides the authors with a clear direction for enhancing the paper\\'s clarity and comprehensiveness. However, the comment could be more helpful if it suggested specific components to include in the ablation analysis or provided examples of how this could be effectively implemented. Despite this, the feedback is mostly helpful as it directs the authors to a crucial area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point presents a finding that when the number of classes is large (>8), the noise rate of similarity labels is less than that of class labels. It also mentions the use of \"Th.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the observation or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"2,\" which suggests that it is addressing a specific part of the paper, likely a figure or table. However, without further context or details, the authors may not be able to pinpoint the exact section being discussed. The comment mentions a finding about the noise rate of similarity labels compared to class labels when the number of classes is large, but it does not specify what needs to be addressed or improved in this context. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point presents a factual observation about the noise rate of similarity labels compared to class labels when the number of classes is large. It also mentions the use of \"Th,\" which could refer to a specific method or technique. However, the comment lacks any subjective claims, opinions, or suggestions that would require verification. It is purely descriptive, making it a normal statement. Therefore, the correct label is \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment presents a factual observation about the noise rate of similarity labels compared to class labels when the number of classes is large. It also mentions the use of \"Th,\" which could refer to a specific method or technique. However, the comment lacks any actionable feedback or suggestions for improvement. It does not provide guidance on how the authors might address the observation or what implications it might have for their work. Without actionable advice or insights, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, such as revising the experimental design, providing additional data, or clarifying the results. Without any guidance or direction, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"CNN experiments\" but does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what makes the experiments not fully convincing. The authors cannot confidently determine which experiments are being referred to or what aspects need improvement. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific feedback or suggestions on what aspects of the experiments are lacking or how they could be improved. Without detailed guidance or actionable advice, the authors are left without a clear understanding of how to address the issue. This lack of specificity and actionable feedback makes the comment unhelpful, as it does not provide the authors with a meaningful way to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. While the comment implies that the authors should focus on prompt design and discuss its effectiveness, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the discussion on prompt design without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts can lead to varying performance outcomes. However, the comment does not specify which part of the paper should focus on prompt design or provide specific guidance on what aspects of prompt design need more emphasis. While the authors can infer that the discussion on prompt design should be enhanced, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. However, the comment lacks specific examples or detailed reasoning to support the claim that prompt design is a critical area for improvement. While the suggestion is logical, it requires more elaboration to be fully verifiable. Therefore, the comment is somewhat verifiable, as it provides a general direction but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, given the introduction of several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, as different prompts can lead to varying performance outcomes. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to enhance their work. However, it could be more helpful if it offered specific suggestions or examples on how to effectively design prompts. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection and suggests that if the adaptive method is good, it could be used instead. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors to infer that they should clarify the rationale for using freezing or consider alternative methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or freezing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion to use the adaptive method, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why the adaptive method would be better or why freezing is used. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of freezing in MLS (Maximum Likelihood Subset) selection, suggesting that if the adaptive method is good, it could be used instead. This feedback identifies a potential area for improvement by questioning the rationale behind the choice of method. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue or explore alternative methods. While it prompts the authors to consider an alternative approach, it does not offer detailed guidance or actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the issue is solved in the proposed knowledge-CLIP model and suggests performing a specific analysis similar to existing work that combines text and KG. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the type of analysis to perform, but it lacks directness in terms of action. The authors can infer that they need to conduct this analysis, but the comment could be more explicit in its guidance. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about whether the issue is solved in the proposed knowledge-CLIP model and suggests performing an analysis similar to existing work that combines text and KG. It references a specific existing work (https://arxiv.org/abs/2104.06378) and suggests a specific analysis to be conducted on the proposed model. However, it does not explicitly mention which part of the paper this issue or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular analysis to be performed, which provides clear guidance for the authors. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the issue is solved in the proposed knowledge-CLIP model and suggests performing an analysis similar to existing work that combines text and KG. The comment references a specific existing work (https://arxiv.org/abs/2104.06378) and provides a clear suggestion for further analysis. This reference and the suggestion for analysis provide a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the existing work relates to the proposed model. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent question about whether the issue addressed in the paper is resolved by the proposed knowledge-CLIP model. It also references existing work that combines text and KG, suggesting that the authors perform a similar analysis on their proposed model. This feedback is valuable as it encourages the authors to consider additional analyses that could strengthen their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the existing work should be adapted. Overall, the comment is mostly helpful as it offers a clear direction for further exploration, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more clarification on how novel values in the test set are handled. This is an explicit action that the authors can take to improve their draft. The comment is specific in its request for additional explanation, providing clear guidance on what the authors need to do to enhance the clarity of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining how novel values in the test set are handled. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more clarification on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide more clarification on how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors improve the clarity and comprehensiveness of their paper. By addressing this suggestion, the authors can enhance the reader\\'s understanding of their methodology and results. However, the comment could be more helpful if it provided additional context or examples of what specific aspects of novel values need clarification. Overall, the comment is mostly helpful as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that similar methods have already been proposed for multi-task learning and notes that this has not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper should be revised. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that similar methods have already been proposed for multi-task learning and notes that this has not been discussed in the paper. However, it does not specify which part of the paper should include this discussion or which specific methods are being referred to. The authors can make an educated guess that it relates to the methodology or literature review sections, but the comment lacks full grounding. It is specific in pointing out the omission of discussing similar methods, but without explicit references or detailed guidance, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar methods have already been proposed for multi-task learning and have not been discussed in the paper. However, it does not provide any specific examples or references to these existing methods, making it difficult for the authors to understand the basis of the claim or how to address it. Without supporting evidence or detailed information, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that similar methods for multi-task learning have already been proposed and are not discussed in the paper. This is a relevant observation that could help the authors improve their draft by ensuring they are aware of existing work in the field and potentially incorporating it into their discussion or methodology. However, the comment lacks specificity and does not provide guidance on how the authors might address this issue or integrate the existing methods into their work. While it highlights an important area for consideration, the feedback is incomplete and does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an expectation about the computational complexity of FedMITR compared to other methods and asks if a comparison has been made. While it implies that the authors should consider comparing the computational complexity, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include a comparison, but without specific guidance on how to conduct it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of computational complexity should be compared. The authors can infer that the comment relates to the experimental or results section, but the lack of specificity and explicit grounding makes it difficult for them to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. However, it does not provide any evidence, reasoning, or references to support the expectation that FedMITR\\'s computation is higher. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that a comparison should be made. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on how to conduct such a comparison or what aspects of computational complexity should be considered. This makes it somewhat helpful, as it points out a potential gap in the paper but does not offer actionable advice for addressing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions. While it implies that the authors should provide more information or justification for their choices, it does not explicitly instruct them to do so. The suggestions are concrete, such as considering k-cross-validation and alternative loss functions, but the action is not directly stated. Therefore, the comment is mostly actionable, as it provides clear guidance on what the authors should consider but does not explicitly instruct them to make changes.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions. However, it does not specify which part of the paper these questions and suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its questions and suggestions but lacks grounding, as it does not provide a clear reference to the specific sections or elements of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions. However, it does not provide any supporting evidence, reasoning, or references to justify these questions or suggestions. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the questions and suggestions, rendering the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions. It prompts the authors to provide more information about their methodology and suggests exploring alternative approaches. While the comment identifies areas for improvement and provides some guidance, it lacks depth and specificity, as it does not offer detailed suggestions or examples of how to address these issues. The authors are given some direction but need to infer the exact steps to take, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit suggestions for improving the draft, including using a new method of training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. The comment also explicitly states that three convolutional layers are insufficient for non-synthetic tasks. While the suggestions are clear, the comment could be more actionable by providing specific guidance on how to implement these changes or by offering examples of how to incorporate the suggested methods. Overall, the comment is mostly actionable as it provides concrete suggestions, but it could be more detailed in its guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the new method of training on the labeled data\" and \"incorporating input mask explanation annotations for a few examples,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improving the method, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses skepticism about the effectiveness of the proposed method, citing the failure of similar robustness/domain invariance interventions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the skepticism. The lack of detailed evidence or references limits the verifiability of the claim, rendering it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It suggests using a new method of training on labeled data and incorporating input mask explanation annotations for a few examples, which could enhance the robustness and domain invariance of the model. Additionally, it recommends using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, as the current three convolutional layers are deemed insufficient for non-synthetic tasks. The comment also expresses skepticism about the proposed method, but this is framed as an opinion and does not detract from the actionable suggestions. Overall, the feedback is clear, specific, and provides concrete guidance for improving the draft, making it highly helpful for the authors.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should ensure the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how to implement this action, such as which specific resources should be matched or how to conduct the tuning. While the action is explicit, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned, but it lacks detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should ensure the baseline is fully tuned with similar resources as the proposed method for a fair comparison. This claim is somewhat verifiable as it highlights a potential issue with the comparison between the proposed method and the baseline. However, the comment lacks specific examples or detailed reasoning on why the baseline is not fully tuned or how this affects the comparison. Providing more detailed justification or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the proposed method and the baseline, suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. This is a clear and actionable suggestion that could help the authors improve the robustness of their results. However, the comment could be more helpful if it provided specific guidance on how to conduct this tuning or what resources should be matched. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement in their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential error in the definition of perplexity and its representation in the paper. It explicitly states that the definition provided is incorrect and suggests that it resembles cross-entropy instead. However, the comment does not provide specific guidance on how to correct the definition or clarify the confusion. While it highlights an issue, it lacks actionable steps for the authors to take, such as suggesting alternative definitions or examples to illustrate the correct concept. Therefore, the comment is somewhat actionable, as it points out a problem but does not offer concrete steps for resolution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and its representation, pointing out that it does not align with the actual definition of perplexity and instead resembles cross-entropy. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity provided in the paper is incorrect and that it resembles cross-entropy. However, the comment does not provide any supporting evidence, such as references to standard definitions of perplexity or cross-entropy, to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique or to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of perplexity provided in the paper, pointing out that it is incorrect and more accurately represents cross-entropy. This feedback is clear and actionable, as it directs the authors to correct the definition and ensure that it aligns with the correct concept. However, the comment could be more helpful if it provided additional guidance on how to accurately define perplexity or suggested examples to illustrate the correct concept. Despite this, the comment is mostly helpful as it effectively highlights a critical error that needs correction, providing the authors with a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge map-based defense strategies. It suggests that the authors should evaluate their defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. This implies that the authors should conduct additional experiments to assess the robustness of their defense against such attacks. While the comment provides a clear direction for the authors to follow, it does not specify exactly how to conduct these experiments or what metrics to use. The action is explicit but somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge map-based defense strategies. It suggests evaluating the defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. However, the comment does not explicitly mention which part of the paper this evaluation should be conducted in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the evaluation against a specific type of adversarial attack. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge map-based defense strategies. It suggests that the authors should evaluate their defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. The comment provides a logical reasoning for why this evaluation is crucial, as it highlights a potential vulnerability in the defense strategy. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to consider this suggestion and potentially conduct additional experiments to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the evaluation of the proposed strategies, specifically the consideration of an adaptive attack against the edge map-based defense strategies. It highlights the importance of evaluating the defense against an adversarial attack that aims to produce minimal structural alterations to the edge map while misleading model predictions. This feedback is valuable as it points out a potential vulnerability in the defense strategy and suggests a specific area for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct these evaluations or what specific metrics to use. Overall, the comment is mostly helpful as it directs the authors to a critical area that needs further exploration, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment explicitly identifies a missing element that needs to be included in the experimental section to enhance the clarity and interpretability of the results. However, it does not provide specific guidance on how to calculate or present the standard deviations. While the action is clear, the lack of detailed instructions on how to implement this change makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing standard deviations, which is crucial for judging the significance of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual statement that requires no verification or justification, as it simply points out a missing detail in the presentation of the results. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it difficult to assess the significance of the findings. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations in the experimental results. However, the comment could be more helpful if it offered guidance on how to calculate or present the standard deviations effectively. Despite this, the feedback is mostly helpful as it directs the authors to a critical aspect of their results that needs attention. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the realism of the generated images or suggestions for further experimentation or analysis. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the image quality but lacks grounding, as it does not provide a clear reference to the specific sections or figures being discussed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the realism of the results. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is somewhat helpful as it highlights a potential weakness in the paper, prompting the authors to consider improving the realism of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how to enhance the realism of the generated images. Without actionable advice or examples, the authors may find it challenging to address this issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the statement in lines 559-560, indicating that the claim made is not entirely true. It provides a clear and concrete suggestion by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (A-B-A and B-A-B) using two separate standard backpropagation processes. This feedback is explicit and provides a direct action for the authors to take, which is to correct the statement in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 559-560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, indicating that the claim made is not entirely true and providing an alternative explanation for the Cycle Consistency loss. This level of detail helps the authors understand what needs to be corrected in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement in lines 559-560 is not entirely true. It provides a specific counterexample by explaining that in Cycle Consistency loss, one can iterate between two phases of reconstructions (A-B-A and B-A-B) using two separate standard backpropagation processes. This detailed explanation supports the claim, making it fully verifiable. The reviewer has provided a clear and logical reasoning to substantiate the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the statement in lines 559-560, indicating that it is not entirely true. It provides a clear and detailed explanation of the Cycle Consistency loss, specifically mentioning that it can involve iterating between two phases of reconstructions (A-B-A and B-A-B) using two separate standard backpropagation processes. This feedback is highly helpful as it not only points out the error but also offers a precise correction, empowering the authors to improve the accuracy and clarity of their draft. The comment is actionable, providing a clear path for the authors to enhance their work. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the paper regarding the models, specifically the grammar over kernels. It questions the explanation of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these gaps. The authors are left to infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on what specific details to include or how to present them. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed instructions on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the details of the models\" and \"grammar over kernels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014details about the grammar over kernels, the associated probabilities, and how inference is performed. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some details of the models are missing, specifically regarding the grammar over kernels. It questions the explanation of how this approach is applied in practice and asks about the probabilities associated with the grammar and how inference is performed. While the comment raises valid concerns about the lack of detail, it does not provide specific examples or references to support the claim. The reasoning is somewhat logical, as it points out a gap in the explanation, but it lacks concrete evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels. It highlights the need for a more detailed explanation of how this approach is applied in practice, including the probabilities associated with the grammar and how inference is performed. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the understanding and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar approaches that might be useful for comparison. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these suggestions, such as which specific cases to focus on or how to analyze the limitations. The action is explicit but somewhat vague, as the authors know they need to include qualitative results and failure cases but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. However, the comment does not specify which part of the paper these suggestions should be applied to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but without explicit references, it is challenging to pinpoint the exact parts. The comment is specific in detailing what needs to be addressed, such as showing qualitative results and failure cases, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that qualitative results, particularly with a zoomed-in view, should be included for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not provide specific examples, reasoning, or references to support why these qualitative results are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these suggestions based on the context of their work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors include qualitative results, specifically with a zoomed-in view, for cases where previous methods failed but were successful with the proposed method. It also recommends showing some failure cases and analyzing the limitations. This feedback is clear and actionable, as it provides specific guidance on how to enhance the paper by adding qualitative results and failure cases. By following this advice, the authors can better demonstrate the effectiveness and limitations of their method, which can significantly improve the comprehensiveness and impact of their work. However, the comment could be more helpful if it offered examples or specific suggestions on how to present these qualitative results or analyze the limitations. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests clarifying the title to specify that it refers to machine comprehension of text, rather than human reading comprehension. This is an explicit action that the authors can take to improve their draft. The comment provides a clear direction on what needs to be changed, making it concrete and actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and needs clarification regarding whether it refers to machine comprehension of text or human reading comprehension. The comment provides a clear direction for improvement by suggesting how to clarify the title. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text, rather than human reading comprehension. The reviewer provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" typically refer to human reading abilities. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title of the paper, suggesting that it could be clarified to specify whether it refers to machine comprehension of text or human reading comprehension. This is a clear and actionable suggestion that could help the authors improve the clarity and precision of their title. However, the comment could be more helpful if it provided additional context or examples of how the title might be misleading or if it offered suggestions for rephrasing the title to better reflect the content of the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should switch to a human metric, but the comment lacks concrete details on which human metric to use or how to implement the change. This makes the action implicit and somewhat vague, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"human evaluation\" and \"style control,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with using an automatic metric (TSS) instead of a human metric, which weakens the convincingness of the human evaluation. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. The comment provides a logical reasoning by pointing out the potential weakness in using an automatic metric for human evaluation, which is a valid concern. However, it lacks specific examples or references to support the claim that a human metric would be more appropriate or effective. This makes the claim somewhat verifiable, as it provides a logical basis but requires further elaboration or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of an automatic metric (TSS) in human evaluation for style control, suggesting that a human metric should be used instead. This feedback is clear and actionable, as it identifies a potential weakness in the evaluation methodology and provides a specific suggestion for improvement. By pointing out this issue, the comment helps the authors to reconsider their evaluation approach and potentially enhance the credibility and effectiveness of their human evaluation. However, the comment could be more helpful if it provided additional context or examples of human metrics that could be used. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including experiments across more diverse domains would strengthen the paper. While it implies an action for the authors to take, it does not provide specific guidance on which domains to consider or how to conduct these experiments. The suggestion is explicit but lacks concrete details, making it somewhat actionable. The authors know they need to expand their experiments but may not be entirely sure of the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are effective in proving the authors\\' point but implies that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper the current experiments are in or which domains are being referred to. The authors can infer that the comment relates to the experimental section, but the lack of explicit references or detailed guidance makes it weakly grounded. The comment is specific in suggesting the inclusion of more diverse domains, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments effectively prove the authors\\' point but suggests that including experiments across more diverse domains would strengthen the paper. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that additional domains would be beneficial. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the experiments effectively support the authors\\' claims but suggests that including experiments across more diverse domains would strengthen the paper. This feedback is somewhat helpful as it identifies a potential area for expansion and improvement, which could enhance the paper\\'s impact and relevance. However, the comment lacks specific guidance on which domains to consider or how to conduct these additional experiments, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is rated as somewhat helpful, as it provides a direction for enhancement but could be more actionable with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pre-trained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of confidence intervals for results and the limited evaluation on only two datasets, which are standard in the RNP community. It provides specific references to external works, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pre-trained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The authors can infer that it relates to the results or methodology sections, but this inference is not direct. The comment is specific in detailing what is missing, such as confidence intervals and additional datasets. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes the limited evaluation on only two datasets, which are standard in the RNP community. The comment is supported by references to external works, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pre-trained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. These references provide a basis for the claim that the evaluation could be more comprehensive. However, the comment could be strengthened by providing more detailed reasoning or examples of how the lack of confidence intervals affects the interpretation of results. Overall, the claim is mostly verifiable, as it provides some support but could be further substantiated. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which are standard in the RNP community. The comment provides specific references to external works that could be used for comparison, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks. ICLR 2019, [2] Controlling Selection Bias in Causal Inference. AISTATS 2012, [3] An empirical study on robustness to spurious correlations using pre-trained language models. TACL 2020, and [4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022. This feedback is clear and actionable, as it directs the authors to include confidence intervals and expand their evaluation to more datasets, potentially using the referenced works as benchmarks. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or suggestions for additional datasets to evaluate. Overall, the comment is mostly helpful, as it offers valuable insights for improving the paper but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the design of the Logarithmic Unbiased Quantizer (LUQ) is straightforward once the goal is clear, and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper lies in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the paper or address the feedback, leaving the authors without a clear understanding of what changes are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the perceived lack of novelty in the approaches presented in Section 5. The comment highlights that the main contribution is not in proposing new techniques but rather in demonstrating the effectiveness of combining existing methods. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main contribution of the paper lies in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy, rather than proposing novel techniques. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the reviewer\\'s assertion. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a general direction but lacks concrete justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a nuanced evaluation of the paper\\'s contributions, suggesting that the main contribution lies in demonstrating the effectiveness of combining existing techniques to achieve surprisingly good accuracy, rather than proposing novel techniques. This feedback is somewhat helpful as it offers a perspective on the paper\\'s contributions, encouraging the authors to consider the significance of their work in the context of existing literature. However, the comment lacks specific suggestions or guidance on how the authors might enhance their paper or address potential weaknesses, such as exploring novel techniques or providing more detailed comparisons with existing work. Therefore, while it provides some insight, it is not fully actionable or comprehensive, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses to address the reviewer\\'s concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the training process is discussed. Without explicit references or context, the authors may find it challenging to identify the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the training losses are of interest or how they should be presented. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. However, it does not provide any supporting evidence, reasoning, or references to justify why the stability is a concern or why training losses are necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn and expresses a desire to see some training losses. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable advice or insights that could help the authors improve their draft. Therefore, it is barely helpful, as it highlights a potential issue but does not provide enough detail or direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The authors are left to infer that they should investigate the impact of this sampling rate on the comparison with other methods, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as references to specific experiments or data that demonstrate this issue. Without additional context or examples, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, noting that it processes 2x samples per iteration, which could lead to unfair comparisons with other methods. This observation is relevant and could impact the validity of the results presented in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparisons. While it highlights a critical area for consideration, the feedback could be more actionable and helpful by providing concrete steps or recommendations for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of scalability need to be considered. Without actionable steps or suggestions, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors might investigate this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a relevant question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practical applicability and robustness of their approach. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or address this issue. Without actionable feedback or detailed advice, the authors are left with a general area for improvement but without a clear path forward. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about relaxing the need to visit all ball-action pairs with each iteration, asking for minimal assumptions that could be made or what would happen if they are partially covered. While the comment implies that the authors should consider these aspects, it does not provide explicit guidance or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore these ideas further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is a continuation of a previous remark and does not explicitly mention a specific part of the paper, making it weakly grounded. However, it does provide a clear and specific question about relaxing the need to visit all ball-action pairs with each iteration, suggesting minimal assumptions that could be made or exploring the consequences of partially covering them. This level of specificity helps the authors understand what needs to be addressed, even if they cannot pinpoint the exact section. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking suggestions or ideas for improvement, rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about relaxing the need to visit all ball-action pairs with each iteration, seeking suggestions on minimal assumptions that could be made or exploring the consequences of partially covering them. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to think critically about their approach and consider potential modifications. This feedback encourages the authors to explore alternative methods or assumptions, which could lead to a more efficient or effective algorithm. However, the comment lacks depth and does not offer concrete steps or examples, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. This is an explicit suggestion, as it clearly indicates a potential improvement and provides a specific example of what could be used. However, the comment does not provide detailed guidance on how to implement this change or why RoBERTa-base might be a better choice. While the action is explicit, the lack of concrete details on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an improvement by proposing the use of a better encoder, specifically mentioning RoBERTa-base as an alternative to BERT. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results section. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to identify where this feedback should be addressed. The comment is specific in suggesting a potential improvement but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using a better encoder, such as RoBERTa-base, could lead to improvement. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTa-base would be a better choice or how it would impact the results. The claim lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that using a better encoder, such as RoBERTa-base, could lead to improvements in the paper. This is a specific and actionable suggestion that could help the authors enhance their work. However, the comment lacks depth and does not provide detailed guidance on why RoBERTa-base might be a better choice or how it could be integrated into the existing framework. While it offers a clear direction for improvement, it could be more helpful with additional context or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the performance of the predictive model. While the comment implies that the authors should provide a demonstration or example of this, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how to achieve this demonstration or what specific aspects of the method should be highlighted. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific guidance on how to achieve this demonstration or what aspects of the method should be highlighted. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this demonstration is necessary or how it would be beneficial. Without additional context or explanation, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without negatively impacting the predictive model. This is a valuable suggestion as it highlights a potential trade-off between fairness and performance that the authors should address. However, the comment lacks specificity and does not provide detailed guidance on how to achieve this demonstration or what specific aspects of the method should be emphasized. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should have been included in Section 4.1. This provides a clear and direct action for the authors to take, which is to add the missing implementation details to the specified section. The feedback is concrete, as it specifies exactly where the authors should make the additions, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking implementation details of the proposed methods, which should be described in the implementation details section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details of the proposed methods is a concern. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning on why these details are crucial. The comment lacks evidence or justification, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods. It suggests that these details should have been included in Section 4.1, providing a clear and actionable piece of feedback. By pointing out this omission, the comment helps the authors to focus on a critical aspect of their work that needs improvement. However, the comment could be more helpful if it offered suggestions on how to present these implementation details effectively or provided examples of what should be included. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant lack of empirical evaluation and comparison with other methods, which makes it difficult to assess the practical value of the contribution. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment identifies a critical issue with the paper, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they need to conduct empirical evaluations, comparisons with other methods, and provide theoretical arguments for the significance of their contribution. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it somewhat actionable. The authors know they need to address the lack of empirical evaluation and theoretical justification but may struggle with the specifics of how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to identify the specific parts of the paper that need attention. It also specifies the issues, such as the absence of practical value and the need for theoretical arguments, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. It also criticizes the absence of theoretical arguments for why the contribution matters. While the comment highlights significant gaps in the paper, it does not provide specific examples or references to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It highlights that the absence of such evaluations makes it difficult to assess the practical value of the contribution. The comment also points out the need for theoretical arguments to justify the significance of the contribution. While the feedback is clear about the weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues. The comment is somewhat helpful as it directs the authors' attention to important areas for improvement but lacks actionable advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the paper, noting that while the method discussed can be applied in general MDPs, it is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRM-RL~[1] and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this limitation or explore new applications. The action is implicit and vague, as the authors are left to infer that they should consider broader applications but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the paper in applying the method to general MDPs, specifically mentioning navigation problems. It also references PRM-RL~[1] as a related work that has already discussed combining RL and planning. However, the comment does not specify which part of the paper discusses the method or where the limitation is explicitly stated. While it provides some context, it lacks full grounding as it does not explicitly mention sections or figures, making it difficult for the authors to pinpoint the exact parts needing revision. The comment is specific in suggesting the exploration of broader applications, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper is limited to navigation problems and suggests that combining RL and planning has already been discussed in PRM-RL~[1]. The comment provides a reference to a specific work, which supports the claim by indicating that the idea is not novel. However, the comment could be strengthened by providing more detailed reasoning or examples of how the paper\\'s method is limited or how it relates to PRM-RL. This would make the claim more fully verifiable. Therefore, the comment is mostly verifiable, as it provides some support but lacks additional details for a more robust justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation of the paper, noting that the method discussed is primarily applicable to navigation problems and suggests that it could be more broadly applicable. It also references a related work, PRM-RL~[1], which has already discussed combining RL and planning. This feedback is somewhat helpful as it points out a potential area for expansion and suggests exploring more general applications. However, the comment lacks specific guidance or suggestions on how the authors might address this limitation or explore new applications, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a critical concept in the paper. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap. While the action is implicit, it is concrete in suggesting that the authors need to define the concept more formally. This provides the authors with a clear direction on how to improve their draft, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific concept in the paper. It also provides a clear indication of what is lacking, namely a formal definition for the contrastive gap. The comment suggests that while an intuitive example is given, it is not convincing, and a clear definition is needed. This provides specific guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed \"contrastive gap\" is unclear and lacks a formal definition. It acknowledges that an intuitive example is provided but questions its convincingness. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or lacking. This makes the claim somewhat verifiable, as it highlights an issue but lacks detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the work. It acknowledges that an intuitive example is provided but notes that the setting of this example is less convincing. The comment highlights the need for a clear, formal definition of the contrastive gap, which is a crucial step in ensuring the paper\\'s clarity and rigor. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the definition of the contrastive gap. However, the comment could be more helpful if it offered suggestions on how to formalize the definition or provided examples of similar definitions in related literature. Overall, the comment is mostly helpful as it directs the authors to a significant area of improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including other baselines, such as those discussed in the related work section, and recommends adding an explanation for why the chosen baseline is the most appropriate. The comment also includes a question about testing beforehand whether a specific condition is met. While the suggestion to include other baselines is explicit, the comment lacks concrete guidance on which specific baselines to include or how to implement the suggested testing. The question about testing is also not actionable as it does not provide a clear direction for the authors. Overall, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the inclusion of other baselines, such as those discussed in the related work section, and references specific works ([29, 5, 6]). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests including these baselines and provides a rationale for why the chosen baseline is the most appropriate. Additionally, it mentions that the authors have addressed the reviewer\\'s previous concerns and raised their score, indicating that the authors have clarified unclear parts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including other baselines, such as those discussed in the related work section, and recommends adding an explanation for why the chosen baseline is the most appropriate. The reviewer also mentions that their previous concerns have been addressed and their score has been raised. However, the comment does not provide specific reasoning or evidence to support the claim that including other baselines would improve the paper. The suggestion is somewhat verifiable as it provides a logical rationale for including additional baselines, but it lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including other baselines, such as those discussed in the related work section, would enhance the paper. It also recommends adding an explanation for why the chosen baseline is the most appropriate, which would provide clarity to the readers. The comment is somewhat helpful as it identifies a potential area for improvement and offers a specific suggestion for enhancing the paper. However, it could be more helpful if it provided additional guidance on which specific baselines to include or how to effectively integrate them into the paper. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them might be more beneficial. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for dynamic weighting. The comment implies that the authors should consider alternative approaches, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue with uniformly setting \\alpha_m to 1/M and suggests that dynamically weighting modalities is important, referencing works in multimodal fusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\alpha_m uniformly to 1/M implies equal contributions from all modalities, and suggests that dynamically weighting modalities is important based on works in multimodal fusion. However, the comment does not provide specific references or examples to support this claim, making it somewhat verifiable. The authors would need to look into the literature on multimodal fusion to understand the basis of the suggestion, which adds a layer of effort to verify the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the uniform weighting of modalities, suggesting that dynamically weighting them might be more beneficial. It references works in multimodal fusion that support this claim, providing a basis for the suggestion. However, the comment could be more helpful if it offered specific examples or methods for dynamic weighting, which would give the authors more actionable guidance. Despite this, the feedback is clear and highlights an important area for improvement, making it mostly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. It suggests that this phrase is difficult to understand. However, the comment does not provide any guidance on how to address this issue or suggest alternative phrasing. The action is implicit, as the authors need to infer that they should clarify or rephrase the sentence to improve comprehension. The feedback lacks concrete details on how to implement the suggested change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (\"line 280\") where the issue is identified, allowing the authors to accurately pinpoint the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"to meet\" and its difficulty in understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"to meet\" is difficult to understand, specifically mentioning \"a response candidate can meet each utterance\" on line 280. However, the comment does not provide any further explanation or justification for why this phrase is problematic or how it could be improved. Without additional context or reasoning, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, which is described as difficult to understand. However, it does not provide any suggestions or guidance on how to clarify or rephrase this phrase to improve comprehension. Without actionable feedback or examples of alternative phrasing, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the method, specifically asking about other limitations beyond the shallow network in the graph case. While it implies that the authors should consider and address these limitations, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore and discuss additional limitations. However, the comment does suggest a specific area for consideration, which is a step towards actionability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the method, specifically asking if the network is shallow in the graph case and if this is also the case here. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about limitations and the network depth, but it lacks grounding as it does not reference a particular section or figure. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking about other limitations of the method and inquiring about the depth of the network in the graph case. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the method, specifically asking about other limitations beyond the shallow network in the graph case. While it prompts the authors to consider additional limitations, it lacks specificity and does not provide any actionable guidance or suggestions on how to address these limitations. The comment is vague and does not offer any constructive feedback that would help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these questions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the dropping rate and the number of masks generated. This provides clear guidance on what the authors need to address in their response. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the dropout process, specifically regarding the dropping rate and the number of masks generated. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While it identifies areas that need further explanation, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their understanding of the dropout process. The feedback is somewhat helpful as it points out a need for clarification, but it lacks depth and actionable advice, making it incomplete for the authors to fully address the issues. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors need to provide further justification for the effectiveness of their proposed two-stage optimization approach. It specifically recommends including comparisons with other single-stage attacks to demonstrate the effectiveness of the approach. Additionally, it emphasizes the importance of using proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms to justify the technical contributions. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly addresses the effectiveness of the proposed two-stage optimization approach, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed: providing further justification for the effectiveness, including comparisons with other single-stage attacks, and using proper benchmarks and comparisons with other state-of-the-art algorithms. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification. It suggests that showing performance drops on fusion models is insufficient and that comparisons with other single-stage attacks are necessary to demonstrate effectiveness. The comment also emphasizes the importance of using proper benchmarks and comparisons with other state-of-the-art algorithms. While the comment provides a logical reasoning for the need for additional justification and comparisons, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a general direction for improvement but requires more detailed evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed two-stage optimization approach. It points out that merely showing performance drops on fusion models is insufficient and suggests that comparisons with other single-stage attacks are necessary to demonstrate the approach\\'s effectiveness. Additionally, the comment emphasizes the importance of using proper benchmarks and comparisons with other state-of-the-art algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific guidance on how to strengthen their argument and improve the credibility of their work. However, it could be more helpful if it included examples or references to support the suggested comparisons. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the rigor and validity of their research.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback provides a clear and direct action for the authors to take, ensuring that the Perceptual Metric is correctly aligned. The comment is explicit and concrete, leaving no ambiguity about what needs to be corrected. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the Perceptual Metric in Figure 2, suggesting a correction in how it is connected. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for improvement. By addressing this issue, the authors can enhance the clarity and accuracy of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) in equation 2. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or clarify the issue in their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether each node can attend to its own lower-level representation, referencing equation 2 and the description of N_l^(s). This provides some grounding as it mentions a specific equation, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what needs to be addressed or clarified regarding this issue, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether each node can attend to its own lower-level representation, based on the description of N_l^(s) in equation 2. The comment suggests that only neighboring nodes are attended to, as inferred from the description. However, the claim lacks specific evidence or detailed reasoning to fully substantiate the inference. While it points out a potential issue, the lack of detailed explanation or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether each node can attend to its own lower-level representation, based on the description of N_l^(s) in equation 2. It suggests that only neighboring nodes are attended to, which could be a critical aspect of the model\\'s functionality. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the representation in their draft. While it identifies a potential area of confusion, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider this aspect but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic large-scale multitasking and achieves automation. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback is implicit, as it points out areas that need improvement but does not specify what changes should be made. Additionally, the actions are vague, as the authors are left to infer what specific steps to take to clarify the main contribution and address the concerns. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically questioning the clarity of the proposed method\\'s novel properties and its applicability. It also raises concerns about the lack of clarity regarding how the method copes with dynamic large-scale multitasking and the achievement of automation. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors can infer that it relates to the introduction or methodology sections, the comment lacks full grounding. It is specific in detailing the issues with the main contribution and the lack of clarity in certain aspects, but without explicit references to sections, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the proposed method\\'s novel properties are either overstated or not well-supported. It also questions the clarity of how the method copes with dynamic large-scale multitasking and achieves automation. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to substantiate the claims. The lack of concrete evidence or references makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but requires more detailed support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several critical issues with the paper, including the unclear main contribution, overstated claims about the proposed method, and a lack of clarity regarding how the method copes with dynamic large-scale multitasking and achieves automation. These are important areas that need to be addressed to improve the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the main contribution, address the overstated claims, or enhance the explanation of the method\\'s capabilities. While it highlights key weaknesses, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance on how to address them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the novelty of the proposed methodology in the context of long document summarization. It questions what the system offers over previous extract-then-generate methodologies and notes the absence of a Related Work section or experiments comparing the proposed model with existing ones. While the comment highlights areas that need attention, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they should include a Related Work section and conduct comparative experiments, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide specific instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the novelty of the proposed methodology in the context of long document summarization, questioning what the system offers over previous extract-then-generate methodologies. It also notes the absence of a Related Work section and experiments comparing the proposed model with existing ones. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections or experiments, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of a Related Work section and comparative experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the novelty of the proposed methodology in the context of long document summarization, questioning what the system offers over previous extract-then-generate methodologies. It also notes the absence of a Related Work section and experiments comparing the proposed model with existing ones. While the comment highlights a potential issue with the paper\\'s originality and suggests that the authors should provide more context or comparisons, it does not provide specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully address the concerns raised. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the novelty of the proposed methodology in the context of long document summarization. It questions what the system offers over previous extract-then-generate methodologies and notes the absence of a Related Work section or experiments comparing the proposed model with existing ones. This feedback is somewhat helpful as it identifies a potential weakness in the paper and suggests that the authors should provide more context or comparisons to establish the novelty of their approach. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of related work that could be included. Overall, the comment provides some direction for improvement but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. While it implies that the authors should consider these alternatives, it does not provide explicit guidance on how to implement them or what specific steps to take. The suggestion is vague and lacks concrete details, making it difficult for the authors to know exactly how to apply the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the need to train multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it does not specify which part of the paper this concern or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative directions for dealing with churn, but without clear references to specific sections or elements of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a subjective opinion about the appeal of training multiple models to test the approach and suggests exploring alternative directions, such as using unlabeled data or constraints. However, it lacks specific reasoning, examples, or references to support the claim that training 30-40 models is not appealing or to substantiate the suggestion of using unlabeled data or constraints. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of training multiple models to test the approach, which could be seen as a limitation. It also suggests exploring alternative directions, such as using unlabeled data or constraints, to improve the stability of the model. While the comment identifies a potential issue and offers a direction for improvement, it lacks specific guidance or examples on how to implement these suggestions. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed actionable steps for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measurement regarding the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors might address this issue. There is no suggestion of what specific measurements could be used or how they might be incorporated into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of quantitative measurement for occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue pertains to, such as a particular section or analysis. This makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique but lacks grounding, as it does not provide a clear reference to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks quantitative measurement, specifically regarding the extent of occupation bias relative to real distributions in society. This is a clear and actionable feedback that highlights a gap in the analysis. However, the comment does not provide suggestions on how the authors might address this issue or propose specific quantitative measurements that could be used. While it points out a significant weakness, it lacks depth and guidance, making it somewhat helpful. The authors are informed of a critical area for improvement but are left to figure out the specifics themselves. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends using the real DICOM image instead of the PNG image for experiment data and suggests the FastMRI challenge dataset as a good choice. It also explicitly states that inference speed should be compared between different methods. These suggestions are clear and direct, providing the authors with specific actions to take to improve their draft. The comment is highly actionable as it gives concrete guidance on what needs to be done and how to implement the changes.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of a real DICOM image instead of a PNG image and suggests the FastMRI challenge dataset. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it provides clear guidance on what needs to be addressed, namely the use of real DICOM images and the comparison of inference speeds between different methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests using a real DICOM image instead of a PNG image for experiment data and recommends the FastMRI challenge dataset. It also advises comparing inference speeds between different methods. While the suggestion to use a real DICOM image is based on common knowledge in medical imaging, the comment lacks specific reasoning or references to support the claim that the FastMRI challenge dataset is a good choice or that inference speed comparison is necessary. This makes the claim somewhat verifiable, as it provides a general direction but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by recommending the use of real DICOM images instead of PNG images for experiment data. It also suggests the FastMRI challenge dataset as a good choice for this purpose. Additionally, the comment advises comparing inference speeds between different methods, which is a valuable suggestion for improving the experimental section of the paper. This feedback is clear and provides concrete guidance for the authors to enhance their work, making it mostly helpful. However, it could be more comprehensive if it included additional suggestions or explanations for implementing these changes. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter, specifically noting that it only offers an empirical conformation estimation. However, the comment does not provide explicit guidance on how to achieve this optimization and validation. The authors are left to infer that they need to conduct additional experiments or analyses to improve the binder design, but without specific instructions on what these experiments should entail or how to validate the results. This lack of concrete guidance makes the action vague and difficult for the authors to implement. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"binder design\" aspect of the paper, specifically mentioning that ProtPainter only provides an empirical conformation estimation. However, it does not specify which part of the paper discusses the binder design, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, but it lacks detailed guidance on how to achieve this. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that ProtPainter only provides an empirical conformation estimation for binder design and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that additional optimization and validation are necessary. Without these elements, the authors may find it challenging to understand the basis of the suggestion or to address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, namely that ProtPainter only provides an empirical conformation estimation for binder design, and suggests that further optimization and validation are required. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work by conducting additional experiments or analyses. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this optimization and validation. Overall, the comment is mostly helpful as it points out a clear area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the scenario where the original CAD model is already associated with spatially-varying (SV) BRDF maps. While it implies that the authors should consider this scenario, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario, but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the scenario where the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry, as it clearly asks for clarification on a particular scenario. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific scenario involving CAD models and spatially-varying BRDF maps. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scenario where the original CAD model is already associated with spatially-varying (SV) BRDF maps. While it identifies a potential area of interest, it lacks depth and does not provide any guidance or suggestions on how the authors might address this scenario or its implications. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about initialization should be more carefully stated, implying that the authors should provide a more detailed explanation or clarification regarding the role of initialization in the context of NGD and NGF. While the comment implies that the authors should revise their statement, it does not provide specific guidance on how to do so or what aspects of the statement need clarification. The action is implicit and somewhat vague, as the authors can infer that they need to revise the statement but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the statement about initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that the statement should be more carefully stated, particularly in relation to the role of initialization in the context of NGD and NGF. The reference to a specific reference [1] Kunstner et al. provides additional context and support for the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that initialization plays a role in the context of NGD and NGF, specifically mentioning that NGD is a discretization of NGF and that solving NGF is an initial value problem (IVP). The reviewer supports this claim by referencing a specific paper by Kunstner et al. (2019), which provides a detailed explanation of the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a robust basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the statement about initialization could be more carefully stated, particularly in the context of NGD and NGF. It provides a reference to a relevant paper by Kunstner et al. (2019), which offers additional context and support for the claim. This feedback is actionable as it directs the authors to reconsider their statement and potentially incorporate more detailed explanations or references. However, the comment could be more helpful if it provided specific suggestions on how to improve the statement or what aspects of the initialization process should be clarified. Overall, the comment is mostly helpful, as it guides the authors toward a more accurate and detailed representation of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first comment raises a concern about the clarity of named entity extraction from the datasets, implying that this aspect needs further explanation or clarification. However, it does not provide specific guidance on how to address this issue, leaving the authors to infer that they should provide more details about the extraction process. The second comment suggests an English proofreading to improve readability, which is a direct and concrete action. However, the first part of the comment is vague and lacks specific guidance, making the overall comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two separate issues: the clarity of named entity extraction from datasets and the need for an English proofreading to improve readability. However, it does not specify which part of the paper discusses named entity extraction, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in suggesting improvements, such as clarifying the extraction process and enhancing readability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim, \"It is not clear how named entities were extracted from the datasets,\" is somewhat verifiable as it highlights a lack of clarity in the paper. However, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The second claim, \"An English-proofreading would significantly improve the readability of the paper,\" is a factual statement and does not require verification. Therefore, the overall comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two separate issues: the lack of clarity regarding the extraction of named entities from datasets and the need for an English proofreading to improve readability. While the comment highlights important areas for improvement, it does not provide specific guidance or suggestions on how the authors might address these issues. For example, it does not offer examples of how to clarify the extraction process or provide tips for improving readability. As a result, the comment is somewhat helpful, as it points out areas that need attention but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide explicit guidance or suggestions on how to address the issue or clarify the confusion. The authors are left to infer that they need to correct the equation and possibly clarify the context, but the comment lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. This provides full grounding as it explicitly mentions the equation, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the equation, indicating that there is a mistake related to the inversion or division of the number of samples. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim of a mistake in the equation. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the inversion of matrix determination versus the division of the number of samples, specifically mentioning a mistake in Equation W4. While it identifies a potential issue, it lacks specificity and does not provide any guidance or suggestions on how the authors might address the problem or clarify the confusion. The comment does not offer actionable feedback or insights that could help the authors improve their draft. As a result, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations for occluded objects and the handling of uncertainty in amodal predictions. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide more detailed information about the motivation and potential applications of their work, as well as how they handle uncertainty. However, the lack of specific guidance makes the action vague, aligning with a score of 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations for occluded objects and the handling of uncertainty in amodal predictions. However, it does not specify which part of the paper discusses the motivation or the potential applications, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique but lacks grounding, as it does not provide explicit references to the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the motivation of the task and the potential downstream applications or benefits of amodal tracking. It questions the quality of annotations for occluded objects and the handling of uncertainty in amodal predictions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a critical concern about the motivation of the task, specifically questioning the clarity of the task's objectives and the potential benefits of amodal tracking. It highlights the difficulty in predicting the state of occluded objects and the challenges in ensuring the quality of annotations. The comment also prompts the authors to consider the potential downstream applications and how uncertainty in amodal predictions might be handled or utilized. While the comment identifies important areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is somewhat helpful as it points out critical issues but could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, a more affordable option compared to GPT-4, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action with concrete details on how to implement it, as it specifies the alternative model to be used and the purpose of the suggestion. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, a more affordable option compared to GPT-4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to these sections, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in suggesting the use of GPT-3.5, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including experiments with GPT-3.5 as a more affordable alternative to GPT-4, implying that this would provide a more comprehensive evaluation of the proposed approach. However, the comment does not provide any reasoning or evidence to support why GPT-3.5 is a suitable or necessary addition. Without specific examples or references to studies that have used GPT-3.5, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including experiments with GPT-3.5, a more affordable option compared to GPT-4, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific suggestion for improving the experimental setup. By incorporating GPT-3.5, the authors can enhance the comprehensiveness of their evaluation, which is a valuable insight for improving the draft. However, the comment could be more helpful if it provided additional context or reasoning for why GPT-3.5 is a better choice or how it would impact the evaluation. Overall, the comment is mostly helpful as it provides a concrete suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential ambiguity in the phrase \"ceterus paribus convexity\" and suggests that the word \"confident\" could be clarified to distinguish between model confidence and human interpretability. The reviewer implies that a slight rephrasing would be beneficial to avoid confusion. While the comment identifies an issue and suggests a possible solution, it does not provide explicit guidance on how to rephrase the sentence. The action is implicit and somewhat vague, as the authors need to infer the exact changes needed to clarify the text. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific phrase, \"ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the ambiguity caused by the word \"confident,\" and suggests that the authors should rephrase it to clarify whether it refers to model confidence or human interpretability. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of the word \"confident\" in the context of \"ceterus paribus convexity,\" suggesting that it may be ambiguous between model confidence and human interpretability. The reviewer provides a logical reasoning by questioning the intended meaning of \"confident\" and suggests that a slight rephrasing would be beneficial to clarify the context. However, the comment does not provide specific examples or references to support the claim of ambiguity, which limits its verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the phrase \"ceterus paribus convexity\" due to the use of the word \"confident,\" which could be interpreted as either model confidence or human interpretability. The reviewer suggests that a slight rephrasing would be beneficial to clarify the intended meaning. This feedback is clear and actionable, as it provides a specific suggestion for improvement that can help the authors enhance the clarity and precision of their text. However, the comment could be more helpful if it offered additional guidance on how to rephrase the sentence or provided examples of alternative phrasing. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement that can enhance the readability and understanding of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of polish in the presentation of figures and empirical results, which affects the clarity and confidence in the empirical findings. It specifically mentions missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small-scale datasets and a single architecture type. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to improve the presentation of their figures and results, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed steps for execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section one\" and \"empirical results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the presentation of figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small-scale datasets and a single architecture type. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks polish in its figures and empirical results, which affects the clarity and confidence in the empirical findings. It provides specific examples, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small-scale datasets and a single architecture type. These examples are detailed and provide a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed guidance on how to address these issues or by referencing similar practices in the field. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a lack of polish in the presentation of figures and empirical results, which affects the clarity and confidence in the empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, and the use of single seed experiments. Additionally, it points out the limited scope of the datasets and architecture types used, which could impact the generalizability of the findings. This feedback is clear and actionable, as it directs the authors to improve the presentation of their results and consider broader datasets and architectures to enhance the validity of their conclusions. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of best practices. Overall, the comment is mostly helpful, as it provides valuable insights for improving the draft but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific changes should be made to the paper. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide any details on what aspects of the paper are being questioned or how the authors might address this issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the choice of metric, specifically asking why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. It lacks specific examples or explanations that would help the authors understand the basis of the question or how it relates to the paper. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metric, specifically questioning why the number of weight updates is considered better than the number of network updates, given that the brain operates in parallel. While it identifies a potential area of confusion or inconsistency in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the real-world scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on how the authors might address this concern or what specific aspects of their work need to be revised. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the real-world scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks grounding as it does not reference a specific section, figure, or table, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the real-world scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the real-world scenarios where the proposed objective, based on adversarial prediction accuracy, differs from classical prediction accuracy. While it identifies a potential area for clarification, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point simply states that the contrastive learning framework is the same as SimCLR, without providing any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this observation or improve their work. As a result, the comment is unactionable, as it does not offer any direction for the authors to enhance their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where this claim is being made. Additionally, the comment lacks specificity regarding what aspects of the framework are identical or how this similarity affects the paper. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without further explanation or context, the authors may find it challenging to understand the basis of this assertion or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment simply states that the contrastive learning framework is the same as SimCLR without providing any context, explanation, or suggestions for improvement. It lacks depth and does not offer any actionable feedback or guidance for the authors to enhance their draft. Without specific details or examples, the comment does not help the authors understand the implications of this observation or how to address it. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could improve their paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method, implying that the authors should provide a more detailed and structured comparison. While the comment is explicit in its suggestion, it lacks concrete guidance on how to implement this improvement, such as suggesting specific metrics or analysis techniques to use. Therefore, the comment is somewhat actionable, as it provides a clear direction for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Originality\" and references the work of Zemel et al. (2013), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons with the related work more systematic by comparing the best performance of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons with the closely related work of Zemel et al. (2013) more systematic. It suggests comparing the best performance of each method, which is a logical and reasonable suggestion. However, the comment does not provide specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. While the suggestion is clear, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by making the comparisons with the closely related work of Zemel et al. (2013) more systematic. It recommends comparing the best performance of each method, which could help the authors to better highlight the original contributions of their work. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and impact of their paper. However, the comment could be more helpful if it included additional guidance on how to structure these comparisons or what specific metrics to use. Overall, the comment is mostly helpful as it provides a valuable direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This provides a clear and direct action for the authors to take, which is to include an explicit estimation of the time complexity in their draft. The comment is specific and concrete, as it clearly instructs the authors on what needs to be done to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the time complexity is discussed. Without explicit references, the authors may find it challenging to identify the exact area needing revision. The comment is specific in its request for estimation of time complexity but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This claim is somewhat verifiable as it provides a logical reasoning for why estimating time complexity is important for assessing scalability. However, the comment lacks specific examples or references to support the claim, which would make it more robust. The authors would need to infer the importance of time complexity estimation based on general knowledge of algorithmic complexity and scalability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove scalability properties. This is a clear and actionable suggestion that can help the authors enhance the rigor and clarity of their work. By addressing this point, the authors can provide a more comprehensive understanding of their algorithm's scalability, which is crucial for readers and potential users. However, the comment could be more helpful if it provided additional guidance on how to estimate the time complexity or examples of similar approaches that have done so. Overall, the comment is mostly helpful as it directs the authors to a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the third point of definition one and properties of universal kernels. It suggests that the authors should consider this connection and references a specific chapter in Steinwart and Christmann that discusses universal kernels. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the connection and possibly incorporate the referenced chapter into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides specific guidance by suggesting a connection to properties of universal kernels and referencing a particular chapter in Steinwart and Christmann. This detailed reference helps the authors understand what needs to be addressed in terms of exploring the connection between the definition and universal kernels. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This reference provides a clear and specific external source that supports the claim, making the comment mostly verifiable. The mention of a specific chapter and the ability of universal kernels to separate an arbitrary finite data set with a margin arbitrarily close to one offers a robust basis for the claim. However, the comment could be more fully verifiable if it included a brief explanation of how this connection might be relevant to the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a specific question about the connection between the third point of definition one and properties of universal kernels. It references a particular chapter in Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite data set with a margin arbitrarily close to one. This feedback is helpful as it prompts the authors to consider a potential link between their work and existing literature, which could enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided a clearer explanation of how this connection might be relevant or suggested specific ways to incorporate this information into the paper. Overall, the comment is mostly helpful, as it offers a valuable direction for further exploration but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
